# Справочник ответов: Техническое интервью по брокерам сообщений

## БЛОК 1: Базовые концепции

### 1. Основы брокеров сообщений

**Вопрос:** Объясните разницу между RabbitMQ, Kafka и NATS с точки зрения архитектуры и use cases.

**Развернутый ответ:**

**RabbitMQ** - традиционный message broker с push-моделью:
- **Архитектура:** Publisher → Exchange → Queue → Consumer
- **Модель:** Push-based (брокер активно отправляет сообщения)
- **Гарантии:** Strong consistency, ACID transactions
- **Use cases:** Request-reply, RPC, complex routing, low-latency messaging

**Apache Kafka** - distributed streaming platform с pull-моделью:
- **Архитектура:** Producer → Topic/Partition → Consumer Group
- **Модель:** Pull-based (consumers запрашивают сообщения)
- **Гарантии:** At-least-once by default, exactly-once при настройке
- **Use cases:** Event streaming, log aggregation, real-time analytics, high-throughput

**NATS** - lightweight cloud-native messaging:
- **Архитектура:** Publisher → Subject → Subscriber
- **Модель:** Fire-and-forget по умолчанию
- **Гарантии:** At-most-once (core NATS), exactly-once (JetStream)
- **Use cases:** Microservices communication, IoT, request-reply с низкой latency

**Сравнительная таблица:**

| Характеристика | RabbitMQ | Kafka | NATS |
|---|---|---|---|
| Throughput | Средний (20K-100K msg/s) | Высокий (100K-1M+ msg/s) | Высокий (10M+ msg/s) |
| Latency | Низкая (< 1ms) | Средняя (5-50ms) | Очень низкая (< 1ms) |
| Persistence | Опциональная | По умолчанию | JetStream only |
| Operational complexity | Средняя | Высокая | Низкая |

```python
# RabbitMQ - Push модель
import pika

connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
channel = connection.channel()

def callback(ch, method, properties, body):
    print(f"Received {body}")
    ch.basic_ack(delivery_tag=method.delivery_tag)

channel.basic_consume(queue='task_queue', on_message_callback=callback)
channel.start_consuming()  # Блокирующий вызов, ждет push от брокера
```

```python
# Kafka - Pull модель
from kafka import KafkaConsumer

consumer = KafkaConsumer(
    'my-topic',
    bootstrap_servers=['localhost:9092'],
    group_id='my-group'
)

for message in consumer:  # Активно запрашивает сообщения
    print(f"Received: {message.value}")
```

### 2. Message delivery semantics

**Вопрос:** Как реализовать exactly-once delivery в distributed системе?

**Развернутый ответ:**

Exactly-once delivery - это одна из самых сложных проблем в distributed systems из-за сетевых сбоев и partial failures.

**Проблема exactly-once:**
- Сетевые таймауты могут привести к дублированию
- Partial failures могут привести к потере сообщений
- Distributed consensus требует координации между компонентами

**Подходы к решению:**

**1. Idempotent Operations (самый практичный):**
```python
# Idempotent consumer с деduplication
import redis

redis_client = redis.Redis()

def process_message(message_id, data):
    # Проверяем, обработали ли уже это сообщение
    if redis_client.get(f"processed:{message_id}"):
        return "already_processed"
    
    try:
        # Бизнес-логика
        result = business_logic(data)
        
        # Атомарно сохраняем результат и mark как processed
        with redis_client.pipeline() as pipe:
            pipe.set(f"result:{message_id}", result)
            pipe.set(f"processed:{message_id}", "1", ex=3600)
            pipe.execute()
            
        return result
    except Exception as e:
        # При ошибке не помечаем как processed
        raise e
```

**2. Transactional Outbox Pattern:**
```python
# Атомарная запись в БД и отправка сообщения
def transfer_money_with_notification(from_account, to_account, amount):
    with database.transaction():
        # 1. Бизнес-операция
        accounts.debit(from_account, amount)
        accounts.credit(to_account, amount)
        
        # 2. Запись в outbox table
        outbox.insert({
            'event_type': 'money_transferred',
            'payload': {'from': from_account, 'to': to_account, 'amount': amount},
            'status': 'pending'
        })
    
    # 3. Отдельный процесс читает outbox и отправляет события
```

**3. Kafka Exactly-Once Semantics:**
```python
from kafka import KafkaProducer, KafkaConsumer

# Producer с idempotence
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    enable_idempotence=True,  # Автоматическая дедупликация
    transactional_id='my-transactional-id'
)

producer.init_transactions()

try:
    producer.begin_transaction()
    producer.send('output-topic', value=processed_data)
    producer.commit_transaction()
except Exception:
    producer.abort_transaction()
```

### 3. Паттерны messaging

**Вопрос:** Опишите реализацию pub-sub и request-reply паттернов.

**Развернутый ответ:**

**Publish-Subscribe Pattern:**

Позволяет one-to-many communication где publishers не знают о конкретных subscribers.

```python
# RabbitMQ Pub-Sub с fanout exchange
import pika

# Publisher
connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
channel = connection.channel()

# Объявляем fanout exchange
channel.exchange_declare(exchange='notifications', exchange_type='fanout')

# Публикуем сообщение (все подписчики получат копию)
channel.basic_publish(
    exchange='notifications',
    routing_key='',  # Игнорируется для fanout
    body='New order created: #12345'
)

# Subscriber
def setup_subscriber(service_name):
    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
    channel = connection.channel()
    
    # Создаем временную queue для этого subscriber
    result = channel.queue_declare(queue='', exclusive=True)
    queue_name = result.method.queue
    
    # Привязываем queue к exchange
    channel.queue_bind(exchange='notifications', queue=queue_name)
    
    def callback(ch, method, properties, body):
        print(f"[{service_name}] Received: {body}")
    
    channel.basic_consume(queue=queue_name, on_message_callback=callback, auto_ack=True)
    return channel

# Каждый сервис создает свой subscriber
email_channel = setup_subscriber("email-service")
sms_channel = setup_subscriber("sms-service")
push_channel = setup_subscriber("push-service")
```

**Request-Reply Pattern:**

Синхронная коммуникация через асинхронные сообщения с correlation ID.

```python
# RabbitMQ Request-Reply
import pika
import uuid
import json

class RPCClient:
    def __init__(self):
        self.connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
        self.channel = self.connection.channel()
        
        # Создаем temporary queue для получения ответов
        result = self.channel.queue_declare(queue='', exclusive=True)
        self.callback_queue = result.method.queue
        self.channel.basic_consume(
            queue=self.callback_queue,
            on_message_callback=self.on_response,
            auto_ack=True
        )
        
        self.response = None
        self.correlation_id = None
    
    def on_response(self, ch, method, props, body):
        if self.correlation_id == props.correlation_id:
            self.response = json.loads(body)
    
    def call(self, request_data):
        self.response = None
        self.correlation_id = str(uuid.uuid4())
        
        # Отправляем request с correlation_id и reply_to
        self.channel.basic_publish(
            exchange='',
            routing_key='rpc_queue',
            properties=pika.BasicProperties(
                reply_to=self.callback_queue,
                correlation_id=self.correlation_id,
            ),
            body=json.dumps(request_data)
        )
        
        # Ждем ответ
        while self.response is None:
            self.connection.process_data_events()
        
        return self.response

# Server
def rpc_server():
    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
    channel = connection.channel()
    channel.queue_declare(queue='rpc_queue')
    
    def process_request(ch, method, props, body):
        request = json.loads(body)
        
        # Обрабатываем запрос
        response = {'result': request['a'] + request['b']}
        
        # Отправляем ответ
        ch.basic_publish(
            exchange='',
            routing_key=props.reply_to,
            properties=pika.BasicProperties(correlation_id=props.correlation_id),
            body=json.dumps(response)
        )
        ch.basic_ack(delivery_tag=method.delivery_tag)
    
    channel.basic_consume(queue='rpc_queue', on_message_callback=process_request)
    channel.start_consuming()

# Использование
client = RPCClient()
result = client.call({'a': 5, 'b': 3})
print(f"Result: {result}")  # {'result': 8}
```

**Load Balancing Consumers:**

```python
# RabbitMQ Work Queue - automatic load balancing
channel.basic_qos(prefetch_count=1)  # Справедливое распределение

# Каждый consumer получает по одному сообщению за раз
# Следующее сообщение отправляется только после ACK предыдущего
```

## БЛОК 2: RabbitMQ

### 4. Архитектура RabbitMQ

**Вопрос:** Объясните путь сообщения от publisher до consumer через exchange и queue.

**Развернутый ответ:**

**Поток сообщения в RabbitMQ:**
1. **Publisher** отправляет сообщение в **Exchange**
2. **Exchange** маршрутизирует сообщение в **Queue(s)** на основе **routing key** и **bindings**
3. **Queue** хранит сообщение до получения **Consumer**'ом
4. **Consumer** получает сообщение и отправляет **acknowledgment**

**Типы Exchange:**

**1. Direct Exchange:**
```python
# Точное совпадение routing key
channel.exchange_declare(exchange='direct_logs', exchange_type='direct')

# Publisher
channel.basic_publish(
    exchange='direct_logs',
    routing_key='error',  # Точное совпадение
    body='Error message'
)

# Binding
channel.queue_bind(
    exchange='direct_logs',
    queue='error_queue',
    routing_key='error'  # Получит только сообщения с routing_key='error'
)
```

**2. Topic Exchange:**
```python
# Pattern matching с wildcards
channel.exchange_declare(exchange='topic_logs', exchange_type='topic')

# Publisher с иерархическими routing keys
channel.basic_publish(exchange='topic_logs', routing_key='payment.credit_card.failed', body='CC payment failed')
channel.basic_publish(exchange='topic_logs', routing_key='payment.bank_transfer.success', body='Bank transfer ok')

# Bindings с patterns
channel.queue_bind(exchange='topic_logs', queue='all_payments', routing_key='payment.*')  # Все платежи
channel.queue_bind(exchange='topic_logs', queue='failures', routing_key='*.*.failed')    # Все ошибки
channel.queue_bind(exchange='topic_logs', queue='cc_only', routing_key='payment.credit_card.*')  # Только CC
```

**3. Fanout Exchange:**
```python
# Broadcast ко всем привязанным queues
channel.exchange_declare(exchange='broadcast', exchange_type='fanout')

# routing_key игнорируется
channel.basic_publish(exchange='broadcast', routing_key='', body='Broadcast message')
```

**Dead Letter Exchange (DLX):**
```python
# Настройка queue с DLX
channel.queue_declare(
    queue='main_queue',
    arguments={
        'x-dead-letter-exchange': 'dlx_exchange',
        'x-dead-letter-routing-key': 'failed',
        'x-message-ttl': 60000,  # 60 секунд TTL
        'x-max-retries': 3
    }
)

# DLX exchange для обработки failed messages
channel.exchange_declare(exchange='dlx_exchange', exchange_type='direct')
channel.queue_declare(queue='dead_letter_queue')
channel.queue_bind(exchange='dlx_exchange', queue='dead_letter_queue', routing_key='failed')
```

**Практический сценарий - Microservices уведомления:**
```python
# Topology для e-commerce уведомлений
def setup_order_notifications():
    channel.exchange_declare(exchange='orders', exchange_type='topic')
    
    # Queues для разных сервисов
    queues = [
        ('payment_queue', 'order.*.payment_required'),
        ('shipping_queue', 'order.*.shipped'),
        ('analytics_queue', 'order.*'),  # Все события заказов
        ('email_queue', 'order.created'),
        ('sms_queue', 'order.urgent.*')
    ]
    
    for queue_name, pattern in queues:
        channel.queue_declare(queue=queue_name, durable=True)
        channel.queue_bind(exchange='orders', queue=queue_name, routing_key=pattern)

# Publisher в Order Service
def publish_order_event(event_type, order_data):
    routing_key = f"order.{order_data['priority']}.{event_type}"
    channel.basic_publish(
        exchange='orders',
        routing_key=routing_key,
        body=json.dumps(order_data),
        properties=pika.BasicProperties(delivery_mode=2)  # Persistent
    )
```

### 5. Production issues

**Вопрос:** Как диагностировать и решить проблему медленной обработки сообщений?

**Развернутый ответ:**

**Key Metrics для диагностики:**
1. **Queue depth** - количество unprocessed сообщений
2. **Consumer utilization** - процент времени активной обработки
3. **Message processing time** - среднее время обработки
4. **Connection count** - количество активных соединений
5. **Memory usage** - использование памяти брокером

```python
# Мониторинг через RabbitMQ Management API
import requests

def get_queue_metrics(queue_name):
    response = requests.get(
        f'http://localhost:15672/api/queues/%2F/{queue_name}',
        auth=('guest', 'guest')
    )
    data = response.json()
    
    metrics = {
        'messages': data['messages'],
        'messages_ready': data['messages_ready'],
        'messages_unacknowledged': data['messages_unacknowledged'],
        'consumers': data['consumers'],
        'message_stats': data.get('message_stats', {})
    }
    
    return metrics

# Алерты на основе метрик
def check_queue_health(queue_name, thresholds):
    metrics = get_queue_metrics(queue_name)
    
    alerts = []
    if metrics['messages_ready'] > thresholds['max_ready']:
        alerts.append(f"High queue depth: {metrics['messages_ready']}")
    
    if metrics['consumers'] == 0:
        alerts.append("No active consumers")
    
    return alerts
```

**Оптимизация Prefetch:**
```python
# Настройка prefetch для optimal performance
def configure_optimal_prefetch(channel, processing_time_ms, target_latency_ms=1000):
    # Формула: prefetch = target_latency / processing_time
    optimal_prefetch = max(1, target_latency_ms // processing_time_ms)
    
    channel.basic_qos(prefetch_count=optimal_prefetch)
    
    print(f"Set prefetch to {optimal_prefetch} based on {processing_time_ms}ms processing time")

# Consumer с метриками
import time

class MetricConsumer:
    def __init__(self):
        self.processing_times = []
        self.last_metrics_report = time.time()
    
    def callback(self, ch, method, properties, body):
        start_time = time.time()
        
        try:
            # Основная логика обработки
            process_message(body)
            
            processing_time = (time.time() - start_time) * 1000
            self.processing_times.append(processing_time)
            
            # Отправляем ACK только после успешной обработки
            ch.basic_ack(delivery_tag=method.delivery_tag)
            
        except Exception as e:
            # Reject с requeue для retry
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
            
        # Периодически отправляем метрики
        if time.time() - self.last_metrics_report > 60:  # Каждую минуту
            self.report_metrics()
    
    def report_metrics(self):
        if self.processing_times:
            avg_time = sum(self.processing_times) / len(self.processing_times)
            print(f"Average processing time: {avg_time:.2f}ms")
            self.processing_times = []
            self.last_metrics_report = time.time()
```

**Troubleshooting Checklist:**
1. **Queue depth растет** → Увеличить consumers или оптимизировать обработку
2. **High memory usage** → Снизить prefetch, включить lazy queues
3. **Connection timeouts** → Увеличить heartbeat, проверить network
4. **Slow publishing** → Использовать connection pooling, async publishing

## БЛОК 3: Apache Kafka

### 6. Kafka fundamentals

**Вопрос:** Объясните архитектуру Kafka: topics, partitions, replicas, ISR.

**Развернутый ответ:**

**Иерархия в Kafka:**
- **Cluster** → **Topics** → **Partitions** → **Messages**
- **Replicas** обеспечивают fault tolerance
- **ISR (In-Sync Replicas)** - реплики, синхронизированные с leader

```python
# Создание topic с правильными настройками
from kafka.admin import KafkaAdminClient, NewTopic

admin_client = KafkaAdminClient(bootstrap_servers=['localhost:9092'])

# Topic для high-throughput с ordering guarantees
user_events_topic = NewTopic(
    name='user-events',
    num_partitions=12,      # Баланс между parallelism и ordering
    replication_factor=3,   # Fault tolerance
    topic_configs={
        'retention.ms': '604800000',        # 7 дней
        'segment.ms': '86400000',           # 24 часа
        'min.insync.replicas': '2',         # Минимум 2 реплики для записи
        'unclean.leader.election.enable': 'false'  # Предотвращает data loss
    }
)

admin_client.create_topics([user_events_topic])
```

**Ordering Guarantees:**
- **Partition level**: строгий порядок внутри partition
- **Topic level**: порядок НЕ гарантируется между partitions
- **Key-based partitioning**: сообщения с одним key попадают в одну partition

```python
# Producer с key-based partitioning
from kafka import KafkaProducer
import json

producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8'),
    key_serializer=lambda k: str(k).encode('utf-8'),
    acks='all',  # Ждем подтверждения от всех ISR
    retries=3,
    batch_size=16384,
    linger_ms=10  # Небольшая задержка для batching
)

# Все события пользователя попадут в одну partition (ordering сохраняется)
def send_user_event(user_id, event_type, data):
    producer.send(
        'user-events',
        key=user_id,  # Partition определяется по hash(key)
        value={
            'user_id': user_id,
            'event_type': event_type,
            'timestamp': time.time(),
            'data': data
        }
    )
```

**Consumer Groups и Rebalancing:**
```python
from kafka import KafkaConsumer

# Consumer group для parallel processing
consumer = KafkaConsumer(
    'user-events',
    bootstrap_servers=['localhost:9092'],
    group_id='analytics-service',
    auto_offset_reset='earliest',
    enable_auto_commit=False,  # Manual commit для exactly-once
    max_poll_records=500,      # Batch size для обработки
    session_timeout_ms=30000,  # Timeout для rebalancing
    heartbeat_interval_ms=10000
)

# Graceful handling rebalancing
def on_assign(consumer, partitions):
    print(f"Partitions assigned: {[p.partition for p in partitions]}")

def on_revoke(consumer, partitions):
    print(f"Partitions revoked: {[p.partition for p in partitions]}")
    # Завершаем обработку текущих сообщений
    consumer.commit()

consumer.subscribe(['user-events'], 
                   on_assign=on_assign, 
                   on_revoke=on_revoke)

# Processing loop с manual commit
def process_messages():
    while True:
        message_batch = consumer.poll(timeout_ms=1000)
        
        for topic_partition, messages in message_batch.items():
            for message in messages:
                try:
                    process_single_message(message.value)
                except Exception as e:
                    # Логируем ошибку, но продолжаем обработку
                    logger.error(f"Failed to process message: {e}")
                
        # Commit offset только после успешной обработки всего batch
        consumer.commit()
```

**ISR и Leader Election:**
```bash
# Мониторинг ISR через kafka-topics
kafka-topics --bootstrap-server localhost:9092 \
             --describe \
             --topic user-events

# Output показывает ISR для каждой partition:
# Topic: user-events	Partition: 0	Leader: 1	Replicas: 1,2,3	Isr: 1,2,3
# Topic: user-events	Partition: 1	Leader: 2	Replicas: 2,3,1	Isr: 2,3
```

**Практический сценарий - 100K events/sec с ordering:**
```python
# Design для high-throughput с user ordering
def design_high_throughput_kafka():
    # 1. Достаточно partitions для parallelism
    # Rule of thumb: (target_throughput / single_consumer_throughput)
    # 100K events/sec, consumer handles 2K/sec → 50 partitions minimum
    
    # 2. Key strategy для ordering
    def partition_key(user_id, event_type):
        # Все события пользователя в одну partition
        return f"user:{user_id}"
    
    # 3. Producer configuration для throughput
    producer_config = {
        'batch_size': 65536,        # Larger batches
        'linger_ms': 50,            # Allow batching
        'compression_type': 'lz4',  # Fast compression
        'buffer_memory': 67108864,  # 64MB buffer
        'max_in_flight_requests_per_connection': 5
    }
    
    # 4. Consumer configuration
    consumer_config = {
        'max_poll_records': 1000,   # Process in batches
        'fetch_min_bytes': 50000,   # Wait for larger fetches
        'fetch_max_wait_ms': 500    # Max wait time
    }
    
    return producer_config, consumer_config
```

### 7. Kafka operations

**Вопрос:** Как обеспечить exactly-once processing в Kafka?

**Развернутый ответ:**

Exactly-once в Kafka достигается комбинацией трех механизмов:
1. **Idempotent Producer** - предотвращает дублирование при retry
2. **Transactional Producer** - атомарные операции записи
3. **Exactly-once Consumer** - isolation уровень для чтения

**Idempotent Producer:**
```python
# Автоматическая дедупликация на уровне producer
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    enable_idempotence=True,    # Ключевая настройка
    acks='all',                 # Требует подтверждения от всех ISR
    retries=2147483647,         # Максимальные retry
    max_in_flight_requests_per_connection=5,  # Ограничение для ordering
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

# Producer автоматически добавляет sequence numbers и producer ID
# Broker отклоняет duplicate messages на основе этих идентификаторов
```

**Transactional Producer:**
```python
# Транзакционный producer для атомарных операций
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    transactional_id='payment-processor-1',  # Уникальный ID для этого producer
    enable_idempotence=True,
    acks='all'
)

# Инициализация транзакций
producer.init_transactions()

def process_payment_with_notifications(payment_data):
    try:
        producer.begin_transaction()
        
        # 1. Публикуем результат обработки платежа
        producer.send('payment-results', 
                     key=payment_data['payment_id'],
                     value={'status': 'completed', 'amount': payment_data['amount']})
        
        # 2. Публикуем уведомление
        producer.send('notifications',
                     key=payment_data['user_id'], 
                     value={'type': 'payment_success', 'payment_id': payment_data['payment_id']})
        
        # 3. Атомарный commit - либо оба сообщения, либо ни одного
        producer.commit_transaction()
        
    except Exception as e:
        producer.abort_transaction()
        raise e
```

**Exactly-Once Consumer с Kafka Streams:**
```python
# Kafka Streams с exactly-once семантикой
from kafka import KafkaConsumer, KafkaProducer
import json

class ExactlyOnceProcessor:
    def __init__(self, input_topic, output_topic, group_id):
        self.input_topic = input_topic
        self.output_topic = output_topic
        
        # Consumer с read_committed isolation
        self.consumer = KafkaConsumer(
            input_topic,
            bootstrap_servers=['localhost:9092'],
            group_id=group_id,
            isolation_level='read_committed',  # Читаем только committed transactions
            enable_auto_commit=False,
            value_deserializer=lambda m: json.loads(m.decode('utf-8'))
        )
        
        # Transactional producer
        self.producer = KafkaProducer(
            bootstrap_servers=['localhost:9092'],
            transactional_id=f'{group_id}-producer',
            enable_idempotence=True,
            acks='all',
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )
        
        self.producer.init_transactions()
    
    def process_stream(self):
        for message in self.consumer:
            try:
                self.producer.begin_transaction()
                
                # Обрабатываем входящее сообщение
                processed_data = self.transform_message(message.value)
                
                # Отправляем результат
                self.producer.send(self.output_topic, 
                                 key=message.key, 
                                 value=processed_data)
                
                # Сохраняем consumer offset в той же транзакции
                self.producer.send_offsets_to_transaction(
                    {TopicPartition(message.topic, message.partition): message.offset + 1},
                    self.consumer.config['group_id']
                )
                
                # Атомарный commit offset + output message
                self.producer.commit_transaction()
                
            except Exception as e:
                self.producer.abort_transaction()
                print(f"Transaction aborted: {e}")
    
    def transform_message(self, data):
        # Бизнес-логика трансформации
        return {
            'processed_at': time.time(),
            'original_data': data,
            'result': data.get('value', 0) * 2
        }
```

**Ограничения Exactly-Once:**
- Работает только для Kafka → Kafka processing
- Требует Kafka 0.11+
- Performance overhead (~20-30%)
- Сложность в настройке и отладке

### 8. Performance & Monitoring

**Вопрос:** Какие key metrics мониторить в production Kafka?

**Развернутый ответ:**

**Критичные метрики по уровням:**

**Broker Level Metrics:**
```python
# JMX метрики через kafka-python
import subprocess
import json

def get_broker_metrics():
    # CPU и Memory
    metrics = {
        'cpu_usage': get_jmx_metric('java.lang:type=OperatingSystem', 'ProcessCpuLoad'),
        'heap_memory': get_jmx_metric('java.lang:type=Memory', 'HeapMemoryUsage'),
        
        # Kafka-specific метрики
        'messages_per_sec': get_jmx_metric('kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec'),
        'bytes_in_per_sec': get_jmx_metric('kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec'),
        'bytes_out_per_sec': get_jmx_metric('kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec'),
        
        # Request метрики
        'request_handler_avg_idle': get_jmx_metric('kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent'),
        'network_processor_avg_idle': get_jmx_metric('kafka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent'),
        
        # Log flush метрики
        'log_flush_rate': get_jmx_metric('kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs')
    }
    
    return metrics

def get_jmx_metric(mbean, attribute):
    # Упрощенный пример получения JMX метрик
    # В реальности используйте jmxtrans, Prometheus JMX exporter, или подобные
    pass
```

**Producer Performance Monitoring:**
```python
class MonitoredProducer:
    def __init__(self, **config):
        self.producer = KafkaProducer(**config)
        self.metrics = {
            'sent_count': 0,
            'failed_count': 0,
            'retry_count': 0,
            'latencies': []
        }
    
    def send_with_monitoring(self, topic, key=None, value=None):
        start_time = time.time()
        
        try:
            future = self.producer.send(topic, key=key, value=value)
            
            # Callback для успешной отправки
            future.add_callback(self._on_send_success, start_time)
            future.add_errback(self._on_send_error)
            
            return future
            
        except Exception as e:
            self.metrics['failed_count'] += 1
            raise e
    
    def _on_send_success(self, metadata, start_time):
        self.metrics['sent_count'] += 1
        latency = (time.time() - start_time) * 1000
        self.metrics['latencies'].append(latency)
        
        # Логируем медленные отправки
        if latency > 100:  # > 100ms
            print(f"Slow send: {latency:.2f}ms to {metadata.topic}:{metadata.partition}")
    
    def _on_send_error(self, exception):
        self.metrics['failed_count'] += 1
        if 'retry' in str(exception).lower():
            self.metrics['retry_count'] += 1
    
    def get_metrics_summary(self):
        if self.metrics['latencies']:
            latencies = sorted(self.metrics['latencies'])
            return {
                'sent_messages': self.metrics['sent_count'],
                'failed_messages': self.metrics['failed_count'],
                'retry_count': self.metrics['retry_count'],
                'avg_latency_ms': sum(latencies) / len(latencies),
                'p95_latency_ms': latencies[int(0.95 * len(latencies))],
                'p99_latency_ms': latencies[int(0.99 * len(latencies))]
            }
        return self.metrics
```

**Consumer Lag Monitoring:**
```python
def monitor_consumer_lag():
    from kafka import KafkaConsumer
    from kafka.structs import TopicPartition
    
    # Административный consumer для получения offsets
    admin_consumer = KafkaConsumer(
        bootstrap_servers=['localhost:9092'],
        group_id=None  # Не входит в consumer group
    )
    
    def get_consumer_lag(group_id, topic):
        # Получаем committed offsets для group
        partitions = admin_consumer.partitions_for_topic(topic)
        topic_partitions = [TopicPartition(topic, p) for p in partitions]
        
        # Committed offsets (где остановился consumer)
        committed = admin_consumer.committed(topic_partitions, group_id)
        
        # Latest offsets (актуальные high water marks)
        latest = admin_consumer.end_offsets(topic_partitions)
        
        lag_info = {}
        total_lag = 0
        
        for tp in topic_partitions:
            committed_offset = committed.get(tp, 0) or 0
            latest_offset = latest[tp]
            lag = latest_offset - committed_offset
            total_lag += lag
            
            lag_info[f"partition_{tp.partition}"] = {
                'committed_offset': committed_offset,
                'latest_offset': latest_offset,
                'lag': lag
            }
        
        lag_info['total_lag'] = total_lag
        return lag_info

# Алерты на основе lag
def check_consumer_health(group_id, topic, max_lag=10000):
    lag_info = get_consumer_lag(group_id, topic)
    
    if lag_info['total_lag'] > max_lag:
        alert = {
            'severity': 'critical' if lag_info['total_lag'] > max_lag * 2 else 'warning',
            'message': f"High consumer lag: {lag_info['total_lag']} messages",
            'group_id': group_id,
            'topic': topic,
            'details': lag_info
        }
        send_alert(alert)
```

**End-to-End Latency Monitoring:**
```python
# Мониторинг полной latency через embedded timestamps
def measure_e2e_latency():
    # Producer добавляет timestamp
    def send_with_timestamp(topic, data):
        message = {
            'timestamp': time.time() * 1000,  # milliseconds
            'data': data
        }
        producer.send(topic, value=message)
    
    # Consumer измеряет latency
    def consume_with_latency_tracking():
        for message in consumer:
            received_time = time.time() * 1000
            sent_time = message.value.get('timestamp', received_time)
            
            e2e_latency = received_time - sent_time
            
            # Метрика для мониторинга
            latency_histogram.observe(e2e_latency)
            
            if e2e_latency > 1000:  # > 1 секунды
                print(f"High E2E latency: {e2e_latency:.2f}ms")
```

**Ключевые алерты для production:**
1. **Consumer lag > 10K messages** (warning) / **> 50K** (critical)
2. **Broker CPU > 80%** или **Memory > 85%**
3. **Request handler idle < 30%** (broker перегружен)
4. **P99 latency > 100ms** для producer
5. **ISR shrinks** (реплики отстают)
6. **Under-replicated partitions > 0**

## БЛОК 4: NATS

### 9. NATS особенности

**Вопрос:** В чем принципиальные отличия NATS от традиционных брокеров?

**Развернутый ответ:**

**Философия NATS - "Fire and Forget":**
В отличие от традиционных брокеров (RabbitMQ, Kafka), NATS изначально создавался для максимальной простоты и performance, жертвуя некоторыми гарантиями.

**Ключевые отличия:**

**1. Subject-Based Routing vs Queue-Based:**
```python
import asyncio
import nats

# NATS использует hierarchical subjects вместо queues
async def nats_example():
    nc = await nats.connect("nats://localhost:4222")
    
    # Subject hierarchy - естественное дерево маршрутизации
    await nc.publish("orders.created.premium", b"Order #12345")
    await nc.publish("orders.updated.standard", b"Order #12346") 
    await nc.publish("users.login.mobile", b"User login from mobile")
    
    # Wildcards для subscription
    await nc.subscribe("orders.*", callback=handle_all_orders)
    await nc.subscribe("orders.created.*", callback=handle_new_orders)
    await nc.subscribe("*.*.mobile", callback=handle_mobile_events)
```

**2. Core NATS - At-Most-Once vs At-Least-Once:**
```python
# Core NATS - максимальная скорость, минимальные гарантии
async def core_nats_publisher():
    nc = await nats.connect()
    
    # Отправляем и забываем - никаких гарантий доставки
    await nc.publish("fast.events", b"High frequency data")
    
    # Если нет subscribers - сообщение теряется
    # Если subscriber медленный - сообщения могут отбрасываться

# Отличие от RabbitMQ/Kafka:
# - Нет persistence по умолчанию
# - Нет acknowledgments
# - Нет retries
# - Максимальная latency < 1ms
```

**3. JetStream - Persistence Layer:**
```python
# JetStream добавляет persistence и гарантии поверх core NATS
async def jetstream_example():
    nc = await nats.connect()
    js = nc.jetstream()
    
    # Создаем stream для persistent storage
    await js.add_stream(name="ORDERS", subjects=["orders.*"])
    
    # Publish с acknowledgment
    ack = await js.publish("orders.created", b"Order data")
    print(f"Message stored at sequence: {ack.seq}")
    
    # Pull subscriber с manual ack
    psub = await js.pull_subscribe("orders.*", "order-processors")
    
    while True:
        msgs = await psub.fetch(10, timeout=1)
        for msg in msgs:
            # Обрабатываем сообщение
            process_order(msg.data)
            # Подтверждаем обработку
            await msg.ack()
```

**4. Request-Reply Pattern - First-Class Citizen:**
```python
# NATS request-reply значительно проще чем в RabbitMQ
async def nats_request_reply():
    nc = await nats.connect()
    
    # Server
    async def request_handler(msg):
        request_data = json.loads(msg.data)
        response = {"result": request_data["a"] + request_data["b"]}
        await msg.respond(json.dumps(response).encode())
    
    await nc.subscribe("math.add", cb=request_handler)
    
    # Client - простой request/response
    response = await nc.request("math.add", 
                               json.dumps({"a": 5, "b": 3}).encode(),
                               timeout=1.0)
    
    result = json.loads(response.data)
    print(f"Result: {result}")  # {"result": 8}
```

**5. Leaf Nodes и Super Clusters:**
```python
# NATS поддерживает уникальную топологию для edge computing
# Leaf nodes автоматически подключаются к кластеру

# Конфигурация leaf node для edge location
leaf_node_config = """
port: 4222
leafnodes {
    remotes = [
        {
            url: "nats-leaf://central-cluster:7422"
            account: "edge-account"
        }
    ]
}
"""

# Edge devices подключаются к локальному leaf node
# Сообщения автоматически маршрутизируются в центральный кластер
```

### 10. NATS use cases

**Вопрос:** Когда NATS предпочтительнее RabbitMQ или Kafka?

**Развернутый ответ:**

**Идеальные сценарии для NATS:**

**1. Microservices Request-Reply Communication:**
```python
# Простая service discovery и load balancing
async def setup_microservice_mesh():
    nc = await nats.connect()
    
    # Service registry через subjects
    services = {
        "user-service": ["user.get", "user.create", "user.update"],
        "payment-service": ["payment.process", "payment.verify"],
        "inventory-service": ["inventory.check", "inventory.reserve"]
    }
    
    # Автоматический load balancing между instances
    async def user_service_handler(msg):
        # Обрабатываем запрос
        await msg.respond(b"User data")
    
    # Несколько instances одного сервиса автоматически load balance
    await nc.subscribe("user.get", cb=user_service_handler, queue="user-service")
    await nc.subscribe("user.get", cb=user_service_handler, queue="user-service")
    await nc.subscribe("user.get", cb=user_service_handler, queue="user-service")

# API Gateway делает requests к services
async def api_gateway():
    nc = await nats.connect()
    
    # Request автоматически load-balances между доступными instances
    user_data = await nc.request("user.get", b"user_id:123", timeout=2.0)
    payment_result = await nc.request("payment.process", b"payment_data", timeout=5.0)
```

**2. IoT и High-Frequency Data:**
```python
# Сбор telemetry с множества устройств
async def iot_telemetry_collector():
    nc = await nats.connect()
    
    # Subjects для разных типов устройств и метрик
    subjects = [
        "sensors.temperature.*",
        "sensors.humidity.*", 
        "sensors.pressure.*",
        "devices.status.*"
    ]
    
    # High-throughput subscriber
    async def telemetry_handler(msg):
        # Minimal processing - store in time-series DB
        timestamp = time.time()
        device_id = msg.subject.split('.')[-1]
        metric_type = msg.subject.split('.')[1]
        
        # Async write to InfluxDB/TimescaleDB
        await store_metric(device_id, metric_type, msg.data, timestamp)
    
    for subject in subjects:
        await nc.subscribe(subject, cb=telemetry_handler)

# Device publishing telemetry
async def iot_device_publisher(device_id):
    nc = await nats.connect()
    
    while True:
        # Простая отправка без ack - максимальная скорость
        temperature = read_temperature_sensor()
        await nc.publish(f"sensors.temperature.{device_id}", 
                        json.dumps({"value": temperature, "timestamp": time.time()}).encode())
        
        await asyncio.sleep(1)  # 1 Hz
```

**3. Event-Driven Architecture с Low Latency:**
```python
# Real-time notifications system
async def realtime_notifications():
    nc = await nats.connect()
    
    # Пользователи подписываются на свои уведомления
    user_connections = {}
    
    async def user_notification_handler(msg):
        subject_parts = msg.subject.split('.')
        user_id = subject_parts[-1]
        
        # Отправляем через WebSocket если пользователь онлайн
        if user_id in user_connections:
            await user_connections[user_id].send(msg.data)
    
    # Subscribe на все уведомления пользователей
    await nc.subscribe("notifications.user.*", cb=user_notification_handler)
    
    # Service публикует уведомления
    async def send_notification(user_id, notification_type, data):
        await nc.publish(f"notifications.user.{user_id}", 
                        json.dumps({
                            "type": notification_type,
                            "data": data,
                            "timestamp": time.time()
                        }).encode())

# Latency < 1ms для local delivery
```

**4. Edge Computing и Distributed Systems:**
```python
# Multi-region deployment с автоматической топологией
async def edge_architecture():
    # Central cluster configuration
    central_config = """
    cluster {
        name: "central"
        listen: "0.0.0.0:6222"
        routes = [
            "nats://region-us:6222"
            "nats://region-eu:6222"
            "nats://region-asia:6222"
        ]
    }
    
    leafnodes {
        listen: "0.0.0.0:7422"
    }
    """
    
    # Edge locations автоматически подключаются
    edge_config = """
    leafnodes {
        remotes = [
            { url: "nats-leaf://central-cluster:7422" }
        ]
    }
    """
    
    # Messages автоматически маршрутизируются между регионами
    # Локальные subscribers получают приоритет
```

**Сравнение Use Cases:**

| Сценарий | NATS | RabbitMQ | Kafka |
|---|---|---|---|
| Request-Reply RPC | ✅ Идеально | ⚠️ Сложно | ❌ Не подходит |
| Low latency (< 1ms) | ✅ Да | ⚠️ 1-5ms | ❌ 5-50ms |
| IoT telemetry | ✅ Отлично | ⚠️ Ограничено | ✅ Хорошо |
| Event sourcing | ❌ JetStream only | ⚠️ Ограничено | ✅ Идеально |
| Audit trails | ❌ | ⚠️ Да | ✅ Да |
| Complex routing | ⚠️ Subject wildcards | ✅ Exchange types | ❌ |
| High throughput | ✅ 10M+ msg/s | ⚠️ 100K msg/s | ✅ 1M+ msg/s |
| Operational simplicity | ✅ Минимальная | ⚠️ Средняя | ❌ Высокая |

**Persistence в NATS JetStream:**
```python
# JetStream для scenarios требующих persistence
async def jetstream_persistence():
    nc = await nats.connect()
    js = nc.jetstream()
    
    # Stream с retention policies
    await js.add_stream(
        name="AUDIT_LOGS",
        subjects=["audit.*"],
        retention="limits",  # or "interest", "workqueue"
        max_msgs=1000000,
        max_age=30 * 24 * 3600,  # 30 days
        storage="file"  # or "memory"
    )
    
    # Durable consumer для guaranteed processing
    await js.add_consumer(
        stream="AUDIT_LOGS",
        config=nats.js.api.ConsumerConfig(
            durable_name="audit-processor",
            deliver_policy="all",
            ack_policy="explicit",
            max_deliver=3  # retry limit
        )
    )
```

NATS лучше выбирать когда:
- **Latency критична** (< 1ms)
- **Простота операций** важнее сложных гарантий
- **Request-reply** - основной паттерн
- **Cloud-native / K8s** environment
- **IoT** с high frequency data
- **Microservices** mesh communication

## Продолжение следует...

*Это первая часть справочника. Следующие блоки будут включать архитектурные решения, сравнительный анализ, troubleshooting сценарии и практические кейсы.*