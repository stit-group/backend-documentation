# ğŸš€ Ğ‘Ğ»Ğ¾Ğº 5: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğµ Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸

---

**â± Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 7-9 Ğ½ĞµĞ´ĞµĞ»ÑŒ  
**ğŸ¯ Ğ¦ĞµĞ»ÑŒ:** ĞÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹  
**ğŸ“Š Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸:** â˜…â˜…â˜…â˜…â˜†

---

## ğŸ“‹ ĞĞ±Ğ·Ğ¾Ñ€ Ğ±Ğ»Ğ¾ĞºĞ°

```
Ğ‘Ğ»Ğ¾Ğº 5: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”œâ”€â”€ ğŸ“– Ğ“Ğ»Ğ°Ğ²Ğ° 5.1: ĞĞ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹ (1 Ğ½ĞµĞ´ĞµĞ»Ñ)
â”œâ”€â”€ ğŸ¨ Ğ“Ğ»Ğ°Ğ²Ğ° 5.2: Ğ’Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹ (VAE) (1-2 Ğ½ĞµĞ´ĞµĞ»Ğ¸)  
â”œâ”€â”€ âš”ï¸ Ğ“Ğ»Ğ°Ğ²Ğ° 5.3: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾-ÑĞ¾ÑÑ‚ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑĞµÑ‚Ğ¸ (GAN) (2 Ğ½ĞµĞ´ĞµĞ»Ğ¸)
â”œâ”€â”€ ğŸŒŠ Ğ“Ğ»Ğ°Ğ²Ğ° 5.4: Ğ”Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (1-2 Ğ½ĞµĞ´ĞµĞ»Ğ¸)
â”œâ”€â”€ ğŸ® Ğ“Ğ»Ğ°Ğ²Ğ° 5.5: Reinforcement Learning Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹ (1 Ğ½ĞµĞ´ĞµĞ»Ñ)
â”œâ”€â”€ ğŸ§  Ğ“Ğ»Ğ°Ğ²Ğ° 5.6: Meta-learning Ğ¸ Few-shot learning (1 Ğ½ĞµĞ´ĞµĞ»Ñ)
â””â”€â”€ ğŸ”— Ğ“Ğ»Ğ°Ğ²Ğ° 5.7: Multimodal Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (1 Ğ½ĞµĞ´ĞµĞ»Ñ)
```

---

## ğŸ“– Ğ“Ğ»Ğ°Ğ²Ğ° 5.1: ĞĞ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹
**â± Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 1 Ğ½ĞµĞ´ĞµĞ»Ñ

### ğŸ¯ Ğ¦ĞµĞ»Ğ¸ Ğ³Ğ»Ğ°Ğ²Ñ‹
- ĞŸĞ¾Ğ½ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ¾Ğ²
- Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ¾Ğ²
- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€ Ğ´Ğ»Ñ ÑĞ¶Ğ°Ñ‚Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

### ğŸ“š Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€?

```
Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (X) â†’ [Ğ­Ğ½ĞºĞ¾Ğ´ĞµÑ€] â†’ Ğ›Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ¾ (Z) â†’ [Ğ”ĞµĞºĞ¾Ğ´ĞµÑ€] â†’ Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (X')
```

**ĞĞ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€** - ÑÑ‚Ğ¾ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ ÑĞµÑ‚ÑŒ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ ÑƒÑ‡Ğ¸Ñ‚ÑÑ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ² ÑĞ¶Ğ°Ñ‚Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ (Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ¾), Ğ° Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ñ… Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾.

#### ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ°

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚                    ĞĞ’Ğ¢ĞĞ­ĞĞšĞĞ”Ğ•Ğ                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        Ğ­ĞĞšĞĞ”Ğ•Ğ           â”‚          Ğ”Ğ•ĞšĞĞ”Ğ•Ğ                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         â”‚                                 â”‚
â”‚  Input (784)            â”‚              Output (784)       â”‚
â”‚     â†“                   â”‚                 â†‘               â”‚
â”‚  Hidden (512)           â”‚              Hidden (512)       â”‚
â”‚     â†“                   â”‚                 â†‘               â”‚
â”‚  Hidden (256)           â”‚              Hidden (256)       â”‚
â”‚     â†“                   â”‚                 â†‘               â”‚
â”‚  Latent (32) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Latent (32)     â”‚
â”‚                         â”‚                                 â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

#### Ğ¢Ğ¸Ğ¿Ñ‹ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ¾Ğ²

##### 1. **ĞšĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€**
```python
# ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°
Input â†’ Dense(512) â†’ Dense(256) â†’ Dense(32) â†’ Dense(256) â†’ Dense(512) â†’ Output
```

##### 2. **Denoising Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€**
```
Ğ§Ğ¸ÑÑ‚Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ â†’ [Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑˆÑƒĞ¼Ğ°] â†’ Ğ—Ğ°ÑˆÑƒĞ¼Ğ»ĞµĞ½Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ â†’ [ĞĞ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€] â†’ Ğ§Ğ¸ÑÑ‚Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
```

##### 3. **Sparse Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€**
```
ĞĞ±Ñ‹Ñ‡Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ + L1 Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°
Loss = Reconstruction_Loss + Î» * ||z||â‚
```

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 1: Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ°

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
import matplotlib.pyplot as plt

class Autoencoder(nn.Module):
    def __init__(self, input_dim=784, hidden_dims=[512, 256], latent_dim=32):
        super(Autoencoder, self).__init__()
        
        # Ğ­Ğ½ĞºĞ¾Ğ´ĞµÑ€
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dims[0]),
            nn.ReLU(),
            nn.Linear(hidden_dims[0], hidden_dims[1]),
            nn.ReLU(),
            nn.Linear(hidden_dims[1], latent_dim)
        )
        
        # Ğ”ĞµĞºĞ¾Ğ´ĞµÑ€
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dims[1]),
            nn.ReLU(),
            nn.Linear(hidden_dims[1], hidden_dims[0]),
            nn.ReLU(),
            nn.Linear(hidden_dims[0], input_dim),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded
```

#### Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 2: Denoising Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€

```python
def add_noise(data, noise_factor=0.3):
    """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ³Ğ°ÑƒÑÑĞ¾Ğ²ÑĞºĞ¸Ğ¹ ÑˆÑƒĞ¼ Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼"""
    noise = torch.randn_like(data) * noise_factor
    noisy_data = data + noise
    return torch.clamp(noisy_data, 0., 1.)

# Ğ¢Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ñ Ğ·Ğ°ÑˆÑƒĞ¼Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸
for epoch in range(num_epochs):
    for batch_idx, (data, _) in enumerate(train_loader):
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑˆÑƒĞ¼
        noisy_data = add_noise(data.view(-1, 784))
        clean_data = data.view(-1, 784)
        
        # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
        optimizer.zero_grad()
        reconstructed = model(noisy_data)
        loss = criterion(reconstructed, clean_data)  # Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ Ñ‡Ğ¸ÑÑ‚Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸!
        loss.backward()
        optimizer.step()
```

### ğŸ“Š Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²

```
ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ:
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚  ğŸ”¢  â”‚  ğŸ”¢  â”‚  ğŸ”¢  â”‚  ğŸ”¢  â”‚  ğŸ”¢  â”‚
â”‚  3   â”‚  7   â”‚  2   â”‚  1   â”‚  0   â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ:
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚  ğŸ”¢  â”‚  ğŸ”¢  â”‚  ğŸ”¢  â”‚  ğŸ”¢  â”‚  ğŸ”¢  â”‚
â”‚  3   â”‚  7   â”‚  2   â”‚  1   â”‚  0   â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ: 95.2%
```

### ğŸ† ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- âœ… Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ° Ñ Ğ½ÑƒĞ»Ñ
- âœ… Ğ¡Ğ¶Ğ°Ñ‚Ğ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ MNIST Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ¼Ğ¸ <5%
- âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ denoising Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ°
- âœ… Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°

---

## ğŸ¨ Ğ“Ğ»Ğ°Ğ²Ğ° 5.2: Ğ’Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹ (VAE)
**â± Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 1-2 Ğ½ĞµĞ´ĞµĞ»Ğ¸

### ğŸ¯ Ğ¦ĞµĞ»Ğ¸ Ğ³Ğ»Ğ°Ğ²Ñ‹
- ĞŸĞ¾Ğ½ÑÑ‚ÑŒ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹ VAE
- Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ reparameterization trick
- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ VAE Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

### ğŸ“š Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ñ VAE Ğ¾Ñ‚ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ°

```
ĞĞ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€:
Input â†’ Encoder â†’ z (Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹) â†’ Decoder â†’ Output

VAE:
Input â†’ Encoder â†’ Î¼, Ïƒ â†’ z ~ N(Î¼, Ïƒ) â†’ Decoder â†’ Output
                     â†‘
              (ÑÑ‚Ğ¾Ñ…Ğ°ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹)
```

#### ĞœĞ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹

**Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ VAE:**
```
L = E[log p(x|z)] - KL(q(z|x) || p(z))
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Reconstruction Loss    Regularization
```

**KL-Ğ´Ğ¸Ğ²ĞµÑ€Ğ³ĞµĞ½Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ:**
```
KL(N(Î¼,Ïƒ) || N(0,1)) = Â½ * Î£(Î¼Â² + ÏƒÂ² - log(ÏƒÂ²) - 1)
```

#### Reparameterization trick

```
ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: z ~ N(Î¼, Ïƒ) - Ğ½Ğµ Ğ´Ğ¸Ñ„Ñ„ĞµÑ€ĞµĞ½Ñ†Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾
                 â†“
Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ: z = Î¼ + Ïƒ * Îµ, Ğ³Ğ´Ğµ Îµ ~ N(0,1)
```

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ VAE

```python
class VAE(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=512, latent_dim=32):
        super(VAE, self).__init__()
        
        # Ğ­Ğ½ĞºĞ¾Ğ´ĞµÑ€
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU()
        )
        
        # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)
        
        # Ğ”ĞµĞºĞ¾Ğ´ĞµÑ€
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim),
            nn.Sigmoid()
        )
    
    def encode(self, x):
        h = self.encoder(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        z = mu + eps * std
        return z
    
    def decode(self, z):
        return self.decoder(z)
    
    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        recon_x = self.decode(z)
        return recon_x, mu, logvar

def vae_loss(recon_x, x, mu, logvar, beta=1.0):
    """VAE Loss = Reconstruction Loss + Î² * KL Divergence"""
    recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')
    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return recon_loss + beta * kl_loss
```

### ğŸ“Š Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

```python
def generate_samples(model, num_samples=16):
    """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ñ‹ Ğ¸Ğ· VAE"""
    with torch.no_grad():
        # Ğ¡ÑĞ¼Ğ¿Ğ»Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ· prior Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ
        z = torch.randn(num_samples, latent_dim)
        generated = model.decode(z)
        return generated
```

### ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°

```
Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ° VAE:

        zâ‚‚
         â†‘
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
    â”‚ ğŸ”¢ â”‚ ğŸ”¢ â”‚
    â”‚ 1  â”‚ 7  â”‚
â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â†’ zâ‚
    â”‚ ğŸ”¢ â”‚ ğŸ”¢ â”‚
    â”‚ 0  â”‚ 2  â”‚
    â””â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”˜
         
Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ‚Ğ¾Ñ‡ĞºĞ°Ğ¼Ğ¸:
ğŸ”¢ â†’ ğŸ”¢ â†’ ğŸ”¢ â†’ ğŸ”¢ â†’ ğŸ”¢
1   1.5   ?   8.5   8
```

### ğŸ† ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- âœ… Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ VAE Ñ Ğ½ÑƒĞ»Ñ
- âœ… Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
- âœ… Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ
- âœ… ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Î²-VAE Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ñ disentanglement

---

## âš”ï¸ Ğ“Ğ»Ğ°Ğ²Ğ° 5.3: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾-ÑĞ¾ÑÑ‚ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑĞµÑ‚Ğ¸ (GAN)
**â± Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 2 Ğ½ĞµĞ´ĞµĞ»Ğ¸

### ğŸ¯ Ğ¦ĞµĞ»Ğ¸ Ğ³Ğ»Ğ°Ğ²Ñ‹
- ĞŸĞ¾Ğ½ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹ adversarial training
- Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ GAN
- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ GAN Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹

### ğŸ“š Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ GAN

```
                    Ğ“Ğ•ĞĞ•Ğ ĞĞ¢Ğ˜Ğ’ĞĞ-Ğ¡ĞĞ¡Ğ¢Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞĞ¯ Ğ¡Ğ•Ğ¢Ğ¬
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚                    â”‚                 â”‚
    â”‚   Ğ“Ğ•ĞĞ•Ğ ĞĞ¢ĞĞ      â”‚                    â”‚ Ğ”Ğ˜Ğ¡ĞšĞ Ğ˜ĞœĞ˜ĞĞĞ¢ĞĞ    â”‚
    â”‚       G         â”‚                    â”‚       D         â”‚
    â”‚                 â”‚                    â”‚                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†‘                                      â†‘
            â”‚                                      â”‚
      Ğ¡Ğ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼                         Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ + Ğ¤Ğ°Ğ»ÑŒÑˆĞ¸Ğ²Ñ‹Ğµ
         z ~ N(0,1)                              Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
            â”‚                                      â”‚
            â†“                                      â†“
      Ğ¤Ğ°Ğ»ÑŒÑˆĞ¸Ğ²Ñ‹Ğµ                              Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ
      Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ                          "Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸"
        G(z)                                   D(x)
```

#### Ğ˜Ğ³Ñ€Ğ° Ñ Ğ½ÑƒĞ»ĞµĞ²Ğ¾Ğ¹ ÑÑƒĞ¼Ğ¼Ğ¾Ğ¹

```
Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ (G):  ĞœĞ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚  log(D(G(z)))
Ğ”Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€ (D): ĞœĞ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚  log(D(x)) + log(1 - D(G(z)))

ĞĞ±Ñ‰Ğ°Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°:  min max V(D,G) = E[log D(x)] + E[log(1 - D(G(z)))]
                G   D
```

#### ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ GAN

```
ğŸš¨ ĞĞ¡ĞĞĞ’ĞĞ«Ğ• ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ«:

1. Mode Collapse
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Ğ’ÑĞµ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµâ”‚
   â”‚ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ñ‹ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸  â”‚ 
   â”‚ ğŸ”¢ ğŸ”¢ ğŸ”¢ ğŸ”¢     â”‚
   â”‚ 3  3  3  3      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. Training Instability
   Loss G â†—ï¸â†˜ï¸â†—ï¸â†˜ï¸â†—ï¸
   Loss D â†˜ï¸â†—ï¸â†˜ï¸â†—ï¸â†˜ï¸

3. Vanishing Gradients
   D ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ñ…Ğ¾Ñ€Ğ¾Ñˆ â†’ G Ğ½Ğµ Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ
```

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ DCGAN

```python
class Generator(nn.Module):
    def __init__(self, latent_dim=100, img_channels=1, img_size=28):
        super(Generator, self).__init__()
        
        self.init_size = img_size // 4
        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))
        
        self.conv_blocks = nn.Sequential(
            nn.BatchNorm2d(128),
            nn.Upsample(scale_factor=2),
            nn.Conv2d(128, 128, 3, stride=1, padding=1),
            nn.BatchNorm2d(128, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Upsample(scale_factor=2),
            nn.Conv2d(128, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64, 0.8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, img_channels, 3, stride=1, padding=1),
            nn.Tanh()
        )
    
    def forward(self, z):
        out = self.l1(z)
        out = out.view(out.shape[0], 128, self.init_size, self.init_size)
        img = self.conv_blocks(out)
        return img

class Discriminator(nn.Module):
    def __init__(self, img_channels=1, img_size=28):
        super(Discriminator, self).__init__()
        
        def discriminator_block(in_filters, out_filters, bn=True):
            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]
            if bn:
                block.append(nn.BatchNorm2d(out_filters, 0.8))
            return block
        
        self.model = nn.Sequential(
            *discriminator_block(img_channels, 16, bn=False),
            *discriminator_block(16, 32),
            *discriminator_block(32, 64),
            *discriminator_block(64, 128),
        )
        
        ds_size = img_size // 2 ** 4
        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())
    
    def forward(self, img):
        out = self.model(img)
        out = out.view(out.shape[0], -1)
        validity = self.adv_layer(out)
        return validity
```

#### Ğ¦Ğ¸ĞºĞ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ GAN

```python
def train_gan(generator, discriminator, dataloader, num_epochs=100):
    
    # ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ñ‹
    opt_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
    opt_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))
    
    criterion = nn.BCELoss()
    
    for epoch in range(num_epochs):
        for i, (real_imgs, _) in enumerate(dataloader):
            
            # ĞœĞµÑ‚ĞºĞ¸
            valid = torch.ones(real_imgs.size(0), 1, requires_grad=False)
            fake = torch.zeros(real_imgs.size(0), 1, requires_grad=False)
            
            # -----------------
            #  ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Generator
            # -----------------
            
            opt_G.zero_grad()
            
            # Ğ¡ÑĞ¼Ğ¿Ğ»Ğ¸Ñ€ÑƒĞµĞ¼ ÑˆÑƒĞ¼
            z = torch.randn(real_imgs.size(0), latent_dim)
            
            # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
            gen_imgs = generator(z)
            
            # ĞŸĞ¾Ñ‚ĞµÑ€Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
            g_loss = criterion(discriminator(gen_imgs), valid)
            
            g_loss.backward()
            opt_G.step()
            
            # ---------------------
            #  ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Discriminator
            # ---------------------
            
            opt_D.zero_grad()
            
            # ĞŸĞ¾Ñ‚ĞµÑ€Ñ Ğ½Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑÑ…
            real_loss = criterion(discriminator(real_imgs), valid)
            
            # ĞŸĞ¾Ñ‚ĞµÑ€Ñ Ğ½Ğ° Ñ„Ğ°Ğ»ÑŒÑˆĞ¸Ğ²Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑÑ…
            fake_loss = criterion(discriminator(gen_imgs.detach()), fake)
            
            # ĞĞ±Ñ‰Ğ°Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€Ñ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ°
            d_loss = (real_loss + fake_loss) / 2
            
            d_loss.backward()
            opt_D.step()
            
            # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
            if i % 100 == 0:
                print(f"Epoch {epoch}, Batch {i}, G_loss: {g_loss.item():.4f}, D_loss: {d_loss.item():.4f}")
```

### ğŸ“Š Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğµ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ GAN

#### StyleGAN ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ

```
    Ğ¢Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ GAN:
    z â†’ Generator â†’ Image
    
    StyleGAN:
    z â†’ Mapping Network â†’ w
    Noise â†’ AdaIN(w) â†’ Progressive Generation â†’ High-Res Image
```

#### CycleGAN Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹

```
    Ğ”Ğ¾Ğ¼ĞµĞ½ A â†â†’ Ğ”Ğ¾Ğ¼ĞµĞ½ B
    
    ğŸ´ â”€â”€â”€â”€â†’ ğŸ¦“
    â”‚  G_AB  â”‚
    â”‚        â”‚
    â”‚  G_BA  â”‚
    ğŸ¦“ â†â”€â”€â”€â”€ ğŸ´
    
    Cycle Consistency: G_BA(G_AB(x)) â‰ˆ x
```

### ğŸ† ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- âœ… Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ DCGAN Ñ Ğ½ÑƒĞ»Ñ
- âœ… Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ»Ğ¸Ñ†
- âœ… ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ GAN
- âœ… Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°Ğ¼Ğ¸

---

## ğŸŒŠ Ğ“Ğ»Ğ°Ğ²Ğ° 5.4: Ğ”Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
**â± Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 1-2 Ğ½ĞµĞ´ĞµĞ»Ğ¸

### ğŸ¯ Ğ¦ĞµĞ»Ğ¸ Ğ³Ğ»Ğ°Ğ²Ñ‹
- ĞŸĞ¾Ğ½ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ²
- Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ DDPM (Denoising Diffusion Probabilistic Models)
- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚ÑƒÑ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ

### ğŸ“š Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸

```
ĞŸĞ Ğ¯ĞœĞĞ™ ĞŸĞ ĞĞ¦Ğ•Ğ¡Ğ¡ (Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑˆÑƒĞ¼Ğ°):
xâ‚€ â†’ xâ‚ â†’ xâ‚‚ â†’ xâ‚ƒ â†’ ... â†’ xâ‚œ â†’ ... â†’ xâ‚œâ‚‹â‚ â†’ xâ‚œ (Ñ‡Ğ¸ÑÑ‚Ñ‹Ğ¹ ÑˆÑƒĞ¼)
ğŸ–¼ï¸   ğŸ“¸   ğŸ“·   ğŸ“¹         ğŸŒ«ï¸         âšª    âš«

ĞĞ‘Ğ ĞĞ¢ĞĞ«Ğ™ ĞŸĞ ĞĞ¦Ğ•Ğ¡Ğ¡ (ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑˆÑƒĞ¼Ğ°):
xâ‚œ â†’ xâ‚œâ‚‹â‚ â†’ xâ‚œâ‚‹â‚‚ â†’ ... â†’ xâ‚ â†’ xâ‚€
âš«    âšª    ğŸŒ«ï¸       ğŸ“·  ğŸ–¼ï¸

ĞœĞ¾Ğ´ĞµĞ»ÑŒ ÑƒÑ‡Ğ¸Ñ‚ÑÑ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑƒ!
```

#### ĞœĞ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹

**ĞŸÑ€ÑĞ¼Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ:**
```
q(xâ‚œ|xâ‚œâ‚‹â‚) = N(xâ‚œ; âˆš(1-Î²â‚œ)xâ‚œâ‚‹â‚, Î²â‚œI)

Ğ³Ğ´Ğµ Î²â‚œ - schedule ÑˆÑƒĞ¼Ğ°
```

**ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ:**
```
pÎ¸(xâ‚œâ‚‹â‚|xâ‚œ) = N(xâ‚œâ‚‹â‚; Î¼Î¸(xâ‚œ,t), Î£Î¸(xâ‚œ,t))
```

#### U-Net Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸

```
                    U-NET Ğ”Ğ›Ğ¯ Ğ”Ğ˜Ğ¤Ğ¤Ğ£Ğ—Ğ˜Ğ˜
    
    Ğ’Ñ…Ğ¾Ğ´: xâ‚œ (Ğ·Ğ°ÑˆÑƒĞ¼Ğ»ĞµĞ½Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ) + t (Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ ÑˆĞ°Ğ³)
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    Ğ­ĞĞšĞĞ”Ğ•Ğ                               â”‚
    â”‚  32x32 â†’ 16x16 â†’ 8x8 â†’ 4x4 â†’ 2x2                      â”‚
    â”‚   â†“       â†“      â†“     â†“     â†“                         â”‚
    â”‚  Conv   Conv   Conv  Conv   Conv                       â”‚
    â”‚   â†“       â†“      â†“     â†“     â†“                         â”‚
    â”‚  [Skip connections]   â†“                                â”‚
    â”‚                       â†“                                â”‚
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
    â”‚              â”‚  BOTTLENECK     â”‚                       â”‚
    â”‚              â”‚  + Time Embed   â”‚                       â”‚
    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
    â”‚                       â†“                                â”‚
    â”‚                    Ğ”Ğ•ĞšĞĞ”Ğ•Ğ                              â”‚
    â”‚  2x2 â†’ 4x4 â†’ 8x8 â†’ 16x16 â†’ 32x32                      â”‚
    â”‚   â†‘     â†‘     â†‘      â†‘       â†‘                         â”‚
    â”‚  Conv Conv  Conv   Conv    Conv                        â”‚
    â”‚   â†‘     â†‘     â†‘      â†‘       â†‘                         â”‚
    â”‚  [Skip connections from encoder]                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Ğ’Ñ‹Ñ…Ğ¾Ğ´: ÎµÌ‚Î¸(xâ‚œ,t) (Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼)
```

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class SimpleDiffusion:
    def __init__(self, num_timesteps=1000):
        self.num_timesteps = num_timesteps
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ schedule Ğ´Ğ»Ñ ÑˆÑƒĞ¼Ğ°
        self.betas = self.linear_beta_schedule(num_timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
        
    def linear_beta_schedule(self, timesteps, start=0.0001, end=0.02):
        """Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğ¹ schedule Ğ´Ğ»Ñ ÑˆÑƒĞ¼Ğ°"""
        return torch.linspace(start, end, timesteps)
    
    def q_sample(self, x_start, t, noise=None):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑˆÑƒĞ¼ Ğº Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ° ÑˆĞ°Ğ³Ğµ t"""
        if noise is None:
            noise = torch.randn_like(x_start)
        
        sqrt_alphas_cumprod_t = self.alphas_cumprod[t].sqrt()
        sqrt_one_minus_alphas_cumprod_t = (1 - self.alphas_cumprod[t]).sqrt()
        
        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise
    
    def p_losses(self, denoise_model, x_start, t, noise=None):
        """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ"""
        if noise is None:
            noise = torch.randn_like(x_start)
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑˆÑƒĞ¼
        x_noisy = self.q_sample(x_start, t, noise)
        
        # ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑˆÑƒĞ¼
        predicted_noise = denoise_model(x_noisy, t)
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸
        loss = F.mse_loss(noise, predicted_noise)
        return loss

class TimeEmbedding(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim
        
    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = np.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings

class SimpleUNet(nn.Module):
    def __init__(self, channels=1, time_emb_dim=128):
        super().__init__()
        
        self.time_embedding = TimeEmbedding(time_emb_dim)
        
        # Ğ­Ğ½ĞºĞ¾Ğ´ĞµÑ€
        self.conv1 = nn.Conv2d(channels, 64, 3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)
        
        # Bottleneck
        self.bottleneck = nn.Conv2d(256, 512, 3, padding=1)
        self.time_proj = nn.Linear(time_emb_dim, 512)
        
        # Ğ”ĞµĞºĞ¾Ğ´ĞµÑ€
        self.upconv3 = nn.ConvTranspose2d(512, 256, 3, padding=1)
        self.upconv2 = nn.ConvTranspose2d(256 + 256, 128, 3, padding=1)  # +256 Ğ´Ğ»Ñ skip connection
        self.upconv1 = nn.ConvTranspose2d(128 + 128, 64, 3, padding=1)   # +128 Ğ´Ğ»Ñ skip connection
        self.final_conv = nn.Conv2d(64 + 64, channels, 3, padding=1)     # +64 Ğ´Ğ»Ñ skip connection
        
    def forward(self, x, time):
        # Time embedding
        time_emb = self.time_embedding(time)
        
        # Ğ­Ğ½ĞºĞ¾Ğ´ĞµÑ€ Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸ĞµĞ¼ skip connections
        skip1 = F.relu(self.conv1(x))
        skip2 = F.relu(self.conv2(F.max_pool2d(skip1, 2)))
        skip3 = F.relu(self.conv3(F.max_pool2d(skip2, 2)))
        
        # Bottleneck Ñ time embedding
        bottleneck = F.relu(self.bottleneck(F.max_pool2d(skip3, 2)))
        time_proj = self.time_proj(time_emb)
        bottleneck = bottleneck + time_proj.view(-1, 512, 1, 1)
        
        # Ğ”ĞµĞºĞ¾Ğ´ĞµÑ€ Ñ skip connections
        x = F.relu(self.upconv3(F.interpolate(bottleneck, scale_factor=2)))
        x = torch.cat([x, skip3], dim=1)
        
        x = F.relu(self.upconv2(F.interpolate(x, scale_factor=2)))
        x = torch.cat([x, skip2], dim=1)
        
        x = F.relu(self.upconv1(F.interpolate(x, scale_factor=2)))
        x = torch.cat([x, skip1], dim=1)
        
        x = self.final_conv(x)
        return x
```

#### ĞŸÑ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ

```python
def train_diffusion_model(model, dataloader, diffusion, num_epochs=100):
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    
    for epoch in range(num_epochs):
        total_loss = 0
        for batch_idx, (data, _) in enumerate(dataloader):
            optimizer.zero_grad()
            
            # Ğ¡Ğ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ ÑˆĞ°Ğ³Ğ¸
            batch_size = data.shape[0]
            t = torch.randint(0, diffusion.num_timesteps, (batch_size,))
            
            # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸
            loss = diffusion.p_losses(model, data, t)
            
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            
        print(f'Epoch {epoch}, Average Loss: {total_loss/len(dataloader):.4f}')
```

#### Ğ¡ÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ (Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ)

```python
@torch.no_grad()
def sample_from_model(model, diffusion, image_size=(28, 28), num_samples=16):
    """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ· Ñ‡Ğ¸ÑÑ‚Ğ¾Ğ³Ğ¾ ÑˆÑƒĞ¼Ğ°"""
    
    # ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ñ Ñ‡Ğ¸ÑÑ‚Ğ¾Ğ³Ğ¾ ÑˆÑƒĞ¼Ğ°
    img = torch.randn(num_samples, 1, *image_size)
    
    # ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ´Ğ°Ğ»ÑĞµĞ¼ ÑˆÑƒĞ¼
    for i in reversed(range(diffusion.num_timesteps)):
        t = torch.full((num_samples,), i, dtype=torch.long)
        
        # ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑˆÑƒĞ¼
        predicted_noise = model(img, t)
        
        # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼
        alpha = diffusion.alphas[i]
        alpha_cumprod = diffusion.alphas_cumprod[i]
        beta = diffusion.betas[i]
        
        # Ğ¤Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ° Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ ÑˆÑƒĞ¼Ğ°
        img = (1 / alpha.sqrt()) * (img - beta * predicted_noise / (1 - alpha_cumprod).sqrt())
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ ÑˆÑƒĞ¼Ğ° (ĞºÑ€Ğ¾Ğ¼Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ ÑˆĞ°Ğ³Ğ°)
        if i > 0:
            noise = torch.randn_like(img)
            img = img + (beta.sqrt() * noise)
    
    return img
```

### ğŸ“Š Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ñ GAN

```
                    GAN vs Ğ”Ğ˜Ğ¤Ğ¤Ğ£Ğ—Ğ˜Ğ¯
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      GAN        â”‚   Ğ”Ğ˜Ğ¤Ğ¤Ğ£Ğ—Ğ˜Ğ¯      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ         â”‚ ĞœĞµĞ´Ğ»ĞµĞ½Ğ½Ğ°Ñ       â”‚
    â”‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ       â”‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ       â”‚
    â”‚ (1 Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´)      â”‚ (1000 ÑˆĞ°Ğ³Ğ¾Ğ²)    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ ĞĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ    â”‚ Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ      â”‚
    â”‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ        â”‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ        â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Mode collapse   â”‚ ĞŸĞ¾ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²ÑĞµ   â”‚
    â”‚                 â”‚ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Ğ’Ñ‹ÑĞ¾ĞºĞ¾Ğµ         â”‚ Ğ˜ÑĞºĞ»ÑÑ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ  â”‚
    â”‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾        â”‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ† ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- âœ… Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ DDPM Ñ Ğ½ÑƒĞ»Ñ
- âœ… Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
- âœ… ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸
- âœ… Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ñ Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸

---

## ğŸ® Ğ“Ğ»Ğ°Ğ²Ğ° 5.5: Reinforcement Learning Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹
**â± Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 1 Ğ½ĞµĞ´ĞµĞ»Ñ

### ğŸ¯ Ğ¦ĞµĞ»Ğ¸ Ğ³Ğ»Ğ°Ğ²Ñ‹
- ĞŸĞ¾Ğ½ÑÑ‚ÑŒ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼
- Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ Q-learning Ğ¸ Deep Q-Networks
- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¸Ğ³Ñ€Ñ‹

### ğŸ“š Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸ RL

```
               Ğ¡Ğ Ğ•Ğ”Ğ (Environment)
                     â”‚
                   state s
                     â”‚
                     â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            ĞĞ“Ğ•ĞĞ¢                    â”‚
    â”‚                                     â”‚
    â”‚  Policy Ï€(a|s) â†’ action a           â”‚
    â”‚                                     â”‚
    â”‚  Value V(s) / Q(s,a)                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                  action a
                     â”‚
                     â†“
               Ğ¡Ğ Ğ•Ğ”Ğ (Environment)
                     â”‚
                  reward r
                     â”‚
                     â†“
                ĞĞ“Ğ•ĞĞ¢ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚
               reward Ğ¸ new state
```

#### ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹

```
ğŸ¯ Ğ¦Ğ•Ğ›Ğ¬: ĞœĞ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºÑƒĞ¼ÑƒĞ»ÑÑ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ñƒ

ğŸ“Š ĞĞ¡ĞĞĞ’ĞĞ«Ğ• Ğ­Ğ›Ğ•ĞœĞ•ĞĞ¢Ğ«:
   â€¢ State (s): Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
   â€¢ Action (a): Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°  
   â€¢ Reward (r): Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ° Ğ·Ğ° Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ
   â€¢ Policy (Ï€): ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹
   â€¢ Value (V): Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ°Ñ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ° Ğ¸Ğ· ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ
```

#### Q-Learning Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼

```
Q-Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ: Q(s,a) = Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ°Ñ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ° Ğ·Ğ° Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ a Ğ² ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğ¸ s

ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Q-Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸:
Q(s,a) â† Q(s,a) + Î±[r + Î³ max Q(s',a') - Q(s,a)]
                    a'
Ğ³Ğ´Ğµ:
Î± - learning rate
Î³ - discount factor
```

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Deep Q-Network (DQN)

```python
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import random
from collections import deque

class DQN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(DQN, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, output_size)
        )
    
    def forward(self, x):
        return self.network(x)

class DQNAgent:
    def __init__(self, state_size, action_size, lr=0.001):
        self.state_size = state_size
        self.action_size = action_size
        self.memory = deque(maxlen=10000)
        self.epsilon = 1.0  # exploration rate
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.learning_rate = lr
        
        # ĞĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ ÑĞµÑ‚Ğ¸
        self.q_network = DQN(state_size, 128, action_size)
        self.target_network = DQN(state_size, 128, action_size)
        self.optimizer = optim.Adam(self.q_network.parameters(), lr=lr)
        
        # ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ĞµÑĞ° Ğ² target network
        self.target_network.load_state_dict(self.q_network.state_dict())
    
    def remember(self, state, action, reward, next_state, done):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ğ¿Ñ‹Ñ‚ Ğ² replay buffer"""
        self.memory.append((state, action, reward, next_state, done))
    
    def act(self, state):
        """Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ Ñ epsilon-greedy ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸ĞµĞ¹"""
        if np.random.random() <= self.epsilon:
            return random.randrange(self.action_size)
        
        state_tensor = torch.FloatTensor(state).unsqueeze(0)
        q_values = self.q_network(state_tensor)
        return np.argmax(q_values.cpu().data.numpy())
    
    def replay(self, batch_size=32):
        """ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ ÑĞµÑ‚ÑŒ Ğ½Ğ° Ğ±Ğ°Ñ‚Ñ‡Ğµ Ğ¸Ğ· replay buffer"""
        if len(self.memory) < batch_size:
            return
        
        batch = random.sample(self.memory, batch_size)
        states = torch.FloatTensor([e[0] for e in batch])
        actions = torch.LongTensor([e[1] for e in batch])
        rewards = torch.FloatTensor([e[2] for e in batch])
        next_states = torch.FloatTensor([e[3] for e in batch])
        dones = torch.BoolTensor([e[4] for e in batch])
        
        current_q_values = self.q_network(states).gather(1, actions.unsqueeze(1))
        next_q_values = self.target_network(next_states).max(1)[0].detach()
        target_q_values = rewards + (0.99 * next_q_values * ~dones)
        
        loss = nn.MSELoss()(current_q_values.squeeze(), target_q_values)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay
    
    def update_target_network(self):
        """ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ target network"""
        self.target_network.load_state_dict(self.q_network.state_dict())
```

#### ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ğ¸Ğ³Ñ€Ğ¾Ğ²Ğ°Ñ ÑÑ€ĞµĞ´Ğ° (CartPole)

```python
import gym

def train_dqn_agent():
    env = gym.make('CartPole-v1')
    state_size = env.observation_space.shape[0]
    action_size = env.action_space.n
    
    agent = DQNAgent(state_size, action_size)
    
    scores = []
    episodes = 1000
    
    for episode in range(episodes):
        state = env.reset()
        if isinstance(state, tuple):
            state = state[0]  # Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ²ĞµÑ€ÑĞ¸Ğ¹ gym
        
        total_reward = 0
        
        for time in range(500):  # Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 500 ÑˆĞ°Ğ³Ğ¾Ğ²
            action = agent.act(state)
            next_state, reward, done, truncated, info = env.step(action)
            
            # ĞœĞ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ñƒ Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
            if done and time < 499:
                reward = -10  # ÑˆÑ‚Ñ€Ğ°Ñ„ Ğ·Ğ° Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
            
            agent.remember(state, action, reward, next_state, done)
            state = next_state
            total_reward += reward
            
            if done:
                break
        
        scores.append(total_reward)
        
        # ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
        if len(agent.memory) > 32:
            agent.replay(32)
        
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ target network ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 100 ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´Ğ¾Ğ²
        if episode % 100 == 0:
            agent.update_target_network()
        
        # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
        if episode % 100 == 0:
            avg_score = np.mean(scores[-100:])
            print(f'Episode {episode}, Average Score: {avg_score:.2f}, Epsilon: {agent.epsilon:.3f}')
    
    return agent, scores
```

### ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ

```python
def plot_training_progress(scores):
    """Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ"""
    import matplotlib.pyplot as plt
    
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(scores)
    plt.title('Score per Episode')
    plt.xlabel('Episode')
    plt.ylabel('Score')
    
    plt.subplot(1, 2, 2)
    rolling_avg = [np.mean(scores[max(0, i-100):i+1]) for i in range(len(scores))]
    plt.plot(rolling_avg)
    plt.title('Rolling Average (100 episodes)')
    plt.xlabel('Episode')
    plt.ylabel('Average Score')
    
    plt.tight_layout()
    plt.show()
```

### ğŸ¯ ĞŸÑ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹

#### Policy Gradient (REINFORCE)

```python
class PolicyNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(PolicyNetwork, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, output_size),
            nn.Softmax(dim=-1)
        )
    
    def forward(self, x):
        return self.network(x)

def reinforce_update(policy_net, optimizer, states, actions, rewards, gamma=0.99):
    """REINFORCE Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ"""
    
    # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ´Ğ¸ÑĞºĞ¾Ğ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ñ‹
    discounted_rewards = []
    cumulative_reward = 0
    for reward in reversed(rewards):
        cumulative_reward = reward + gamma * cumulative_reward
        discounted_rewards.insert(0, cumulative_reward)
    
    # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ñ‹
    discounted_rewards = torch.tensor(discounted_rewards)
    discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-8)
    
    # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸
    policy_loss = []
    for log_prob, reward in zip(log_probs, discounted_rewards):
        policy_loss.append(-log_prob * reward)
    
    # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ²ĞµÑĞ°
    optimizer.zero_grad()
    policy_loss = torch.stack(policy_loss).sum()
    policy_loss.backward()
    optimizer.step()
```

### ğŸ† ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- âœ… Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ DQN Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
- âœ… ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¸Ğ³Ñ€Ğ°Ñ‚ÑŒ Ğ² CartPole
- âœ… ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ exploration vs exploitation
- âœ… Ğ—Ğ½Ğ°ĞºĞ¾Ğ¼ÑÑ‚Ğ²Ğ¾ Ñ Policy Gradient Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸

---

## ğŸ§  Ğ“Ğ»Ğ°Ğ²Ğ° 5.6: Meta-learning Ğ¸ Few-shot learning
**â± Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 1 Ğ½ĞµĞ´ĞµĞ»Ñ

### ğŸ¯ Ğ¦ĞµĞ»Ğ¸ Ğ³Ğ»Ğ°Ğ²Ñ‹
- ĞŸĞ¾Ğ½ÑÑ‚ÑŒ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ "Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ"
- Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ MAML (Model-Agnostic Meta-Learning)
- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ few-shot ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€

### ğŸ“š Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Meta-learning?

```
                ĞĞ‘Ğ«Ğ§ĞĞĞ• ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ•
    
    Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ â†’ ĞœĞ¾Ğ´ĞµĞ»ÑŒ â†’ ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ
    
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
                META-LEARNING
    
    Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° 1: ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ĞºĞ¾ÑˆĞµĞº/ÑĞ¾Ğ±Ğ°Ğº
    Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° 2: ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¿Ñ‚Ğ¸Ñ†/Ñ€Ñ‹Ğ±  
    Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° 3: ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¼Ğ°ÑˆĞ¸Ğ½/ÑĞ°Ğ¼Ğ¾Ğ»ĞµÑ‚Ğ¾Ğ²
                        â”‚
                        â†“
                Meta-Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑƒÑ‡Ğ¸Ñ‚ÑÑ
               "ĞºĞ°Ğº Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ"
                        â”‚
                        â†“
                ĞĞ¾Ğ²Ğ°Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°: ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ²
                â†’ Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ·Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ²
```

#### Few-shot learning Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°

```
ĞŸĞĞ”Ğ”Ğ•Ğ Ğ–ĞšĞ (Support Set):
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ ğŸŒ¹  â”‚ ğŸŒ¹  â”‚ ğŸŒ»  â”‚ ğŸŒ»  â”‚  â† ĞœĞ°Ğ»Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ĞºĞ»Ğ°ÑÑĞ°
â”‚Rose â”‚Rose â”‚Sun- â”‚Sun- â”‚    (Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ 1-5 Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ²)
â”‚     â”‚     â”‚flowerâ”‚flowerâ”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

Ğ—ĞĞŸĞ ĞĞ¡ (Query Set):
â”Œâ”€â”€â”€â”€â”€â”
â”‚ ğŸŒ¹? â”‚  â† ĞÑƒĞ¶Ğ½Ğ¾ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ
â”‚  ?  â”‚
â””â”€â”€â”€â”€â”€â”˜

Ğ¦Ğ•Ğ›Ğ¬: ĞĞ°ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğº Ğ½Ğ¾Ğ²Ñ‹Ğ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼
```

#### MAML Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼

```
MAML (Model-Agnostic Meta-Learning):

1. Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Î¸
2. Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ï„áµ¢:
   â€¢ Ğ‘ĞµÑ€ĞµĞ¼ few-shot support set
   â€¢ Ğ”ĞµĞ»Ğ°ĞµĞ¼ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ gradient steps: Î¸'áµ¢ = Î¸ - Î±âˆ‡Î¸LÏ„áµ¢(Î¸)
   â€¢ Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ° query set: LÏ„áµ¢(Î¸'áµ¢)
3. ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¼ĞµÑ‚Ğ°-Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹: Î¸ = Î¸ - Î²âˆ‡Î¸ Î£áµ¢ LÏ„áµ¢(Î¸'áµ¢)
```

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ MAML

```python
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from collections import OrderedDict

class MAMLModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(MAMLModel, self).__init__()
        self.layers = nn.Sequential(
            OrderedDict([
                ('conv1', nn.Conv2d(3, 32, 3, padding=1)),
                ('bn1', nn.BatchNorm2d(32)),
                ('relu1', nn.ReLU()),
                ('pool1', nn.MaxPool2d(2)),
                
                ('conv2', nn.Conv2d(32, 64, 3, padding=1)),
                ('bn2', nn.BatchNorm2d(64)),
                ('relu2', nn.ReLU()),
                ('pool2', nn.MaxPool2d(2)),
                
                ('flatten', nn.Flatten()),
                ('fc1', nn.Linear(64 * 8 * 8, hidden_size)),
                ('relu3', nn.ReLU()),
                ('fc2', nn.Linear(hidden_size, output_size))
            ])
        )
    
    def forward(self, x, params=None):
        if params is None:
            return self.layers(x)
        
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
        x = self.functional_forward(x, params)
        return x
    
    def functional_forward(self, x, params):
        """Forward pass Ñ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸"""
        # Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ forward
        # (ÑƒĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ´Ğ»Ñ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸)
        for name, layer in self.layers.named_children():
            if name in params:
                if isinstance(layer, nn.Conv2d):
                    x = F.conv2d(x, params[name + '.weight'], params[name + '.bias'], 
                               layer.stride, layer.padding)
                elif isinstance(layer, nn.Linear):
                    x = F.linear(x, params[name + '.weight'], params[name + '.bias'])
            else:
                x = layer(x)
        return x

class MAML:
    def __init__(self, model, inner_lr=0.01, outer_lr=0.001, inner_steps=5):
        self.model = model
        self.inner_lr = inner_lr
        self.outer_lr = outer_lr
        self.inner_steps = inner_steps
        self.optimizer = optim.Adam(model.parameters(), lr=outer_lr)
        self.loss_fn = nn.CrossEntropyLoss()
    
    def inner_update(self, support_x, support_y, params=None):
        """Ğ’Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ Ñ†Ğ¸ĞºĞ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° support set"""
        if params is None:
            params = {name: param.clone() for name, param in self.model.named_parameters()}
        
        for _ in range(self.inner_steps):
            # Forward pass
            logits = self.model(support_x, params)
            loss = self.loss_fn(logits, support_y)
            
            # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ñ‹
            grads = torch.autograd.grad(loss, params.values(), create_graph=True)
            
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
            params = {name: param - self.inner_lr * grad 
                     for (name, param), grad in zip(params.items(), grads)}
        
        return params
    
    def meta_update(self, tasks):
        """ĞœĞµÑ‚Ğ°-Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ±Ğ°Ñ‚Ñ‡Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡"""
        self.optimizer.zero_grad()
        
        meta_loss = 0
        for task in tasks:
            support_x, support_y, query_x, query_y = task
            
            # Ğ’Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ Ñ†Ğ¸ĞºĞ»
            adapted_params = self.inner_update(support_x, support_y)
            
            # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ğ½Ğ° query set
            query_logits = self.model(query_x, adapted_params)
            query_loss = self.loss_fn(query_logits, query_y)
            
            meta_loss += query_loss
        
        meta_loss /= len(tasks)
        meta_loss.backward()
        self.optimizer.step()
        
        return meta_loss.item()
```

#### Prototypical Networks

```python
class PrototypicalNetwork(nn.Module):
    def __init__(self, encoder_dim=64):
        super(PrototypicalNetwork, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            nn.Flatten(),
            nn.Linear(64 * 4 * 4, encoder_dim)
        )
    
    def forward(self, support_set, query_set):
        """
        support_set: (n_way * n_shot, C, H, W)
        query_set: (n_query, C, H, W)
        """
        # ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ support set
        support_embeddings = self.encoder(support_set)
        
        # ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ query set
        query_embeddings = self.encoder(query_set)
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾Ñ‚Ğ¸Ğ¿Ñ‹ (Ñ†ĞµĞ½Ñ‚Ñ€Ğ¾Ğ¸Ğ´Ñ‹ ĞºĞ»Ğ°ÑÑĞ¾Ğ²)
        n_way = len(torch.unique(support_labels))
        n_shot = support_set.size(0) // n_way
        
        prototypes = support_embeddings.view(n_way, n_shot, -1).mean(dim=1)
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ
        distances = self.euclidean_distance(query_embeddings, prototypes)
        
        # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² Ğ»Ğ¾Ğ³Ğ¸Ñ‚Ñ‹
        logits = -distances
        
        return logits
    
    def euclidean_distance(self, x, y):
        """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ ĞµĞ²ĞºĞ»Ğ¸Ğ´Ğ¾Ğ²Ğ¾ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ"""
        n = x.size(0)
        m = y.size(0)
        d = x.size(1)
        
        x = x.unsqueeze(1).expand(n, m, d)
        y = y.unsqueeze(0).expand(n, m, d)
        
        return torch.pow(x - y, 2).sum(2)
```

#### Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ few-shot Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°

```python
class FewShotDataset:
    def __init__(self, data, labels, n_way=5, n_shot=1, n_query=15):
        self.data = data
        self.labels = labels
        self.n_way = n_way
        self.n_shot = n_shot
        self.n_query = n_query
        self.classes = np.unique(labels)
    
    def sample_episode(self):
        """Ğ¡ÑĞ¼Ğ¿Ğ»Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´ Ğ´Ğ»Ñ few-shot Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ"""
        # Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ ĞºĞ»Ğ°ÑÑÑ‹
        selected_classes = np.random.choice(self.classes, self.n_way, replace=False)
        
        support_x, support_y = [], []
        query_x, query_y = [], []
        
        for i, cls in enumerate(selected_classes):
            # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ²ÑĞµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ ÑÑ‚Ğ¾Ğ³Ğ¾ ĞºĞ»Ğ°ÑÑĞ°
            class_indices = np.where(self.labels == cls)[0]
            
            # Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ»Ñ support Ğ¸ query
            selected_indices = np.random.choice(class_indices, 
                                              self.n_shot + self.n_query, 
                                              replace=False)
            
            support_indices = selected_indices[:self.n_shot]
            query_indices = selected_indices[self.n_shot:]
            
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² support set
            support_x.append(self.data[support_indices])
            support_y.extend([i] * self.n_shot)
            
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² query set
            query_x.append(self.data[query_indices])
            query_y.extend([i] * self.n_query)
        
        support_x = np.concatenate(support_x)
        query_x = np.concatenate(query_x)
        
        return (torch.tensor(support_x), torch.tensor(support_y),
                torch.tensor(query_x), torch.tensor(query_y))
```

### ğŸ“Š Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹

```python
def train_few_shot_model(model, dataset, num_episodes=10000):
    """ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ° few-shot Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…"""
    
    accuracies = []
    
    for episode in range(num_episodes):
        # Ğ¡ÑĞ¼Ğ¿Ğ»Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´
        support_x, support_y, query_x, query_y = dataset.sample_episode()
        
        # ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
        if isinstance(model, MAML):
            loss = model.meta_update([(support_x, support_y, query_x, query_y)])
        else:
            # Ğ”Ğ»Ñ Prototypical Networks
            logits = model(support_x, query_x)
            loss = F.cross_entropy(logits, query_y)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ
        if episode % 100 == 0:
            with torch.no_grad():
                logits = model(support_x, query_x)
                pred = logits.argmax(dim=1)
                acc = (pred == query_y).float().mean()
                accuracies.append(acc.item())
                print(f'Episode {episode}, Accuracy: {acc:.3f}')
    
    return accuracies
```

### ğŸ† ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- âœ… Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ MAML Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°
- âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Prototypical Networks
- âœ… Few-shot ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒÑ 80%+
- âœ… ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ¾Ğ² meta-learning

---

## ğŸ”— Ğ“Ğ»Ğ°Ğ²Ğ° 5.7: Multimodal Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
**â± Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 1 Ğ½ĞµĞ´ĞµĞ»Ñ

### ğŸ¯ Ğ¦ĞµĞ»Ğ¸ Ğ³Ğ»Ğ°Ğ²Ñ‹
- ĞŸĞ¾Ğ½ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
- Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ CLIP Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ
- Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ²Ğ¸Ğº Ğ¿Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼ Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸

### ğŸ“š Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸?

```
                ĞœĞ£Ğ›Ğ¬Ğ¢Ğ˜ĞœĞĞ”ĞĞ›Ğ¬ĞĞ«Ğ• ĞœĞĞ”Ğ•Ğ›Ğ˜
    
    Ğ¢ĞµĞºÑÑ‚: "ĞšÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹ Ğ·Ğ°ĞºĞ°Ñ‚ Ğ½Ğ°Ğ´ Ğ¾ĞºĞµĞ°Ğ½Ğ¾Ğ¼"
      â†“
    [Text Encoder] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚
                                 â†“
                         ĞĞ±Ñ‰ĞµĞµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ¾
                         Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹
                                 â†‘
                                 â”‚
    [Image Encoder] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†‘
    Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ: ğŸŒ…
    
    Ğ¦Ğ•Ğ›Ğ¬: Ğ¡Ğ²ÑĞ·Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² ĞµĞ´Ğ¸Ğ½Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ
```

#### CLIP Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°

```
                        CLIP ĞœĞĞ”Ğ•Ğ›Ğ¬
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                         â”‚
    â”‚  Text: "A cat sitting on a table"                      â”‚
    â”‚    â†“                                                    â”‚
    â”‚  [Text Encoder] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
    â”‚  (Transformer)                â”‚                        â”‚
    â”‚                               â”‚                        â”‚
    â”‚                               â†“                        â”‚
    â”‚                       [Contrastive Loss]               â”‚
    â”‚                               â†‘                        â”‚
    â”‚                               â”‚                        â”‚
    â”‚  [Image Encoder] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
    â”‚  (Vision Transformer)                                  â”‚
    â”‚    â†‘                                                   â”‚
    â”‚  Image: ğŸ±                                            â”‚
    â”‚                                                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ: ĞŸĞ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ñ‹ (Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ + Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ) Ğ¿Ñ€Ğ¸Ñ‚ÑĞ³Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ,
              Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ñ‹ Ğ¾Ñ‚Ñ‚Ğ°Ğ»ĞºĞ¸Ğ²Ğ°ÑÑ‚ÑÑ
```

#### Contrastive Learning

```
Ğ‘Ğ°Ñ‚Ñ‡ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹: [ğŸ±, ğŸ¶, ğŸš—, ğŸŒ³]
Ğ‘Ğ°Ñ‚Ñ‡ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹:   ["cat", "dog", "car", "tree"]

ĞœĞ°Ñ‚Ñ€Ğ¸Ñ†Ğ° ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚Ğ¸:
        "cat" "dog" "car" "tree"
ğŸ±      [0.9   0.1   0.2   0.1 ]
ğŸ¶      [0.1   0.8   0.1   0.2 ]
ğŸš—      [0.2   0.1   0.9   0.1 ]
ğŸŒ³      [0.1   0.2   0.1   0.8 ]

Ğ¦ĞµĞ»ÑŒ: ĞœĞ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ¸Ğ°Ğ³Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹,
      Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ
```

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ

#### Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ³Ğ¾ CLIP

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import clip
from PIL import Image
import requests
from transformers import AutoTokenizer, AutoModel

class SimpleTextEncoder(nn.Module):
    def __init__(self, vocab_size, embed_dim=512, max_len=77):
        super(SimpleTextEncoder, self).__init__()
        self.embed_dim = embed_dim
        self.token_embedding = nn.Embedding(vocab_size, embed_dim)
        self.position_embedding = nn.Embedding(max_len, embed_dim)
        
        # Transformer Ğ±Ğ»Ğ¾ĞºĞ¸
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(embed_dim, nhead=8, dim_feedforward=2048),
            num_layers=12
        )
        
        self.ln_final = nn.LayerNorm(embed_dim)
        
    def forward(self, text_tokens):
        seq_len = text_tokens.size(1)
        positions = torch.arange(seq_len, device=text_tokens.device)
        
        # Embeddings
        x = self.token_embedding(text_tokens) + self.position_embedding(positions)
        
        # Transformer
        x = x.permute(1, 0, 2)  # (seq_len, batch_size, embed_dim)
        x = self.transformer(x)
        x = x.permute(1, 0, 2)  # (batch_size, seq_len, embed_dim)
        
        # Pooling (Ğ±ĞµÑ€ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½)
        x = self.ln_final(x[:, -1, :])
        
        return x

class SimpleImageEncoder(nn.Module):
    def __init__(self, embed_dim=512):
        super(SimpleImageEncoder, self).__init__()
        
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ResNet backbone
        self.backbone = nn.Sequential(
            # Conv Block 1
            nn.Conv2d(3, 64, 7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2, padding=1),
            
            # Conv Block 2
            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            
            # Conv Block 3
            nn.Conv2d(128, 256, 3, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            
            # Conv Block 4
            nn.Conv2d(256, 512, 3, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            
            # Global Average Pooling
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten()
        )
        
        self.projection = nn.Linear(512, embed_dim)
        
    def forward(self, images):
        features = self.backbone(images)
        embeddings = self.projection(features)
        return embeddings

class SimpleCLIP(nn.Module):
    def __init__(self, vocab_size=50000, embed_dim=512, temperature=0.07):
        super(SimpleCLIP, self).__init__()
        
        self.text_encoder = SimpleTextEncoder(vocab_size, embed_dim)
        self.image_encoder = SimpleImageEncoder(embed_dim)
        self.temperature = nn.Parameter(torch.tensor(temperature))
        
    def forward(self, images, text_tokens):
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ embeddings
        image_features = self.image_encoder(images)
        text_features = self.text_encoder(text_tokens)
        
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ features
        image_features = F.normalize(image_features, dim=-1)
        text_features = F.normalize(text_features, dim=-1)
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ similarity matrix
        logits = torch.matmul(image_features, text_features.T) / self.temperature
        
        return logits, image_features, text_features

def clip_loss(logits):
    """Contrastive loss Ğ´Ğ»Ñ CLIP"""
    batch_size = logits.size(0)
    labels = torch.arange(batch_size, device=logits.device)
    
    # Loss Ğ² Ğ¾Ğ±Ğµ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‹
    loss_i2t = F.cross_entropy(logits, labels)
    loss_t2i = F.cross_entropy(logits.T, labels)
    
    return (loss_i2t + loss_t2i) / 2
```

#### ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ CLIP Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸

```python
def train_clip_model(model, dataloader, num_epochs=10):
    """ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ CLIP Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ"""
    
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    model.train()
    
    for epoch in range(num_epochs):
        total_loss = 0
        
        for batch_idx, (images, text_tokens) in enumerate(dataloader):
            optimizer.zero_grad()
            
            # Forward pass
            logits, image_features, text_features = model(images, text_tokens)
            
            # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ loss
            loss = clip_loss(logits)
            
            # Backward pass
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            
            if batch_idx % 100 == 0:
                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')
        
        print(f'Epoch {epoch}, Average Loss: {total_loss/len(dataloader):.4f}')
```

#### Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ CLIP

```python
import clip
import torch
from PIL import Image

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

def image_search(query_text, image_paths):
    """ĞŸĞ¾Ğ¸ÑĞº Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ"""
    
    # Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµĞºÑÑ‚
    text_tokens = clip.tokenize([query_text]).to(device)
    
    # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
    images = []
    for path in image_paths:
        image = preprocess(Image.open(path)).unsqueeze(0).to(device)
        images.append(image)
    
    images = torch.cat(images)
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ embeddings
    with torch.no_grad():
        text_features = model.encode_text(text_tokens)
        image_features = model.encode_image(images)
        
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼
        text_features = F.normalize(text_features, dim=-1)
        image_features = F.normalize(image_features, dim=-1)
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ
        similarities = torch.matmul(text_features, image_features.T)
    
    # Ğ Ğ°Ğ½Ğ¶Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
    similarities = similarities.squeeze().cpu().numpy()
    ranked_indices = similarities.argsort()[::-1]
    
    results = []
    for idx in ranked_indices:
        results.append({
            'image_path': image_paths[idx],
            'similarity': similarities[idx]
        })
    
    return results

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
query = "a cat sitting on a table"
image_paths = ["cat1.jpg", "dog1.jpg", "table1.jpg", "cat2.jpg"]
results = image_search(query, image_paths)

for result in results[:3]:  # Ğ¢Ğ¾Ğ¿-3 Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°
    print(f"Image: {result['image_path']}, Similarity: {result['similarity']:.3f}")
```

#### Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²ĞµĞ±-Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°

```python
import streamlit as st
import torch
import clip
from PIL import Image
import os
import numpy as np

class ImageSearchApp:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model, self.preprocess = clip.load("ViT-B/32", device=self.device)
        self.image_features = None
        self.image_paths = []
    
    def index_images(self, image_folder):
        """Ğ˜Ğ½Ğ´ĞµĞºÑĞ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ² Ğ¿Ğ°Ğ¿ĞºĞµ"""
        image_paths = []
        for filename in os.listdir(image_folder):
            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(image_folder, filename))
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ embeddings Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
        image_features = []
        for path in image_paths:
            image = self.preprocess(Image.open(path)).unsqueeze(0).to(self.device)
            with torch.no_grad():
                features = self.model.encode_image(image)
                features = F.normalize(features, dim=-1)
                image_features.append(features)
        
        self.image_features = torch.cat(image_features)
        self.image_paths = image_paths
        
        print(f"ĞŸÑ€Ğ¾Ğ¸Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ {len(image_paths)} Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹")
    
    def search(self, query_text, top_k=5):
        """ĞŸĞ¾Ğ¸ÑĞº Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ"""
        if self.image_features is None:
            return []
        
        # ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
        text_tokens = clip.tokenize([query_text]).to(self.device)
        
        with torch.no_grad():
            text_features = self.model.encode_text(text_tokens)
            text_features = F.normalize(text_features, dim=-1)
            
            # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ
            similarities = torch.matmul(text_features, self.image_features.T)
            similarities = similarities.squeeze().cpu().numpy()
        
        # Ğ Ğ°Ğ½Ğ¶Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
        top_indices = similarities.argsort()[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            results.append({
                'image_path': self.image_paths[idx],
                'similarity': similarities[idx]
            })
        
        return results

# Streamlit Ğ²ĞµĞ±-Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
def main():
    st.title("ğŸ” CLIP Image Search")
    st.write("ĞŸĞ¾Ğ¸ÑĞº Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ")
    
    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    if 'search_app' not in st.session_state:
        st.session_state.search_app = ImageSearchApp()
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
    st.header("ğŸ“ Ğ˜Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹")
    image_folder = st.text_input("ĞŸÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸:", "images/")
    
    if st.button("Ğ˜Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ"):
        if os.path.exists(image_folder):
            st.session_state.search_app.index_images(image_folder)
            st.success(f"ĞŸÑ€Ğ¾Ğ¸Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹: {len(st.session_state.search_app.image_paths)}")
        else:
            st.error("ĞŸĞ°Ğ¿ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°!")
    
    # ĞŸĞ¾Ğ¸ÑĞº
    st.header("ğŸ” ĞŸĞ¾Ğ¸ÑĞº")
    query = st.text_input("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ:", "a cat sitting on a table")
    top_k = st.slider("ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²:", 1, 10, 5)
    
    if st.button("ĞĞ°Ğ¹Ñ‚Ğ¸"):
        if st.session_state.search_app.image_features is not None:
            results = st.session_state.search_app.search(query, top_k)
            
            st.header("ğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹")
            for i, result in enumerate(results):
                col1, col2 = st.columns([1, 3])
                
                with col1:
                    try:
                        image = Image.open(result['image_path'])
                        st.image(image, caption=f"Similarity: {result['similarity']:.3f}")
                    except Exception as e:
                        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ: {e}")
                
                with col2:
                    st.write(f"**ĞŸÑƒÑ‚ÑŒ:** {result['image_path']}")
                    st.write(f"**Ğ¡Ñ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ:** {result['similarity']:.3f}")
                    st.write("---")
        else:
            st.warning("Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ½Ğ´ĞµĞºÑĞ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ!")

if __name__ == "__main__":
    main()
```

### ğŸ¨ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ (DALL-E ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ)

```python
class SimpleTextToImage(nn.Module):
    def __init__(self, text_encoder, image_decoder):
        super(SimpleTextToImage, self).__init__()
        self.text_encoder = text_encoder
        self.image_decoder = image_decoder
        
    def forward(self, text_tokens):
        # ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµĞºÑÑ‚
        text_features = self.text_encoder(text_tokens)
        
        # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
        generated_image = self.image_decoder(text_features)
        
        return generated_image

class ImageDecoder(nn.Module):
    def __init__(self, text_dim=512, image_size=64):
        super(ImageDecoder, self).__init__()
        
        self.text_projection = nn.Linear(text_dim, 1024)
        
        # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
        self.generator = nn.Sequential(
            # Ğ’Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ ÑĞ»Ğ¾Ğ¹
            nn.Linear(1024, 8 * 8 * 512),
            nn.ReLU(),
            
            # Reshape
            nn.Unflatten(1, (512, 8, 8)),
            
            # Upsampling Ğ±Ğ»Ğ¾ĞºĞ¸
            nn.ConvTranspose2d(512, 256, 4, 2, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            
            nn.ConvTranspose2d(256, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            
            nn.ConvTranspose2d(64, 3, 3, 1, 1),
            nn.Tanh()
        )
    
    def forward(self, text_features):
        # ĞŸÑ€Ğ¾ĞµÑ†Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ features
        x = self.text_projection(text_features)
        
        # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
        image = self.generator(x)
        
        return image
```

### ğŸ“Š ĞÑ†ĞµĞ½ĞºĞ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹

```python
def evaluate_clip_model(model, test_dataloader):
    """ĞÑ†ĞµĞ½ĞºĞ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° CLIP Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"""
    model.eval()
    
    total_accuracy = 0
    total_samples = 0
    
    with torch.no_grad():
        for images, text_tokens in test_dataloader:
            batch_size = images.size(0)
            
            # Forward pass
            logits, _, _ = model(images, text_tokens)
            
            # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ accuracy
            # Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ¸Ğ¼ĞµÑ‚ÑŒ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ
            predicted_texts = logits.argmax(dim=1)
            true_labels = torch.arange(batch_size)
            
            accuracy = (predicted_texts == true_labels).float().mean()
            total_accuracy += accuracy.item() * batch_size
            total_samples += batch_size
    
    return total_accuracy / total_samples

def zero_shot_classification(model, image, class_names):
    """Zero-shot ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ CLIP"""
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ĞºĞ»Ğ°ÑÑĞ°
    text_prompts = [f"a photo of a {class_name}" for class_name in class_names]
    text_tokens = clip.tokenize(text_prompts).to(device)
    
    # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
    image_tensor = preprocess(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ embeddings
        text_features = model.encode_text(text_tokens)
        image_features = model.encode_image(image_tensor)
        
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼
        text_features = F.normalize(text_features, dim=-1)
        image_features = F.normalize(image_features, dim=-1)
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ
        similarities = torch.matmul(image_features, text_features.T)
        probabilities = F.softmax(similarities * 100, dim=-1)
    
    # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
    results = []
    for i, class_name in enumerate(class_names):
        results.append({
            'class': class_name,
            'probability': probabilities[0, i].item()
        })
    
    # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ ÑƒĞ±Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸
    results.sort(key=lambda x: x['probability'], reverse=True)
    
    return results

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
image = Image.open("test_image.jpg")
classes = ["cat", "dog", "bird", "car", "airplane"]
results = zero_shot_classification(model, image, classes)

for result in results[:3]:
    print(f"{result['class']}: {result['probability']:.3f}")
```

### ğŸ† ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- âœ… Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ CLIP Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
- âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ²Ğ¸ĞºĞ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ
- âœ… Zero-shot ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
- âœ… Ğ’ĞµĞ±-Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸

---

## ğŸ¯ Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ±Ğ»Ğ¾ĞºĞ°

### Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹

**Ğ¦ĞµĞ»ÑŒ:** ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½Ğ¸Ñ‚ÑŒ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ²ÑĞµÑ… Ğ³Ğ»Ğ°Ğ² Ğ² Ğ¾Ğ´Ğ¸Ğ½ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚

**ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹:**
1. **VAE** Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
2. **CLIP** Ğ´Ğ»Ñ ÑĞ²ÑĞ·Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
3. **GAN** Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
4. **Ğ’ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ** Ğ´Ğ»Ñ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ

### ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

```
                    ĞœĞ£Ğ›Ğ¬Ğ¢Ğ˜ĞœĞĞ”ĞĞ›Ğ¬ĞĞĞ¯ Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ
    
    Ğ¢ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ: "ĞšÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹ Ğ·Ğ°ĞºĞ°Ñ‚ Ğ½Ğ°Ğ´ Ğ¾ĞºĞµĞ°Ğ½Ğ¾Ğ¼"
                                â”‚
                                â†“
                        [CLIP Text Encoder]
                                â”‚
                                â†“
                        Ğ¢ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ embeddings
                                â”‚
                                â†“
                        [VAE Decoder]
                                â”‚
                                â†“
                        Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
                                â”‚
                                â†“
                        [GAN Generator]
                                â”‚
                                â†“
                        Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ğŸŒ…
```

### ĞšÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ¸

```
ğŸ“Š ĞĞ¦Ğ•ĞĞšĞ ĞŸĞ ĞĞ•ĞšĞ¢Ğ (100 Ğ±Ğ°Ğ»Ğ»Ğ¾Ğ²):

âœ… Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (40 Ğ±Ğ°Ğ»Ğ»Ğ¾Ğ²):
   â€¢ ĞšĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹
   â€¢ ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ĞºĞ¾Ğ´Ğ°
   â€¢ ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ

âœ… ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² (30 Ğ±Ğ°Ğ»Ğ»Ğ¾Ğ²):
   â€¢ Ğ ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
   â€¢ Ğ¡Ğ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ
   â€¢ Ğ Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²

âœ… ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ (20 Ğ±Ğ°Ğ»Ğ»Ğ¾Ğ²):
   â€¢ Ğ£Ğ´Ğ¾Ğ±ÑÑ‚Ğ²Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
   â€¢ Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ñ„Ğ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ
   â€¢ Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ

âœ… Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ (10 Ğ±Ğ°Ğ»Ğ»Ğ¾Ğ²):
   â€¢ ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹
   â€¢ Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
   â€¢ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
```

---

## ğŸ“ Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ±Ğ»Ğ¾ĞºĞ°

### Ğ§ĞµĞ¼Ñƒ Ğ²Ñ‹ Ğ½Ğ°ÑƒÑ‡Ğ¸Ğ»Ğ¸ÑÑŒ:

```
ğŸ§  Ğ¢Ğ•ĞĞ Ğ•Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• Ğ—ĞĞĞĞ˜Ğ¯:
â”œâ”€â”€ ĞœĞ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
â”œâ”€â”€ ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹ adversarial training
â”œâ”€â”€ Ğ”Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑ‹
â”œâ”€â”€ Meta-learning ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸
â””â”€â”€ ĞœÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ

ğŸ’» ĞŸĞ ĞĞšĞ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• ĞĞĞ’Ğ«ĞšĞ˜:
â”œâ”€â”€ Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ 6 Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
â”œâ”€â”€ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²ĞµĞ±-Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ ML
â”œâ”€â”€ ĞÑ†ĞµĞ½ĞºĞ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
â”œâ”€â”€ Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸
â””â”€â”€ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€

ğŸš€ Ğ“ĞĞ¢ĞĞ’ĞĞĞ¡Ğ¢Ğ¬ Ğš ĞŸĞ Ğ˜ĞœĞ•ĞĞ•ĞĞ˜Ğ®:
â”œâ”€â”€ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹
â”œâ”€â”€ Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€
â”œâ”€â”€ Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ SOTA Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸
â””â”€â”€ Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡
```

### Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸:

1. **Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚Ğµ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹:** Stable Diffusion, DALL-E 2, Midjourney
2. **Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸:** Ğ Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ loss functions, Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹
3. **Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ Ğ¿Ğ¾Ñ€Ñ‚Ñ„Ğ¾Ğ»Ğ¸Ğ¾:** Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹
4. **Ğ¡Ğ»ĞµĞ´Ğ¸Ñ‚Ğµ Ğ·Ğ° Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸:** ĞĞ¾Ğ²Ñ‹Ğµ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹

### ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğµ Ñ€ĞµÑÑƒÑ€ÑÑ‹:

```
ğŸ“š Ğ”ĞĞŸĞĞ›ĞĞ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞĞ• Ğ˜Ğ—Ğ£Ğ§Ğ•ĞĞ˜Ğ•:
â”œâ”€â”€ Papers With Code (Generative Models)
â”œâ”€â”€ Hugging Face Transformers
â”œâ”€â”€ OpenAI API Documentation
â”œâ”€â”€ Stability AI Research
â””â”€â”€ Google Research Blog

ğŸ› ï¸ Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞœĞ•ĞĞ¢Ğ«:
â”œâ”€â”€ PyTorch / TensorFlow
â”œâ”€â”€ Hugging Face Diffusers
â”œâ”€â”€ OpenAI CLIP
â”œâ”€â”€ Streamlit / Gradio
â””â”€â”€ Weights & Biases
```

**ğŸ‰ ĞŸĞ¾Ğ·Ğ´Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸ĞµĞ¼ Ğ±Ğ»Ğ¾ĞºĞ° "Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğµ Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸"!**

Ğ’Ñ‹ Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ²Ğ»Ğ°Ğ´ĞµĞµÑ‚Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¸Ğ· ÑĞ°Ğ¼Ñ‹Ñ… Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ĞµĞ¹ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ÑÑ‚ Ğ±ĞµĞ·Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ñ‚Ğ²Ğ¾Ñ€Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¸ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ğ¹. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ÑƒĞ´Ğ¸Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°Ğ¹Ñ‚Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ñƒ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¸Ğ²Ğ°ÑÑ‰ÑƒÑÑÑ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑŒ!