# Блок 1: Математические основы и базовые концепции

**⏱ Длительность:** 4-6 недель  
**🎯 Цель:** Заложить прочный математический фундамент для понимания нейронных сетей

---

## 📊 Обзор блока

```
Математические основы Deep Learning
├── Линейная алгебра ──────────────┐
├── Математический анализ ─────────┤
├── Теория вероятностей ───────────┼─── Градиентный спуск ──┐
├── Основы оптимизации ────────────┘                        │
└── Введение в ML ──────────────────────────────────────────┘
                                                             │
                                                             ▼
                                                    Нейронные сети
```

---

## Глава 1.1: Линейная алгебра для машинного обучения
**📅 Длительность:** 1 неделя

### 🎯 Зачем нужна линейная алгебра?

Нейронные сети - это по сути операции с многомерными массивами (тензорами). Каждый слой сети выполняет матричные умножения:

```
Входные данные    Веса слоя    Результат
     [x₁]           [w₁₁ w₁₂]     [y₁]
     [x₂]     ×     [w₂₁ w₂₂]  =  [y₂]
     
X (batch×features) × W (features×neurons) = Y (batch×neurons)
```

### 📐 Ключевые концепции

#### 1. Векторы и операции с ними

```
Вектор: v = [v₁, v₂, v₃]

Операции:
┌─────────────────┬─────────────────┬─────────────────┐
│ Сложение        │ Скалярное       │ Длина (норма)   │
│ a + b = [a₁+b₁] │ произведение:   │ ||v|| = √(v₁²+  │
│        [a₂+b₂]  │ a·b = a₁b₁+a₂b₂ │       v₂²+v₃²)  │
└─────────────────┴─────────────────┴─────────────────┘
```

#### 2. Матрицы и их свойства

```
Матрица A (m×n):
┌─────────────────────────────────────┐
│ a₁₁  a₁₂  a₁₃  ... a₁ₙ            │
│ a₂₁  a₂₂  a₂₃  ... a₂ₙ            │
│ ...  ...  ...  ... ...            │
│ aₘ₁  aₘ₂  aₘ₃  ... aₘₙ            │
└─────────────────────────────────────┘

Умножение матриц: A(m×k) × B(k×n) = C(m×n)
C[i,j] = Σ(A[i,l] × B[l,j]) для l=1..k
```

#### 3. Собственные векторы и значения

```
Av = λv

где: A - матрица
     v - собственный вектор  
     λ - собственное значение

Геометрический смысл:
───────────────────────
v ────A────► λv
(вектор не меняет направление, только масштабируется)
```

### 💻 Практический пример

```python
import numpy as np

# Создание матрицы весов для нейронного слоя
weights = np.random.normal(0, 0.1, (784, 128))  # MNIST: 784 пикселя → 128 нейронов
bias = np.zeros(128)

# Прямое распространение для одного примера
input_image = np.random.rand(784)  # Пример: изображение 28×28 = 784 пикселя
output = np.dot(input_image, weights) + bias
print(f"Размер входа: {input_image.shape}")
print(f"Размер весов: {weights.shape}")  
print(f"Размер выхода: {output.shape}")
```

### ✅ Чек-лист главы 1.1
- [ ] Понимаю, что такое вектор и как с ним работать
- [ ] Могу выполнить матричное умножение вручную (для малых матриц)
- [ ] Понимаю связь между матричными операциями и нейронными сетями
- [ ] Знаю, что такое собственные векторы и зачем они нужны

---

## Глава 1.2: Математический анализ
**📅 Длительность:** 1 неделя

### 🎯 Зачем нужен матанализ?

Обучение нейронных сетей = поиск минимума функции потерь с помощью градиентов:

```
Функция потерь     Градиент        Обновление весов
     L(w)     →   ∇L = ∂L/∂w   →   w := w - α∇L

┌─────────────────────────────────────────────────────┐
│           Ландшафт функции потерь                   │
│                                                     │
│     ╭─╮                                            │
│    ╱   ╲                    🎯 глобальный          │
│   ╱     ╲      ╭╮             минимум              │
│  ╱       ╲    ╱  ╲                                 │
│ ╱         ╲  ╱    ╲                               │
│╱           ╲╱      ╲                              │
│             ▼ градиент показывает направление      │
│                     наискорейшего спуска          │
└─────────────────────────────────────────────────────┘
```

### 📐 Ключевые концепции

#### 1. Производная и её смысл

```
Производная f'(x) = lim[h→0] (f(x+h) - f(x))/h

Геометрический смысл:
───────────────────
      ╱ ← касательная (наклон = производная)
     ╱
f(x)╱
   ╱
  ╱────────► x
```

#### 2. Частные производные

```
Для функции f(x,y):

∂f/∂x - частная производная по x (y считается константой)
∂f/∂y - частная производная по y (x считается константой)

Пример: f(x,y) = x² + 3xy + y²
∂f/∂x = 2x + 3y
∂f/∂y = 3x + 2y
```

#### 3. Градиент - вектор частных производных

```
∇f = [∂f/∂x₁, ∂f/∂x₂, ..., ∂f/∂xₙ]

Свойства градиента:
┌─────────────────────────────────┐
│ • Показывает направление        │
│   наискорейшего возрастания     │
│ • -∇f показывает направление    │
│   наискорейшего убывания        │
│ • |∇f| = скорость изменения     │
└─────────────────────────────────┘
```

#### 4. Цепное правило - основа backpropagation

```
Композиция функций: z = f(g(x))

dz/dx = dz/dg × dg/dx

Для нейронных сетей:
input → layer1 → layer2 → layer3 → output → loss
  x   →   h₁   →   h₂   →   h₃   →   ŷ    →   L

∂L/∂w₁ = ∂L/∂ŷ × ∂ŷ/∂h₃ × ∂h₃/∂h₂ × ∂h₂/∂h₁ × ∂h₁/∂w₁
        └────────── backpropagation ──────────┘
```

### 💻 Практический пример

```python
import numpy as np

# Простая функция потерь: L = (y_true - y_pred)²
def loss_function(y_true, y_pred):
    return (y_true - y_pred) ** 2

# Градиент функции потерь по предсказанию
def loss_gradient(y_true, y_pred):
    return -2 * (y_true - y_pred)

# Пример вычисления градиента
y_true = 1.0
y_pred = 0.5
gradient = loss_gradient(y_true, y_pred)
print(f"Градиент: {gradient}")  # Выведет: 1.0 (нужно увеличить предсказание)
```

### ✅ Чек-лист главы 1.2
- [ ] Понимаю геометрический смысл производной
- [ ] Могу вычислить частные производные простых функций
- [ ] Понимаю, что такое градиент и как он связан с оптимизацией
- [ ] Знаю цепное правило и его роль в обучении нейросетей

---

## Глава 1.3: Теория вероятностей и статистика
**📅 Длительность:** 1 неделя

### 🎯 Зачем нужна теория вероятностей?

Машинное обучение работает с неопределенностью и неполными данными:

```
Реальный мир                    Модель
─────────────                   ──────
Зашумленные данные       →     Вероятностные предсказания
Неполная информация      →     Доверительные интервалы  
Случайные процессы       →     Байесовский подход
```

### 📐 Ключевые концепции

#### 1. Основы вероятности

```
Вероятность события A: P(A) ∈ [0, 1]

Свойства:
┌─────────────────────────────────┐
│ P(A) + P(A̅) = 1               │
│ P(A ∪ B) = P(A) + P(B) - P(A∩B)│
│ P(A ∩ B) = P(A) × P(B|A)       │
└─────────────────────────────────┘

Классический пример: бросок кубика
P(четное число) = P(2,4,6) = 3/6 = 0.5
```

#### 2. Условная вероятность и теорема Байеса

```
P(A|B) = P(A ∩ B) / P(B)

Теорема Байеса:
P(A|B) = P(B|A) × P(A) / P(B)

В ML: P(класс|признаки) = P(признаки|класс) × P(класс) / P(признаки)
                         └─── модель ────┘   └─── приор ───┘
```

#### 3. Распределения вероятностей

```
Нормальное распределение N(μ, σ²):
    
        │    μ=0, σ=1 (стандартное)
   0.4  │      ╭─╮
        │     ╱   ╲
   0.3  │    ╱     ╲
        │   ╱       ╲
   0.2  │  ╱         ╲
        │ ╱           ╲
   0.1  │╱             ╲
        └──────────────────► x
       -3  -2  -1  0  1  2  3

68% данных в [μ-σ, μ+σ]
95% данных в [μ-2σ, μ+2σ]
```

#### 4. Статистические метрики

```
Для классификации:
┌─────────────┬─────────────┐
│  Реальность │ Предсказание│
├─────────────┼─────────────┤
│             │  +    -     │
│ Факт   +    │ TP   FN     │
│        -    │ FP   TN     │
└─────────────┴─────────────┘

Accuracy = (TP + TN) / (TP + TN + FP + FN)
Precision = TP / (TP + FP)
Recall = TP / (TP + FN)
F1-score = 2 × (Precision × Recall) / (Precision + Recall)
```

### 💻 Практический пример

```python
import numpy as np
from scipy import stats

# Генерация данных из нормального распределения
data = np.random.normal(loc=0, scale=1, size=1000)

# Основные статистики
mean = np.mean(data)
std = np.std(data)
print(f"Среднее: {mean:.3f}, Стандартное отклонение: {std:.3f}")

# Проверка гипотезы: "среднее равно 0"
t_stat, p_value = stats.ttest_1samp(data, 0)
print(f"p-value: {p_value:.3f}")
if p_value < 0.05:
    print("Отвергаем H₀: среднее НЕ равно 0")
else:
    print("Не можем отвергнуть H₀: среднее равно 0")
```

### ✅ Чек-лист главы 1.3
- [ ] Понимаю основные понятия теории вероятностей
- [ ] Знаю теорему Байеса и её применение в ML
- [ ] Понимаю нормальное распределение и его свойства
- [ ] Умею интерпретировать метрики качества классификации

---

## Глава 1.4: Основы оптимизации
**📅 Длительность:** 1 неделя

### 🎯 Зачем нужна оптимизация?

Обучение нейронной сети = решение задачи оптимизации:

```
Найти: w* = argmin L(w)
              w

где L(w) - функция потерь, w - параметры модели

Проблема: L(w) сложная, невыпуклая, многомерная функция
Решение: Итеративные методы градиентного спуска
```

### 📐 Градиентный спуск - сердце обучения

#### 1. Базовый алгоритм

```
Repeat until convergence:
    1. Вычислить градиент: g = ∇L(w)
    2. Обновить веса: w := w - α × g
    
где α (learning rate) - размер шага

Визуализация:
    
    L(w) │                  
         │     ╭─╮         ← старт здесь
         │    ╱   ╲        
         │   ╱  ●  ╲  ←── шаг 1: w₁ = w₀ - α∇L(w₀)
         │  ╱   ↓   ╲
         │ ╱     ●   ╲ ←─ шаг 2: w₂ = w₁ - α∇L(w₁)  
         │╱       ↓   ╲
         │         ●   ╲← шаг 3: w₃ = w₂ - α∇L(w₂)
         └──────────●───► w  ← минимум найден!
```

#### 2. Стохастический градиентный спуск (SGD)

```
Проблема: Вычисление градиента по всему датасету медленно

Решение: Используем мини-батчи

Обычный GD:        ∇L = (1/N) Σ ∇L_i     (по всем N примерам)
                              i=1

Стохастический:    ∇L ≈ (1/B) Σ ∇L_i     (по батчу размера B)
                              i∈batch

Преимущества SGD:
┌─────────────────────────────────┐
│ ✓ Быстрее вычисления           │
│ ✓ Может выбираться из локальных │
│   минимумов за счет шума        │
│ ✓ Онлайн обучение              │
└─────────────────────────────────┘
```

#### 3. Продвинутые оптимизаторы

```
Momentum: учитывает "инерцию" движения
─────────
v := β × v + (1-β) × ∇L
w := w - α × v

Adam: адаптивный learning rate
─────
m := β₁ × m + (1-β₁) × ∇L        (momentum)
v := β₂ × v + (1-β₂) × (∇L)²     (RMSprop)
w := w - α × m / (√v + ε)

Сравнение траекторий:
    
    │  SGD ──────╲
    │            ╲
    │ Momentum ───╲╲──╮
    │              ╲╲ │ быстрее
    │ Adam ────────╲╲╲
    │               ╲╲╲
    └─────────────────●─► минимум
```

### 💻 Практический пример

```python
import numpy as np

class SimpleOptimizer:
    def __init__(self, learning_rate=0.01):
        self.lr = learning_rate
    
    def sgd_step(self, weights, gradients):
        """Обычный SGD"""
        return weights - self.lr * gradients
    
    def momentum_step(self, weights, gradients, velocity, beta=0.9):
        """SGD with Momentum"""
        velocity = beta * velocity + (1 - beta) * gradients
        return weights - self.lr * velocity, velocity

# Пример: минимизация функции f(x) = x²
def f(x):
    return x**2

def df_dx(x):
    return 2*x

# Градиентный спуск
x = 10.0  # начальная точка
optimizer = SimpleOptimizer(learning_rate=0.1)

for i in range(10):
    grad = df_dx(x)
    x = optimizer.sgd_step(x, grad)
    print(f"Шаг {i+1}: x = {x:.4f}, f(x) = {f(x):.4f}")
```

### ✅ Чек-лист главы 1.4
- [ ] Понимаю принцип работы градиентного спуска
- [ ] Знаю разницу между batch, mini-batch и stochastic GD
- [ ] Понимаю роль learning rate и его влияние на сходимость
- [ ] Знаю основные продвинутые оптимизаторы (Momentum, Adam)

---

## Глава 1.5: Введение в машинное обучение
**📅 Длительность:** 1-2 недели

### 🎯 От оптимизации к машинному обучению

Машинное обучение = автоматическое нахождение паттернов в данных:

```
Традиционное программирование:
Данные + Программа → Результат

Машинное обучение:
Данные + Результат → Программа (модель)
```

### 📐 Типы машинного обучения

#### 1. Supervised Learning (Обучение с учителем)

```
Есть пары (вход, правильный ответ)

Задачи:
┌─────────────────┬─────────────────┐
│ Классификация   │ Регрессия       │
├─────────────────┼─────────────────┤
│ Дискретный      │ Непрерывный     │
│ результат       │ результат       │
│                 │                 │
│ "Кот или собака"│ "Цена дома"     │
│ "Спам или нет"  │ "Температура"   │
└─────────────────┴─────────────────┘

Примеры алгоритмов:
• Линейная регрессия
• Логистическая регрессия  
• Деревья решений
• Нейронные сети
```

#### 2. Unsupervised Learning (Обучение без учителя)

```
Есть только входные данные, нет правильных ответов

Задачи:
┌─────────────────┬─────────────────┐
│ Кластеризация   │ Снижение        │
│                 │ размерности     │
├─────────────────┼─────────────────┤
│ Группировка     │ Сжатие данных   │
│ похожих объектов│ Визуализация    │
│                 │                 │
│ K-means         │ PCA             │
│ DBSCAN          │ t-SNE           │
└─────────────────┴─────────────────┘
```

#### 3. Reinforcement Learning (Обучение с подкреплением)

```
Агент взаимодействует со средой и получает награды

Схема:
Agent ←──── state, reward ────┐
  │                           │
  └── action ──→ Environment ─┘

Примеры:
• Игры (шахматы, Go, видеоигры)
• Робототехника
• Рекомендательные системы
• Автономные автомобили
```

### 📐 Ключевые проблемы ML

#### 1. Переобучение (Overfitting) vs Недообучение (Underfitting)

```
Training Loss vs Validation Loss

Loss │
     │ ╭─ Underfitting ──╮  ╭── Overfitting ──╮
     │ │                 │  │                  │
     │ │ High bias       │  │ High variance    │
     │ │ Простая модель  │  │ Сложная модель   │
     │ ╰─────────────────╯  ╰──────────────────╯
     │        ╲                      ╱ validation
     │         ╲                    ╱  loss
     │          ╲────────╲         ╱
     │                   ╲───────╱ 
     │ ───────────────────╲─────────── training loss
     └────────────────────────────────► Model Complexity

Золотая середина: модель достаточно сложная, но не переобучается
```

#### 2. Bias-Variance Trade-off

```
Total Error = Bias² + Variance + Irreducible Error

Bias (смещение):
┌─────────────────────────────────┐
│ Ошибка из-за слишком простых    │
│ предположений модели            │
│                                 │
│ Высокий bias → Underfitting     │
└─────────────────────────────────┘

Variance (разброс):
┌─────────────────────────────────┐
│ Ошибка из-за чувствительности   │
│ к малым изменениям данных       │
│                                 │
│ Высокий variance → Overfitting  │
└─────────────────────────────────┘
```

#### 3. Кросс-валидация

```
K-Fold Cross Validation (k=5):

Fold 1: [TEST] [train] [train] [train] [train]
Fold 2: [train] [TEST] [train] [train] [train]  
Fold 3: [train] [train] [TEST] [train] [train]
Fold 4: [train] [train] [train] [TEST] [train]
Fold 5: [train] [train] [train] [train] [TEST]

Результат: CV Score = (Score₁ + Score₂ + ... + Score₅) / 5

Преимущества:
• Используем все данные для обучения и тестирования
• Более надежная оценка качества модели
• Помогает выявить переобучение
```

### 💻 Практический пример

```python
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np

# Создаем синтетический датасет
np.random.seed(42)
X = np.random.randn(1000, 1)
y = 2 * X.ravel() + np.random.randn(1000) * 0.1  # y = 2x + шум

# Разделяем на train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Обучаем модель
model = LinearRegression()
model.fit(X_train, y_train)

# Оценка качества
train_score = model.score(X_train, y_train)
test_score = model.score(X_test, y_test)

print(f"R² на train: {train_score:.3f}")
print(f"R² на test: {test_score:.3f}")

# Кросс-валидация
cv_scores = cross_val_score(model, X_train, y_train, cv=5)
print(f"CV scores: {cv_scores}")
print(f"CV mean: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}")
```

### 🔄 Deep Learning vs Traditional ML

```
Traditional ML                    Deep Learning
──────────────                    ─────────────

Данные → Feature Engineering → ML Algorithm → Prediction
         (ручное создание          
          признаков)              

Данные ──────────→ Neural Network ──────────→ Prediction
                   (автоматическое извлечение признаков)

Преимущества DL:
┌─────────────────────────────────┐
│ ✓ Автоматическое извлечение     │
│   признаков                     │
│ ✓ Работа с сырыми данными       │
│ ✓ Масштабируется с количеством  │
│   данных                        │
│ ✓ State-of-the-art результаты   │
│   в CV, NLP, речи               │
└─────────────────────────────────┘
```

### ✅ Чек-лист главы 1.5
- [ ] Понимаю типы машинного обучения и их применение
- [ ] Знаю проблемы overfitting/underfitting и способы их решения
- [ ] Понимаю важность правильного разделения данных
- [ ] Знаю основные метрики качества для разных задач
- [ ] Понимаю, чем Deep Learning отличается от традиционного ML

---

## 🏆 Итоговый результат Блока 1

После завершения этого блока вы будете:

### ✅ Знать математику:
- Выполнять матричные операции для нейросетей
- Вычислять градиенты и понимать их геометрический смысл
- Применять основы теории вероятностей для оценки моделей
- Понимать принципы оптимизации и градиентного спуска

### ✅ Понимать ML:
- Различать типы машинного обучения
- Избегать переобучения и правильно валидировать модели
- Выбирать подходящие метрики качества
- Понимать место Deep Learning в экосистеме ML

### ✅ Быть готовыми к:
- Изучению архитектур нейронных сетей
- Пониманию алгоритма backpropagation
- Работе с реальными датасетами
- Реализации нейросетей с нуля

---

## 📝 Итоговое задание

**Задача:** Реализовать градиентный спуск для линейной регрессии с нуля

**Требования:**
1. Создать синтетический датасет с шумом
2. Реализовать функцию потерь (MSE) и её градиент
3. Реализовать SGD с Momentum
4. Визуализировать процесс обучения
5. Сравнить с sklearn.LinearRegression

**Критерии успеха:**
- Ваша реализация должна сходиться к тому же решению, что и sklearn
- График функции потерь должен показывать убывание
- Финальная ошибка < 0.1 от ошибки sklearn

**Время на выполнение:** 2-3 дня

---

**🎯 Следующий блок:** Основы нейронных сетей и их реализация

Теперь, имея прочный математический фундамент, мы готовы перейти к изучению того, как устроены и работают нейронные сети!