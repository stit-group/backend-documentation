# üß† –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –≥–ª—É–±–æ–∫–æ–º—É –æ–±—É—á–µ–Ω–∏—é —Å PyTorch
*–û—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Å–Ω–æ–≤ –¥–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä*

---

## üéØ –û —á–µ–º —ç—Ç–æ—Ç –º–∞—Ç–µ—Ä–∏–∞–ª

–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –æ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Å–Ω–æ–≤ –¥–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. **–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥:** –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞ ‚Üí –¥–∞–Ω–Ω—ã–µ ‚Üí –∑–∞–¥–∞—á–∏ ‚Üí –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ‚Üí –ø—Ä–∞–∫—Ç–∏–∫–∞.

**–ß—Ç–æ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ:**
- üßÆ –ü–æ–Ω–∏–º–∞–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Å–Ω–æ–≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π
- üìä –ó–Ω–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–¥–∞—á –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- üèóÔ∏è –ì–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
- ‚ö° –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏ –Ω–∞ PyTorch

---

# üìö –ë–õ–û–ö 1: –ú–ê–¢–ï–ú–ê–¢–ò–ß–ï–°–ö–ò–ï –û–°–ù–û–í–´

## –ì–ª–∞–≤–∞ 1: –õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞

### üéØ –ó–∞—á–µ–º –Ω—É–∂–Ω–∞ –ª–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞
–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ - —ç—Ç–æ –∫–æ–º–ø–æ–∑–∏—Ü–∏—è –ª–∏–Ω–µ–π–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π —Å –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–º–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è–º–∏. –ü–æ–Ω–∏–º–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ –∏ –º–∞—Ç—Ä–∏—Ü –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ.

### üìê –í–µ–∫—Ç–æ—Ä—ã –∏ –æ–ø–µ—Ä–∞—Ü–∏–∏

```
–í–µ–∫—Ç–æ—Ä x = [x‚ÇÅ, x‚ÇÇ, x‚ÇÉ]·µÄ

‚ú® –û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏:
‚Ä¢ –°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ: x¬∑y = x‚ÇÅy‚ÇÅ + x‚ÇÇy‚ÇÇ + x‚ÇÉy‚ÇÉ
‚Ä¢ –ù–æ—Ä–º–∞ –≤–µ–∫—Ç–æ—Ä–∞: ||x|| = ‚àö(x‚ÇÅ¬≤ + x‚ÇÇ¬≤ + x‚ÇÉ¬≤)
‚Ä¢ –ö–æ—Å–∏–Ω—É—Å —É–≥–ª–∞: cos(Œ∏) = (x¬∑y)/(||x|| ||y||)
```

### üî¢ –ú–∞—Ç—Ä–∏—Ü—ã - –æ—Å–Ω–æ–≤–∞ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π

```
–õ–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: y = Wx + b

W = [w‚ÇÅ‚ÇÅ w‚ÇÅ‚ÇÇ w‚ÇÅ‚ÇÉ]    x = [x‚ÇÅ]    b = [b‚ÇÅ]
    [w‚ÇÇ‚ÇÅ w‚ÇÇ‚ÇÇ w‚ÇÇ‚ÇÉ]        [x‚ÇÇ]        [b‚ÇÇ]
                          [x‚ÇÉ]

üí° –†–µ–∑—É–ª—å—Ç–∞—Ç: 
y‚ÇÅ = w‚ÇÅ‚ÇÅx‚ÇÅ + w‚ÇÅ‚ÇÇx‚ÇÇ + w‚ÇÅ‚ÇÉx‚ÇÉ + b‚ÇÅ
y‚ÇÇ = w‚ÇÇ‚ÇÅx‚ÇÅ + w‚ÇÇ‚ÇÇx‚ÇÇ + w‚ÇÇ‚ÇÉx‚ÇÉ + b‚ÇÇ
```

### üíª –ü—Ä–∞–∫—Ç–∏–∫–∞ —Å PyTorch

```python
import torch
import numpy as np

# üöÄ –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ PyTorch
x = torch.tensor([1.0, 2.0, 3.0])
y = torch.tensor([4.0, 5.0, 6.0])

# –°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
dot_product = torch.dot(x, y)  # 32.0

# L2 –Ω–æ—Ä–º–∞
l2_norm = torch.norm(x)  # 3.742

# –ú–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ
W = torch.randn(2, 3)  # –°–ª—É—á–∞–π–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ 2x3
b = torch.randn(2)     # Bias –≤–µ–∫—Ç–æ—Ä
output = torch.matmul(W, x) + b  # –õ–∏–Ω–µ–π–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è
```

### üîç –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è

```
Ax = Œªx, –≥–¥–µ Œª - —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, x - —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä

üí° –ò–Ω—Ç—É–∏—Ü–∏—è: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è, –≤–¥–æ–ª—å –∫–æ—Ç–æ—Ä—ã—Ö –º–∞—Ç—Ä–∏—Ü–∞ —Ç–æ–ª—å–∫–æ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç
üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: PCA, –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö
```

---

## –ì–ª–∞–≤–∞ 2: –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

### üìà –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ - –æ—Å–Ω–æ–≤–∞ –æ–±—É—á–µ–Ω–∏—è

```
–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è f'(x) = lim[h‚Üí0] (f(x+h) - f(x))/h

üìê –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª: –Ω–∞–∫–ª–æ–Ω –∫–∞—Å–∞—Ç–µ–ª—å–Ω–æ–π
‚ö° –§–∏–∑–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª: —Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏
üß† ML —Å–º—ã—Å–ª: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–∏—Å–∫–æ—Ä–µ–π—à–µ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—è
```

### üßÆ –ü—Ä–∞–≤–∏–ª–∞ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è

```python
# üìö –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞
# (f + g)' = f' + g'
# (f * g)' = f'g + fg'
# (f(g(x)))' = f'(g(x)) * g'(x)  ‚Üê –¶–µ–ø–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ!

# üåü –ü—Ä–∏–º–µ—Ä—ã –≤–∞–∂–Ω—ã—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö
def sigmoid(x):
    return 1 / (1 + torch.exp(-x))

def sigmoid_derivative(x):
    s = sigmoid(x)
    return s * (1 - s)  # –û—á–µ–Ω—å —ç–ª–µ–≥–∞–Ω—Ç–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞! ‚ú®

def relu_derivative(x):
    return (x > 0).float()  # 1 –µ—Å–ª–∏ x > 0, –∏–Ω–∞—á–µ 0
```

### üéØ –ß–∞—Å—Ç–Ω—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç

```
–§—É–Ω–∫—Ü–∏—è –º–Ω–æ–≥–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: f(x‚ÇÅ, x‚ÇÇ, ..., x‚Çô)

‚àÇ –ß–∞—Å—Ç–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è: ‚àÇf/‚àÇx·µ¢ (—Ñ–∏–∫—Å–∏—Ä—É–µ–º –≤—Å–µ –∫—Ä–æ–º–µ x·µ¢)
‚àá –ì—Ä–∞–¥–∏–µ–Ω—Ç: ‚àáf = [‚àÇf/‚àÇx‚ÇÅ, ‚àÇf/‚àÇx‚ÇÇ, ..., ‚àÇf/‚àÇx‚Çô]·µÄ

‚≠ê –°–≤–æ–π—Å—Ç–≤–æ: –≥—Ä–∞–¥–∏–µ–Ω—Ç —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–∏—Å–∫–æ—Ä–µ–π—à–µ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—è
```

### üî• –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
# ‚ö° –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ PyTorch
x = torch.tensor([2.0, 3.0], requires_grad=True)
y = x[0]**2 + x[1]**3  # f(x‚ÇÅ,x‚ÇÇ) = x‚ÇÅ¬≤ + x‚ÇÇ¬≥

y.backward()  # –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
print(x.grad)  # [4.0, 27.0] = [2*x‚ÇÅ, 3*x‚ÇÇ¬≤]
```

### üîó –¶–µ–ø–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ - —Å–µ—Ä–¥—Ü–µ backpropagation

```
–ö–æ–º–ø–æ–∑–∏—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–π: h(x) = f(g(x))
–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è: h'(x) = f'(g(x)) * g'(x)

üß† –í –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö:
x ‚Üí —Å–ª–æ–π1 ‚Üí —Å–ª–æ–π2 ‚Üí ... ‚Üí –≤—ã—Ö–æ–¥ ‚Üí –æ—à–∏–±–∫–∞
‚¨ÖÔ∏è –ì—Ä–∞–¥–∏–µ–Ω—Ç –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞–∑–∞–¥ –ø–æ —Ü–µ–ø–Ω–æ–º—É –ø—Ä–∞–≤–∏–ª—É
```

---

## –ì–ª–∞–≤–∞ 3: –¢–µ–æ—Ä–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

### üé≤ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∏ —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ–ª–∏—á–∏–Ω—ã

```
P(A) - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏—è A
P(A|B) - —É—Å–ª–æ–≤–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å A –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ B

üßÆ –¢–µ–æ—Ä–µ–º–∞ –ë–∞–π–µ—Å–∞: P(A|B) = P(B|A) * P(A) / P(B)
üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ ML: –Ω–∞–∏–≤–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
```

### üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è

```python
import torch.distributions as dist

# üìà –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ N(Œº, œÉ¬≤)
normal = dist.Normal(0, 1)  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª—å
samples = normal.sample((1000,))

# üéØ –ë–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
binomial = dist.Binomial(10, 0.5)  # 10 –∏—Å–ø—ã—Ç–∞–Ω–∏–π, p=0.5

# ‚öñÔ∏è –ë–µ—Ä–Ω—É–ª–ª–∏ (–¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
bernoulli = dist.Bernoulli(0.7)  # p=0.7
```

### üìè –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã

```
üìä –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ: E[X] = Œº
üìà –î–∏—Å–ø–µ—Ä—Å–∏—è: Var[X] = E[(X-Œº)¬≤] = œÉ¬≤
üìê –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: œÉ = ‚àöVar[X]

üî¢ –î–ª—è –≤—ã–±–æ—Ä–∫–∏:
xÃÑ = (1/n) Œ£x·µ¢  (–≤—ã–±–æ—Ä–æ—á–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ)
s¬≤ = (1/(n-1)) Œ£(x·µ¢ - xÃÑ)¬≤  (–≤—ã–±–æ—Ä–æ—á–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è)
```

### üí° –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏ —ç–Ω—Ç—Ä–æ–ø–∏—è

```
üîç –≠–Ω—Ç—Ä–æ–ø–∏—è: H(X) = -Œ£ p(x) log p(x)
üí≠ –ò–Ω—Ç—É–∏—Ü–∏—è: –º–µ—Ä–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏

‚ùå –ö—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è: H(p,q) = -Œ£ p(x) log q(x)
üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

üìä KL-–¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è: D_KL(p||q) = Œ£ p(x) log(p(x)/q(x))
üîç –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
```

```python
# üî• –ö—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è –≤ PyTorch
import torch.nn.functional as F

# –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (one-hot)
targets = torch.tensor([0, 1, 2])  # –ö–ª–∞—Å—Å—ã 0, 1, 2

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–ª–æ–≥–∏—Ç—ã)
predictions = torch.tensor([[2.0, 1.0, 0.1],
                           [0.5, 2.5, 1.0], 
                           [0.1, 0.2, 3.0]])

# –ö—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è
loss = F.cross_entropy(predictions, targets)
```

---

## –ì–ª–∞–≤–∞ 4: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

### ‚¨áÔ∏è –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫

```
üéØ –¶–µ–ª—å: –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å L(Œ∏)

üîÑ –ê–ª–≥–æ—Ä–∏—Ç–º:
Œ∏_{t+1} = Œ∏_t - Œ∑ * ‚àáL(Œ∏_t)

–≥–¥–µ Œ∑ - learning rate (—à–∞–≥ –æ–±—É—á–µ–Ω–∏—è)
```

### ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞

```
1. üï≥Ô∏è –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã
2. üèîÔ∏è –°–µ–¥–ª–æ–≤—ã–µ —Ç–æ—á–∫–∏  
3. ‚öñÔ∏è –ü–ª–æ—Ö–∞—è –æ–±—É—Å–ª–æ–≤–ª–µ–Ω–Ω–æ—Å—Ç—å (—Ä–∞–∑–Ω—ã–µ –º–∞—Å—à—Ç–∞–±—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤)
4. üéõÔ∏è –í—ã–±–æ—Ä learning rate
```

### üöÄ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã

```python
# üå™Ô∏è Momentum - —É—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
# v_{t+1} = Œ≤*v_t + (1-Œ≤)*‚àáL(Œ∏_t)
# Œ∏_{t+1} = Œ∏_t - Œ∑*v_{t+1}
optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)

# üß† Adam - –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π learning rate
# –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç momentum –∏ RMSprop
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))

# ‚ö° AdamW - Adam —Å –≤–µ—Å–æ–≤—ã–º –∑–∞—Ç—É—Ö–∞–Ω–∏–µ–º
optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
```

---

# üìä –ë–õ–û–ö 2: –¢–ò–ü–´ –î–ê–ù–ù–´–• –ò –ó–ê–î–ê–ß–ò –ò–ò

## –ì–ª–∞–≤–∞ 5: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

### üìã –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

```
üìä –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: —Å—Ç—Ä–æ–∫–∏ = –ø—Ä–∏–º–µ—Ä—ã, —Å—Ç–æ–ª–±—Ü—ã = –ø—Ä–∏–∑–Ω–∞–∫–∏
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –í–æ–∑—Ä–∞—Å—Ç     ‚îÇ –î–æ—Ö–æ–¥       ‚îÇ –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ ‚îÇ –ö–ª–∞—Å—Å       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 25          ‚îÇ 50000       ‚îÇ –í—ã—Å—à–µ–µ      ‚îÇ –û–¥–æ–±—Ä–µ–Ω     ‚îÇ
‚îÇ 45          ‚îÇ 80000       ‚îÇ –°—Ä–µ–¥–Ω–µ–µ     ‚îÇ –û–¥–æ–±—Ä–µ–Ω     ‚îÇ
‚îÇ 22          ‚îÇ 30000       ‚îÇ –°—Ä–µ–¥–Ω–µ–µ     ‚îÇ –û—Ç–∫–ª–æ–Ω–µ–Ω    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: MLP, –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥, SVM
```

### üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

```
üìê 2D —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: –≤—ã—Å–æ—Ç–∞ √ó —à–∏—Ä–∏–Ω–∞ √ó –∫–∞–Ω–∞–ª—ã
üé® RGB: 3 –∫–∞–Ω–∞–ª–∞ (–∫—Ä–∞—Å–Ω—ã–π, –∑–µ–ª–µ–Ω—ã–π, —Å–∏–Ω–∏–π)
‚ö´ Grayscale: 1 –∫–∞–Ω–∞–ª

üí° –ü—Ä–∏–º–µ—Ä: 224√ó224√ó3 = 150,528 –ø–∏–∫—Å–µ–ª–µ–π
üéØ –ö–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å: –∑–Ω–∞—á–µ–Ω–∏–µ 0-255 (–∏–ª–∏ 0-1 –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)

üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: CNN (ResNet, EfficientNet, Vision Transformer)
```

### üìù –¢–µ–∫—Å—Ç—ã

```
üìú –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–æ–≤/—Å–ª–æ–≤
‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã: –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª–∏–Ω–∞, –ø–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω, –∫–æ–Ω—Ç–µ–∫—Å—Ç

üî§ –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è:
‚Ä¢ One-hot encoding: [0,0,1,0,0] –¥–ª—è —Å–ª–æ–≤–∞—Ä—è –∏–∑ 5 —Å–ª–æ–≤
‚Ä¢ Word embeddings: –ø–ª–æ—Ç–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, 300 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏)
‚Ä¢ Subword tokens: BPE, WordPiece

üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: RNN, LSTM, Transformer (BERT, GPT)
```

### üéµ –ê—É–¥–∏–æ

```
üìà –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã: –∞–º–ø–ª–∏—Ç—É–¥–∞ –∑–≤—É–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
üéöÔ∏è –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: 16kHz, 44.1kHz

üéº –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è:
‚Ä¢ Waveform: –∏—Å—Ö–æ–¥–Ω—ã–π —Å–∏–≥–Ω–∞–ª
‚Ä¢ –°–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞: —á–∞—Å—Ç–æ—Ç–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è
‚Ä¢ MFCC: mel-frequency cepstral coefficients

üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: 1D CNN, RNN, Transformer
```

### ‚è∞ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã

```
üìÖ –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –≤–æ –≤—Ä–µ–º–µ–Ω–∏
üìä –°–≤–æ–π—Å—Ç–≤–∞: —Ç—Ä–µ–Ω–¥, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è

üí° –ü—Ä–∏–º–µ—Ä—ã:
‚Ä¢ üí∞ –¶–µ–Ω—ã –∞–∫—Ü–∏–π
‚Ä¢ üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
‚Ä¢ üìà –ü—Ä–æ–¥–∞–∂–∏ –ø–æ –º–µ—Å—è—Ü–∞–º

üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: ARIMA, LSTM, Temporal CNN
```

---

## –ì–ª–∞–≤–∞ 6: –¢–∏–ø—ã –∑–∞–¥–∞—á –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

### üè∑Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

```
üéØ –¶–µ–ª—å: –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é (–∫–ª–∞—Å—Å)

üìß –ë–∏–Ω–∞—Ä–Ω–∞—è: —Å–ø–∞–º/–Ω–µ —Å–ø–∞–º, –±–æ–ª–µ–Ω/–∑–¥–æ—Ä–æ–≤
  üìè –ú–µ—Ç—Ä–∏–∫–∏: accuracy, precision, recall, F1, AUC-ROC

üñºÔ∏è –ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (1000 –∫–ª–∞—Å—Å–æ–≤ ImageNet)
  üìè –ú–µ—Ç—Ä–∏–∫–∏: accuracy, macro/micro F1

üè∑Ô∏è –ú–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–∞—è: —Ç–µ–≥ —Ñ–æ—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å [—Å–æ–±–∞–∫–∞, –ø–∞—Ä–∫, —Å–æ–ª–Ω–µ—á–Ω–æ]
  üìè –ú–µ—Ç—Ä–∏–∫–∏: Hamming loss, subset accuracy
```

```python
# üí° –ü—Ä–∏–º–µ—Ä –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
import torch.nn as nn

class BinaryClassifier(nn.Module):
    def __init__(self, input_size):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_size, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()  # –í—ã—Ö–æ–¥ –æ—Ç 0 –¥–æ 1
        )
    
    def forward(self, x):
        return self.layers(x)

# –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
criterion = nn.BCELoss()  # Binary Cross-Entropy
```

### üìà –†–µ–≥—Ä–µ—Å—Å–∏—è

```
üéØ –¶–µ–ª—å: –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

üí° –ü—Ä–∏–º–µ—Ä—ã:
‚Ä¢ üè† –¶–µ–Ω–∞ –¥–æ–º–∞ –ø–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º
‚Ä¢ üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∑–∞–≤—Ç—Ä–∞
‚Ä¢ ‚≠ê –†–µ–π—Ç–∏–Ω–≥ —Ñ–∏–ª—å–º–∞ (1-10)

üìè –ú–µ—Ç—Ä–∏–∫–∏:
‚Ä¢ MSE: Mean Squared Error
‚Ä¢ MAE: Mean Absolute Error  
‚Ä¢ R¬≤: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏
```

```python
class Regressor(nn.Module):
    def __init__(self, input_size):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_size, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)  # –û–¥–∏–Ω –≤—ã—Ö–æ–¥, –±–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        )
    
    def forward(self, x):
        return self.layers(x)

# –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
criterion = nn.MSELoss()
```

### üîç –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (–±–µ–∑ —É—á–∏—Ç–µ–ª—è)

```
üéØ –¶–µ–ª—å: –Ω–∞–π—Ç–∏ —Å–∫—Ä—ã—Ç—ã–µ –≥—Ä—É–ø–ø—ã –≤ –¥–∞–Ω–Ω—ã—Ö

üîß –ê–ª–≥–æ—Ä–∏—Ç–º—ã:
‚Ä¢ K-means: —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ k –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
‚Ä¢ DBSCAN: –∫–ª–∞—Å—Ç–µ—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã
‚Ä¢ Hierarchical clustering: –∏–µ—Ä–∞—Ä—Ö–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

üìè –ú–µ—Ç—Ä–∏–∫–∏: silhouette score, inertia
```

### üéÆ –û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º

```
ü§ñ –ê–≥–µ–Ω—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç —Å–æ —Å—Ä–µ–¥–æ–π:
–°–æ—Å—Ç–æ—è–Ω–∏–µ ‚Üí –î–µ–π—Å—Ç–≤–∏–µ ‚Üí –ù–∞–≥—Ä–∞–¥–∞ ‚Üí –ù–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

üí° –ü—Ä–∏–º–µ—Ä—ã:
‚Ä¢ ‚ôüÔ∏è –ò–≥—Ä—ã (—à–∞—Ö–º–∞—Ç—ã, Go)
‚Ä¢ ü§ñ –†–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞
‚Ä¢ üì± –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã

üîß –ê–ª–≥–æ—Ä–∏—Ç–º—ã: Q-learning, Policy Gradient, Actor-Critic
```

---

## –ì–ª–∞–≤–∞ 7: –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö

### üîÑ –ò–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç–∏

```
üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
‚Ä¢ üìç –¢—Ä–∞–Ω—Å–ª—è—Ü–∏–æ–Ω–Ω–∞—è: –∫–æ—Ç –æ—Å—Ç–∞–µ—Ç—Å—è –∫–æ—Ç–æ–º –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ
‚Ä¢ üìè –ú–∞—Å—à—Ç–∞–±–Ω–∞—è: –∫–æ—Ç –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è—Ö
‚Ä¢ üîÑ –ü–æ–≤–æ—Ä–æ—Ç–Ω–∞—è: –∫–æ—Ç –ø–æ–¥ —Ä–∞–∑–Ω—ã–º–∏ —É–≥–ª–∞–º–∏

üìù –¢–µ–∫—Å—Ç—ã:
‚Ä¢ ‚ö†Ô∏è –ü–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω
‚Ä¢ üè† –õ–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Å–æ—Å–µ–¥–Ω–∏–µ —Å–ª–æ–≤–∞)
‚Ä¢ üîó –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

üéµ –ê—É–¥–∏–æ:
‚Ä¢ ‚è∞ –í—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
‚Ä¢ üéº –ß–∞—Å—Ç–æ—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
‚Ä¢ üìä –§–∞–∑–æ–≤—ã–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
```

### üõ†Ô∏è Preprocessing –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

```python
# üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
transform = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])

# üìù –¢–µ–∫—Å—Ç—ã  
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
tokens = tokenizer("Hello world", return_tensors="pt")

# üìä –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

---

# üèóÔ∏è –ë–õ–û–ö 3: –ê–†–•–ò–¢–ï–ö–¢–£–†–´ –ò –ò–• –ù–ê–ó–ù–ê–ß–ï–ù–ò–ï

## –ì–ª–∞–≤–∞ 8: –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–π –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω (MLP)

### üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞

```
üîó –°–ª–æ–π: z = Wx + b
‚ö° –ê–∫—Ç–∏–≤–∞—Ü–∏—è: a = f(z)

üß† –ü–æ–ª–Ω–∞—è —Å–µ—Ç—å:
x ‚Üí z‚ÇÅ = W‚ÇÅx + b‚ÇÅ ‚Üí a‚ÇÅ = f(z‚ÇÅ) ‚Üí z‚ÇÇ = W‚ÇÇa‚ÇÅ + b‚ÇÇ ‚Üí a‚ÇÇ = f(z‚ÇÇ) ‚Üí ...

‚≠ê –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è: MLP –º–æ–∂–µ—Ç –ø—Ä–∏–±–ª–∏–∑–∏—Ç—å –ª—é–±—É—é 
–Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —Å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
```

### üéØ –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

- üìä –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- üìè –ó–∞–¥–∞—á–∏ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º –≤—Ö–æ–¥–∞
- üìà Baseline –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

```python
class DeepMLP(nn.Module):
    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.2):
        super().__init__()
        
        layers = []
        prev_size = input_size
        
        for hidden_size in hidden_sizes:
            layers.extend([
                nn.Linear(prev_size, hidden_size),
                nn.BatchNorm1d(hidden_size),
                nn.ReLU(),
                nn.Dropout(dropout)
            ])
            prev_size = hidden_size
        
        layers.append(nn.Linear(prev_size, output_size))
        self.network = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.network(x)

# üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
model = DeepMLP(
    input_size=100,
    hidden_sizes=[512, 256, 128],
    output_size=10,
    dropout=0.3
)
```

---

## –ì–ª–∞–≤–∞ 9: –°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–µ—Ç–∏ (CNN)

### üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞

```
üîç –û–ø–µ—Ä–∞—Ü–∏—è —Å–≤–µ—Ä—Ç–∫–∏ (2D):
(f * g)[i,j] = Œ£Œ£ f[m,n] * g[i-m, j-n]

üí° –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏:
output[i,j] = Œ£ Œ£ input[i+m, j+n] * kernel[m,n] + bias

‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
‚Ä¢ Kernel size: —Ä–∞–∑–º–µ—Ä —Ñ–∏–ª—å—Ç—Ä–∞ (3√ó3, 5√ó5)
‚Ä¢ Stride: —à–∞–≥ —Å–¥–≤–∏–≥–∞ —Ñ–∏–ª—å—Ç—Ä–∞
‚Ä¢ Padding: –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—Ä–∞–µ–≤
‚Ä¢ Dilation: —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞
```

### üèóÔ∏è –û—Å–Ω–æ–≤–Ω—ã–µ —Å–ª–æ–∏

```python
# üîç –°–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π
conv = nn.Conv2d(
    in_channels=3,      # RGB –≤—Ö–æ–¥
    out_channels=64,    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    kernel_size=3,      # –†–∞–∑–º–µ—Ä —Ñ–∏–ª—å—Ç—Ä–∞ 3√ó3
    stride=1,           # –®–∞–≥
    padding=1           # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
)

# üìâ –ü—É–ª–∏–Ω–≥ - —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
pool = nn.MaxPool2d(kernel_size=2, stride=2)  # –£–º–µ–Ω—å—à–∞–µ–º –≤ 2 —Ä–∞–∑–∞

# üìä Batch normalization - —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
bn = nn.BatchNorm2d(64)

# üéØ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø—É–ª–∏–Ω–≥ - —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä
adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))  # –õ—é–±–æ–π —Ä–∞–∑–º–µ—Ä ‚Üí 1√ó1
```

### üìö –≠–≤–æ–ª—é—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä CNN

```
üìñ LeNet (1998): Conv‚ÜíPool‚ÜíConv‚ÜíPool‚ÜíFC‚ÜíFC
  ‚Ä¢ –ü–µ—Ä–≤–∞—è —É—Å–ø–µ—à–Ω–∞—è CNN
  ‚Ä¢ –î–ª—è —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä MNIST

üöÄ AlexNet (2012): Conv‚ÜíPool‚ÜíConv‚ÜíPool‚ÜíConv‚ÜíConv‚ÜíConv‚ÜíPool‚ÜíFC‚ÜíFC‚ÜíFC
  ‚Ä¢ ReLU –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
  ‚Ä¢ Dropout —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
  ‚Ä¢ GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ

üèóÔ∏è VGG (2014): –û—á–µ–Ω—å –≥–ª—É–±–æ–∫–∞—è —Å–µ—Ç—å —Å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ 3√ó3
  ‚Ä¢ VGG-16: 16 —Å–ª–æ–µ–≤
  ‚Ä¢ –ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: —Ç–æ–ª—å–∫–æ Conv3√ó3 –∏ MaxPool2√ó2

‚ö° ResNet (2015): Residual connections
  ‚Ä¢ –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∑–∞—Ç—É—Ö–∞—é—â–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
  ‚Ä¢ –°–µ—Ç–∏ –¥–æ 152 —Å–ª–æ–µ–≤
```

### üîó ResNet Block

```python
class ResNetBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å
        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        # Skip connection
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
    
    def forward(self, x):
        out = torch.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)  # ‚ö° Residual connection
        out = torch.relu(out)
        return out
```

### üåü –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏

```python
# üì± Depthwise Separable Convolution (MobileNet)
class DepthwiseSeparableConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        # Depthwise: —Å–≤–µ—Ä—Ç–∫–∞ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É –æ—Ç–¥–µ–ª—å–Ω–æ
        self.depthwise = nn.Conv2d(in_channels, in_channels, 3, 1, 1, 
                                  groups=in_channels, bias=False)
        # Pointwise: —Å–º–µ—à–∏–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–æ–≤
        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)
        
    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        return x

# üëÅÔ∏è Attention –≤ CNN (Squeeze-and-Excitation)
class SEBlock(nn.Module):
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.squeeze = nn.AdaptiveAvgPool2d(1)
        self.excitation = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.squeeze(x).view(b, c)
        y = self.excitation(y).view(b, c, 1, 1)
        return x * y.expand_as(x)
```

---

## –ì–ª–∞–≤–∞ 10: –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏ (RNN)

### üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞

```
üîÑ Vanilla RNN:
h_t = tanh(W_hh * h_{t-1} + W_xh * x_t + b_h)
y_t = W_hy * h_t + b_y

‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–∞: –∑–∞—Ç—É—Ö–∞—é—â–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
‚àÇh_t/‚àÇh_{t-k} = ‚àè(i=0 to k-1) ‚àÇh_{t-i}/‚àÇh_{t-i-1}
–ï—Å–ª–∏ |‚àÇh_{t-i}/‚àÇh_{t-i-1}| < 1, —Ç–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ ‚Üí 0
```

### üß† LSTM - Long Short-Term Memory

```
üí° –ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è: —É–ø—Ä–∞–≤–ª—è–µ–º–∞—è –ø–∞–º—è—Ç—å —á–µ—Ä–µ–∑ "–≤–æ—Ä–æ—Ç–∞"

üö™ Forget gate: f_t = œÉ(W_f * [h_{t-1}, x_t] + b_f)
üîç Input gate:  i_t = œÉ(W_i * [h_{t-1}, x_t] + b_i)
üì§ Output gate: o_t = œÉ(W_o * [h_{t-1}, x_t] + b_o)

üí≠ Candidate: CÃÉ_t = tanh(W_C * [h_{t-1}, x_t] + b_C)
üßÆ Cell state: C_t = f_t * C_{t-1} + i_t * CÃÉ_t
üîç Hidden state: h_t = o_t * tanh(C_t)
```

```python
class LSTMFromScratch(nn.Module):
    def __init__(self, input_size, hidden_size):
        super().__init__()
        self.hidden_size = hidden_size
        
        # –í—Å–µ –≤–æ—Ä–æ—Ç–∞ –≤ –æ–¥–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        self.weight_ih = nn.Linear(input_size, 4 * hidden_size)
        self.weight_hh = nn.Linear(hidden_size, 4 * hidden_size)
        
    def forward(self, input, hidden=None):
        if hidden is None:
            h = torch.zeros(input.size(0), self.hidden_size)
            c = torch.zeros(input.size(0), self.hidden_size)
        else:
            h, c = hidden
            
        outputs = []
        
        for x in input.unbind(1):  # –ü–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —à–∞–≥–∞–º
            # –í—Å–µ –≤–æ—Ä–æ—Ç–∞ —Å—Ä–∞–∑—É
            gates = self.weight_ih(x) + self.weight_hh(h)
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ 4 –≤–æ—Ä–æ—Ç–∞
            i_gate, f_gate, g_gate, o_gate = gates.chunk(4, 1)
            
            i_gate = torch.sigmoid(i_gate)  # Input gate
            f_gate = torch.sigmoid(f_gate)  # Forget gate
            g_gate = torch.tanh(g_gate)     # New info
            o_gate = torch.sigmoid(o_gate)  # Output gate
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
            c = f_gate * c + i_gate * g_gate
            h = o_gate * torch.tanh(c)
            
            outputs.append(h)
            
        return torch.stack(outputs, 1), (h, c)
```

### ‚ö° GRU - Gated Recurrent Unit

```
üîß –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è LSTM:
z_t = œÉ(W_z * [h_{t-1}, x_t])  # Update gate
r_t = œÉ(W_r * [h_{t-1}, x_t])  # Reset gate
hÃÉ_t = tanh(W * [r_t * h_{t-1}, x_t])  # New hidden state
h_t = (1 - z_t) * h_{t-1} + z_t * hÃÉ_t  # Final hidden state

‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –±—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–∞–µ—Ç—Å—è
```

### ‚ÜîÔ∏è Bidirectional RNN

```
üí° –ò–¥–µ—è: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã

‚û°Ô∏è Forward:  h‚ÇÅ‚Åª ‚Üí h‚ÇÇ‚Åª ‚Üí h‚ÇÉ‚Åª ‚Üí h‚ÇÑ‚Åª
‚¨ÖÔ∏è Backward: h‚ÇÅ‚Å∫ ‚Üê h‚ÇÇ‚Å∫ ‚Üê h‚ÇÉ‚Å∫ ‚Üê h‚ÇÑ‚Å∫

üîó –ò—Ç–æ–≥–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: h_t = [h_t‚Åª; h_t‚Å∫]
```

```python
class BiLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers=1):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size, 
            hidden_size, 
            num_layers, 
            batch_first=True,
            bidirectional=True  # üîë –ö–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä
        )
        self.hidden_size = hidden_size
        
    def forward(self, x):
        # –í—ã—Ö–æ–¥: (batch, seq_len, 2*hidden_size)
        # –ü–æ—Å–ª–µ–¥–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä —É–¥–≤–∞–∏–≤–∞–µ—Ç—Å—è –∏–∑-–∑–∞ bidirectional
        output, (hidden, cell) = self.lstm(x)
        return output

# üëÅÔ∏è Attention –¥–ª—è RNN
class AttentionRNN(nn.Module):
    def __init__(self, hidden_size):
        super().__init__()
        self.attention = nn.Linear(hidden_size, 1)
        
    def forward(self, rnn_outputs):
        # rnn_outputs: (batch, seq_len, hidden_size)
        scores = self.attention(rnn_outputs)  # (batch, seq_len, 1)
        weights = torch.softmax(scores, dim=1)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
        context = torch.sum(weights * rnn_outputs, dim=1)
        return context, weights
```

---

## –ì–ª–∞–≤–∞ 11: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã

### üöÄ –†–µ–≤–æ–ª—é—Ü–∏—è –≤ NLP

```
‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã RNN:
1. üêå –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–º–µ–¥–ª–µ–Ω–Ω–æ)
2. üìâ –ó–∞—Ç—É—Ö–∞—é—â–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
3. üö´ –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏

‚úÖ –†–µ—à–µ–Ω–∏–µ Transformer:
1. ‚ö° Self-attention - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
2. üîó –ü—Ä—è–º—ã–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ª—é–±—ã–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏
3. üìç Positional encoding –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞
```

### üëÅÔ∏è Self-Attention –º–µ—Ö–∞–Ω–∏–∑–º

```
üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞:
Attention(Q,K,V) = softmax(QK^T/‚àöd_k)V

–≥–¥–µ:
üîç Q = XW_Q  (Query - —á—Ç–æ –∏—â–µ–º)
üóùÔ∏è K = XW_K  (Key - –≥–¥–µ –∏—â–µ–º)  
üíé V = XW_V  (Value - —á—Ç–æ –∏–∑–≤–ª–µ–∫–∞–µ–º)

üí° –ò–Ω—Ç—É–∏—Ü–∏—è: –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –º–æ–∂–µ—Ç "–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å" –Ω–∞ –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ
```

```python
class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, num_heads):
        super().__init__()
        assert d_model % num_heads == 0
        
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_k = d_model // num_heads
        
        # –õ–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–æ–µ–∫—Ü–∏–∏ –¥–ª—è Q, K, V
        self.w_q = nn.Linear(d_model, d_model)
        self.w_k = nn.Linear(d_model, d_model)
        self.w_v = nn.Linear(d_model, d_model)
        self.w_o = nn.Linear(d_model, d_model)
        
    def scaled_dot_product_attention(self, Q, K, V, mask=None):
        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)
        
        if mask is not None:
            scores = scores.masked_fill(mask == 0, -1e9)
            
        attention_weights = torch.softmax(scores, dim=-1)
        context = torch.matmul(attention_weights, V)
        
        return context, attention_weights
    
    def forward(self, x, mask=None):
        batch_size, seq_len, d_model = x.size()
        
        # –õ–∏–Ω–µ–π–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        Q = self.w_q(x)  # (batch, seq_len, d_model)
        K = self.w_k(x)
        V = self.w_v(x)
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –≥–æ–ª–æ–≤—ã
        Q = Q.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)
        K = K.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2) 
        V = V.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)
        
        # Attention –¥–ª—è –∫–∞–∂–¥–æ–π –≥–æ–ª–æ–≤—ã
        context, attention = self.scaled_dot_product_attention(Q, K, V, mask)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≥–æ–ª–æ–≤—ã
        context = context.transpose(1, 2).contiguous().view(
            batch_size, seq_len, d_model
        )
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è
        output = self.w_o(context)
        return output
```

### üèóÔ∏è Transformer Block

```python
class TransformerBlock(nn.Module):
    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):
        super().__init__()
        
        # Multi-head attention
        self.attention = MultiHeadAttention(d_model, num_heads)
        
        # Feed-forward network
        self.feed_forward = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.ReLU(),
            nn.Linear(d_ff, d_model)
        )
        
        # Layer normalization
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        
        # Dropout
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x, mask=None):
        # Self-attention —Å residual connection
        attention_output = self.attention(x, mask)
        x = self.norm1(x + self.dropout(attention_output))
        
        # Feed-forward —Å residual connection  
        ff_output = self.feed_forward(x)
        x = self.norm2(x + self.dropout(ff_output))
        
        return x
```

### üìç Positional Encoding

```
‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–∞: Transformer –Ω–µ –∑–Ω–∞–µ—Ç –æ –ø–æ—Ä—è–¥–∫–µ —Å–ª–æ–≤
‚úÖ –†–µ—à–µ–Ω–∏–µ: –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

üßÆ –§–æ—Ä–º—É–ª–∞:
PE(pos, 2i) = sin(pos / 10000^(2i/d_model))
PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))
```

```python
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super().__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1).float()
        
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * 
                           -(math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        self.register_buffer('pe', pe.unsqueeze(0))
        
    def forward(self, x):
        return x + self.pe[:, :x.size(1)]
```

---

# üîß –ë–õ–û–ö 4: –î–ï–¢–ê–õ–ò –°–õ–û–ï–í –ò –ê–†–•–ò–¢–ï–ö–¢–£–†

## –ì–ª–∞–≤–∞ 12: –°–ª–æ–∏ –∏ –∏—Ö —Ä–æ–ª–∏

### üîó Linear (Dense) —Å–ª–æ–π

```
üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞: y = xW^T + b
‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: W (weight matrix), b (bias vector)
üéØ –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –∏–∑—É—á–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: input_size * output_size + output_size
```

### üìä Normalization —Å–ª–æ–∏

```python
# üìà Batch Normalization - –ø–æ –±–∞—Ç—á—É
bn = nn.BatchNorm1d(num_features)
# –§–æ—Ä–º—É–ª–∞: (x - Œº_batch) / ‚àö(œÉ¬≤_batch + Œµ) * Œ≥ + Œ≤

# üß≠ Layer Normalization - –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
ln = nn.LayerNorm(normalized_shape)
# –§–æ—Ä–º—É–ª–∞: (x - Œº_layer) / ‚àö(œÉ¬≤_layer + Œµ) * Œ≥ + Œ≤

# üë• Group Normalization - –ø–æ –≥—Ä—É–ø–ø–∞–º –∫–∞–Ω–∞–ª–æ–≤
gn = nn.GroupNorm(num_groups, num_channels)

# üè† Instance Normalization - –ø–æ –∫–∞–∂–¥–æ–º—É –ø—Ä–∏–º–µ—Ä—É
instance_norm = nn.InstanceNorm2d(num_features)
```

### ‚ö° –ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

```python
# üî• ReLU: max(0, x)
relu = nn.ReLU()
# ‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: –ø—Ä–æ—Å—Ç–∞—è, —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∑–∞—Ç—É—Ö–∞—é—â–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
# ‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏: "–º–µ—Ä—Ç–≤—ã–µ –Ω–µ–π—Ä–æ–Ω—ã" –ø—Ä–∏ x < 0

# üíß Leaky ReLU: max(0.01x, x)
leaky_relu = nn.LeakyReLU(0.01)
# ‚úÖ –†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤

# üìä ELU: x –µ—Å–ª–∏ x > 0, Œ±(e^x - 1) –µ—Å–ª–∏ x ‚â§ 0
elu = nn.ELU(alpha=1.0)
# ‚úÖ –ì–ª–∞–¥–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è, —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –±–ª–∏–∑–∫–æ –∫ 0

# üåÄ Swish: x * sigmoid(x)
def swish(x):
    return x * torch.sigmoid(x)
# üéØ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ EfficientNet

# üß† GELU: x * Œ¶(x), –≥–¥–µ Œ¶ - CDF —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏
gelu = nn.GELU()
# üöÄ –ü–æ–ø—É–ª—è—Ä–Ω–∞ –≤ Transformers
```

### üõ°Ô∏è –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è

```python
# üé≤ Dropout - —Å–ª—É—á–∞–π–Ω–æ –æ–±–Ω—É–ª—è–µ—Ç –Ω–µ–π—Ä–æ–Ω—ã
dropout = nn.Dropout(p=0.5)  # 50% –Ω–µ–π—Ä–æ–Ω–æ–≤

# üèóÔ∏è DropBlock - structured dropout –¥–ª—è CNN
class DropBlock2d(nn.Module):
    def __init__(self, drop_rate, block_size):
        super().__init__()
        self.drop_rate = drop_rate
        self.block_size = block_size
        
    def forward(self, x):
        if not self.training:
            return x
        # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è structured dropout
        # –û–±–Ω—É–ª—è–µ—Ç —Ü–µ–ª—ã–µ –±–ª–æ–∫–∏ –≤ feature maps

# ‚öñÔ∏è Weight Decay - L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)
# –î–æ–±–∞–≤–ª—è–µ—Ç Œª||W||¬≤ –∫ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å
```

---

## –ì–ª–∞–≤–∞ 13: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

### üîó Residual Connections

```
‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–∞: –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∑–∞—Ç—É—Ö–∞—é—Ç –≤ –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç—è—Ö
‚úÖ –†–µ—à–µ–Ω–∏–µ: F(x) + x –≤–º–µ—Å—Ç–æ F(x)

üí™ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
1. ‚ö° –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç –Ω–∞–ø—Ä—è–º—É—é
2. üéØ –õ–µ–≥—á–µ –æ–±—É—á–∏—Ç—å —Ç–æ–∂–¥–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
3. üèóÔ∏è –ü–æ–∑–≤–æ–ª—è–µ—Ç —Å—Ç—Ä–æ–∏—Ç—å –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–∏–µ —Å–µ—Ç–∏
```

### üï∏Ô∏è Dense Connections (DenseNet)

```
üí° –ò–¥–µ—è: –∫–∞–∂–¥—ã–π —Å–ª–æ–π –ø–æ–ª—É—á–∞–µ—Ç –≤—Ö–æ–¥—ã –æ—Ç –≤—Å–µ—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö

üîó –°–ª–æ–π 1: x‚ÇÅ = f‚ÇÅ(x‚ÇÄ)
üîó –°–ª–æ–π 2: x‚ÇÇ = f‚ÇÇ([x‚ÇÄ, x‚ÇÅ])  
üîó –°–ª–æ–π 3: x‚ÇÉ = f‚ÇÉ([x‚ÇÄ, x‚ÇÅ, x‚ÇÇ])
...

‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç—å
```

### üëÅÔ∏è Attention –º–µ—Ö–∞–Ω–∏–∑–º—ã

```python
# üó∫Ô∏è Spatial Attention –¥–ª—è CNN
class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super().__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2)
        
    def forward(self, x):
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –∫–∞–Ω–∞–ª–∞–º
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ –ø–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è
        attention = torch.cat([avg_out, max_out], dim=1)
        attention = torch.sigmoid(self.conv(attention))
        
        return x * attention

# üì∫ Channel Attention
class ChannelAttention(nn.Module):
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels)
        )
        
    def forward(self, x):
        b, c, _, _ = x.size()
        
        # Global average –∏ max pooling
        avg = self.avg_pool(x).view(b, c)
        max_val = self.max_pool(x).view(b, c)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞
        avg_out = self.fc(avg)
        max_out = self.fc(max_val)
        
        attention = torch.sigmoid(avg_out + max_out).view(b, c, 1, 1)
        return x * attention
```

---

## –ì–ª–∞–≤–∞ 14: –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

### üëÅÔ∏è Vision Transformer (ViT)

```
üí° –ò–¥–µ—è: –ø—Ä–∏–º–µ–Ω–∏—Ç—å Transformer –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
üß© –†–µ—à–µ–Ω–∏–µ: —Ä–∞–∑–±–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –ø–∞—Ç—á–∏

üìê –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 224√ó224√ó3 ‚Üí –ü–∞—Ç—á–∏ 16√ó16√ó3 ‚Üí –í–µ–∫—Ç–æ—Ä—ã 768D
üìä 196 –ø–∞—Ç—á–µ–π ‚Üí –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è Transformer
```

```python
class VisionTransformer(nn.Module):
    def __init__(self, img_size=224, patch_size=16, num_classes=1000, 
                 dim=768, depth=12, heads=12):
        super().__init__()
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ç—á–µ–π
        self.patch_size = patch_size
        self.num_patches = (img_size // patch_size) ** 2
        patch_dim = 3 * patch_size ** 2
        
        # Embedding –ø–∞—Ç—á–µ–π
        self.patch_embedding = nn.Linear(patch_dim, dim)
        
        # Positional embeddings
        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches + 1, dim))
        
        # CLS token –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))
        
        # Transformer blocks
        self.transformer = nn.ModuleList([
            TransformerBlock(dim, heads, dim * 4)
            for _ in range(depth)
        ])
        
        # Classification head
        self.mlp_head = nn.Linear(dim, num_classes)
        
    def forward(self, x):
        batch_size = x.shape[0]
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–∞—Ç—á–∏
        x = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)
        x = x.contiguous().view(batch_size, -1, 3 * self.patch_size ** 2)
        
        # Embedding –ø–∞—Ç—á–µ–π
        x = self.patch_embedding(x)
        
        # –î–æ–±–∞–≤–ª—è–µ–º CLS token
        cls_tokens = self.cls_token.expand(batch_size, -1, -1)
        x = torch.cat([cls_tokens, x], dim=1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º positional encoding
        x += self.pos_embedding
        
        # Transformer layers
        for transformer in self.transformer:
            x = transformer(x)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ CLS token
        return self.mlp_head(x[:, 0])
```

### ‚ö° EfficientNet - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

```
üí° –ò–¥–µ—è: —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã, —à–∏—Ä–∏–Ω—ã –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è

üîß Compound Scaling:
depth = Œ±^œÜ
width = Œ≤^œÜ  
resolution = Œ≥^œÜ

–≥–¥–µ Œ±¬∑Œ≤¬≤¬∑Œ≥¬≤ ‚âà 2 (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤)
```

### üì± MobileNet - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

```python
class DepthwiseSeparableConv(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        
        # Depthwise convolution
        self.depthwise = nn.Conv2d(
            in_channels, in_channels, 3, stride, 1, 
            groups=in_channels, bias=False
        )
        self.bn1 = nn.BatchNorm2d(in_channels)
        
        # Pointwise convolution
        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
    def forward(self, x):
        x = torch.relu(self.bn1(self.depthwise(x)))
        x = torch.relu(self.bn2(self.pointwise(x)))
        return x

# üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:
# –û–±—ã—á–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞: K √ó K √ó C_in √ó C_out
# Depthwise Separable: K √ó K √ó C_in + C_in √ó C_out
# üí∞ –≠–∫–æ–Ω–æ–º–∏—è: (K √ó K √ó C_in √ó C_out) / (K √ó K √ó C_in + C_in √ó C_out)
```

---

# üíº –ë–õ–û–ö 5: –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –ê–°–ü–ï–ö–¢–´

## –ì–ª–∞–≤–∞ 15: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

### üìÇ Data Loading –∏ Preprocessing

```python
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms

class CustomDataset(Dataset):
    def __init__(self, data, labels, transform=None):
        self.data = data
        self.labels = labels
        self.transform = transform
        
    def __len__(self):
        return len(self.data)
        
    def __getitem__(self, idx):
        sample = self.data[idx]
        label = self.labels[idx]
        
        if self.transform:
            sample = self.transform(sample)
            
        return sample, label

# üé® –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
train_transform = transforms.Compose([
    transforms.RandomRotation(10),
    transforms.RandomHorizontalFlip(0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

# ‚ö° DataLoader —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
train_loader = DataLoader(
    dataset=train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,  # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
    pin_memory=True  # –ë—ã—Å—Ç—Ä–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –Ω–∞ GPU
)
```

### üìä –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è

```python
# üìè Z-score –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
def normalize_features(X):
    mean = X.mean(dim=0, keepdim=True)
    std = X.std(dim=0, keepdim=True)
    return (X - mean) / (std + 1e-8)

# üìê Min-Max –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
def minmax_scale(X):
    min_val = X.min(dim=0, keepdim=True)[0]
    max_val = X.max(dim=0, keepdim=True)[0]
    return (X - min_val) / (max_val - min_val + 1e-8)

# üõ°Ô∏è Robust scaling (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ–¥–∏–∞–Ω—É –∏ IQR)
def robust_scale(X):
    median = X.median(dim=0, keepdim=True)[0]
    q75 = X.quantile(0.75, dim=0, keepdim=True)
    q25 = X.quantile(0.25, dim=0, keepdim=True)
    iqr = q75 - q25
    return (X - median) / (iqr + 1e-8)
```

---

## –ì–ª–∞–≤–∞ 16: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

### üîÑ –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è

```python
def train_model(model, train_loader, val_loader, num_epochs, device):
    # üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)
    criterion = nn.CrossEntropyLoss()
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)
    
    # üìä –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫
    train_losses, val_losses = [], []
    train_accs, val_accs = [], []
    
    # üõë Early stopping
    best_val_loss = float('inf')
    patience = 10
    patience_counter = 0
    
    for epoch in range(num_epochs):
        # üèãÔ∏è –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–∞—è —ç–ø–æ—Ö–∞
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (data, targets) in enumerate(train_loader):
            data, targets = data.to(device), targets.to(device)
            
            # ‚û°Ô∏è Forward pass
            outputs = model(data)
            loss = criterion(outputs, targets)
            
            # ‚¨ÖÔ∏è Backward pass
            optimizer.zero_grad()
            loss.backward()
            
            # ‚úÇÔ∏è Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            train_total += targets.size(0)
            train_correct += (predicted == targets).sum().item()
            
        # üß™ –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, targets in val_loader:
                data, targets = data.to(device), targets.to(device)
                outputs = model(data)
                loss = criterion(outputs, targets)
                
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += targets.size(0)
                val_correct += (predicted == targets).sum().item()
        
        # üìä –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_acc = 100. * train_correct / train_total
        val_acc = 100. * val_correct / val_total
        
        # üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        train_accs.append(train_acc)
        val_accs.append(val_acc)
        
        # üìà –û–±–Ω–æ–≤–ª—è–µ–º learning rate
        scheduler.step()
        
        # üõë Early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            # üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            torch.save(model.state_dict(), 'best_model.pth')
        else:
            patience_counter += 1
            
        if patience_counter >= patience:
            print(f"Early stopping at epoch {epoch+1}")
            break
            
        # üìù –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        print(f'Epoch [{epoch+1}/{num_epochs}]')
        print(f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')
        print(f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')
        print(f'LR: {scheduler.get_last_lr()[0]:.6f}')
        print('-' * 50)
    
    return train_losses, val_losses, train_accs, val_accs
```

---

## –ì–ª–∞–≤–∞ 17: –ú–µ—Ç—Ä–∏–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∞

### üè∑Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

```python
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix

def evaluate_classification(model, test_loader, device):
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for data, targets in test_loader:
            data = data.to(device)
            outputs = model(data)
            _, predicted = torch.max(outputs, 1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(targets.numpy())
    
    # üìä –ú–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(all_targets, all_preds)
    precision, recall, f1, _ = precision_recall_fscore_support(
        all_targets, all_preds, average='macro'
    )
    
    print(f"üéØ Accuracy: {accuracy:.4f}")
    print(f"üîç Precision: {precision:.4f}")
    print(f"üìû Recall: {recall:.4f}")
    print(f"‚öñÔ∏è F1-Score: {f1:.4f}")
    
    # üîç Confusion Matrix
    cm = confusion_matrix(all_targets, all_preds)
    return accuracy, precision, recall, f1, cm
```

### üìà –†–µ–≥—Ä–µ—Å—Å–∏—è

```python
def evaluate_regression(model, test_loader, device):
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for data, targets in test_loader:
            data = data.to(device)
            outputs = model(data)
            
            all_preds.extend(outputs.cpu().numpy())
            all_targets.extend(targets.numpy())
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy arrays
    preds = np.array(all_preds)
    targets = np.array(all_targets)
    
    # üìä –ú–µ—Ç—Ä–∏–∫–∏
    mse = np.mean((preds - targets) ** 2)
    mae = np.mean(np.abs(preds - targets))
    rmse = np.sqrt(mse)
    
    # R-squared
    ss_res = np.sum((targets - preds) ** 2)
    ss_tot = np.sum((targets - np.mean(targets)) ** 2)
    r2 = 1 - (ss_res / ss_tot)
    
    print(f"üìè MSE: {mse:.4f}")
    print(f"üìê MAE: {mae:.4f}")
    print(f"üìä RMSE: {rmse:.4f}")
    print(f"üéØ R¬≤: {r2:.4f}")
    
    return mse, mae, rmse, r2
```

---

## –ì–ª–∞–≤–∞ 18: –û—Ç–ª–∞–¥–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

### üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤

```python
def monitor_gradients(model):
    total_norm = 0
    for name, param in model.named_parameters():
        if param.grad is not None:
            param_norm = param.grad.data.norm(2)
            total_norm += param_norm.item() ** 2
            
            # ‚ö†Ô∏è –õ–æ–≥–∏—Ä—É–µ–º –∞–Ω–æ–º–∞–ª—å–Ω–æ –±–æ–ª—å—à–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
            if param_norm > 10:
                print(f"Large gradient in {name}: {param_norm:.4f}")
                
    total_norm = total_norm ** 0.5
    return total_norm

# üîß –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ —Ü–∏–∫–ª–µ –æ–±—É—á–µ–Ω–∏—è
loss.backward()
grad_norm = monitor_gradients(model)

if grad_norm > 5.0:  # ‚úÇÔ∏è Gradient clipping
    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)
    
optimizer.step()
```

### üîç –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```python
import torch.profiler

def profile_model(model, data_loader, device):
    model.eval()
    
    with torch.profiler.profile(
        activities=[torch.profiler.ProfilerActivity.CPU, 
                   torch.profiler.ProfilerActivity.CUDA],
        record_shapes=True,
        profile_memory=True,
        with_stack=True
    ) as prof:
        
        for i, (data, _) in enumerate(data_loader):
            if i >= 10:  # üìä –ü—Ä–æ—Ñ–∏–ª–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 –±–∞—Ç—á–µ–π
                break
                
            data = data.to(device)
            with torch.no_grad():
                _ = model(data)
    
    # üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    print(prof.key_averages().table(sort_by="cuda_time_total", row_limit=10))
    
    # üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    prof.export_chrome_trace("trace.json")
```

### üíæ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏

```python
# üîÑ Gradient Checkpointing - —ç–∫–æ–Ω–æ–º–∏–º –ø–∞–º—è—Ç—å –∑–∞ —Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏
from torch.utils.checkpoint import checkpoint

class MemoryEfficientBlock(nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__()
        # ... –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–µ–≤
        
    def forward(self, x):
        # üíæ –ò—Å–ø–æ–ª—å–∑—É–µ–º checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        return checkpoint(self._forward_impl, x)
    
    def _forward_impl(self, x):
        # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        return self.layers(x)

# ‚ö° Mixed Precision Training
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for data, targets in train_loader:
    optimizer.zero_grad()
    
    # ‚û°Ô∏è Forward pass —Å autocast
    with autocast():
        outputs = model(data)
        loss = criterion(outputs, targets)
    
    # ‚¨ÖÔ∏è Backward pass —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

---

# üéì –ë–õ–û–ö 6: –ü–†–û–î–í–ò–ù–£–¢–´–ï –¢–ï–•–ù–ò–ö–ò

## –ì–ª–∞–≤–∞ 19: Transfer Learning –∏ Fine-tuning

### üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏

```
üí° Transfer Learning: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

üìä –¢—Ä–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:
1. üîí Feature Extraction: –∑–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤–µ—Å–∞, —Ç—Ä–µ–Ω–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
2. ‚ö° Fine-tuning: —Ç—Ä–µ–Ω–∏—Ä—É–µ–º –≤—Å—é —Å–µ—Ç—å —Å –º–∞–ª–µ–Ω—å–∫–∏–º learning rate
3. üîß Mixed: —Å–Ω–∞—á–∞–ª–∞ Feature Extraction, –ø–æ—Ç–æ–º Fine-tuning
```

### üñºÔ∏è –ü—Ä–∏–º–µ—Ä –¥–ª—è Computer Vision

```python
import torchvision.models as models

# üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
model = models.resnet50(pretrained=True)

# üîí –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: Feature Extraction
# –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤—Å–µ –≤–µ—Å–∞ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è
for param in model.parameters():
    param.requires_grad = False

# –ó–∞–º–µ–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π
num_classes = 10  # –í–∞—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
model.fc = nn.Linear(model.fc.in_features, num_classes)

# ‚ö° –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: Fine-tuning –≤—Å–µ–π —Å–µ—Ç–∏
# –†–∞–∑–º–æ—Ä–æ–∑–∏–º –≤—Å–µ —Å–ª–æ–∏
for param in model.parameters():
    param.requires_grad = True

# üéõÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–Ω—ã–µ learning rates –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π
backbone_params = []
classifier_params = []

for name, param in model.named_parameters():
    if 'fc' in name:  # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        classifier_params.append(param)
    else:  # Backbone
        backbone_params.append(param)

# üìä –î–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ learning rates
optimizer = torch.optim.Adam([
    {'params': backbone_params, 'lr': 1e-5},    # –ú–∞–ª–µ–Ω—å–∫–∏–π LR –¥–ª—è backbone
    {'params': classifier_params, 'lr': 1e-3}   # –ë–æ–ª—å—à–æ–π LR –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
])
```

### üìù –ü—Ä–∏–º–µ—Ä –¥–ª—è NLP

```python
from transformers import AutoModel, AutoTokenizer

# üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å BERT
model_name = 'bert-base-uncased'
tokenizer = AutoTokenizer.from_pretrained(model_name)
bert_model = AutoModel.from_pretrained(model_name)

class BERTClassifier(nn.Module):
    def __init__(self, bert_model, num_classes, dropout=0.3):
        super().__init__()
        self.bert = bert_model
        self.dropout = nn.Dropout(dropout)
        self.classifier = nn.Linear(bert_model.config.hidden_size, num_classes)
        
    def forward(self, input_ids, attention_mask):
        # üß† –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç BERT
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        
        # üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º [CLS] —Ç–æ–∫–µ–Ω –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        cls_output = outputs.last_hidden_state[:, 0]  # [CLS] —Ç–æ–∫–µ–Ω
        
        # üé≤ Dropout –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        cls_output = self.dropout(cls_output)
        logits = self.classifier(cls_output)
        
        return logits

# üîß –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
model = BERTClassifier(bert_model, num_classes=3)

# üîí –ú–æ–∂–µ–º –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å BERT –∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
for param in model.bert.parameters():
    param.requires_grad = False
```

---

## –ì–ª–∞–≤–∞ 20: Generative Adversarial Networks (GANs)

### üé≠ –û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è

```
üéÆ –ò–≥—Ä–∞ –¥–≤—É—Ö —Å–µ—Ç–µ–π:
üé® Generator (G): —Å–æ–∑–¥–∞–µ—Ç –ø–æ–¥–¥–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
üïµÔ∏è Discriminator (D): –æ—Ç–ª–∏—á–∞–µ—Ç –Ω–∞—Å—Ç–æ—è—â–∏–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç –ø–æ–¥–¥–µ–ª—å–Ω—ã—Ö

üéØ –¶–µ–ª—å:
‚Ä¢ G –ø—ã—Ç–∞–µ—Ç—Å—è –æ–±–º–∞–Ω—É—Ç—å D
‚Ä¢ D –ø—ã—Ç–∞–µ—Ç—Å—è –Ω–µ –¥–∞—Ç—å —Å–µ–±—è –æ–±–º–∞–Ω—É—Ç—å

üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞:
min_G max_D V(D,G) = E_x[log D(x)] + E_z[log(1 - D(G(z)))]
```

### üèóÔ∏è –ü—Ä–æ—Å—Ç–æ–π GAN –¥–ª—è MNIST

```python
class Generator(nn.Module):
    def __init__(self, latent_dim=100, img_size=28*28):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, img_size),
            nn.Tanh()  # üìê –í—ã—Ö–æ–¥ [-1, 1]
        )
        
    def forward(self, z):
        return self.model(z)

class Discriminator(nn.Module):
    def __init__(self, img_size=28*28):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(img_size, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()  # üéØ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å [0, 1]
        )
        
    def forward(self, img):
        return self.model(img)

# üöÄ –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª–∏
generator = Generator()
discriminator = Discriminator()

# üîß –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã
g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

# üìä –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
criterion = nn.BCELoss()
```

### üîÑ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Ü–∏–∫–ª GAN

```python
def train_gan(generator, discriminator, dataloader, num_epochs, device):
    for epoch in range(num_epochs):
        for i, (real_images, _) in enumerate(dataloader):
            batch_size = real_images.size(0)
            real_images = real_images.view(batch_size, -1).to(device)
            
            # üè∑Ô∏è –ú–µ—Ç–∫–∏
            real_labels = torch.ones(batch_size, 1).to(device)
            fake_labels = torch.zeros(batch_size, 1).to(device)
            
            # üïµÔ∏è === –¢—Ä–µ–Ω–∏—Ä—É–µ–º Discriminator ===
            d_optimizer.zero_grad()
            
            # –ù–∞—Å—Ç–æ—è—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            real_outputs = discriminator(real_images)
            d_loss_real = criterion(real_outputs, real_labels)
            
            # –ü–æ–¥–¥–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            z = torch.randn(batch_size, 100).to(device)
            fake_images = generator(z)
            fake_outputs = discriminator(fake_images.detach())
            d_loss_fake = criterion(fake_outputs, fake_labels)
            
            # –û–±—â–∞—è –ø–æ—Ç–µ—Ä—è discriminator
            d_loss = d_loss_real + d_loss_fake
            d_loss.backward()
            d_optimizer.step()
            
            # üé® === –¢—Ä–µ–Ω–∏—Ä—É–µ–º Generator ===
            g_optimizer.zero_grad()
            
            # Generator —Ö–æ—á–µ—Ç, —á—Ç–æ–±—ã discriminator –¥—É–º–∞–ª, —á—Ç–æ fake = real
            fake_outputs = discriminator(fake_images)
            g_loss = criterion(fake_outputs, real_labels)
            
            g_loss.backward()
            g_optimizer.step()
            
            # üìä –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            if i % 100 == 0:
                print(f'Epoch [{epoch}/{num_epochs}], Step [{i}/{len(dataloader)}]')
                print(f'D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')
```

### üåü –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ GAN –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

```python
# üé® Deep Convolutional GAN (DCGAN)
class DCGANGenerator(nn.Module):
    def __init__(self, latent_dim=100, channels=3):
        super().__init__()
        self.main = nn.Sequential(
            # üìê Input: latent_dim x 1 x 1
            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),
            # üìê State: 512 x 4 x 4
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),
            # üìê State: 256 x 8 x 8
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            # üìê State: 128 x 16 x 16
            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),
            # üìê State: 64 x 32 x 32
            nn.ConvTranspose2d(64, channels, 4, 2, 1, bias=False),
            nn.Tanh()
            # üìê Output: channels x 64 x 64
        )
    
    def forward(self, input):
        return self.main(input)
```

---

## –ì–ª–∞–≤–∞ 21: –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—ã –∏ Variational Autoencoders

### üîÑ –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—ã

```
üí° –ò–¥–µ—è: —Å–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ —Å–∫—Ä—ã—Ç–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, –∑–∞—Ç–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å

üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
Input ‚Üí Encoder ‚Üí Latent Space ‚Üí Decoder ‚Üí Reconstructed Input

üéØ –¶–µ–ª—å: minimize ||x - xÃÇ||¬≤ (reconstruction loss)
```

### üèóÔ∏è –ü—Ä–æ—Å—Ç–æ–π –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä

```python
class Autoencoder(nn.Module):
    def __init__(self, input_dim=784, latent_dim=64):
        super().__init__()
        
        # üìâ Encoder
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
        
        # üìà Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, input_dim),
            nn.Sigmoid()  # üéØ –î–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö [0,1]
        )
    
    def forward(self, x):
        latent = self.encoder(x)
        reconstructed = self.decoder(latent)
        return reconstructed, latent

# üîß –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
autoencoder = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)

for epoch in range(num_epochs):
    for data, _ in dataloader:
        data = data.view(data.size(0), -1)
        
        # Forward pass
        reconstructed, _ = autoencoder(data)
        loss = criterion(reconstructed, data)
        
        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

### üé≤ Variational Autoencoder (VAE)

```
üí° –ò–¥–µ—è: –∏–∑—É—á–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ

üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞:
‚Ä¢ Encoder –≤—ã–¥–∞–µ—Ç Œº –∏ œÉ (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)
‚Ä¢ z ~ N(Œº, œÉ¬≤) (sampling —Å reparameterization trick)
‚Ä¢ Decoder –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑ z

üìä Loss = Reconstruction Loss + KL Divergence
```

```python
class VAE(nn.Module):
    def __init__(self, input_dim=784, latent_dim=20):
        super().__init__()
        
        # üìâ Encoder
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 400),
            nn.ReLU(),
            nn.Linear(400, 200),
            nn.ReLU()
        )
        
        # üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        self.fc_mu = nn.Linear(200, latent_dim)
        self.fc_logvar = nn.Linear(200, latent_dim)
        
        # üìà Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 200),
            nn.ReLU(),
            nn.Linear(200, 400),
            nn.ReLU(),
            nn.Linear(400, input_dim),
            nn.Sigmoid()
        )
    
    def encode(self, x):
        h = self.encoder(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar
    
    def reparameterize(self, mu, logvar):
        # üé≤ Reparameterization trick: z = Œº + œÉ * Œµ, –≥–¥–µ Œµ ~ N(0,1)
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        return self.decoder(z)
    
    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        reconstructed = self.decode(z)
        return reconstructed, mu, logvar

# üìä VAE Loss —Ñ—É–Ω–∫—Ü–∏—è
def vae_loss(reconstructed, original, mu, logvar, beta=1.0):
    # üî® Reconstruction loss
    reconstruction_loss = F.binary_cross_entropy(reconstructed, original, reduction='sum')
    
    # üìä KL divergence: KL(q(z|x) || p(z)) –≥–¥–µ p(z) = N(0,I)
    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    
    return reconstruction_loss + beta * kl_divergence
```

---

# üöÄ –ë–õ–û–ö 7: –°–û–í–†–ï–ú–ï–ù–ù–´–ï –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø

## –ì–ª–∞–≤–∞ 22: Attention –∏ Self-Attention

### üéØ –≠–≤–æ–ª—é—Ü–∏—è –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è

```
üìà –ò—Å—Ç–æ—Ä–∏—è:
1. üëÅÔ∏è –ü—Ä–æ—Å—Ç–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –≤ RNN (Bahdanau, 2014)
2. üéØ Luong attention (2015)
3. üöÄ Self-attention –≤ Transformer (2017)
4. üåü Multi-head attention
5. üîÑ Cross-attention –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π
```

### üëÅÔ∏è –ë–∞–∑–æ–≤—ã–π attention –º–µ—Ö–∞–Ω–∏–∑–º

```python
class AttentionMechanism(nn.Module):
    def __init__(self, hidden_size):
        super().__init__()
        self.hidden_size = hidden_size
        self.attention = nn.Linear(hidden_size * 2, hidden_size)
        self.v = nn.Linear(hidden_size, 1, bias=False)
        
    def forward(self, decoder_hidden, encoder_outputs):
        # decoder_hidden: (batch, hidden_size)
        # encoder_outputs: (batch, seq_len, hidden_size)
        
        seq_len = encoder_outputs.size(1)
        
        # üîÑ –ü–æ–≤—Ç–æ—Ä—è–µ–º decoder_hidden –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏
        decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, seq_len, 1)
        
        # üîó –û–±—ä–µ–¥–∏–Ω—è–µ–º decoder –∏ encoder —Å–æ—Å—Ç–æ—è–Ω–∏—è
        energy = torch.tanh(self.attention(torch.cat([decoder_hidden, encoder_outputs], dim=2)))
        
        # üìä –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è
        attention_weights = torch.softmax(self.v(energy).squeeze(2), dim=1)
        
        # üéØ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –∫–∞–∫ –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
        context = torch.sum(attention_weights.unsqueeze(2) * encoder_outputs, dim=1)
        
        return context, attention_weights
```

### üß† Scaled Dot-Product Attention (–∏–∑ Transformer)

```python
def scaled_dot_product_attention(Q, K, V, mask=None, dropout=None):
    """
    üßÆ –í—ã—á–∏—Å–ª—è–µ—Ç Scaled Dot-Product Attention
    
    Args:
        Q: Queries (batch, heads, seq_len, d_k)
        K: Keys (batch, heads, seq_len, d_k)  
        V: Values (batch, heads, seq_len, d_v)
        mask: –ú–∞—Å–∫–∞ –¥–ª—è padding –∏–ª–∏ causal attention
        dropout: Dropout —Å–ª–æ–π
    """
    d_k = Q.size(-1)
    
    # üìä –í—ã—á–∏—Å–ª—è–µ–º attention scores
    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)
    
    # üö´ –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if mask is not None:
        scores = scores.masked_fill(mask == 0, -1e9)
    
    # üìà Softmax –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Å–æ–≤
    attention_weights = F.softmax(scores, dim=-1)
    
    # üé≤ Dropout –µ—Å–ª–∏ –Ω—É–∂–µ–Ω
    if dropout is not None:
        attention_weights = dropout(attention_weights)
    
    # üéØ –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ –∑–Ω–∞—á–µ–Ω–∏–π
    context = torch.matmul(attention_weights, V)
    
    return context, attention_weights
```

### üîÑ Cross-Modal Attention

```python
class CrossModalAttention(nn.Module):
    """
    üîÑ Cross-attention –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    """
    def __init__(self, text_dim, image_dim, hidden_dim):
        super().__init__()
        
        # üîç –ü—Ä–æ–µ–∫—Ü–∏–∏ –¥–ª—è text (queries)
        self.text_query = nn.Linear(text_dim, hidden_dim)
        
        # üñºÔ∏è –ü—Ä–æ–µ–∫—Ü–∏–∏ –¥–ª—è image (keys –∏ values)
        self.image_key = nn.Linear(image_dim, hidden_dim)
        self.image_value = nn.Linear(image_dim, hidden_dim)
        
        self.scale = math.sqrt(hidden_dim)
        
    def forward(self, text_features, image_features):
        # text_features: (batch, text_len, text_dim)
        # image_features: (batch, image_patches, image_dim)
        
        # üîç –ü–æ–ª—É—á–∞–µ–º Q, K, V
        Q = self.text_query(text_features)  # (batch, text_len, hidden_dim)
        K = self.image_key(image_features)   # (batch, image_patches, hidden_dim)
        V = self.image_value(image_features) # (batch, image_patches, hidden_dim)
        
        # üìä Attention scores –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale
        attention_weights = F.softmax(scores, dim=-1)
        
        # üéØ –ö–æ–Ω—Ç–µ–∫—Å—Ç: —á—Ç–æ –≤–∏–¥–∏—Ç –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        context = torch.matmul(attention_weights, V)
        
        return context, attention_weights
```

---

## –ì–ª–∞–≤–∞ 23: –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Transformer

### üé® BERT - Bidirectional Encoder

```
üí° –ö–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏:
‚Ä¢ üìñ Bidirectional: —á–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã
‚Ä¢ üé≠ Masked Language Modeling: –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
‚Ä¢ üîó Next Sentence Prediction: –ø–æ–Ω–∏–º–∞–µ—Ç —Å–≤—è–∑—å –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏

üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
Input ‚Üí Token + Position + Segment Embeddings ‚Üí 12 Transformer Layers ‚Üí Outputs
```

### üß† GPT - Generative Pre-trained Transformer

```
üí° –ö–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏:
‚Ä¢ ‚û°Ô∏è Autoregressive: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ
‚Ä¢ üéØ Causal masking: –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –≤–∏–¥–∏—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ
‚Ä¢ üìö Language Modeling: –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω

üöÄ –≠–≤–æ–ª—é—Ü–∏—è: GPT ‚Üí GPT-2 ‚Üí GPT-3 ‚Üí GPT-4
–†–æ—Å—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 117M ‚Üí 1.5B ‚Üí 175B ‚Üí ~1T+
```

```python
class GPTBlock(nn.Module):
    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):
        super().__init__()
        
        # üëÅÔ∏è Causal self-attention
        self.attention = MultiHeadAttention(d_model, n_heads)
        self.norm1 = nn.LayerNorm(d_model)
        
        # üß† Feed-forward network
        self.feed_forward = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.GELU(),  # üåü GELU –≤–º–µ—Å—Ç–æ ReLU
            nn.Linear(d_ff, d_model),
            nn.Dropout(dropout)
        )
        self.norm2 = nn.LayerNorm(d_model)
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x, mask=None):
        # üëÅÔ∏è Self-attention —Å residual connection
        attn_output = self.attention(x, x, x, mask)  # Self-attention
        x = self.norm1(x + self.dropout(attn_output))
        
        # üß† Feed-forward —Å residual connection
        ff_output = self.feed_forward(x)
        x = self.norm2(x + ff_output)
        
        return x

def create_causal_mask(seq_len):
    """
    üö´ –°–æ–∑–¥–∞–µ—Ç –∫–∞—É–∑–∞–ª—å–Ω—É—é –º–∞—Å–∫—É –¥–ª—è GPT
    –ö–∞–∂–¥–∞—è –ø–æ–∑–∏—Ü–∏—è –º–æ–∂–µ—Ç –≤–∏–¥–µ—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ø–æ–∑–∏—Ü–∏–∏
    """
    mask = torch.tril(torch.ones(seq_len, seq_len))
    return mask.unsqueeze(0).unsqueeze(0)  # (1, 1, seq_len, seq_len)
```

### üåü T5 - Text-to-Text Transfer Transformer

```
üí° –§–∏–ª–æ—Å–æ—Ñ–∏—è: "Everything is text-to-text"

üîÑ –ü–æ–¥—Ö–æ–¥:
‚Ä¢ üìù –í—Å–µ –∑–∞–¥–∞—á–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä—É—é—Ç—Å—è –∫–∞–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
‚Ä¢ üéØ Classification: "sentiment: positive"
‚Ä¢ üìÑ Summarization: "summarize: [long text]"
‚Ä¢ üåç Translation: "translate English to French: [text]"

üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –ø–æ–ª–Ω—ã–π encoder-decoder Transformer
```

```python
class T5Model(nn.Module):
    def __init__(self, vocab_size, d_model=512, n_heads=8, n_layers=6):
        super().__init__()
        
        # üìù Embeddings
        self.embedding = nn.Embedding(vocab_size, d_model)
        self.pos_encoding = PositionalEncoding(d_model)
        
        # üìñ Encoder
        self.encoder_layers = nn.ModuleList([
            TransformerBlock(d_model, n_heads, d_model * 4)
            for _ in range(n_layers)
        ])
        
        # ‚úçÔ∏è Decoder  
        self.decoder_layers = nn.ModuleList([
            TransformerDecoderBlock(d_model, n_heads, d_model * 4)
            for _ in range(n_layers)
        ])
        
        # üéØ Output projection
        self.output_projection = nn.Linear(d_model, vocab_size)
        
    def forward(self, input_ids, decoder_input_ids=None):
        # üìñ Encode input
        encoder_embeddings = self.embedding(input_ids)
        encoder_embeddings = self.pos_encoding(encoder_embeddings)
        
        encoder_output = encoder_embeddings
        for layer in self.encoder_layers:
            encoder_output = layer(encoder_output)
        
        # ‚úçÔ∏è Decode output (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω)
        if decoder_input_ids is not None:
            decoder_embeddings = self.embedding(decoder_input_ids)
            decoder_embeddings = self.pos_encoding(decoder_embeddings)
            
            decoder_output = decoder_embeddings
            for layer in self.decoder_layers:
                decoder_output = layer(decoder_output, encoder_output)
            
            # üéØ –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è
            logits = self.output_projection(decoder_output)
            return logits
        
        return encoder_output
```

---

## –ì–ª–∞–≤–∞ 24: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ

### ‚ö° –¢–µ—Ö–Ω–∏–∫–∏ —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è

```python
# üî• Mixed Precision Training —Å PyTorch AMP
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for batch in dataloader:
    optimizer.zero_grad()
    
    # ‚ö° Forward pass –≤ mixed precision
    with autocast():
        outputs = model(batch)
        loss = criterion(outputs, targets)
    
    # üìä Backward pass —Å scaling
    scaler.scale(loss).backward()
    
    # ‚úÇÔ∏è Gradient clipping
    scaler.unscale_(optimizer)
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
    
    scaler.step(optimizer)
    scaler.update()
```

### üîÑ Gradient Accumulation

```python
# üíæ –ö–æ–≥–¥–∞ GPU –ø–∞–º—è—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞, –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
accumulation_steps = 4
effective_batch_size = batch_size * accumulation_steps

optimizer.zero_grad()

for i, batch in enumerate(dataloader):
    outputs = model(batch)
    loss = criterion(outputs, targets) / accumulation_steps  # üìä –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º loss
    
    loss.backward()
    
    # üîÑ –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞ –∫–∞–∂–¥—ã–µ accumulation_steps –±–∞—Ç—á–µ–π
    if (i + 1) % accumulation_steps == 0:
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        optimizer.zero_grad()
```

### üìä Learning Rate Scheduling

```python
# üå°Ô∏è –†–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è learning rate

# 1. üìâ Exponential Decay
scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)

# 2. üéØ Reduce on Plateau
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=5, verbose=True
)

# 3. üåä Cosine Annealing
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)

# 4. üî• One Cycle Policy (–æ—á–µ–Ω—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω!)
scheduler = torch.optim.lr_scheduler.OneCycleLR(
    optimizer, max_lr=0.01, epochs=num_epochs, steps_per_epoch=len(dataloader)
)

# 5. üõ°Ô∏è Warmup + Cosine (–¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π)
def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):
    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))
        
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))
    
    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
```

### üöÄ Model Parallelism

```python
# üñ•Ô∏è Data Parallelism - –ø—Ä–æ—Å—Ç–µ–π—à–∏–π —Å–ø–æ—Å–æ–±
if torch.cuda.device_count() > 1:
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º {torch.cuda.device_count()} GPU!")
    model = nn.DataParallel(model)

# üåê Distributed Data Parallel (DDP) - –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

def setup_ddp(rank, world_size):
    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '12355'
    dist.init_process_group("nccl", rank=rank, world_size=world_size)

def train_ddp(rank, world_size):
    setup_ddp(rank, world_size)
    
    # üèóÔ∏è –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –∫–∞–∂–¥–æ–º GPU
    model = YourModel().to(rank)
    model = DDP(model, device_ids=[rank])
    
    # üìä Distributed sampler
    sampler = torch.utils.data.distributed.DistributedSampler(dataset)
    dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)
    
    # üîÑ –û–±—ã—á–Ω—ã–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Ü–∏–∫–ª
    for epoch in range(num_epochs):
        sampler.set_epoch(epoch)  # üîÄ –í–∞–∂–Ω–æ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ shuffling
        
        for batch in dataloader:
            # ... –æ–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
            pass
    
    dist.destroy_process_group()

# üöÄ –ó–∞–ø—É—Å–∫ DDP
if __name__ == "__main__":
    world_size = torch.cuda.device_count()
    torch.multiprocessing.spawn(train_ddp, args=(world_size,), nprocs=world_size)
```

---

## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

### üéä –ß—Ç–æ –≤—ã —Ç–µ–ø–µ—Ä—å –∑–Ω–∞–µ—Ç–µ:

‚úÖ **üìö –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã:** –õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞, –º–∞—Ç–∞–Ω–∞–ª–∏–∑, —Ç–µ–æ—Ä–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π  
‚úÖ **üìä –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:** –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ç–µ–∫—Å—Ç—ã, –∞—É–¥–∏–æ, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã  
‚úÖ **üéØ –ó–∞–¥–∞—á–∏ –ò–ò:** –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Ä–µ–≥—Ä–µ—Å—Å–∏—è, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è, –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º  
‚úÖ **üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:** MLP, CNN, RNN/LSTM, Transformers –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è  
‚úÖ **üîß –î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:** –°–ª–æ–∏, –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã, —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è  
‚úÖ **üíº –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏:** –û–±—É—á–µ–Ω–∏–µ, –æ—Ü–µ–Ω–∫–∞, –æ—Ç–ª–∞–¥–∫–∞, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è  
‚úÖ **üöÄ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏:** Transfer Learning, GANs, VAE, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ Transformers  

### üó∫Ô∏è –î–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞ –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏–∑—É—á–µ–Ω–∏—è:

#### 1. üéØ –£–≥–ª—É–±–ª–µ–Ω–∏–µ –≤ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏:
   - üëÅÔ∏è **Computer Vision:** Object Detection, Segmentation, GANs
   - üìù **NLP:** BERT, GPT, T5, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ LLM
   - üì± **Recommender Systems:** Collaborative Filtering, Deep Learning –ø–æ–¥—Ö–æ–¥—ã

#### 2. üß† –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏:
   - üîÑ **Transfer Learning –∏ Fine-tuning**
   - üéì **Meta-Learning –∏ Few-shot Learning**  
   - üõ°Ô∏è **Adversarial Training –∏ Robustness**
   - üîç **Neural Architecture Search (NAS)**

#### 3. üöÄ Production –∏ MLOps:
   - üê≥ **–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (Docker, Kubernetes)**
   - üìä **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**
   - üåê **Distributed Training**
   - üì± **Edge Deployment**

#### 4. üî¨ –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
   - üîç **Explainable AI (LIME, SHAP)**
   - üåê **Federated Learning**
   - ‚öõÔ∏è **Quantum Machine Learning**
   - üß† **Neuromorphic Computing**

### üí° –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã:

üî¨ **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ:** –ö–∞–∂–¥—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö  
üìä **–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ:** –í—Å–µ–≥–¥–∞ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ loss curves –∏ –º–µ—Ç—Ä–∏–∫–∏  
üêõ **–û—Ç–ª–∞–∂–∏–≤–∞–π—Ç–µ:** –ù–∞—á–∏–Ω–∞–π—Ç–µ —Å overfitting –Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ  
üìö **–ß–∏—Ç–∞–π—Ç–µ:** –°–ª–µ–¥–∏—Ç–µ –∑–∞ –Ω–æ–≤—ã–º–∏ —Å—Ç–∞—Ç—å—è–º–∏ –Ω–∞ arXiv  
ü§ù **–î–µ–ª–∏—Ç–µ—Å—å:** –£—á–∞—Å—Ç–≤—É–π—Ç–µ –≤ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è—Ö –∏ open-source –ø—Ä–æ–µ–∫—Ç–∞—Ö  

### üåü –§–∏–Ω–∞–ª—å–Ω—ã–µ –º—ã—Å–ª–∏

**–ü–æ–º–Ω–∏—Ç–µ:** –ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚Äî —ç—Ç–æ –∏–Ω–∂–µ–Ω–µ—Ä–Ω–∞—è –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞. –í–∞–∂–Ω—ã –∫–∞–∫ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è, —Ç–∞–∫ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏. 

üéØ **–ù–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–æ—Å—Ç–æ–≥–æ** ‚Üí üìà **–ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É—Å–ª–æ–∂–Ω—è–π—Ç–µ** ‚Üí üöÄ **–ü—Ä–∏–º–µ–Ω—è–π—Ç–µ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ**

**–£–¥–∞—á–∏ –≤ –∏–∑—É—á–µ–Ω–∏–∏ –º–∏—Ä–∞ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è! üöÄüß†‚ú®**

---

*¬© 2024 - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –≥–ª—É–±–æ–∫–æ–º—É –æ–±—É—á–µ–Ω–∏—é —Å PyTorch*