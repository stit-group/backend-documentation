# –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –≥–ª—É–±–æ–∫–æ–º—É –æ–±—É—á–µ–Ω–∏—é —Å PyTorch
*–û—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Å–Ω–æ–≤ –¥–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä*

---

## üéØ –û —á–µ–º —ç—Ç–æ—Ç –º–∞—Ç–µ—Ä–∏–∞–ª

–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –æ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Å–Ω–æ–≤ –¥–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. **–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥:** –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞ ‚Üí –¥–∞–Ω–Ω—ã–µ ‚Üí –∑–∞–¥–∞—á–∏ ‚Üí –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ‚Üí –ø—Ä–∞–∫—Ç–∏–∫–∞.

**–ß—Ç–æ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ:**
- –ü–æ–Ω–∏–º–∞–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Å–Ω–æ–≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π
- –ó–Ω–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–¥–∞—á –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- –ì–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏ –Ω–∞ PyTorch

---

## üìä –ß–∞—Å—Ç—å 1: –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã

### 1.1 –õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞

**–ó–∞—á–µ–º –Ω—É–∂–Ω–∞:** –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ - —ç—Ç–æ –∫–æ–º–ø–æ–∑–∏—Ü–∏—è –ª–∏–Ω–µ–π–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π —Å –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–º–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è–º–∏.

**–í–µ–∫—Ç–æ—Ä—ã –∏ –æ–ø–µ—Ä–∞—Ü–∏–∏:**
```
–í–µ–∫—Ç–æ—Ä x = [x‚ÇÅ, x‚ÇÇ, x‚ÇÉ]·µÄ

–°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ: x¬∑y = x‚ÇÅy‚ÇÅ + x‚ÇÇy‚ÇÇ + x‚ÇÉy‚ÇÉ
–ù–æ—Ä–º–∞ –≤–µ–∫—Ç–æ—Ä–∞: ||x|| = ‚àö(x‚ÇÅ¬≤ + x‚ÇÇ¬≤ + x‚ÇÉ¬≤)
–ö–æ—Å–∏–Ω—É—Å —É–≥–ª–∞: cos(Œ∏) = (x¬∑y)/(||x|| ||y||)
```

**–ú–∞—Ç—Ä–∏—Ü—ã - –æ—Å–Ω–æ–≤–∞ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π:**
```
–õ–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: y = Wx + b

W = [w‚ÇÅ‚ÇÅ w‚ÇÅ‚ÇÇ w‚ÇÅ‚ÇÉ]    x = [x‚ÇÅ]    b = [b‚ÇÅ]
    [w‚ÇÇ‚ÇÅ w‚ÇÇ‚ÇÇ w‚ÇÇ‚ÇÉ]        [x‚ÇÇ]        [b‚ÇÇ]
                          [x‚ÇÉ]

–†–µ–∑—É–ª—å—Ç–∞—Ç: y‚ÇÅ = w‚ÇÅ‚ÇÅx‚ÇÅ + w‚ÇÅ‚ÇÇx‚ÇÇ + w‚ÇÅ‚ÇÉx‚ÇÉ + b‚ÇÅ
           y‚ÇÇ = w‚ÇÇ‚ÇÅx‚ÇÅ + w‚ÇÇ‚ÇÇx‚ÇÇ + w‚ÇÇ‚ÇÉx‚ÇÉ + b‚ÇÇ
```

```python
import torch
import numpy as np

# –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ PyTorch
x = torch.tensor([1.0, 2.0, 3.0])
y = torch.tensor([4.0, 5.0, 6.0])

# –°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
dot_product = torch.dot(x, y)  # 32.0

# L2 –Ω–æ—Ä–º–∞
l2_norm = torch.norm(x)  # 3.742

# –ú–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ
W = torch.randn(2, 3)  # –°–ª—É—á–∞–π–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ 2x3
b = torch.randn(2)     # Bias –≤–µ–∫—Ç–æ—Ä
output = torch.matmul(W, x) + b  # –õ–∏–Ω–µ–π–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è
```

**–°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è:**
```
Ax = Œªx, –≥–¥–µ Œª - —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, x - —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä

–ò–Ω—Ç—É–∏—Ü–∏—è: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è, –≤–¥–æ–ª—å –∫–æ—Ç–æ—Ä—ã—Ö –º–∞—Ç—Ä–∏—Ü–∞ —Ç–æ–ª—å–∫–æ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç
–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: PCA, –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö
```

### 1.2 –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ - –æ—Å–Ω–æ–≤–∞ –æ–±—É—á–µ–Ω–∏—è:**
```
–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è f'(x) = lim[h‚Üí0] (f(x+h) - f(x))/h

–ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª: –Ω–∞–∫–ª–æ–Ω –∫–∞—Å–∞—Ç–µ–ª—å–Ω–æ–π
–§–∏–∑–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª: —Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏
ML —Å–º—ã—Å–ª: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–∏—Å–∫–æ—Ä–µ–π—à–µ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—è
```

**–ü—Ä–∞–≤–∏–ª–∞ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è:**
```python
# –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞
# (f + g)' = f' + g'
# (f * g)' = f'g + fg'
# (f(g(x)))' = f'(g(x)) * g'(x)  ‚Üê –¶–µ–ø–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ!

# –ü—Ä–∏–º–µ—Ä—ã –≤–∞–∂–Ω—ã—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö
def sigmoid(x):
    return 1 / (1 + torch.exp(-x))

def sigmoid_derivative(x):
    s = sigmoid(x)
    return s * (1 - s)  # –û—á–µ–Ω—å —ç–ª–µ–≥–∞–Ω—Ç–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞!

def relu_derivative(x):
    return (x > 0).float()  # 1 –µ—Å–ª–∏ x > 0, –∏–Ω–∞—á–µ 0
```

**–ß–∞—Å—Ç–Ω—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç:**
```
–§—É–Ω–∫—Ü–∏—è –º–Ω–æ–≥–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: f(x‚ÇÅ, x‚ÇÇ, ..., x‚Çô)

–ß–∞—Å—Ç–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è: ‚àÇf/‚àÇx·µ¢ (—Ñ–∏–∫—Å–∏—Ä—É–µ–º –≤—Å–µ –∫—Ä–æ–º–µ x·µ¢)

–ì—Ä–∞–¥–∏–µ–Ω—Ç: ‚àáf = [‚àÇf/‚àÇx‚ÇÅ, ‚àÇf/‚àÇx‚ÇÇ, ..., ‚àÇf/‚àÇx‚Çô]·µÄ

–°–≤–æ–π—Å—Ç–≤–æ: –≥—Ä–∞–¥–∏–µ–Ω—Ç —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–∏—Å–∫–æ—Ä–µ–π—à–µ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—è
```

```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ PyTorch
x = torch.tensor([2.0, 3.0], requires_grad=True)
y = x[0]**2 + x[1]**3  # f(x‚ÇÅ,x‚ÇÇ) = x‚ÇÅ¬≤ + x‚ÇÇ¬≥

y.backward()  # –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
print(x.grad)  # [4.0, 27.0] = [2*x‚ÇÅ, 3*x‚ÇÇ¬≤]
```

**–¶–µ–ø–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ - —Å–µ—Ä–¥—Ü–µ backpropagation:**
```
–ö–æ–º–ø–æ–∑–∏—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–π: h(x) = f(g(x))
–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è: h'(x) = f'(g(x)) * g'(x)

–í –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö:
x ‚Üí —Å–ª–æ–π1 ‚Üí —Å–ª–æ–π2 ‚Üí ... ‚Üí –≤—ã—Ö–æ–¥ ‚Üí –æ—à–∏–±–∫–∞
–ì—Ä–∞–¥–∏–µ–Ω—Ç –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞–∑–∞–¥ –ø–æ —Ü–µ–ø–Ω–æ–º—É –ø—Ä–∞–≤–∏–ª—É
```

### 1.3 –¢–µ–æ—Ä–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∏ —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ–ª–∏—á–∏–Ω—ã:**
```
P(A) - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏—è A
P(A|B) - —É—Å–ª–æ–≤–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å A –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ B

–¢–µ–æ—Ä–µ–º–∞ –ë–∞–π–µ—Å–∞: P(A|B) = P(B|A) * P(A) / P(B)
–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ ML: –Ω–∞–∏–≤–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
```

**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:**
```python
import torch.distributions as dist

# –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ N(Œº, œÉ¬≤)
normal = dist.Normal(0, 1)  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª—å
samples = normal.sample((1000,))

# –ë–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
binomial = dist.Binomial(10, 0.5)  # 10 –∏—Å–ø—ã—Ç–∞–Ω–∏–π, p=0.5

# –ë–µ—Ä–Ω—É–ª–ª–∏ (–¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
bernoulli = dist.Bernoulli(0.7)  # p=0.7
```

**–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã:**
```
–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ: E[X] = Œº
–î–∏—Å–ø–µ—Ä—Å–∏—è: Var[X] = E[(X-Œº)¬≤] = œÉ¬≤
–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: œÉ = ‚àöVar[X]

–î–ª—è –≤—ã–±–æ—Ä–∫–∏:
xÃÑ = (1/n) Œ£x·µ¢  (–≤—ã–±–æ—Ä–æ—á–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ)
s¬≤ = (1/(n-1)) Œ£(x·µ¢ - xÃÑ)¬≤  (–≤—ã–±–æ—Ä–æ—á–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è)
```

**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏ —ç–Ω—Ç—Ä–æ–ø–∏—è:**
```
–≠–Ω—Ç—Ä–æ–ø–∏—è: H(X) = -Œ£ p(x) log p(x)
–ò–Ω—Ç—É–∏—Ü–∏—è: –º–µ—Ä–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏

–ö—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è: H(p,q) = -Œ£ p(x) log q(x)
–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

KL-–¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è: D_KL(p||q) = Œ£ p(x) log(p(x)/q(x))
–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
```

```python
# –ö—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è –≤ PyTorch
import torch.nn.functional as F

# –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (one-hot)
targets = torch.tensor([0, 1, 2])  # –ö–ª–∞—Å—Å—ã 0, 1, 2

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–ª–æ–≥–∏—Ç—ã)
predictions = torch.tensor([[2.0, 1.0, 0.1],
                           [0.5, 2.5, 1.0], 
                           [0.1, 0.2, 3.0]])

# –ö—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è
loss = F.cross_entropy(predictions, targets)
```

### 1.4 –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

**–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫:**
```
–¶–µ–ª—å: –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å L(Œ∏)

–ê–ª–≥–æ—Ä–∏—Ç–º:
Œ∏_{t+1} = Œ∏_t - Œ∑ * ‚àáL(Œ∏_t)

–≥–¥–µ Œ∑ - learning rate (—à–∞–≥ –æ–±—É—á–µ–Ω–∏—è)
```

**–ü—Ä–æ–±–ª–µ–º—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞:**
```
1. –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã
2. –°–µ–¥–ª–æ–≤—ã–µ —Ç–æ—á–∫–∏  
3. –ü–ª–æ—Ö–∞—è –æ–±—É—Å–ª–æ–≤–ª–µ–Ω–Ω–æ—Å—Ç—å (—Ä–∞–∑–Ω—ã–µ –º–∞—Å—à—Ç–∞–±—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤)
4. –í—ã–±–æ—Ä learning rate
```

**–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã:**
```python
# Momentum - —É—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
# v_{t+1} = Œ≤*v_t + (1-Œ≤)*‚àáL(Œ∏_t)
# Œ∏_{t+1} = Œ∏_t - Œ∑*v_{t+1}
optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)

# Adam - –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π learning rate
# –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç momentum –∏ RMSprop
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))

# AdamW - Adam —Å –≤–µ—Å–æ–≤—ã–º –∑–∞—Ç—É—Ö–∞–Ω–∏–µ–º
optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
```

---

## üìö –ß–∞—Å—Ç—å 2: –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–¥–∞—á–∏ –ò–ò

### 2.1 –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

**–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:**
```
–¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: —Å—Ç—Ä–æ–∫–∏ = –ø—Ä–∏–º–µ—Ä—ã, —Å—Ç–æ–ª–±—Ü—ã = –ø—Ä–∏–∑–Ω–∞–∫–∏
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –í–æ–∑—Ä–∞—Å—Ç     ‚îÇ –î–æ—Ö–æ–¥       ‚îÇ –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ ‚îÇ –ö–ª–∞—Å—Å       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 25          ‚îÇ 50000       ‚îÇ –í—ã—Å—à–µ–µ      ‚îÇ –û–¥–æ–±—Ä–µ–Ω     ‚îÇ
‚îÇ 45          ‚îÇ 80000       ‚îÇ –°—Ä–µ–¥–Ω–µ–µ     ‚îÇ –û–¥–æ–±—Ä–µ–Ω     ‚îÇ
‚îÇ 22          ‚îÇ 30000       ‚îÇ –°—Ä–µ–¥–Ω–µ–µ     ‚îÇ –û—Ç–∫–ª–æ–Ω–µ–Ω    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: MLP, –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥, SVM
```

**–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:**
```
2D —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: –≤—ã—Å–æ—Ç–∞ √ó —à–∏—Ä–∏–Ω–∞ √ó –∫–∞–Ω–∞–ª—ã
RGB: 3 –∫–∞–Ω–∞–ª–∞ (–∫—Ä–∞—Å–Ω—ã–π, –∑–µ–ª–µ–Ω—ã–π, —Å–∏–Ω–∏–π)
Grayscale: 1 –∫–∞–Ω–∞–ª

–ü—Ä–∏–º–µ—Ä: 224√ó224√ó3 = 150,528 –ø–∏–∫—Å–µ–ª–µ–π
–ö–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å: –∑–Ω–∞—á–µ–Ω–∏–µ 0-255 (–∏–ª–∏ 0-1 –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: CNN (ResNet, EfficientNet, Vision Transformer)
```

**–¢–µ–∫—Å—Ç—ã:**
```
–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–æ–≤/—Å–ª–æ–≤
–ü—Ä–æ–±–ª–µ–º—ã: –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª–∏–Ω–∞, –ø–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω, –∫–æ–Ω—Ç–µ–∫—Å—Ç

–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è:
- One-hot encoding: [0,0,1,0,0] –¥–ª—è —Å–ª–æ–≤–∞—Ä—è –∏–∑ 5 —Å–ª–æ–≤
- Word embeddings: –ø–ª–æ—Ç–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, 300 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏)
- Subword tokens: BPE, WordPiece

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: RNN, LSTM, Transformer (BERT, GPT)
```

**–ê—É–¥–∏–æ:**
```
–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã: –∞–º–ø–ª–∏—Ç—É–¥–∞ –∑–≤—É–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
–ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: 16kHz, 44.1kHz

–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è:
- Waveform: –∏—Å—Ö–æ–¥–Ω—ã–π —Å–∏–≥–Ω–∞–ª
- –°–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞: —á–∞—Å—Ç–æ—Ç–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è
- MFCC: mel-frequency cepstral coefficients

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: 1D CNN, RNN, Transformer
```

**–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã:**
```
–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –≤–æ –≤—Ä–µ–º–µ–Ω–∏
–°–≤–æ–π—Å—Ç–≤–∞: —Ç—Ä–µ–Ω–¥, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è

–ü—Ä–∏–º–µ—Ä—ã:
- –¶–µ–Ω—ã –∞–∫—Ü–∏–π
- –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
- –ü—Ä–æ–¥–∞–∂–∏ –ø–æ –º–µ—Å—è—Ü–∞–º

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: ARIMA, LSTM, Temporal CNN
```

### 2.2 –¢–∏–ø—ã –∑–∞–¥–∞—á –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

**–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:**
```
–¶–µ–ª—å: –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é (–∫–ª–∞—Å—Å)

–ë–∏–Ω–∞—Ä–Ω–∞—è: —Å–ø–∞–º/–Ω–µ —Å–ø–∞–º, –±–æ–ª–µ–Ω/–∑–¥–æ—Ä–æ–≤
  –ú–µ—Ç—Ä–∏–∫–∏: accuracy, precision, recall, F1, AUC-ROC

–ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (1000 –∫–ª–∞—Å—Å–æ–≤ ImageNet)
  –ú–µ—Ç—Ä–∏–∫–∏: accuracy, macro/micro F1

–ú–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–∞—è: —Ç–µ–≥ —Ñ–æ—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å [—Å–æ–±–∞–∫–∞, –ø–∞—Ä–∫, —Å–æ–ª–Ω–µ—á–Ω–æ]
  –ú–µ—Ç—Ä–∏–∫–∏: Hamming loss, subset accuracy
```

```python
# –ü—Ä–∏–º–µ—Ä –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
import torch.nn as nn

class BinaryClassifier(nn.Module):
    def __init__(self, input_size):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_size, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()  # –í—ã—Ö–æ–¥ –æ—Ç 0 –¥–æ 1
        )
    
    def forward(self, x):
        return self.layers(x)

# –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
criterion = nn.BCELoss()  # Binary Cross-Entropy
```

**–†–µ–≥—Ä–µ—Å—Å–∏—è:**
```
–¶–µ–ª—å: –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

–ü—Ä–∏–º–µ—Ä—ã:
- –¶–µ–Ω–∞ –¥–æ–º–∞ –ø–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º
- –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∑–∞–≤—Ç—Ä–∞
- –†–µ–π—Ç–∏–Ω–≥ —Ñ–∏–ª—å–º–∞ (1-10)

–ú–µ—Ç—Ä–∏–∫–∏:
- MSE: Mean Squared Error
- MAE: Mean Absolute Error  
- R¬≤: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏
```

```python
class Regressor(nn.Module):
    def __init__(self, input_size):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_size, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)  # –û–¥–∏–Ω –≤—ã—Ö–æ–¥, –±–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        )
    
    def forward(self, x):
        return self.layers(x)

# –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
criterion = nn.MSELoss()
```

**–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (–±–µ–∑ —É—á–∏—Ç–µ–ª—è):**
```
–¶–µ–ª—å: –Ω–∞–π—Ç–∏ —Å–∫—Ä—ã—Ç—ã–µ –≥—Ä—É–ø–ø—ã –≤ –¥–∞–Ω–Ω—ã—Ö

–ê–ª–≥–æ—Ä–∏—Ç–º—ã:
- K-means: —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ k –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
- DBSCAN: –∫–ª–∞—Å—Ç–µ—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã
- Hierarchical clustering: –∏–µ—Ä–∞—Ä—Ö–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

–ú–µ—Ç—Ä–∏–∫–∏: silhouette score, inertia
```

**–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º:**
```
–ê–≥–µ–Ω—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç —Å–æ —Å—Ä–µ–¥–æ–π:
–°–æ—Å—Ç–æ—è–Ω–∏–µ ‚Üí –î–µ–π—Å—Ç–≤–∏–µ ‚Üí –ù–∞–≥—Ä–∞–¥–∞ ‚Üí –ù–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

–ü—Ä–∏–º–µ—Ä—ã:
- –ò–≥—Ä—ã (—à–∞—Ö–º–∞—Ç—ã, Go)
- –†–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã

–ê–ª–≥–æ—Ä–∏—Ç–º—ã: Q-learning, Policy Gradient, Actor-Critic
```

### 2.3 –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö

**–ò–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç–∏:**
```
–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
- –¢—Ä–∞–Ω—Å–ª—è—Ü–∏–æ–Ω–Ω–∞—è: –∫–æ—Ç –æ—Å—Ç–∞–µ—Ç—Å—è –∫–æ—Ç–æ–º –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ
- –ú–∞—Å—à—Ç–∞–±–Ω–∞—è: –∫–æ—Ç –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è—Ö
- –ü–æ–≤–æ—Ä–æ—Ç–Ω–∞—è: –∫–æ—Ç –ø–æ–¥ —Ä–∞–∑–Ω—ã–º–∏ —É–≥–ª–∞–º–∏

–¢–µ–∫—Å—Ç—ã:
- –ü–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω
- –õ–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Å–æ—Å–µ–¥–Ω–∏–µ —Å–ª–æ–≤–∞)
- –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

–ê—É–¥–∏–æ:
- –í—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- –ß–∞—Å—Ç–æ—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- –§–∞–∑–æ–≤—ã–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
```

**Preprocessing –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
```python
# –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
transform = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])

# –¢–µ–∫—Å—Ç—ã  
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
tokens = tokenizer("Hello world", return_tensors="pt")

# –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

---

## üß† –ß–∞—Å—Ç—å 3: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –∏—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ

### 3.1 –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–π –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω (MLP)

**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞:**
```
–°–ª–æ–π: z = Wx + b
–ê–∫—Ç–∏–≤–∞—Ü–∏—è: a = f(z)

–ü–æ–ª–Ω–∞—è —Å–µ—Ç—å:
x ‚Üí z‚ÇÅ = W‚ÇÅx + b‚ÇÅ ‚Üí a‚ÇÅ = f(z‚ÇÅ) ‚Üí z‚ÇÇ = W‚ÇÇa‚ÇÅ + b‚ÇÇ ‚Üí a‚ÇÇ = f(z‚ÇÇ) ‚Üí ...

–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è: MLP –º–æ–∂–µ—Ç –ø—Ä–∏–±–ª–∏–∑–∏—Ç—å –ª—é–±—É—é 
–Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —Å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
```

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- –ó–∞–¥–∞—á–∏ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º –≤—Ö–æ–¥–∞
- Baseline –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

```python
class DeepMLP(nn.Module):
    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.2):
        super().__init__()
        
        layers = []
        prev_size = input_size
        
        for hidden_size in hidden_sizes:
            layers.extend([
                nn.Linear(prev_size, hidden_size),
                nn.BatchNorm1d(hidden_size),
                nn.ReLU(),
                nn.Dropout(dropout)
            ])
            prev_size = hidden_size
        
        layers.append(nn.Linear(prev_size, output_size))
        self.network = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.network(x)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
model = DeepMLP(
    input_size=100,
    hidden_sizes=[512, 256, 128],
    output_size=10,
    dropout=0.3
)
```

### 3.2 –°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–µ—Ç–∏ (CNN)

**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞:**
```
–û–ø–µ—Ä–∞—Ü–∏—è —Å–≤–µ—Ä—Ç–∫–∏ (2D):
(f * g)[i,j] = Œ£Œ£ f[m,n] * g[i-m, j-n]

–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏:
output[i,j] = Œ£ Œ£ input[i+m, j+n] * kernel[m,n] + bias

–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
- Kernel size: —Ä–∞–∑–º–µ—Ä —Ñ–∏–ª—å—Ç—Ä–∞ (3√ó3, 5√ó5)
- Stride: —à–∞–≥ —Å–¥–≤–∏–≥–∞ —Ñ–∏–ª—å—Ç—Ä–∞
- Padding: –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—Ä–∞–µ–≤
- Dilation: —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞
```

**–û—Å–Ω–æ–≤–Ω—ã–µ —Å–ª–æ–∏:**
```python
# –°–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π
conv = nn.Conv2d(
    in_channels=3,      # RGB –≤—Ö–æ–¥
    out_channels=64,    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    kernel_size=3,      # –†–∞–∑–º–µ—Ä —Ñ–∏–ª—å—Ç—Ä–∞ 3√ó3
    stride=1,           # –®–∞–≥
    padding=1           # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
)

# –ü—É–ª–∏–Ω–≥ - —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
pool = nn.MaxPool2d(kernel_size=2, stride=2)  # –£–º–µ–Ω—å—à–∞–µ–º –≤ 2 —Ä–∞–∑–∞

# Batch normalization - —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
bn = nn.BatchNorm2d(64)

# –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø—É–ª–∏–Ω–≥ - —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä
adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))  # –õ—é–±–æ–π —Ä–∞–∑–º–µ—Ä ‚Üí 1√ó1
```

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã CNN:**
```
LeNet (1998): Conv‚ÜíPool‚ÜíConv‚ÜíPool‚ÜíFC‚ÜíFC
  - –ü–µ—Ä–≤–∞—è —É—Å–ø–µ—à–Ω–∞—è CNN
  - –î–ª—è —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä MNIST

AlexNet (2012): Conv‚ÜíPool‚ÜíConv‚ÜíPool‚ÜíConv‚ÜíConv‚ÜíConv‚ÜíPool‚ÜíFC‚ÜíFC‚ÜíFC
  - ReLU –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
  - Dropout —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
  - GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ

VGG (2014): –û—á–µ–Ω—å –≥–ª—É–±–æ–∫–∞—è —Å–µ—Ç—å —Å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ 3√ó3
  - VGG-16: 16 —Å–ª–æ–µ–≤
  - –ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: —Ç–æ–ª—å–∫–æ Conv3√ó3 –∏ MaxPool2√ó2

ResNet (2015): Residual connections
  - –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∑–∞—Ç—É—Ö–∞—é—â–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
  - –°–µ—Ç–∏ –¥–æ 152 —Å–ª–æ–µ–≤
```

```python
class ResNetBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å
        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        # Skip connection
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
    
    def forward(self, x):
        out = torch.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)  # Residual connection
        out = torch.relu(out)
        return out
```

**–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏:**
```python
# Depthwise Separable Convolution (MobileNet)
class DepthwiseSeparableConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        # Depthwise: —Å–≤–µ—Ä—Ç–∫–∞ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É –æ—Ç–¥–µ–ª—å–Ω–æ
        self.depthwise = nn.Conv2d(in_channels, in_channels, 3, 1, 1, 
                                  groups=in_channels, bias=False)
        # Pointwise: —Å–º–µ—à–∏–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–æ–≤
        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)
        
    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        return x

# Attention –≤ CNN (Squeeze-and-Excitation)
class SEBlock(nn.Module):
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.squeeze = nn.AdaptiveAvgPool2d(1)
        self.excitation = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.squeeze(x).view(b, c)
        y = self.excitation(y).view(b, c, 1, 1)
        return x * y.expand_as(x)
```

### 3.3 –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏ (RNN)

**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞:**
```
Vanilla RNN:
h_t = tanh(W_hh * h_{t-1} + W_xh * x_t + b_h)
y_t = W_hy * h_t + b_y

–ü—Ä–æ–±–ª–µ–º–∞: –∑–∞—Ç—É—Ö–∞—é—â–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
‚àÇh_t/‚àÇh_{t-k} = ‚àè(i=0 to k-1) ‚àÇh_{t-i}/‚àÇh_{t-i-1}
–ï—Å–ª–∏ |‚àÇh_{t-i}/‚àÇh_{t-i-1}| < 1, —Ç–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ ‚Üí 0
```

**LSTM - Long Short-Term Memory:**
```
–ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è: —É–ø—Ä–∞–≤–ª—è–µ–º–∞—è –ø–∞–º—è—Ç—å —á–µ—Ä–µ–∑ "–≤–æ—Ä–æ—Ç–∞"

Forget gate: f_t = œÉ(W_f * [h_{t-1}, x_t] + b_f)
Input gate:  i_t = œÉ(W_i * [h_{t-1}, x_t] + b_i)
Output gate: o_t = œÉ(W_o * [h_{t-1}, x_t] + b_o)

Candidate: CÃÉ_t = tanh(W_C * [h_{t-1}, x_t] + b_C)
Cell state: C_t = f_t * C_{t-1} + i_t * CÃÉ_t
Hidden state: h_t = o_t * tanh(C_t)
```

```python
class LSTMFromScratch(nn.Module):
    def __init__(self, input_size, hidden_size):
        super().__init__()
        self.hidden_size = hidden_size
        
        # –í—Å–µ –≤–æ—Ä–æ—Ç–∞ –≤ –æ–¥–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        self.weight_ih = nn.Linear(input_size, 4 * hidden_size)
        self.weight_hh = nn.Linear(hidden_size, 4 * hidden_size)
        
    def forward(self, input, hidden=None):
        if hidden is None:
            h = torch.zeros(input.size(0), self.hidden_size)
            c = torch.zeros(input.size(0), self.hidden_size)
        else:
            h, c = hidden
            
        outputs = []
        
        for x in input.unbind(1):  # –ü–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —à–∞–≥–∞–º
            # –í—Å–µ –≤–æ—Ä–æ—Ç–∞ —Å—Ä–∞–∑—É
            gates = self.weight_ih(x) + self.weight_hh(h)
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ 4 –≤–æ—Ä–æ—Ç–∞
            i_gate, f_gate, g_gate, o_gate = gates.chunk(4, 1)
            
            i_gate = torch.sigmoid(i_gate)  # Input gate
            f_gate = torch.sigmoid(f_gate)  # Forget gate
            g_gate = torch.tanh(g_gate)     # New info
            o_gate = torch.sigmoid(o_gate)  # Output gate
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
            c = f_gate * c + i_gate * g_gate
            h = o_gate * torch.tanh(c)
            
            outputs.append(h)
            
        return torch.stack(outputs, 1), (h, c)
```

**GRU - Gated Recurrent Unit:**
```
–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è LSTM:
z_t = œÉ(W_z * [h_{t-1}, x_t])  # Update gate
r_t = œÉ(W_r * [h_{t-1}, x_t])  # Reset gate
hÃÉ_t = tanh(W * [r_t * h_{t-1}, x_t])  # New hidden state
h_t = (1 - z_t) * h_{t-1} + z_t * hÃÉ_t  # Final hidden state

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –±—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–∞–µ—Ç—Å—è
```

**Bidirectional RNN:**
```
–ò–¥–µ—è: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã

Forward:  h‚ÇÅ‚Åª ‚Üí h‚ÇÇ‚Åª ‚Üí h‚ÇÉ‚Åª ‚Üí h‚ÇÑ‚Åª
Backward: h‚ÇÅ‚Å∫ ‚Üê h‚ÇÇ‚Å∫ ‚Üê h‚ÇÉ‚Å∫ ‚Üê h‚ÇÑ‚Å∫

–ò—Ç–æ–≥–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: h_t = [h_t‚Åª; h_t‚Å∫]
```

```python
class BiLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers=1):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size, 
            hidden_size, 
            num_layers, 
            batch_first=True,
            bidirectional=True  # –ö–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä
        )
        self.hidden_size = hidden_size
        
    def forward(self, x):
        # –í—ã—Ö–æ–¥: (batch, seq_len, 2*hidden_size)
        # –ü–æ—Å–ª–µ–¥–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä —É–¥–≤–∞–∏–≤–∞–µ—Ç—Å—è –∏–∑-–∑–∞ bidirectional
        output, (hidden, cell) = self.lstm(x)
        return output

# Attention –¥–ª—è RNN
class AttentionRNN(nn.Module):
    def __init__(self, hidden_size):
        super().__init__()
        self.attention = nn.Linear(hidden_size, 1)
        
    def forward(self, rnn_outputs):
        # rnn_outputs: (batch, seq_len, hidden_size)
        scores = self.attention(rnn_outputs)  # (batch, seq_len, 1)
        weights = torch.softmax(scores, dim=1)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
        context = torch.sum(weights * rnn_outputs, dim=1)
        return context, weights
```

### 3.4 –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã

**–†–µ–≤–æ–ª—é—Ü–∏—è –≤ NLP:**
```
–ü—Ä–æ–±–ª–µ–º—ã RNN:
1. –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–º–µ–¥–ª–µ–Ω–Ω–æ)
2. –ó–∞—Ç—É—Ö–∞—é—â–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
3. –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏

–†–µ—à–µ–Ω–∏–µ Transformer:
1. Self-attention - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
2. –ü—Ä—è–º—ã–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ª—é–±—ã–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏
3. Positional encoding –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞
```

**Self-Attention –º–µ—Ö–∞–Ω–∏–∑–º:**
```
–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞:
Attention(Q,K,V) = softmax(QK^T/‚àöd_k)V

–≥–¥–µ:
Q = XW_Q  (Query - —á—Ç–æ –∏—â–µ–º)
K = XW_K  (Key - –≥–¥–µ –∏—â–µ–º)  
V = XW_V  (Value - —á—Ç–æ –∏–∑–≤–ª–µ–∫–∞–µ–º)

–ò–Ω—Ç—É–∏—Ü–∏—è: –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –º–æ–∂–µ—Ç "–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å" –Ω–∞ –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ
```

```python
class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, num_heads):
        super().__init__()
        assert d_model % num_heads == 0
        
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_k = d_model // num_heads
        
        # –õ–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–æ–µ–∫—Ü–∏–∏ –¥–ª—è Q, K, V
        self.w_q = nn.Linear(d_model, d_model)
        self.w_k = nn.Linear(d_model, d_model)
        self.w_v = nn.Linear(d_model, d_model)
        self.w_o = nn.Linear(d_model, d_model)
        
    def scaled_dot_product_attention(self, Q, K, V, mask=None):
        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)
        
        if mask is not None:
            scores = scores.masked_fill(mask == 0, -1e9)
            
        attention_weights = torch.softmax(scores, dim=-1)
        context = torch.matmul(attention_weights, V)
        
        return context, attention_weights
    
    def forward(self, x, mask=None):
        batch_size, seq_len, d_model = x.size()
        
        # –õ–∏–Ω–µ–π–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        Q = self.w_q(x)  # (batch, seq_len, d_model)
        K = self.w_k(x)
        V = self.w_v(x)
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –≥–æ–ª–æ–≤—ã
        Q = Q.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)
        K = K.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2) 
        V = V.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)
        
        # Attention –¥–ª—è –∫–∞–∂–¥–æ–π –≥–æ–ª–æ–≤—ã
        context, attention = self.scaled_dot_product_attention(Q, K, V, mask)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≥–æ–ª–æ–≤—ã
        context = context.transpose(1, 2).contiguous().view(
            batch_size, seq_len, d_model
        )
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è
        output = self.w_o(context)
        return output
```

**Transformer Block:**
```python
class TransformerBlock(nn.Module):
    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):
        super().__init__()
        
        # Multi-head attention
        self.attention = MultiHeadAttention(d_model, num_heads)
        
        # Feed-forward network
        self.feed_forward = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.ReLU(),
            nn.Linear(d_ff, d_model)
        )
        
        # Layer normalization
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        
        # Dropout
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x, mask=None):
        # Self-attention —Å residual connection
        attention_output = self.attention(x, mask)
        x = self.norm1(x + self.dropout(attention_output))
        
        # Feed-forward —Å residual connection  
        ff_output = self.feed_forward(x)
        x = self.norm2(x + self.dropout(ff_output))
        
        return x
```

**Positional Encoding:**
```
–ü—Ä–æ–±–ª–µ–º–∞: Transformer –Ω–µ –∑–Ω–∞–µ—Ç –æ –ø–æ—Ä—è–¥–∫–µ —Å–ª–æ–≤
–†–µ—à–µ–Ω–∏–µ: –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

PE(pos, 2i) = sin(pos / 10000^(2i/d_model))
PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))
```

```python
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super().__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1).float()
        
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * 
                           -(math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        self.register_buffer('pe', pe.unsqueeze(0))
        
    def forward(self, x):
        return x + self.pe[:, :x.size(1)]
```

---

## üîß –ß–∞—Å—Ç—å 4: –î–µ—Ç–∞–ª–∏ —Å–ª–æ–µ–≤ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä

### 4.1 –°–ª–æ–∏ –∏ –∏—Ö —Ä–æ–ª–∏

**Linear (Dense) —Å–ª–æ–π:**
```
–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞: y = xW^T + b
–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: W (weight matrix), b (bias vector)
–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –∏–∑—É—á–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: input_size * output_size + output_size
```

**Normalization —Å–ª–æ–∏:**
```python
# Batch Normalization - –ø–æ –±–∞—Ç—á—É
bn = nn.BatchNorm1d(num_features)
# –§–æ—Ä–º—É–ª–∞: (x - Œº_batch) / ‚àö(œÉ¬≤_batch + Œµ) * Œ≥ + Œ≤

# Layer Normalization - –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
ln = nn.LayerNorm(normalized_shape)
# –§–æ—Ä–º—É–ª–∞: (x - Œº_layer) / ‚àö(œÉ¬≤_layer + Œµ) * Œ≥ + Œ≤

# Group Normalization - –ø–æ –≥—Ä—É–ø–ø–∞–º –∫–∞–Ω–∞–ª–æ–≤
gn = nn.GroupNorm(num_groups, num_channels)

# Instance Normalization - –ø–æ –∫–∞–∂–¥–æ–º—É –ø—Ä–∏–º–µ—Ä—É
instance_norm = nn.InstanceNorm2d(num_features)
```

**–ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
```python
# ReLU: max(0, x)
relu = nn.ReLU()
# –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: –ø—Ä–æ—Å—Ç–∞—è, —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∑–∞—Ç—É—Ö–∞—é—â–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
# –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏: "–º–µ—Ä—Ç–≤—ã–µ –Ω–µ–π—Ä–æ–Ω—ã" –ø—Ä–∏ x < 0

# Leaky ReLU: max(0.01x, x)
leaky_relu = nn.LeakyReLU(0.01)
# –†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤

# ELU: x –µ—Å–ª–∏ x > 0, Œ±(e^x - 1) –µ—Å–ª–∏ x ‚â§ 0
elu = nn.ELU(alpha=1.0)
# –ì–ª–∞–¥–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è, —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –±–ª–∏–∑–∫–æ –∫ 0

# Swish: x * sigmoid(x)
def swish(x):
    return x * torch.sigmoid(x)
# –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ EfficientNet

# GELU: x * Œ¶(x), –≥–¥–µ Œ¶ - CDF —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏
gelu = nn.GELU()
# –ü–æ–ø—É–ª—è—Ä–Ω–∞ –≤ Transformers
```

**–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è:**
```python
# Dropout - —Å–ª—É—á–∞–π–Ω–æ –æ–±–Ω—É–ª—è–µ—Ç –Ω–µ–π—Ä–æ–Ω—ã
dropout = nn.Dropout(p=0.5)  # 50% –Ω–µ–π—Ä–æ–Ω–æ–≤

# DropBlock - structured dropout –¥–ª—è CNN
class DropBlock2d(nn.Module):
    def __init__(self, drop_rate, block_size):
        super().__init__()
        self.drop_rate = drop_rate
        self.block_size = block_size
        
    def forward(self, x):
        if not self.training:
            return x
        # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è structured dropout
        # –û–±–Ω—É–ª—è–µ—Ç —Ü–µ–ª—ã–µ –±–ª–æ–∫–∏ –≤ feature maps

# Weight Decay - L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)
# –î–æ–±–∞–≤–ª—è–µ—Ç Œª||W||¬≤ –∫ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å
```

### 4.2 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

**Residual Connections:**
```
–ü—Ä–æ–±–ª–µ–º–∞: –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∑–∞—Ç—É—Ö–∞—é—Ç –≤ –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç—è—Ö
–†–µ—à–µ–Ω–∏–µ: F(x) + x –≤–º–µ—Å—Ç–æ F(x)

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
1. –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç –Ω–∞–ø—Ä—è–º—É—é
2. –õ–µ–≥—á–µ –æ–±—É—á–∏—Ç—å —Ç–æ–∂–¥–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
3. –ü–æ–∑–≤–æ–ª—è–µ—Ç —Å—Ç—Ä–æ–∏—Ç—å –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–∏–µ —Å–µ—Ç–∏
```

**Dense Connections (DenseNet):**
```
–ò–¥–µ—è: –∫–∞–∂–¥—ã–π —Å–ª–æ–π –ø–æ–ª—É—á–∞–µ—Ç –≤—Ö–æ–¥—ã –æ—Ç –≤—Å–µ—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö

–°–ª–æ–π 1: x‚ÇÅ = f‚ÇÅ(x‚ÇÄ)
–°–ª–æ–π 2: x‚ÇÇ = f‚ÇÇ([x‚ÇÄ, x‚ÇÅ])  
–°–ª–æ–π 3: x‚ÇÉ = f‚ÇÉ([x‚ÇÄ, x‚ÇÅ, x‚ÇÇ])
...

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç—å
```

**Attention –º–µ—Ö–∞–Ω–∏–∑–º—ã:**
```python
# Spatial Attention –¥–ª—è CNN
class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super().__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2)
        
    def forward(self, x):
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –∫–∞–Ω–∞–ª–∞–º
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ –ø–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è
        attention = torch.cat([avg_out, max_out], dim=1)
        attention = torch.sigmoid(self.conv(attention))
        
        return x * attention

# Channel Attention
class ChannelAttention(nn.Module):
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels)
        )
        
    def forward(self, x):
        b, c, _, _ = x.size()
        
        # Global average –∏ max pooling
        avg = self.avg_pool(x).view(b, c)
        max_val = self.max_pool(x).view(b, c)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞
        avg_out = self.fc(avg)
        max_out = self.fc(max_val)
        
        attention = torch.sigmoid(avg_out + max_out).view(b, c, 1, 1)
        return x * attention
```

### 4.3 –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

**Vision Transformer (ViT):**
```
–ò–¥–µ—è: –ø—Ä–∏–º–µ–Ω–∏—Ç—å Transformer –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
–†–µ—à–µ–Ω–∏–µ: —Ä–∞–∑–±–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –ø–∞—Ç—á–∏

–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 224√ó224√ó3 ‚Üí –ü–∞—Ç—á–∏ 16√ó16√ó3 ‚Üí –í–µ–∫—Ç–æ—Ä—ã 768D
196 –ø–∞—Ç—á–µ–π ‚Üí –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è Transformer
```

```python
class VisionTransformer(nn.Module):
    def __init__(self, img_size=224, patch_size=16, num_classes=1000, 
                 dim=768, depth=12, heads=12):
        super().__init__()
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ç—á–µ–π
        self.patch_size = patch_size
        self.num_patches = (img_size // patch_size) ** 2
        patch_dim = 3 * patch_size ** 2
        
        # Embedding –ø–∞—Ç—á–µ–π
        self.patch_embedding = nn.Linear(patch_dim, dim)
        
        # Positional embeddings
        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches + 1, dim))
        
        # CLS token –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))
        
        # Transformer blocks
        self.transformer = nn.ModuleList([
            TransformerBlock(dim, heads, dim * 4)
            for _ in range(depth)
        ])
        
        # Classification head
        self.mlp_head = nn.Linear(dim, num_classes)
        
    def forward(self, x):
        batch_size = x.shape[0]
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–∞—Ç—á–∏
        x = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)
        x = x.contiguous().view(batch_size, -1, 3 * self.patch_size ** 2)
        
        # Embedding –ø–∞—Ç—á–µ–π
        x = self.patch_embedding(x)
        
        # –î–æ–±–∞–≤–ª—è–µ–º CLS token
        cls_tokens = self.cls_token.expand(batch_size, -1, -1)
        x = torch.cat([cls_tokens, x], dim=1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º positional encoding
        x += self.pos_embedding
        
        # Transformer layers
        for transformer in self.transformer:
            x = transformer(x)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ CLS token
        return self.mlp_head(x[:, 0])
```

**EfficientNet - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ:**
```
–ò–¥–µ—è: —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã, —à–∏—Ä–∏–Ω—ã –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è

Compound Scaling:
depth = Œ±^œÜ
width = Œ≤^œÜ  
resolution = Œ≥^œÜ

–≥–¥–µ Œ±¬∑Œ≤¬≤¬∑Œ≥¬≤ ‚âà 2 (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤)
```

**MobileNet - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:**
```python
class DepthwiseSeparableConv(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        
        # Depthwise convolution
        self.depthwise = nn.Conv2d(
            in_channels, in_channels, 3, stride, 1, 
            groups=in_channels, bias=False
        )
        self.bn1 = nn.BatchNorm2d(in_channels)
        
        # Pointwise convolution
        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
    def forward(self, x):
        x = torch.relu(self.bn1(self.depthwise(x)))
        x = torch.relu(self.bn2(self.pointwise(x)))
        return x

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:
# –û–±—ã—á–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞: K √ó K √ó C_in √ó C_out
# Depthwise Separable: K √ó K √ó C_in + C_in √ó C_out
# –≠–∫–æ–Ω–æ–º–∏—è: (K √ó K √ó C_in √ó C_out) / (K √ó K √ó C_in + C_in √ó C_out)
```

---

## üìä –ß–∞—Å—Ç—å 5: –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã

### 5.1 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

**Data Loading –∏ Preprocessing:**
```python
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms

class CustomDataset(Dataset):
    def __init__(self, data, labels, transform=None):
        self.data = data
        self.labels = labels
        self.transform = transform
        
    def __len__(self):
        return len(self.data)
        
    def __getitem__(self, idx):
        sample = self.data[idx]
        label = self.labels[idx]
        
        if self.transform:
            sample = self.transform(sample)
            
        return sample, label

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
train_transform = transforms.Compose([
    transforms.RandomRotation(10),
    transforms.RandomHorizontalFlip(0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

# DataLoader —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
train_loader = DataLoader(
    dataset=train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,  # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
    pin_memory=True  # –ë—ã—Å—Ç—Ä–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –Ω–∞ GPU
)
```

**–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è:**
```python
# Z-score –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
def normalize_features(X):
    mean = X.mean(dim=0, keepdim=True)
    std = X.std(dim=0, keepdim=True)
    return (X - mean) / (std + 1e-8)

# Min-Max –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
def minmax_scale(X):
    min_val = X.min(dim=0, keepdim=True)[0]
    max_val = X.max(dim=0, keepdim=True)[0]
    return (X - min_val) / (max_val - min_val + 1e-8)

# Robust scaling (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ–¥–∏–∞–Ω—É –∏ IQR)
def robust_scale(X):
    median = X.median(dim=0, keepdim=True)[0]
    q75 = X.quantile(0.75, dim=0, keepdim=True)
    q25 = X.quantile(0.25, dim=0, keepdim=True)
    iqr = q75 - q25
    return (X - median) / (iqr + 1e-8)
```

### 5.2 –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

**–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è:**
```python
def train_model(model, train_loader, val_loader, num_epochs, device):
    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)
    criterion = nn.CrossEntropyLoss()
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)
    
    # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫
    train_losses, val_losses = [], []
    train_accs, val_accs = [], []
    
    # Early stopping
    best_val_loss = float('inf')
    patience = 10
    patience_counter = 0
    
    for epoch in range(num_epochs):
        # –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–∞—è —ç–ø–æ—Ö–∞
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (data, targets) in enumerate(train_loader):
            data, targets = data.to(device), targets.to(device)
            
            # Forward pass
            outputs = model(data)
            loss = criterion(outputs, targets)
            
            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            train_total += targets.size(0)
            train_correct += (predicted == targets).sum().item()
            
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, targets in val_loader:
                data, targets = data.to(device), targets.to(device)
                outputs = model(data)
                loss = criterion(outputs, targets)
                
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += targets.size(0)
                val_correct += (predicted == targets).sum().item()
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_acc = 100. * train_correct / train_total
        val_acc = 100. * val_correct / val_total
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        train_accs.append(train_acc)
        val_accs.append(val_acc)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º learning rate
        scheduler.step()
        
        # Early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            torch.save(model.state_dict(), 'best_model.pth')
        else:
            patience_counter += 1
            
        if patience_counter >= patience:
            print(f"Early stopping at epoch {epoch+1}")
            break
            
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        print(f'Epoch [{epoch+1}/{num_epochs}]')
        print(f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')
        print(f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')
        print(f'LR: {scheduler.get_last_lr()[0]:.6f}')
        print('-' * 50)
    
    return train_losses, val_losses, train_accs, val_accs
```

### 5.3 –ú–µ—Ç—Ä–∏–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∞

**–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:**
```python
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix

def evaluate_classification(model, test_loader, device):
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for data, targets in test_loader:
            data = data.to(device)
            outputs = model(data)
            _, predicted = torch.max(outputs, 1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(targets.numpy())
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(all_targets, all_preds)
    precision, recall, f1, _ = precision_recall_fscore_support(
        all_targets, all_preds, average='macro'
    )
    
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    
    # Confusion Matrix
    cm = confusion_matrix(all_targets, all_preds)
    return accuracy, precision, recall, f1, cm
```

**–†–µ–≥—Ä–µ—Å—Å–∏—è:**
```python
def evaluate_regression(model, test_loader, device):
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for data, targets in test_loader:
            data = data.to(device)
            outputs = model(data)
            
            all_preds.extend(outputs.cpu().numpy())
            all_targets.extend(targets.numpy())
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy arrays
    preds = np.array(all_preds)
    targets = np.array(all_targets)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    mse = np.mean((preds - targets) ** 2)
    mae = np.mean(np.abs(preds - targets))
    rmse = np.sqrt(mse)
    
    # R-squared
    ss_res = np.sum((targets - preds) ** 2)
    ss_tot = np.sum((targets - np.mean(targets)) ** 2)
    r2 = 1 - (ss_res / ss_tot)
    
    print(f"MSE: {mse:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"R¬≤: {r2:.4f}")
    
    return mse, mae, rmse, r2
```

### 5.4 –û—Ç–ª–∞–¥–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

**–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤:**
```python
def monitor_gradients(model):
    total_norm = 0
    for name, param in model.named_parameters():
        if param.grad is not None:
            param_norm = param.grad.data.norm(2)
            total_norm += param_norm.item() ** 2
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∞–Ω–æ–º–∞–ª—å–Ω–æ –±–æ–ª—å—à–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
            if param_norm > 10:
                print(f"Large gradient in {name}: {param_norm:.4f}")
                
    total_norm = total_norm ** 0.5
    return total_norm

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ —Ü–∏–∫–ª–µ –æ–±—É—á–µ–Ω–∏—è
loss.backward()
grad_norm = monitor_gradients(model)

if grad_norm > 5.0:  # Gradient clipping
    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)
    
optimizer.step()
```

**–ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:**
```python
import torch.profiler

def profile_model(model, data_loader, device):
    model.eval()
    
    with torch.profiler.profile(
        activities=[torch.profiler.ProfilerActivity.CPU, 
                   torch.profiler.ProfilerActivity.CUDA],
        record_shapes=True,
        profile_memory=True,
        with_stack=True
    ) as prof:
        
        for i, (data, _) in enumerate(data_loader):
            if i >= 10:  # –ü—Ä–æ—Ñ–∏–ª–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 –±–∞—Ç—á–µ–π
                break
                
            data = data.to(device)
            with torch.no_grad():
                _ = model(data)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    print(prof.key_averages().table(sort_by="cuda_time_total", row_limit=10))
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    prof.export_chrome_trace("trace.json")
```

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏:**
```python
# Gradient Checkpointing - —ç–∫–æ–Ω–æ–º–∏–º –ø–∞–º—è—Ç—å –∑–∞ —Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏
from torch.utils.checkpoint import checkpoint

class MemoryEfficientBlock(nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__()
        # ... –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–µ–≤
        
    def forward(self, x):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        return checkpoint(self._forward_impl, x)
    
    def _forward_impl(self, x):
        # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        return self.layers(x)

# Mixed Precision Training
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for data, targets in train_loader:
    optimizer.zero_grad()
    
    # Forward pass —Å autocast
    with autocast():
        outputs = model(data)
        loss = criterion(outputs, targets)
    
    # Backward pass —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

---

## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

### –ß—Ç–æ –≤—ã —Ç–µ–ø–µ—Ä—å –∑–Ω–∞–µ—Ç–µ:

‚úÖ **–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã:** –õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞, –º–∞—Ç–∞–Ω–∞–ª–∏–∑, —Ç–µ–æ—Ä–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π  
‚úÖ **–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:** –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ç–µ–∫—Å—Ç—ã, –∞—É–¥–∏–æ, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã  
‚úÖ **–ó–∞–¥–∞—á–∏ –ò–ò:** –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Ä–µ–≥—Ä–µ—Å—Å–∏—è, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è, –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º  
‚úÖ **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:** MLP, CNN, RNN/LSTM, Transformers –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è  
‚úÖ **–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:** –°–ª–æ–∏, –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã, —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è  
‚úÖ **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏:** –û–±—É—á–µ–Ω–∏–µ, –æ—Ü–µ–Ω–∫–∞, –æ—Ç–ª–∞–¥–∫–∞, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è  

### –î–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞ –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏–∑—É—á–µ–Ω–∏—è:

1. **–£–≥–ª—É–±–ª–µ–Ω–∏–µ –≤ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏:**
   - Computer Vision: Object Detection, Segmentation, GANs
   - NLP: BERT, GPT, T5, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ LLM
   - Recommender Systems: Collaborative Filtering, Deep Learning –ø–æ–¥—Ö–æ–¥—ã

2. **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏:**
   - Transfer Learning –∏ Fine-tuning
   - Meta-Learning –∏ Few-shot Learning  
   - Adversarial Training –∏ Robustness
   - Neural Architecture Search (NAS)

3. **Production –∏ MLOps:**
   - –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (Docker, Kubernetes)
   - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
   - Distributed Training
   - Edge Deployment

4. **–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è:**
   - Explainable AI (LIME, SHAP)
   - Federated Learning
   - Quantum Machine Learning
   - Neuromorphic Computing

### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã:

üî¨ **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ:** –ö–∞–∂–¥—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö  
üìä **–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ:** –í—Å–µ–≥–¥–∞ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ loss curves –∏ –º–µ—Ç—Ä–∏–∫–∏  
üêõ **–û—Ç–ª–∞–∂–∏–≤–∞–π—Ç–µ:** –ù–∞—á–∏–Ω–∞–π—Ç–µ —Å overfitting –Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ  
üìö **–ß–∏—Ç–∞–π—Ç–µ:** –°–ª–µ–¥–∏—Ç–µ –∑–∞ –Ω–æ–≤—ã–º–∏ —Å—Ç–∞—Ç—å—è–º–∏ –Ω–∞ arXiv  
ü§ù **–î–µ–ª–∏—Ç–µ—Å—å:** –£—á–∞—Å—Ç–≤—É–π—Ç–µ –≤ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è—Ö –∏ open-source –ø—Ä–æ–µ–∫—Ç–∞—Ö  

**–ü–æ–º–Ω–∏—Ç–µ:** –ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚Äî —ç—Ç–æ –∏–Ω–∂–µ–Ω–µ—Ä–Ω–∞—è –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞. –í–∞–∂–Ω—ã –∫–∞–∫ —Ç–µ