# Полное руководство по глубокому обучению с PyTorch
*От математических основ до продвинутых архитектур*

---

## 🎯 О чем этот материал

Комплексное руководство от математических основ до практической реализации современных архитектур глубокого обучения. **Систематический подход:** математика → данные → задачи → архитектуры → практика.

**Что вы получите:**
- Понимание математических основ нейронных сетей
- Знание типов данных и задач машинного обучения
- Глубокое понимание архитектур и их применения
- Практические навыки на PyTorch

---

## 📊 Часть 1: Математические основы

### 1.1 Линейная алгебра

**Зачем нужна:** Нейронные сети - это композиция линейных преобразований с нелинейными активациями.

**Векторы и операции:**
```
Вектор x = [x₁, x₂, x₃]ᵀ

Скалярное произведение: x·y = x₁y₁ + x₂y₂ + x₃y₃
Норма вектора: ||x|| = √(x₁² + x₂² + x₃²)
Косинус угла: cos(θ) = (x·y)/(||x|| ||y||)
```

**Матрицы - основа нейронных сетей:**
```
Линейное преобразование: y = Wx + b

W = [w₁₁ w₁₂ w₁₃]    x = [x₁]    b = [b₁]
    [w₂₁ w₂₂ w₂₃]        [x₂]        [b₂]
                          [x₃]

Результат: y₁ = w₁₁x₁ + w₁₂x₂ + w₁₃x₃ + b₁
           y₂ = w₂₁x₁ + w₂₂x₂ + w₂₃x₃ + b₂
```

```python
import torch
import numpy as np

# Векторные операции в PyTorch
x = torch.tensor([1.0, 2.0, 3.0])
y = torch.tensor([4.0, 5.0, 6.0])

# Скалярное произведение
dot_product = torch.dot(x, y)  # 32.0

# L2 норма
l2_norm = torch.norm(x)  # 3.742

# Матричное умножение
W = torch.randn(2, 3)  # Случайная матрица 2x3
b = torch.randn(2)     # Bias вектор
output = torch.matmul(W, x) + b  # Линейная трансформация
```

**Собственные векторы и значения:**
```
Ax = λx, где λ - собственное значение, x - собственный вектор

Интуиция: направления, вдоль которых матрица только масштабирует
Применение: PCA, понимание трансформаций в нейронных сетях
```

### 1.2 Математический анализ

**Производные - основа обучения:**
```
Производная f'(x) = lim[h→0] (f(x+h) - f(x))/h

Геометрический смысл: наклон касательной
Физический смысл: скорость изменения функции
ML смысл: направление наискорейшего возрастания
```

**Правила дифференцирования:**
```python
# Основные правила
# (f + g)' = f' + g'
# (f * g)' = f'g + fg'
# (f(g(x)))' = f'(g(x)) * g'(x)  ← Цепное правило!

# Примеры важных производных
def sigmoid(x):
    return 1 / (1 + torch.exp(-x))

def sigmoid_derivative(x):
    s = sigmoid(x)
    return s * (1 - s)  # Очень элегантная формула!

def relu_derivative(x):
    return (x > 0).float()  # 1 если x > 0, иначе 0
```

**Частные производные и градиент:**
```
Функция многих переменных: f(x₁, x₂, ..., xₙ)

Частная производная: ∂f/∂xᵢ (фиксируем все кроме xᵢ)

Градиент: ∇f = [∂f/∂x₁, ∂f/∂x₂, ..., ∂f/∂xₙ]ᵀ

Свойство: градиент указывает направление наискорейшего возрастания
```

```python
# Автоматическое дифференцирование в PyTorch
x = torch.tensor([2.0, 3.0], requires_grad=True)
y = x[0]**2 + x[1]**3  # f(x₁,x₂) = x₁² + x₂³

y.backward()  # Вычисляем градиенты
print(x.grad)  # [4.0, 27.0] = [2*x₁, 3*x₂²]
```

**Цепное правило - сердце backpropagation:**
```
Композиция функций: h(x) = f(g(x))
Производная: h'(x) = f'(g(x)) * g'(x)

В нейронных сетях:
x → слой1 → слой2 → ... → выход → ошибка
Градиент ошибки распространяется назад по цепному правилу
```

### 1.3 Теория вероятностей и статистика

**Вероятность и случайные величины:**
```
P(A) - вероятность события A
P(A|B) - условная вероятность A при условии B

Теорема Байеса: P(A|B) = P(B|A) * P(A) / P(B)
Применение в ML: наивный байесовский классификатор
```

**Распределения:**
```python
import torch.distributions as dist

# Нормальное распределение N(μ, σ²)
normal = dist.Normal(0, 1)  # Стандартная нормаль
samples = normal.sample((1000,))

# Биномиальное распределение
binomial = dist.Binomial(10, 0.5)  # 10 испытаний, p=0.5

# Бернулли (для бинарной классификации)
bernoulli = dist.Bernoulli(0.7)  # p=0.7
```

**Статистические моменты:**
```
Математическое ожидание: E[X] = μ
Дисперсия: Var[X] = E[(X-μ)²] = σ²
Стандартное отклонение: σ = √Var[X]

Для выборки:
x̄ = (1/n) Σxᵢ  (выборочное среднее)
s² = (1/(n-1)) Σ(xᵢ - x̄)²  (выборочная дисперсия)
```

**Информация и энтропия:**
```
Энтропия: H(X) = -Σ p(x) log p(x)
Интуиция: мера неопределенности

Кросс-энтропия: H(p,q) = -Σ p(x) log q(x)
Применение: функция потерь для классификации

KL-дивергенция: D_KL(p||q) = Σ p(x) log(p(x)/q(x))
Применение: сравнение распределений
```

```python
# Кросс-энтропия в PyTorch
import torch.nn.functional as F

# Истинные метки (one-hot)
targets = torch.tensor([0, 1, 2])  # Классы 0, 1, 2

# Предсказания (логиты)
predictions = torch.tensor([[2.0, 1.0, 0.1],
                           [0.5, 2.5, 1.0], 
                           [0.1, 0.2, 3.0]])

# Кросс-энтропия
loss = F.cross_entropy(predictions, targets)
```

### 1.4 Оптимизация

**Градиентный спуск:**
```
Цель: минимизировать функцию потерь L(θ)

Алгоритм:
θ_{t+1} = θ_t - η * ∇L(θ_t)

где η - learning rate (шаг обучения)
```

**Проблемы градиентного спуска:**
```
1. Локальные минимумы
2. Седловые точки  
3. Плохая обусловленность (разные масштабы градиентов)
4. Выбор learning rate
```

**Продвинутые оптимизаторы:**
```python
# Momentum - учитывает предыдущие направления
# v_{t+1} = β*v_t + (1-β)*∇L(θ_t)
# θ_{t+1} = θ_t - η*v_{t+1}
optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)

# Adam - адаптивный learning rate
# Комбинирует momentum и RMSprop
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))

# AdamW - Adam с весовым затуханием
optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
```

---

## 📚 Часть 2: Типы данных и задачи ИИ

### 2.1 Классификация данных

**Структурированные данные:**
```
Табличные данные: строки = примеры, столбцы = признаки
┌─────────────┬─────────────┬─────────────┬─────────────┐
│ Возраст     │ Доход       │ Образование │ Класс       │
├─────────────┼─────────────┼─────────────┼─────────────┤
│ 25          │ 50000       │ Высшее      │ Одобрен     │
│ 45          │ 80000       │ Среднее     │ Одобрен     │
│ 22          │ 30000       │ Среднее     │ Отклонен    │
└─────────────┴─────────────┴─────────────┴─────────────┘

Архитектуры: MLP, градиентный бустинг, SVM
```

**Изображения:**
```
2D структура: высота × ширина × каналы
RGB: 3 канала (красный, зеленый, синий)
Grayscale: 1 канал

Пример: 224×224×3 = 150,528 пикселей
Каждый пиксель: значение 0-255 (или 0-1 после нормализации)

Архитектуры: CNN (ResNet, EfficientNet, Vision Transformer)
```

**Тексты:**
```
Последовательности символов/слов
Проблемы: переменная длина, порядок важен, контекст

Представления:
- One-hot encoding: [0,0,1,0,0] для словаря из 5 слов
- Word embeddings: плотные векторы (например, 300 размерности)
- Subword tokens: BPE, WordPiece

Архитектуры: RNN, LSTM, Transformer (BERT, GPT)
```

**Аудио:**
```
Временные ряды: амплитуда звука по времени
Частота дискретизации: 16kHz, 44.1kHz

Представления:
- Waveform: исходный сигнал
- Спектрограмма: частотно-временная декомпозиция
- MFCC: mel-frequency cepstral coefficients

Архитектуры: 1D CNN, RNN, Transformer
```

**Временные ряды:**
```
Последовательные наблюдения во времени
Свойства: тренд, сезонность, автокорреляция

Примеры:
- Цены акций
- Температура
- Продажи по месяцам

Архитектуры: ARIMA, LSTM, Temporal CNN
```

### 2.2 Типы задач машинного обучения

**Классификация:**
```
Цель: предсказать категорию (класс)

Бинарная: спам/не спам, болен/здоров
  Метрики: accuracy, precision, recall, F1, AUC-ROC

Многоклассовая: классификация изображений (1000 классов ImageNet)
  Метрики: accuracy, macro/micro F1

Многометочная: тег фото может быть [собака, парк, солнечно]
  Метрики: Hamming loss, subset accuracy
```

```python
# Пример бинарной классификации
import torch.nn as nn

class BinaryClassifier(nn.Module):
    def __init__(self, input_size):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_size, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()  # Выход от 0 до 1
        )
    
    def forward(self, x):
        return self.layers(x)

# Функция потерь
criterion = nn.BCELoss()  # Binary Cross-Entropy
```

**Регрессия:**
```
Цель: предсказать непрерывное значение

Примеры:
- Цена дома по характеристикам
- Температура завтра
- Рейтинг фильма (1-10)

Метрики:
- MSE: Mean Squared Error
- MAE: Mean Absolute Error  
- R²: коэффициент детерминации
```

```python
class Regressor(nn.Module):
    def __init__(self, input_size):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_size, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)  # Один выход, без активации
        )
    
    def forward(self, x):
        return self.layers(x)

# Функция потерь
criterion = nn.MSELoss()
```

**Кластеризация (без учителя):**
```
Цель: найти скрытые группы в данных

Алгоритмы:
- K-means: разделение на k кластеров
- DBSCAN: кластеры произвольной формы
- Hierarchical clustering: иерархия кластеров

Метрики: silhouette score, inertia
```

**Обучение с подкреплением:**
```
Агент взаимодействует со средой:
Состояние → Действие → Награда → Новое состояние

Примеры:
- Игры (шахматы, Go)
- Робототехника
- Рекомендательные системы

Алгоритмы: Q-learning, Policy Gradient, Actor-Critic
```

### 2.3 Особенности разных типов данных

**Инвариантности:**
```
Изображения:
- Трансляционная: кот остается котом в любом месте
- Масштабная: кот на разных расстояниях
- Поворотная: кот под разными углами

Тексты:
- Порядок слов критически важен
- Локальный контекст (соседние слова)
- Долгосрочные зависимости

Аудио:
- Временная структура
- Частотные паттерны
- Фазовые соотношения
```

**Preprocessing особенности:**
```python
# Изображения
transform = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])

# Тексты  
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
tokens = tokenizer("Hello world", return_tensors="pt")

# Табличные данные
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

---

## 🧠 Часть 3: Архитектуры и их назначение

### 3.1 Многослойный персептрон (MLP)

**Математическая основа:**
```
Слой: z = Wx + b
Активация: a = f(z)

Полная сеть:
x → z₁ = W₁x + b₁ → a₁ = f(z₁) → z₂ = W₂a₁ + b₂ → a₂ = f(z₂) → ...

Универсальная аппроксимация: MLP может приблизить любую 
непрерывную функцию с произвольной точностью
```

**Когда использовать:**
- Табличные данные
- Задачи с фиксированным размером входа
- Baseline для сравнения

```python
class DeepMLP(nn.Module):
    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.2):
        super().__init__()
        
        layers = []
        prev_size = input_size
        
        for hidden_size in hidden_sizes:
            layers.extend([
                nn.Linear(prev_size, hidden_size),
                nn.BatchNorm1d(hidden_size),
                nn.ReLU(),
                nn.Dropout(dropout)
            ])
            prev_size = hidden_size
        
        layers.append(nn.Linear(prev_size, output_size))
        self.network = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.network(x)

# Использование
model = DeepMLP(
    input_size=100,
    hidden_sizes=[512, 256, 128],
    output_size=10,
    dropout=0.3
)
```

### 3.2 Сверточные сети (CNN)

**Математическая основа:**
```
Операция свертки (2D):
(f * g)[i,j] = ΣΣ f[m,n] * g[i-m, j-n]

Практически:
output[i,j] = Σ Σ input[i+m, j+n] * kernel[m,n] + bias

Параметры:
- Kernel size: размер фильтра (3×3, 5×5)
- Stride: шаг сдвига фильтра
- Padding: дополнение краев
- Dilation: расширенная свертка
```

**Основные слои:**
```python
# Сверточный слой
conv = nn.Conv2d(
    in_channels=3,      # RGB вход
    out_channels=64,    # Количество фильтров
    kernel_size=3,      # Размер фильтра 3×3
    stride=1,           # Шаг
    padding=1           # Сохраняем размер
)

# Пулинг - уменьшение размерности
pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Уменьшаем в 2 раза

# Batch normalization - стабилизация обучения
bn = nn.BatchNorm2d(64)

# Адаптивный пулинг - фиксированный выходной размер
adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))  # Любой размер → 1×1
```

**Архитектуры CNN:**
```
LeNet (1998): Conv→Pool→Conv→Pool→FC→FC
  - Первая успешная CNN
  - Для рукописных цифр MNIST

AlexNet (2012): Conv→Pool→Conv→Pool→Conv→Conv→Conv→Pool→FC→FC→FC
  - ReLU активации
  - Dropout регуляризация
  - GPU ускорение

VGG (2014): Очень глубокая сеть с маленькими фильтрами 3×3
  - VGG-16: 16 слоев
  - Простая архитектура: только Conv3×3 и MaxPool2×2

ResNet (2015): Residual connections
  - Решение проблемы затухающих градиентов
  - Сети до 152 слоев
```

```python
class ResNetBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        
        # Основной путь
        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        # Skip connection
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
    
    def forward(self, x):
        out = torch.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)  # Residual connection
        out = torch.relu(out)
        return out
```

**Современные техники:**
```python
# Depthwise Separable Convolution (MobileNet)
class DepthwiseSeparableConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        # Depthwise: свертка по каждому каналу отдельно
        self.depthwise = nn.Conv2d(in_channels, in_channels, 3, 1, 1, 
                                  groups=in_channels, bias=False)
        # Pointwise: смешивание каналов
        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)
        
    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        return x

# Attention в CNN (Squeeze-and-Excitation)
class SEBlock(nn.Module):
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.squeeze = nn.AdaptiveAvgPool2d(1)
        self.excitation = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.squeeze(x).view(b, c)
        y = self.excitation(y).view(b, c, 1, 1)
        return x * y.expand_as(x)
```

### 3.3 Рекуррентные сети (RNN)

**Математическая основа:**
```
Vanilla RNN:
h_t = tanh(W_hh * h_{t-1} + W_xh * x_t + b_h)
y_t = W_hy * h_t + b_y

Проблема: затухающие градиенты
∂h_t/∂h_{t-k} = ∏(i=0 to k-1) ∂h_{t-i}/∂h_{t-i-1}
Если |∂h_{t-i}/∂h_{t-i-1}| < 1, то произведение → 0
```

**LSTM - Long Short-Term Memory:**
```
Ключевая идея: управляемая память через "ворота"

Forget gate: f_t = σ(W_f * [h_{t-1}, x_t] + b_f)
Input gate:  i_t = σ(W_i * [h_{t-1}, x_t] + b_i)
Output gate: o_t = σ(W_o * [h_{t-1}, x_t] + b_o)

Candidate: C̃_t = tanh(W_C * [h_{t-1}, x_t] + b_C)
Cell state: C_t = f_t * C_{t-1} + i_t * C̃_t
Hidden state: h_t = o_t * tanh(C_t)
```

```python
class LSTMFromScratch(nn.Module):
    def __init__(self, input_size, hidden_size):
        super().__init__()
        self.hidden_size = hidden_size
        
        # Все ворота в одной матрице для эффективности
        self.weight_ih = nn.Linear(input_size, 4 * hidden_size)
        self.weight_hh = nn.Linear(hidden_size, 4 * hidden_size)
        
    def forward(self, input, hidden=None):
        if hidden is None:
            h = torch.zeros(input.size(0), self.hidden_size)
            c = torch.zeros(input.size(0), self.hidden_size)
        else:
            h, c = hidden
            
        outputs = []
        
        for x in input.unbind(1):  # По временным шагам
            # Все ворота сразу
            gates = self.weight_ih(x) + self.weight_hh(h)
            
            # Разделяем на 4 ворота
            i_gate, f_gate, g_gate, o_gate = gates.chunk(4, 1)
            
            i_gate = torch.sigmoid(i_gate)  # Input gate
            f_gate = torch.sigmoid(f_gate)  # Forget gate
            g_gate = torch.tanh(g_gate)     # New info
            o_gate = torch.sigmoid(o_gate)  # Output gate
            
            # Обновляем состояния
            c = f_gate * c + i_gate * g_gate
            h = o_gate * torch.tanh(c)
            
            outputs.append(h)
            
        return torch.stack(outputs, 1), (h, c)
```

**GRU - Gated Recurrent Unit:**
```
Упрощенная версия LSTM:
z_t = σ(W_z * [h_{t-1}, x_t])  # Update gate
r_t = σ(W_r * [h_{t-1}, x_t])  # Reset gate
h̃_t = tanh(W * [r_t * h_{t-1}, x_t])  # New hidden state
h_t = (1 - z_t) * h_{t-1} + z_t * h̃_t  # Final hidden state

Преимущества: меньше параметров, быстрее обучается
```

**Bidirectional RNN:**
```
Идея: обрабатываем последовательность в обе стороны

Forward:  h₁⁻ → h₂⁻ → h₃⁻ → h₄⁻
Backward: h₁⁺ ← h₂⁺ ← h₃⁺ ← h₄⁺

Итоговое состояние: h_t = [h_t⁻; h_t⁺]
```

```python
class BiLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers=1):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size, 
            hidden_size, 
            num_layers, 
            batch_first=True,
            bidirectional=True  # Ключевой параметр
        )
        self.hidden_size = hidden_size
        
    def forward(self, x):
        # Выход: (batch, seq_len, 2*hidden_size)
        # Последний параметр удваивается из-за bidirectional
        output, (hidden, cell) = self.lstm(x)
        return output

# Attention для RNN
class AttentionRNN(nn.Module):
    def __init__(self, hidden_size):
        super().__init__()
        self.attention = nn.Linear(hidden_size, 1)
        
    def forward(self, rnn_outputs):
        # rnn_outputs: (batch, seq_len, hidden_size)
        scores = self.attention(rnn_outputs)  # (batch, seq_len, 1)
        weights = torch.softmax(scores, dim=1)  # Нормализация
        
        # Взвешенная сумма
        context = torch.sum(weights * rnn_outputs, dim=1)
        return context, weights
```

### 3.4 Трансформеры

**Революция в NLP:**
```
Проблемы RNN:
1. Последовательная обработка (медленно)
2. Затухающие градиенты для длинных последовательностей
3. Сложность параллелизации

Решение Transformer:
1. Self-attention - параллельная обработка
2. Прямые связи между любыми позициями
3. Positional encoding для понимания порядка
```

**Self-Attention механизм:**
```
Математика:
Attention(Q,K,V) = softmax(QK^T/√d_k)V

где:
Q = XW_Q  (Query - что ищем)
K = XW_K  (Key - где ищем)  
V = XW_V  (Value - что извлекаем)

Интуиция: каждое слово может "посмотреть" на все остальные
```

```python
class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, num_heads):
        super().__init__()
        assert d_model % num_heads == 0
        
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_k = d_model // num_heads
        
        # Линейные проекции для Q, K, V
        self.w_q = nn.Linear(d_model, d_model)
        self.w_k = nn.Linear(d_model, d_model)
        self.w_v = nn.Linear(d_model, d_model)
        self.w_o = nn.Linear(d_model, d_model)
        
    def scaled_dot_product_attention(self, Q, K, V, mask=None):
        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)
        
        if mask is not None:
            scores = scores.masked_fill(mask == 0, -1e9)
            
        attention_weights = torch.softmax(scores, dim=-1)
        context = torch.matmul(attention_weights, V)
        
        return context, attention_weights
    
    def forward(self, x, mask=None):
        batch_size, seq_len, d_model = x.size()
        
        # Линейные трансформации
        Q = self.w_q(x)  # (batch, seq_len, d_model)
        K = self.w_k(x)
        V = self.w_v(x)
        
        # Разделяем на головы
        Q = Q.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)
        K = K.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2) 
        V = V.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)
        
        # Attention для каждой головы
        context, attention = self.scaled_dot_product_attention(Q, K, V, mask)
        
        # Объединяем головы
        context = context.transpose(1, 2).contiguous().view(
            batch_size, seq_len, d_model
        )
        
        # Финальная проекция
        output = self.w_o(context)
        return output
```

**Transformer Block:**
```python
class TransformerBlock(nn.Module):
    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):
        super().__init__()
        
        # Multi-head attention
        self.attention = MultiHeadAttention(d_model, num_heads)
        
        # Feed-forward network
        self.feed_forward = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.ReLU(),
            nn.Linear(d_ff, d_model)
        )
        
        # Layer normalization
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        
        # Dropout
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x, mask=None):
        # Self-attention с residual connection
        attention_output = self.attention(x, mask)
        x = self.norm1(x + self.dropout(attention_output))
        
        # Feed-forward с residual connection  
        ff_output = self.feed_forward(x)
        x = self.norm2(x + self.dropout(ff_output))
        
        return x
```

**Positional Encoding:**
```
Проблема: Transformer не знает о порядке слов
Решение: добавляем позиционную информацию

PE(pos, 2i) = sin(pos / 10000^(2i/d_model))
PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))
```

```python
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super().__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1).float()
        
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * 
                           -(math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        self.register_buffer('pe', pe.unsqueeze(0))
        
    def forward(self, x):
        return x + self.pe[:, :x.size(1)]
```

---

## 🔧 Часть 4: Детали слоев и архитектур

### 4.1 Слои и их роли

**Linear (Dense) слой:**
```
Математика: y = xW^T + b
Параметры: W (weight matrix), b (bias vector)
Назначение: изучение линейных зависимостей

Количество параметров: input_size * output_size + output_size
```

**Normalization слои:**
```python
# Batch Normalization - по батчу
bn = nn.BatchNorm1d(num_features)
# Формула: (x - μ_batch) / √(σ²_batch + ε) * γ + β

# Layer Normalization - по признакам
ln = nn.LayerNorm(normalized_shape)
# Формула: (x - μ_layer) / √(σ²_layer + ε) * γ + β

# Group Normalization - по группам каналов
gn = nn.GroupNorm(num_groups, num_channels)

# Instance Normalization - по каждому примеру
instance_norm = nn.InstanceNorm2d(num_features)
```

**Активационные функции:**
```python
# ReLU: max(0, x)
relu = nn.ReLU()
# Преимущества: простая, решает проблему затухающих градиентов
# Недостатки: "мертвые нейроны" при x < 0

# Leaky ReLU: max(0.01x, x)
leaky_relu = nn.LeakyReLU(0.01)
# Решает проблему мертвых нейронов

# ELU: x если x > 0, α(e^x - 1) если x ≤ 0
elu = nn.ELU(alpha=1.0)
# Гладкая функция, среднее значение близко к 0

# Swish: x * sigmoid(x)
def swish(x):
    return x * torch.sigmoid(x)
# Используется в EfficientNet

# GELU: x * Φ(x), где Φ - CDF стандартной нормали
gelu = nn.GELU()
# Популярна в Transformers
```

**Регуляризация:**
```python
# Dropout - случайно обнуляет нейроны
dropout = nn.Dropout(p=0.5)  # 50% нейронов

# DropBlock - structured dropout для CNN
class DropBlock2d(nn.Module):
    def __init__(self, drop_rate, block_size):
        super().__init__()
        self.drop_rate = drop_rate
        self.block_size = block_size
        
    def forward(self, x):
        if not self.training:
            return x
        # Реализация structured dropout
        # Обнуляет целые блоки в feature maps

# Weight Decay - L2 регуляризация
optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)
# Добавляет λ||W||² к функции потерь
```

### 4.2 Архитектурные паттерны

**Residual Connections:**
```
Проблема: градиенты затухают в глубоких сетях
Решение: F(x) + x вместо F(x)

Преимущества:
1. Градиенты проходят напрямую
2. Легче обучить тождественное отображение
3. Позволяет строить очень глубокие сети
```

**Dense Connections (DenseNet):**
```
Идея: каждый слой получает входы от всех предыдущих

Слой 1: x₁ = f₁(x₀)
Слой 2: x₂ = f₂([x₀, x₁])  
Слой 3: x₃ = f₃([x₀, x₁, x₂])
...

Преимущества: переиспользование признаков, компактность
```

**Attention механизмы:**
```python
# Spatial Attention для CNN
class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super().__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2)
        
    def forward(self, x):
        # Агрегируем по каналам
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        
        # Объединяем и получаем веса внимания
        attention = torch.cat([avg_out, max_out], dim=1)
        attention = torch.sigmoid(self.conv(attention))
        
        return x * attention

# Channel Attention
class ChannelAttention(nn.Module):
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels)
        )
        
    def forward(self, x):
        b, c, _, _ = x.size()
        
        # Global average и max pooling
        avg = self.avg_pool(x).view(b, c)
        max_val = self.max_pool(x).view(b, c)
        
        # Получаем веса
        avg_out = self.fc(avg)
        max_out = self.fc(max_val)
        
        attention = torch.sigmoid(avg_out + max_out).view(b, c, 1, 1)
        return x * attention
```

### 4.3 Современные архитектуры

**Vision Transformer (ViT):**
```
Идея: применить Transformer к изображениям
Решение: разбить изображение на патчи

Изображение 224×224×3 → Патчи 16×16×3 → Векторы 768D
196 патчей → последовательность для Transformer
```

```python
class VisionTransformer(nn.Module):
    def __init__(self, img_size=224, patch_size=16, num_classes=1000, 
                 dim=768, depth=12, heads=12):
        super().__init__()
        
        # Параметры патчей
        self.patch_size = patch_size
        self.num_patches = (img_size // patch_size) ** 2
        patch_dim = 3 * patch_size ** 2
        
        # Embedding патчей
        self.patch_embedding = nn.Linear(patch_dim, dim)
        
        # Positional embeddings
        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches + 1, dim))
        
        # CLS token для классификации
        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))
        
        # Transformer blocks
        self.transformer = nn.ModuleList([
            TransformerBlock(dim, heads, dim * 4)
            for _ in range(depth)
        ])
        
        # Classification head
        self.mlp_head = nn.Linear(dim, num_classes)
        
    def forward(self, x):
        batch_size = x.shape[0]
        
        # Разбиваем на патчи
        x = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)
        x = x.contiguous().view(batch_size, -1, 3 * self.patch_size ** 2)
        
        # Embedding патчей
        x = self.patch_embedding(x)
        
        # Добавляем CLS token
        cls_tokens = self.cls_token.expand(batch_size, -1, -1)
        x = torch.cat([cls_tokens, x], dim=1)
        
        # Добавляем positional encoding
        x += self.pos_embedding
        
        # Transformer layers
        for transformer in self.transformer:
            x = transformer(x)
        
        # Классификация по CLS token
        return self.mlp_head(x[:, 0])
```

**EfficientNet - оптимальное масштабирование:**
```
Идея: сбалансированное увеличение глубины, ширины и разрешения

Compound Scaling:
depth = α^φ
width = β^φ  
resolution = γ^φ

где α·β²·γ² ≈ 2 (ограничение вычислительных ресурсов)
```

**MobileNet - эффективные архитектуры:**
```python
class DepthwiseSeparableConv(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        
        # Depthwise convolution
        self.depthwise = nn.Conv2d(
            in_channels, in_channels, 3, stride, 1, 
            groups=in_channels, bias=False
        )
        self.bn1 = nn.BatchNorm2d(in_channels)
        
        # Pointwise convolution
        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
    def forward(self, x):
        x = torch.relu(self.bn1(self.depthwise(x)))
        x = torch.relu(self.bn2(self.pointwise(x)))
        return x

# Количество параметров:
# Обычная свертка: K × K × C_in × C_out
# Depthwise Separable: K × K × C_in + C_in × C_out
# Экономия: (K × K × C_in × C_out) / (K × K × C_in + C_in × C_out)
```

---

## 📊 Часть 5: Практические аспекты

### 5.1 Подготовка данных

**Data Loading и Preprocessing:**
```python
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms

class CustomDataset(Dataset):
    def __init__(self, data, labels, transform=None):
        self.data = data
        self.labels = labels
        self.transform = transform
        
    def __len__(self):
        return len(self.data)
        
    def __getitem__(self, idx):
        sample = self.data[idx]
        label = self.labels[idx]
        
        if self.transform:
            sample = self.transform(sample)
            
        return sample, label

# Трансформации для аугментации
train_transform = transforms.Compose([
    transforms.RandomRotation(10),
    transforms.RandomHorizontalFlip(0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

# DataLoader с настройками
train_loader = DataLoader(
    dataset=train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,  # Параллельная загрузка
    pin_memory=True  # Быстрая передача на GPU
)
```

**Нормализация и стандартизация:**
```python
# Z-score нормализация
def normalize_features(X):
    mean = X.mean(dim=0, keepdim=True)
    std = X.std(dim=0, keepdim=True)
    return (X - mean) / (std + 1e-8)

# Min-Max нормализация
def minmax_scale(X):
    min_val = X.min(dim=0, keepdim=True)[0]
    max_val = X.max(dim=0, keepdim=True)[0]
    return (X - min_val) / (max_val - min_val + 1e-8)

# Robust scaling (использует медиану и IQR)
def robust_scale(X):
    median = X.median(dim=0, keepdim=True)[0]
    q75 = X.quantile(0.75, dim=0, keepdim=True)
    q25 = X.quantile(0.25, dim=0, keepdim=True)
    iqr = q75 - q25
    return (X - median) / (iqr + 1e-8)
```

### 5.2 Обучение моделей

**Полный цикл обучения:**
```python
def train_model(model, train_loader, val_loader, num_epochs, device):
    # Оптимизатор и функция потерь
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)
    criterion = nn.CrossEntropyLoss()
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)
    
    # Для отслеживания метрик
    train_losses, val_losses = [], []
    train_accs, val_accs = [], []
    
    # Early stopping
    best_val_loss = float('inf')
    patience = 10
    patience_counter = 0
    
    for epoch in range(num_epochs):
        # Тренировочная эпоха
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (data, targets) in enumerate(train_loader):
            data, targets = data.to(device), targets.to(device)
            
            # Forward pass
            outputs = model(data)
            loss = criterion(outputs, targets)
            
            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # Статистика
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            train_total += targets.size(0)
            train_correct += (predicted == targets).sum().item()
            
        # Валидация
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, targets in val_loader:
                data, targets = data.to(device), targets.to(device)
                outputs = model(data)
                loss = criterion(outputs, targets)
                
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += targets.size(0)
                val_correct += (predicted == targets).sum().item()
        
        # Вычисляем средние значения
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_acc = 100. * train_correct / train_total
        val_acc = 100. * val_correct / val_total
        
        # Сохраняем метрики
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        train_accs.append(train_acc)
        val_accs.append(val_acc)
        
        # Обновляем learning rate
        scheduler.step()
        
        # Early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            # Сохраняем лучшую модель
            torch.save(model.state_dict(), 'best_model.pth')
        else:
            patience_counter += 1
            
        if patience_counter >= patience:
            print(f"Early stopping at epoch {epoch+1}")
            break
            
        # Логирование
        print(f'Epoch [{epoch+1}/{num_epochs}]')
        print(f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')
        print(f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')
        print(f'LR: {scheduler.get_last_lr()[0]:.6f}')
        print('-' * 50)
    
    return train_losses, val_losses, train_accs, val_accs
```

### 5.3 Метрики и оценка

**Классификация:**
```python
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix

def evaluate_classification(model, test_loader, device):
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for data, targets in test_loader:
            data = data.to(device)
            outputs = model(data)
            _, predicted = torch.max(outputs, 1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(targets.numpy())
    
    # Метрики
    accuracy = accuracy_score(all_targets, all_preds)
    precision, recall, f1, _ = precision_recall_fscore_support(
        all_targets, all_preds, average='macro'
    )
    
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    
    # Confusion Matrix
    cm = confusion_matrix(all_targets, all_preds)
    return accuracy, precision, recall, f1, cm
```

**Регрессия:**
```python
def evaluate_regression(model, test_loader, device):
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for data, targets in test_loader:
            data = data.to(device)
            outputs = model(data)
            
            all_preds.extend(outputs.cpu().numpy())
            all_targets.extend(targets.numpy())
    
    # Конвертируем в numpy arrays
    preds = np.array(all_preds)
    targets = np.array(all_targets)
    
    # Метрики
    mse = np.mean((preds - targets) ** 2)
    mae = np.mean(np.abs(preds - targets))
    rmse = np.sqrt(mse)
    
    # R-squared
    ss_res = np.sum((targets - preds) ** 2)
    ss_tot = np.sum((targets - np.mean(targets)) ** 2)
    r2 = 1 - (ss_res / ss_tot)
    
    print(f"MSE: {mse:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"R²: {r2:.4f}")
    
    return mse, mae, rmse, r2
```

### 5.4 Отладка и оптимизация

**Мониторинг градиентов:**
```python
def monitor_gradients(model):
    total_norm = 0
    for name, param in model.named_parameters():
        if param.grad is not None:
            param_norm = param.grad.data.norm(2)
            total_norm += param_norm.item() ** 2
            
            # Логируем аномально большие градиенты
            if param_norm > 10:
                print(f"Large gradient in {name}: {param_norm:.4f}")
                
    total_norm = total_norm ** 0.5
    return total_norm

# Использование в цикле обучения
loss.backward()
grad_norm = monitor_gradients(model)

if grad_norm > 5.0:  # Gradient clipping
    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)
    
optimizer.step()
```

**Профилирование производительности:**
```python
import torch.profiler

def profile_model(model, data_loader, device):
    model.eval()
    
    with torch.profiler.profile(
        activities=[torch.profiler.ProfilerActivity.CPU, 
                   torch.profiler.ProfilerActivity.CUDA],
        record_shapes=True,
        profile_memory=True,
        with_stack=True
    ) as prof:
        
        for i, (data, _) in enumerate(data_loader):
            if i >= 10:  # Профилируем только первые 10 батчей
                break
                
            data = data.to(device)
            with torch.no_grad():
                _ = model(data)
    
    # Результаты профилирования
    print(prof.key_averages().table(sort_by="cuda_time_total", row_limit=10))
    
    # Сохраняем в файл для визуализации
    prof.export_chrome_trace("trace.json")
```

**Оптимизация памяти:**
```python
# Gradient Checkpointing - экономим память за счет времени
from torch.utils.checkpoint import checkpoint

class MemoryEfficientBlock(nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__()
        # ... инициализация слоев
        
    def forward(self, x):
        # Используем checkpointing для экономии памяти
        return checkpoint(self._forward_impl, x)
    
    def _forward_impl(self, x):
        # Фактические вычисления
        return self.layers(x)

# Mixed Precision Training
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for data, targets in train_loader:
    optimizer.zero_grad()
    
    # Forward pass с autocast
    with autocast():
        outputs = model(data)
        loss = criterion(outputs, targets)
    
    # Backward pass с масштабированием
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

---

## 🎯 Заключение

### Что вы теперь знаете:

✅ **Математические основы:** Линейная алгебра, матанализ, теория вероятностей  
✅ **Типы данных:** Структурированные, изображения, тексты, аудио, временные ряды  
✅ **Задачи ИИ:** Классификация, регрессия, кластеризация, обучение с подкреплением  
✅ **Архитектуры:** MLP, CNN, RNN/LSTM, Transformers и их применения  
✅ **Детали реализации:** Слои, активации, оптимизаторы, регуляризация  
✅ **Практические навыки:** Обучение, оценка, отладка, оптимизация  

### Дорожная карта дальнейшего изучения:

1. **Углубление в специализации:**
   - Computer Vision: Object Detection, Segmentation, GANs
   - NLP: BERT, GPT, T5, современные LLM
   - Recommender Systems: Collaborative Filtering, Deep Learning подходы

2. **Продвинутые техники:**
   - Transfer Learning и Fine-tuning
   - Meta-Learning и Few-shot Learning  
   - Adversarial Training и Robustness
   - Neural Architecture Search (NAS)

3. **Production и MLOps:**
   - Развертывание моделей (Docker, Kubernetes)
   - Мониторинг и A/B тестирование
   - Distributed Training
   - Edge Deployment

4. **Исследовательские направления:**
   - Explainable AI (LIME, SHAP)
   - Federated Learning
   - Quantum Machine Learning
   - Neuromorphic Computing

### Практические советы:

🔬 **Экспериментируйте:** Каждую архитектуру попробуйте на реальных данных  
📊 **Анализируйте:** Всегда визуализируйте loss curves и метрики  
🐛 **Отлаживайте:** Начинайте с overfitting на маленьком датасете  
📚 **Читайте:** Следите за новыми статьями на arXiv  
🤝 **Делитесь:** Участвуйте в соревнованиях и open-source проектах  

**Помните:** Глубокое обучение — это инженерная дисциплина. Важны как те