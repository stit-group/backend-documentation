# Ответы на техническое интервью: Backend мониторинг систем

**Стек:** Grafana, Loki, OpenTelemetry, OTEL Collector, VictoriaMetrics, Tempo

---

## Блок 1: Основы Observability

### 1.1 Three Pillars of Observability

**Ответ:**
Три столпа observability - это **метрики, логи и трейсы**. Каждый предоставляет уникальный взгляд на систему:

**Метрики (VictoriaMetrics):**
- Числовые данные во времени (latency, throughput, error rate)
- Эффективны для алертинга и долгосрочных трендов
- Низкие storage costs благодаря агрегации

**Логи (Loki):**
- Структурированные события с контекстом
- Детальная информация о конкретных инцидентах
- Debugging и forensic analysis

**Трейсы (Tempo):**
- Путь запроса через distributed систему
- Понимание dependencies и bottlenecks
- Root cause analysis в микросервисах

**Корреляция между компонентами:**
```yaml
# OTEL инструментация автоматически связывает данные
span_id: "abc123"
trace_id: "xyz789"

# В логах
{"level":"error", "trace_id":"xyz789", "span_id":"abc123", "message":"DB timeout"}

# В метриках
http_requests_total{trace_id="xyz789"} 1
```

### 1.2 SLI/SLO/SLA практика

**PromQL для 99.9% availability:**
```promql
# SLI: Процент успешных запросов за 30 дней
(
  sum(rate(http_requests_total{status!~"5.."}[30d])) 
  / 
  sum(rate(http_requests_total[30d]))
) * 100

# Альтернатива через histogram
1 - (
  sum(rate(http_request_duration_seconds_bucket{le="+Inf",status=~"5.."}[30d]))
  /
  sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[30d]))
)
```

**Алерт при нарушении SLO:**
```yaml
# Grafana Alert Rule
alert: SLO_Violation_99_9
expr: |
  (
    sum(rate(http_requests_total{status!~"5.."}[5m])) 
    / 
    sum(rate(http_requests_total[5m]))
  ) < 0.999
for: 2m
annotations:
  summary: "Availability SLO violated: {{ $value }}%"
```

### 1.3 Cardinality и производительность

**Проблема:** Метрика `http_requests_total{method, endpoint, user_id, session_id}` создает огромную cardinality, так как `user_id` и `session_id` уникальны для каждого запроса.

**Решение:**
```promql
# Плохо - высокая cardinality
http_requests_total{method="GET", endpoint="/api/users/12345", user_id="user_12345", session_id="sess_abc123"}

# Хорошо - контролируемая cardinality
http_requests_total{method="GET", endpoint="/api/users/{id}", service="user-service"}
user_sessions_active{service="user-service"}
```

**OTEL Collector стратегии:**
```yaml
processors:
  # Удаление high-cardinality labels
  attributes/drop_user_id:
    actions:
      - key: user_id
        action: delete
  
  # Группировка эндпойнтов
  resource/normalize_endpoints:
    attributes:
      - key: http.route
        action: update
        value: "/api/users/{id}"
        from_attribute: http.target
```

---

## Блок 2: Технические компоненты

### 2.1 VictoriaMetrics vs Prometheus

**Ключевые преимущества VictoriaMetrics:**

1. **Производительность:** До 10x faster ingestion
2. **Compression:** До 70% меньше disk space
3. **Horizontal scaling:** Native clustering support

**Архитектура кластера:**
```yaml
# vminsert - прием данных
vminsert:
  replicas: 3
  flags:
    - "-storageNode=vmstorage-0:8400,vmstorage-1:8400"

# vmstorage - хранение данных  
vmstorage:
  replicas: 2
  flags:
    - "-retentionPeriod=12"
    - "-dedup.minScrapeInterval=1s"

# vmselect - выполнение запросов
vmselect:
  replicas: 2
  flags:
    - "-storageNode=vmstorage-0:8401,vmstorage-1:8401"
```

**Оптимизация ingestion rate:**
```yaml
# Увеличение batch size
vminsert:
  flags:
    - "-maxInsertRequestSize=32MB"
    - "-maxLabelsPerTimeseries=50"
```

### 2.2 Loki и структурирование логов

**Почему Loki не индексирует содержимое:**
- Фокус на labels для индексации снижает costs
- Полнотекстовый поиск выполняется через grep-like операции
- Это делает Loki cost-effective для больших объемов

**Правильная структура labels:**
```yaml
# Плохо - слишком много labels
{service="api", endpoint="/users/123", user_id="user_123", timestamp="2024-01-01T10:00:00Z"}

# Хорошо - только для фильтрации
{service="api", level="error", environment="production"}
```

**LogQL для поиска ошибок 5xx:**
```logql
# Базовый запрос
{service="api"} 
  |= "5" 
  | json 
  | status_code >= 500 
  | __error__ = ""

# С группировкой по эндпойнтам за час
sum by (endpoint) (
  rate(
    {service="api"} 
      | json 
      | status_code >= 500 
      | __error__ = ""[1h]
  )
)
```

### 2.3 OpenTelemetry инструментация

**Automatic vs Manual:**

**Automatic instrumentation:**
```javascript
// Автоматически инструментирует HTTP, DB calls
import { NodeSDK } from '@opentelemetry/sdk-node';
import { getNodeAutoInstrumentations } from '@opentelemetry/auto-instrumentations-node';

const sdk = new NodeSDK({
  instrumentations: [getNodeAutoInstrumentations()]
});
```

**Manual instrumentation:**
```javascript
// Для business logic
import { trace } from '@opentelemetry/api';

const tracer = trace.getTracer('payment-service');

async function processPayment(amount) {
  const span = tracer.startSpan('process_payment');
  span.setAttributes({
    'payment.amount': amount,
    'payment.currency': 'USD'
  });
  
  try {
    // Business logic
    const result = await chargeCard(amount);
    span.setStatus({ code: SpanStatusCode.OK });
    return result;
  } catch (error) {
    span.setStatus({ code: SpanStatusCode.ERROR, message: error.message });
    throw error;
  } finally {
    span.end();
  }
}
```

**Sampling configuration:**
```yaml
# Head-based sampling
processors:
  probabilistic_sampler:
    sampling_percentage: 10  # 10% всех трейсов

# Tail-based sampling  
  tail_sampling:
    policies:
      - name: errors_policy
        type: status_code
        status_code: {status_codes: [ERROR]}
      - name: slow_requests
        type: latency
        latency: {threshold_ms: 1000}
```

### 2.4 OTEL Collector pipeline

**Компоненты pipeline:**

```yaml
receivers:
  # Получение данных
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
  prometheus:
    config:
      scrape_configs:
        - job_name: 'app'
          static_configs:
            - targets: ['localhost:8080']

processors:
  # Обработка данных
  batch:
    timeout: 1s
    send_batch_size: 1024
  
  attributes/enrich:
    actions:
      - key: environment
        action: insert
        value: "production"
      - key: debug
        action: delete

exporters:
  # Отправка данных
  otlp/tempo:
    endpoint: tempo:4317
  prometheusremotewrite:
    endpoint: http://victoriametrics:8428/api/v1/write

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch, attributes/enrich]
      exporters: [otlp/tempo]
    metrics:
      receivers: [otlp, prometheus]
      processors: [batch]
      exporters: [prometheusremotewrite]
```

**Фильтрация debug логов:**
```yaml
processors:
  filter/logs:
    logs:
      log_record:
        - 'attributes["level"] == "debug"'
```

### 2.5 Tempo и distributed tracing

**Почему нет индексации по умолчанию:**
- Индексация всех span attributes очень дорогая
- Tempo фокусируется на trace_id lookup
- TraceQL позволяет поиск без предварительной индексации

**TraceQL для медленных DB операций:**
```traceql
# Поиск трейсов с медленными DB запросами
{ span.db.system =~ ".*" && duration > 1s }

# Группировка по операциям
{ .service.name = "user-service" } 
  | select(span.db.operation, span.duration)
  | by(span.db.operation)

# Поиск ошибок в конкретном сервисе
{ .service.name = "payment-service" && status = error }
  | select(span.name, span.status_message)
```

### 2.6 Grafana интеграция

**Дашборд с корреляцией:**
```json
{
  "panels": [
    {
      "title": "Error Rate",
      "type": "stat",
      "targets": [
        {
          "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
          "datasource": "VictoriaMetrics"
        }
      ],
      "fieldConfig": {
        "links": [
          {
            "title": "View Logs",
            "url": "/d/logs?var-service=${__field.labels.service}&from=${__from}&to=${__to}"
          }
        ]
      }
    }
  ]
}
```

**Drill-down настройка:**
```javascript
// Template variables для связывания
service: label_values(http_requests_total, service)
trace_id: query_result(increase(traces_total{service="$service"}[1h]))

// Link к трейсам из логов
{service="$service"} | json | trace_id="${trace_id}"
```

---

## Блок 3: Архитектура и Production

### 3.1 High Availability

**HA конфигурация компонентов:**

```yaml
# VictoriaMetrics cluster
vmstorage:
  replicas: 3  # Минимум 3 для кворума
  antiAffinity: required  # Разные ноды

vminsert:
  replicas: 2
  loadBalancer: true

vmselect:
  replicas: 2
  cache:
    enabled: true

# Loki HA
loki:
  memberlist:
    join_members: ["loki-0", "loki-1", "loki-2"]
  replication_factor: 3
  
# Tempo HA  
tempo:
  distributor:
    replicas: 2
  ingester:
    replicas: 3
    replication_factor: 3
```

**Disaster Recovery:**
```bash
# Backup стратегия VictoriaMetrics
vmbackup -storageDataPath=/data -snapshot.createURL=http://vm:8428/snapshot/create

# Restore процедура
vmrestore -src=s3://backup-bucket/snapshot -dst=/new-data-path
```

### 3.2 Security

**Security risks и решения:**

```yaml
# 1. Data in transit encryption
tempo:
  server:
    grpc_tls_config:
      cert_file: /etc/certs/tempo.crt
      key_file: /etc/certs/tempo.key

# 2. Authentication
grafana:
  auth:
    oauth:
      enabled: true
      client_id: "${OAUTH_CLIENT_ID}"

# 3. PII scrubbing в OTEL Collector
processors:
  attributes/scrub_pii:
    actions:
      - key: email
        action: hash
      - key: user.phone
        action: delete
      - key: credit_card
        pattern: '\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}'
        action: update
        value: "****-****-****-XXXX"
```

### 3.3 Cost Optimization

**5 основных стратегий:**

1. **Intelligent Sampling:**
```yaml
# Больше сэмплов для ошибок, меньше для успешных
tail_sampling:
  policies:
    - name: error_traces
      type: status_code  
      status_code: {status_codes: [ERROR]}
      # 100% sampling для ошибок
    - name: normal_traces
      type: probabilistic
      probabilistic: {sampling_percentage: 1}
      # 1% для нормальных запросов
```

2. **Data Retention:**
```yaml
# Разные retention для разных типов данных
victoriametrics:
  retentionPeriod: "30d"  # Детальные метрики
  
downsampling:
  - resolution: "5m"
    retention: "90d"      # Агрегированные данные
  - resolution: "1h" 
    retention: "1y"       # Долгосрочные тренды
```

3. **Label Optimization:**
```promql
# Удаление high-cardinality labels
recording_rules:
  - record: http:request_rate_5m
    expr: sum(rate(http_requests_total[5m])) by (service, method)
    # Исключаем user_id, session_id
```

4. **Compression:**
```yaml
loki:
  chunk_store_config:
    chunk_cache_config:
      compression: "snappy"
  compactor:
    retention_enabled: true
    retention_delete_delay: "2h"
```

5. **Resource Right-sizing:**
```yaml
resources:
  requests:
    memory: "1Gi"     # Базовые требования
    cpu: "500m"
  limits:
    memory: "2Gi"     # Предотвращение OOM
    cpu: "1000m"
```

### 3.4 Multi-tenancy

**Tenant isolation:**
```yaml
# Loki multi-tenancy
loki:
  auth_enabled: true
  server:
    http_listen_port: 3100
    
# Prometheus compatible endpoint с tenant ID
# POST /loki/api/v1/push
# Header: X-Scope-OrgID: tenant-1

# VictoriaMetrics isolation через namespaces
victoriametrics:
  # Разные инстансы для команд
  tenants:
    - name: "team-api"
      retention: "30d"
    - name: "team-data"  
      retention: "90d"
```

---

## Практический кейс: Production Incident

### Сценарий анализа

**Первые 5 минут - Golden Signals:**

```promql
# 1. Error Rate
sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
/ 
sum(rate(http_requests_total[5m])) by (service)

# 2. Latency
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
)

# 3. Throughput  
sum(rate(http_requests_total[5m])) by (service)

# 4. Saturation
rate(cpu_usage_total[5m])
```

**Детальный анализ:**

```logql
# Поиск error patterns в логах
{service="checkout"} 
  |= "error" 
  | json 
  | __error__ = ""
  | line_format "{{.timestamp}} {{.level}} {{.message}}"
```

```traceql
# Анализ медленных трейсов
{ .service.name = "checkout" && duration > 2s }
  | select(span.name, span.duration, span.db.statement)
  | by(span.service.name)
```

**Root Cause Analysis:**

1. **Database bottleneck indicators:**
```promql
# DB connection pool exhaustion
mysql_threads_connected / mysql_max_connections > 0.8

# Query execution time
mysql_global_status_slow_queries_rate > 10
```

2. **Application issue indicators:**
```promql
# Memory pressure
process_resident_memory_bytes / node_memory_MemTotal_bytes > 0.8

# GC pressure  
rate(go_gc_duration_seconds_sum[5m]) > 0.1
```

**Confirmation и Prevention:**
```yaml
# SLI alert для раннего обнаружения
- alert: LatencyHigh
  expr: |
    histogram_quantile(0.95,
      sum(rate(http_request_duration_seconds_bucket{service="checkout"}[5m])) by (le)
    ) > 0.5
  for: 2m
  
- alert: ErrorRateHigh  
  expr: |
    sum(rate(http_requests_total{service="checkout",status=~"5.."}[5m]))
    /
    sum(rate(http_requests_total{service="checkout"}[5m])) > 0.01
  for: 1m
```

---

## Заключение

Эти ответы покрывают ключевые аспекты современного observability стека. Важно помнить:

- **Observability** - это не только мониторинг, но и понимание системы
- **Cost optimization** критично для production deployments  
- **Security** должна быть встроена с самого начала
- **Automation** алертинга и response процедур экономит время при инцидентах

Успешный backend разработчик должен понимать не только как собирать данные, но и как их интерпретировать для быстрого решения проблем в production.