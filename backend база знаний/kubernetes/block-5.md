# ğŸ“Š Ğ‘Ğ»Ğ¾Ğº 5: ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³, Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ° Ğ² Kubernetes

**â±ï¸ ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 2-3 Ğ½ĞµĞ´ĞµĞ»Ğ¸  
**ğŸ¯ Ğ¦ĞµĞ»ÑŒ:** ĞĞ°ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€  
**ğŸ“ Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ:** Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ â†’ ĞŸÑ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğ¹

---

## ğŸ“– Ğ’Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ² Observability

Observability (Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµĞ¼Ğ¾ÑÑ‚ÑŒ) Ğ² Kubernetes â€” ÑÑ‚Ğ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ¿Ğ¾ ĞµĞµ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¼ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼.

**ğŸ” Ğ¢Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ»Ğ¿Ğ° Observability:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 OBSERVABILITY PILLARS              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    METRICS      â”‚      LOGS       â”‚     TRACES      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Ğ§Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ â”‚ Ğ¢ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ       â”‚ ĞŸÑƒÑ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°    â”‚
â”‚ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸      â”‚ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ         â”‚ Ñ‡ĞµÑ€ĞµĞ· ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ   â”‚
â”‚                 â”‚                 â”‚                 â”‚
â”‚ â€¢ CPU/Memory    â”‚ â€¢ Errors        â”‚ â€¢ Latency       â”‚
â”‚ â€¢ Request rate  â”‚ â€¢ Events        â”‚ â€¢ Dependencies  â”‚
â”‚ â€¢ Error rate    â”‚ â€¢ Debugging     â”‚ â€¢ Bottlenecks   â”‚
â”‚ â€¢ Duration      â”‚ â€¢ Audit         â”‚ â€¢ Flow          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ¯ ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°:**

1. **ĞŸÑ€Ğ¾Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ vs Ğ ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ**
```
Ğ Ğ•ĞĞšĞ¢Ğ˜Ğ’ĞĞ«Ğ™ ĞŸĞĞ”Ğ¥ĞĞ”:          ĞŸĞ ĞĞĞšĞ¢Ğ˜Ğ’ĞĞ«Ğ™ ĞŸĞĞ”Ğ¥ĞĞ”:
ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° â†’ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ      ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ â†’ ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ â†’ ĞŸÑ€ĞµĞ²ĞµĞ½Ñ†Ğ¸Ñ
    â†“                           â†“
Ğ Ğ°ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ                Automated Response
    â†“                           â†“
Ğ£ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ                   Minimal Impact
```

2. **SLI, SLO, SLA ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸**
```
SLA (Service Level Agreement)
â”œâ”€ Ğ’Ğ½ĞµÑˆĞ½Ğ¸Ğµ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
â”œâ”€ 99.9% uptime = 8.76 Ñ‡Ğ°ÑĞ¾Ğ² downtime Ğ² Ğ³Ğ¾Ğ´
â””â”€ Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑÑ‚Ğ²Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¸

SLO (Service Level Objective)  
â”œâ”€ Ğ’Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğµ Ñ†ĞµĞ»Ğ¸ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
â”œâ”€ 99.95% availability Ğ´Ğ»Ñ critical services
â””â”€ Error budget Ğ´Ğ»Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

SLI (Service Level Indicator)
â”œâ”€ Ğ¤Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ
â”œâ”€ Request success rate: 99.97%
â””â”€ P99 latency: 150ms
```

---

## 5.1 ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ñ Prometheus Ğ¸ Grafana

### ğŸ¯ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Prometheus

Prometheus â€” ÑÑ‚Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°, Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğµ pull-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑĞ±Ğ¾Ñ€Ğ° Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº.

**ğŸ—ï¸ ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ ÑĞºĞ¾ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Prometheus:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROMETHEUS ECOSYSTEM                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Prometheus  â”‚â—„â”€â”€â”€â”‚   Exporters     â”‚            â”‚
â”‚  â”‚   Server    â”‚    â”‚ â€¢ node-exporter â”‚            â”‚
â”‚  â”‚             â”‚    â”‚ â€¢ kube-state    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â€¢ custom apps   â”‚            â”‚
â”‚         â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                                           â”‚
â”‚         â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   Grafana   â”‚    â”‚  AlertManager   â”‚            â”‚
â”‚  â”‚ Dashboards  â”‚    â”‚  Notifications  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ”„ Pull vs Push Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:**
```
PULL MODEL (Prometheus):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     HTTP GET     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prometheus  â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚   Target    â”‚
â”‚   Server    â”‚    /metrics      â”‚ Application â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ĞŸÑ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ°:
â”œâ”€ Service discovery
â”œâ”€ Health checking
â”œâ”€ Target awareness
â””â”€ Simpler debugging

PUSH MODEL (Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     HTTP POST    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monitoring  â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚   Target    â”‚
â”‚   Server    â”‚    metrics       â”‚ Application â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:
â”œâ”€ Configuration complexity  
â”œâ”€ No health visibility
â”œâ”€ Firewall issues
â””â”€ Load balancing challenges
```

---

### ğŸ“Š Ğ¢Ğ¸Ğ¿Ñ‹ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ² Prometheus

**1. Counter (ÑÑ‡ĞµÑ‚Ñ‡Ğ¸Ğº)**
```
Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸:
â”œâ”€ ĞœĞ¾Ğ½Ğ¾Ñ‚Ğ¾Ğ½Ğ½Ğ¾ Ğ²Ğ¾Ğ·Ñ€Ğ°ÑÑ‚Ğ°ÑÑ‰ĞµĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ
â”œâ”€ Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¸ Ñ€ĞµÑÑ‚Ğ°Ñ€Ñ‚Ğµ
â”œâ”€ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ĞµĞ¹ rate()
â””â”€ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹: HTTP requests, errors, bytes sent

ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸:
http_requests_total{method="GET", status="200"} 1547

PromQL Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹:
rate(http_requests_total[5m])          # Requests per second
increase(http_requests_total[1h])      # Total increase in 1 hour
```

**2. Gauge (Ğ¸Ğ·Ğ¼ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒ)**
```
Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸:
â”œâ”€ ĞœĞ¾Ğ¶ĞµÑ‚ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ¸ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°Ñ‚ÑŒÑÑ
â”œâ”€ ĞÑ‚Ñ€Ğ°Ğ¶Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
â”œâ”€ Snapshot Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ² Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
â””â”€ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹: CPU usage, memory, temperature

ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸:
cpu_usage_percent{instance="node-1"} 75.5

PromQL Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹:
avg(cpu_usage_percent)                 # Average CPU across instances
max(memory_usage_bytes)                # Peak memory usage
```

**3. Histogram (Ğ³Ğ¸ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°)**
```
Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸:
â”œâ”€ Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ buckets
â”œâ”€ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ¾Ğ·Ğ´Ğ°ĞµÑ‚ _count, _sum, _bucket
â”œâ”€ ĞŸĞ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑÑ‚ÑŒ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ»Ğ¸
â””â”€ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹: request duration, response size

ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:
http_request_duration_seconds_bucket{le="0.1"} 100
http_request_duration_seconds_bucket{le="0.5"} 150
http_request_duration_seconds_bucket{le="1.0"} 200
http_request_duration_seconds_bucket{le="+Inf"} 200
http_request_duration_seconds_sum 95.5
http_request_duration_seconds_count 200

PromQL Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹:
histogram_quantile(0.95, http_request_duration_seconds_bucket)  # P95
rate(http_request_duration_seconds_sum[5m]) /                   # Average
rate(http_request_duration_seconds_count[5m])                   # duration
```

**4. Summary (ÑĞ²Ğ¾Ğ´ĞºĞ°)**
```
Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸:
â”œâ”€ ĞŸÑ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ñ‹Ğµ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ»Ğ¸
â”œâ”€ ĞœĞµĞ½ÑŒÑˆĞµ Ğ³Ğ¸Ğ±ĞºĞ¾ÑÑ‚Ğ¸, Ğ½Ğ¾ Ğ²Ñ‹ÑˆĞµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ
â”œâ”€ Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğµ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°
â””â”€ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹: response time percentiles

ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:
http_request_duration_seconds{quantile="0.5"} 0.12
http_request_duration_seconds{quantile="0.9"} 0.38
http_request_duration_seconds{quantile="0.99"} 0.95
http_request_duration_seconds_sum 8953.332
http_request_duration_seconds_count 27892
```

---

### ğŸ¯ Prometheus Operator Ğ¸ ServiceMonitor

**Kubernetes-native Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ñƒ:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            PROMETHEUS OPERATOR                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   manages   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚  Operator   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   Prometheus    â”‚    â”‚
â”‚ â”‚             â”‚             â”‚    Instance     â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                            â–²              â”‚
â”‚         â”‚ watches                    â”‚              â”‚
â”‚         â–¼                            â”‚              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ServiceMonitorâ”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ Scrape Config   â”‚    â”‚
â”‚ â”‚    CRDs     â”‚  generates  â”‚                 â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ServiceMonitor Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€:**
```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: my-app-monitor
  labels:
    app: my-app
spec:
  selector:
    matchLabels:
      app: my-app
  endpoints:
  - port: metrics
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
    # Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
    relabelings:
    - sourceLabels: [__meta_kubernetes_pod_name]
      targetLabel: pod_name
    - sourceLabels: [__meta_kubernetes_namespace]  
      targetLabel: kubernetes_namespace
```

**PrometheusRule Ğ´Ğ»Ñ Ğ°Ğ»ĞµÑ€Ñ‚Ğ¾Ğ²:**
```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: my-app-alerts
spec:
  groups:
  - name: my-app.rules
    rules:
    - alert: HighErrorRate
      expr: |
        (
          rate(http_requests_total{status=~"5.."}[5m]) /
          rate(http_requests_total[5m])
        ) > 0.05
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High error rate detected"
        description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.instance }}"
        
    - alert: HighMemoryUsage
      expr: |
        (
          container_memory_working_set_bytes{container!=""} /
          container_spec_memory_limit_bytes{container!=""} 
        ) > 0.8
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage detected"
        description: "Memory usage is above 80% for container {{ $labels.container }}"
```

---

### ğŸ“ˆ Grafana: Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ñ‹

**ğŸ¨ Ğ¢Ğ¸Ğ¿Ñ‹ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¹ Ğ² Grafana:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                VISUALIZATION TYPES                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   TIME SERIES   â”‚     SINGLE      â”‚    SPECIAL      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Graph         â”‚ â€¢ Stat          â”‚ â€¢ Heatmap       â”‚
â”‚ â€¢ Area chart    â”‚ â€¢ Gauge         â”‚ â€¢ Histogram     â”‚
â”‚ â€¢ Bar gauge     â”‚ â€¢ Big number    â”‚ â€¢ Node graph    â”‚
â”‚ â€¢ State timelineâ”‚ â€¢ Progress bar  â”‚ â€¢ Service map   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ—ï¸ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°:**

```
DASHBOARD HIERARCHY:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 OVERVIEW LEVEL                      â”‚
â”‚ High-level SLIs: Availability, Latency, Throughput â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                SERVICE LEVEL                        â”‚
â”‚ Service-specific metrics: Error rates, Dependenciesâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              INFRASTRUCTURE LEVEL                   â”‚
â”‚ Node metrics: CPU, Memory, Disk, Network           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               APPLICATION LEVEL                     â”‚
â”‚ Custom metrics: Business KPIs, Custom counters     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ“Š PromQL Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ Kubernetes:**

1. **Pod CPU Usage:**
```promql
# CPU usage per pod
rate(container_cpu_usage_seconds_total{container!="POD",container!=""}[5m])

# CPU usage as percentage of limit
rate(container_cpu_usage_seconds_total{container!="POD"}[5m]) / 
on(container,pod,namespace) 
container_spec_cpu_quota{container!="POD"} * 
container_spec_cpu_period{container!="POD"}
```

2. **Memory Usage:**
```promql
# Memory working set
container_memory_working_set_bytes{container!="POD",container!=""}

# Memory usage as percentage of limit  
container_memory_working_set_bytes{container!="POD"} /
on(container,pod,namespace) 
container_spec_memory_limit_bytes{container!="POD"} * 100
```

3. **Network I/O:**
```promql
# Network receive rate
rate(container_network_receive_bytes_total[5m])

# Network transmit rate
rate(container_network_transmit_bytes_total[5m])
```

4. **Disk Usage:**
```promql
# Filesystem usage percentage
(
  node_filesystem_size_bytes{fstype!="tmpfs"} - 
  node_filesystem_free_bytes{fstype!="tmpfs"}
) / 
node_filesystem_size_bytes{fstype!="tmpfs"} * 100
```

---

### ğŸš¨ AlertManager: ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸ÑĞ¼Ğ¸

**ğŸ—ï¸ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° AlertManager:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ALERT FLOW                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   fires    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚ â”‚ Prometheus  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  AlertManager   â”‚     â”‚
â”‚ â”‚    Rules    â”‚   alerts   â”‚                 â”‚     â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                     â”‚               â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                            â–¼        â–¼        â–¼      â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                     â”‚  Email  â”‚ â”‚Slack â”‚ â”‚ PD   â”‚  â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ”§ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ AlertManager:**

```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@company.com'

# ĞœĞ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°Ğ»ĞµÑ€Ñ‚Ğ¾Ğ²
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 30s           # Ğ–Ğ´Ğ°Ñ‚ÑŒ 30Ñ Ğ¿ĞµÑ€ĞµĞ´ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¾Ğ¹ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹
  group_interval: 5m        # Ğ˜Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼Ğ¸
  repeat_interval: 12h      # ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ
  receiver: 'default'
  
  routes:
  # ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ°Ğ»ĞµÑ€Ñ‚Ñ‹ ÑÑ€Ğ°Ğ·Ñƒ Ğ½Ğ° PagerDuty
  - match:
      severity: critical
    receiver: 'pagerduty'
    group_wait: 10s
    
  # ĞĞ»ĞµÑ€Ñ‚Ñ‹ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ°Ğ½Ğ°Ğ»
  - match_re:
      alertname: ^(NodeDown|DiskSpaceLow)$
    receiver: 'infrastructure-team'

# ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°Ñ‚ĞµĞ»Ğ¸ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹
receivers:
- name: 'default'
  slack_configs:
  - api_url: 'https://hooks.slack.com/...'
    channel: '#alerts'
    title: 'Alert: {{ .GroupLabels.alertname }}'
    text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

- name: 'pagerduty'
  pagerduty_configs:
  - service_key: 'YOUR_PAGERDUTY_KEY'
    description: '{{ .GroupLabels.alertname }}: {{ .GroupLabels.instance }}'

- name: 'infrastructure-team'
  email_configs:
  - to: 'infra-team@company.com'
    subject: 'Infrastructure Alert: {{ .GroupLabels.alertname }}'
    body: |
      Alert Details:
      {{ range .Alerts }}
      - {{ .Annotations.summary }}
      - Instance: {{ .Labels.instance }}
      - Value: {{ .Annotations.value }}
      {{ end }}

# ĞŸĞ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ°Ğ»ĞµÑ€Ñ‚Ğ¾Ğ²
inhibit_rules:
- source_match:
    severity: 'critical'
  target_match:
    severity: 'warning'
  equal: ['alertname', 'cluster', 'service']
```

---

## 5.2 Ğ¦ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

### ğŸ¯ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² Kubernetes

**ğŸ—ï¸ ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ log pipeline:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LOGGING ARCHITECTURE                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚ â”‚    PODS     â”‚â”€â”€â”€â–ºâ”‚   Log Agents    â”‚             â”‚
â”‚ â”‚  (stdout)   â”‚    â”‚ â€¢ Fluentd       â”‚             â”‚
â”‚ â”‚  (stderr)   â”‚    â”‚ â€¢ Fluent Bit    â”‚             â”‚
â”‚ â”‚  (files)    â”‚    â”‚ â€¢ Filebeat      â”‚             â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                             â”‚                       â”‚
â”‚                             â–¼                       â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                    â”‚   Aggregation   â”‚             â”‚
â”‚                    â”‚ â€¢ Kafka         â”‚             â”‚
â”‚                    â”‚ â€¢ Redis         â”‚             â”‚
â”‚                    â”‚ â€¢ Logstash      â”‚             â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                             â”‚                       â”‚
â”‚                             â–¼                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚ â”‚   Storage   â”‚â—„â”€â”€â”€â”‚   Processing    â”‚             â”‚
â”‚ â”‚ â€¢ Elastic   â”‚    â”‚ â€¢ Parsing       â”‚             â”‚
â”‚ â”‚ â€¢ Loki      â”‚    â”‚ â€¢ Enrichment    â”‚             â”‚
â”‚ â”‚ â€¢ BigQuery  â”‚    â”‚ â€¢ Filtering     â”‚             â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                                           â”‚
â”‚         â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚ â”‚Visualizationâ”‚                                    â”‚
â”‚ â”‚ â€¢ Kibana    â”‚                                    â”‚
â”‚ â”‚ â€¢ Grafana   â”‚                                    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ“ Fluentd vs Fluent Bit: Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°

**ğŸ”„ Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ log Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FLUENTD vs FLUENT BIT                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      FLUENTD        â”‚         FLUENT BIT            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Ruby-based        â”‚ â€¢ C-based                     â”‚
â”‚ â€¢ Ğ‘Ğ¾Ğ³Ğ°Ñ‚Ğ°Ñ ÑĞºĞ¾ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°â”‚ â€¢ ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ğµ     â”‚
â”‚ â€¢ 40MB+ RAM         â”‚ â€¢ ~650KB RAM                  â”‚
â”‚ â€¢ Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° â”‚ â€¢ ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°           â”‚
â”‚ â€¢ ĞŸĞ»Ğ°Ğ³Ğ¸Ğ½Ñ‹ Ğ½Ğ° Ruby   â”‚ â€¢ Ğ’ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğµ processors       â”‚
â”‚ â€¢ Aggregator Ñ€Ğ¾Ğ»ÑŒ   â”‚ â€¢ Edge agent Ñ€Ğ¾Ğ»ÑŒ             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ¯ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµĞ¼Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:**
```
NODE LEVEL:                    CLUSTER LEVEL:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fluent Bit  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    Fluentd      â”‚
â”‚ DaemonSet   â”‚   forwards    â”‚   Deployment    â”‚
â”‚             â”‚               â”‚                 â”‚
â”‚ â€¢ Collect   â”‚               â”‚ â€¢ Aggregate     â”‚
â”‚ â€¢ Parse     â”‚               â”‚ â€¢ Process       â”‚
â”‚ â€¢ Forward   â”‚               â”‚ â€¢ Route         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ â€¢ Output        â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ”§ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Fluent Bit

**DaemonSet ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:**
```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: logging
spec:
  selector:
    matchLabels:
      name: fluent-bit
  template:
    metadata:
      labels:
        name: fluent-bit
    spec:
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:latest
        ports:
        - containerPort: 2020
        volumeMounts:
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config
          mountPath: /fluent-bit/etc/
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config
        configMap:
          name: fluent-bit-config
```

**ConfigMap Ñ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ¾Ğ¼:**
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
    
    [INPUT]
        Name              tail
        Path              /var/log/containers/*.log
        Parser            docker
        Tag               kube.*
        Refresh_Interval  5
        Mem_Buf_Limit     50MB
        Skip_Long_Lines   On
    
    [FILTER]
        Name                kubernetes
        Match               kube.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        Merge_Log           On
        K8S-Logging.Parser  On
        K8S-Logging.Exclude Off
    
    [OUTPUT]
        Name  es
        Match *
        Host  elasticsearch.logging.svc.cluster.local
        Port  9200
        Index fluentbit
        Type  _doc

  parsers.conf: |
    [PARSER]
        Name   docker
        Format json
        Time_Key time
        Time_Format %Y-%m-%dT%H:%M:%S.%L
    
    [PARSER]
        Name        nginx
        Format      regex
        Regex       ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
        Time_Key    time
        Time_Format %d/%b/%Y:%H:%M:%S %z
```

---

### ğŸ” Structured Logging Best Practices

**ğŸ“‹ ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:**

```
ĞĞ•Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ˜Ğ ĞĞ’ĞĞĞĞ«Ğ• Ğ›ĞĞ“Ğ˜:
2024-01-15 10:30:45 ERROR User john.doe failed to login from 192.168.1.100

Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ˜Ğ ĞĞ’ĞĞĞĞ«Ğ• Ğ›ĞĞ“Ğ˜:
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "level": "ERROR",
  "message": "User login failed",
  "user_id": "john.doe",
  "source_ip": "192.168.1.100",
  "event_type": "authentication",
  "request_id": "req-12345",
  "service": "auth-service",
  "namespace": "production"
}
```

**ğŸ·ï¸ Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ»Ñ Ğ´Ğ»Ñ Kubernetes:**
```json
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "level": "INFO|WARN|ERROR|DEBUG",
  "message": "Human readable message",
  
  // Kubernetes metadata
  "kubernetes": {
    "namespace": "production",
    "pod_name": "web-app-7d4b8c9f5-xyz12",
    "container_name": "web-app",
    "node_name": "worker-node-1",
    "labels": {
      "app": "web-app",
      "version": "v1.2.3"
    }
  },
  
  // Request tracing
  "trace_id": "64f8a2b1-4c5d-4e1f-8a5c-123456789abc",
  "span_id": "7a2b8c9d",
  "request_id": "req-98765",
  
  // Business context
  "user_id": "user-12345",
  "session_id": "sess-67890",
  "operation": "create_order",
  
  // Technical details
  "duration_ms": 245,
  "status_code": 200,
  "error_code": null
}
```

---

### ğŸ“Š Log Retention Ğ¸ Storage

**ğŸ—„ï¸ Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ¾Ğ²:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LOG RETENTION STRATEGY                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   HOT STORAGE   â”‚   WARM STORAGE  â”‚  COLD STORAGE   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Last 7 days     â”‚ 7-30 days       â”‚ 30+ days        â”‚
â”‚ SSD, fast query â”‚ Cheaper SSD     â”‚ Object storage  â”‚
â”‚ Real-time alertsâ”‚ Investigation   â”‚ Compliance      â”‚
â”‚ High cost       â”‚ Medium cost     â”‚ Low cost        â”‚
â”‚ Elasticsearch   â”‚ Elasticsearch   â”‚ S3, GCS         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Index Lifecycle Management (ILM):**
```json
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_size": "50gb",
            "max_age": "1d"
          },
          "set_priority": {
            "priority": 100
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          },
          "set_priority": {
            "priority": 50
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          },
          "set_priority": {
            "priority": 0
          }
        }
      },
      "delete": {
        "min_age": "90d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
```

---

## 5.3 Ğ¢Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¸ APM

### ğŸ¯ Distributed Tracing ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸

**ğŸ” ĞĞ½Ğ°Ñ‚Ğ¾Ğ¼Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ‚Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DISTRIBUTED TRACE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ TRACE ID: abc123def456                              â”‚
â”‚                                                     â”‚
â”‚ â”Œâ”€ SPAN: Frontend (100ms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚                                               â”‚   â”‚
â”‚ â”‚  â”Œâ”€ SPAN: API Gateway (80ms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚ â”‚  â”‚                                         â”‚  â”‚   â”‚
â”‚ â”‚  â”‚  â”Œâ”€ SPAN: Auth Service (20ms) â”€â”€â”€â”     â”‚  â”‚   â”‚
â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚   â”‚
â”‚ â”‚  â”‚                                         â”‚  â”‚   â”‚
â”‚ â”‚  â”‚  â”Œâ”€ SPAN: User Service (40ms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚   â”‚
â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚   â”‚
â”‚ â”‚  â”‚                                         â”‚  â”‚   â”‚
â”‚ â”‚  â”‚  â”Œâ”€ SPAN: Database (15ms) â”€â”€â”€â”€â”        â”‚  â”‚   â”‚
â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”‚   â”‚
â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                     â”‚
â”‚ Timeline: 0ms    25ms    50ms    75ms    100ms      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ“Š ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ñ‚Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸:**

```
PERFORMANCE METRICS:
â”œâ”€ Latency Distribution
â”‚  â”œâ”€ P50: 150ms (median)
â”‚  â”œâ”€ P95: 500ms 
â”‚  â”œâ”€ P99: 1200ms
â”‚  â””â”€ P99.9: 3000ms
â”‚
â”œâ”€ Error Rate Analysis
â”‚  â”œâ”€ Service-level errors
â”‚  â”œâ”€ Dependency failures
â”‚  â””â”€ Timeout patterns
â”‚
â””â”€ Throughput Metrics
   â”œâ”€ Requests per second
   â”œâ”€ Service saturation
   â””â”€ Bottleneck identification
```

---

### ğŸ› ï¸ OpenTelemetry: ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµĞ¼Ğ¾ÑÑ‚Ğ¸

**ğŸ—ï¸ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° OpenTelemetry:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               OPENTELEMETRY STACK                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚ â”‚Application  â”‚â”€â”€â–ºâ”‚ OTel SDK/Agent  â”‚              â”‚
â”‚ â”‚   Code      â”‚   â”‚ â€¢ Auto-instru   â”‚              â”‚
â”‚ â”‚             â”‚   â”‚ â€¢ Manual instru â”‚              â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                            â”‚                        â”‚
â”‚                            â–¼                        â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚                   â”‚ OTel Collector  â”‚              â”‚
â”‚                   â”‚ â€¢ Receive       â”‚              â”‚
â”‚                   â”‚ â€¢ Process       â”‚              â”‚
â”‚                   â”‚ â€¢ Export        â”‚              â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                            â”‚                        â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚              â–¼             â–¼             â–¼          â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚      â”‚   Jaeger    â”‚ â”‚Prometheusâ”‚ â”‚  Backend    â”‚  â”‚
â”‚      â”‚  (traces)   â”‚ â”‚(metrics) â”‚ â”‚  (logs)     â”‚  â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ”§ OpenTelemetry Collector ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:**
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
data:
  config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_http:
            endpoint: 0.0.0.0:14268
            
    processors:
      batch:
        timeout: 1s
        send_batch_size: 1024
      
      resource:
        attributes:
        - key: environment
          value: production
          action: upsert
      
      # Sampling Ğ´Ğ»Ñ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸
      probabilistic_sampler:
        sampling_percentage: 1.0
        
    exporters:
      jaeger:
        endpoint: jaeger-collector:14250
        tls:
          insecure: true
          
      prometheus:
        endpoint: "0.0.0.0:8889"
        
      logging:
        loglevel: debug
        
    service:
      pipelines:
        traces:
          receivers: [otlp, jaeger]
          processors: [batch, resource, probabilistic_sampler]
          exporters: [jaeger, logging]
          
        metrics:
          receivers: [otlp]
          processors: [batch, resource]
          exporters: [prometheus]
```

---

### ğŸ” Jaeger: ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ñ‚Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸

**ğŸ—ï¸ ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Jaeger:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                JAEGER ARCHITECTURE                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚ â”‚  Jaeger     â”‚â”€â”€â”€â–ºâ”‚  Jaeger Agent   â”‚             â”‚
â”‚ â”‚  Client     â”‚    â”‚  (DaemonSet)    â”‚             â”‚
â”‚ â”‚  (in app)   â”‚    â”‚                 â”‚             â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                             â”‚                       â”‚
â”‚                             â–¼                       â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                    â”‚ Jaeger Collectorâ”‚             â”‚
â”‚                    â”‚  (Deployment)   â”‚             â”‚
â”‚                    â”‚ â€¢ Validation    â”‚             â”‚
â”‚                    â”‚ â€¢ Processing    â”‚             â”‚
â”‚                    â”‚ â€¢ Storage       â”‚             â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                             â”‚                       â”‚
â”‚                             â–¼                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚ â”‚   Jaeger    â”‚â—„â”€â”€â”€â”‚    Storage      â”‚             â”‚
â”‚ â”‚   Query     â”‚    â”‚ â€¢ Elasticsearch â”‚             â”‚
â”‚ â”‚   (UI)      â”‚    â”‚ â€¢ Cassandra     â”‚             â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â€¢ Memory        â”‚             â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Deployment example:**
```yaml
# Jaeger All-in-One Ğ´Ğ»Ñ development
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jaeger
  template:
    metadata:
      labels:
        app: jaeger
    spec:
      containers:
      - name: jaeger
        image: jaegertracing/all-in-one:latest
        env:
        - name: COLLECTOR_ZIPKIN_HTTP_PORT
          value: "9411"
        ports:
        - containerPort: 5775
          protocol: UDP
        - containerPort: 6831
          protocol: UDP
        - containerPort: 6832
          protocol: UDP
        - containerPort: 5778
          protocol: TCP
        - containerPort: 16686
          protocol: TCP
        - containerPort: 14268
          protocol: TCP
        - containerPort: 14250
          protocol: TCP
        - containerPort: 9411
          protocol: TCP
```

---

### ğŸ“ˆ Application Performance Monitoring

**ğŸ¯ Key Performance Indicators (KPIs):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 APM METRICS                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    GOLDEN       â”‚    BUSINESS     â”‚   TECHNICAL     â”‚
â”‚   SIGNALS       â”‚    METRICS      â”‚    METRICS      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Latency       â”‚ â€¢ Conversion    â”‚ â€¢ CPU Usage     â”‚
â”‚ â€¢ Throughput    â”‚ â€¢ Revenue       â”‚ â€¢ Memory Usage  â”‚
â”‚ â€¢ Errors        â”‚ â€¢ User Activity â”‚ â€¢ Disk I/O      â”‚
â”‚ â€¢ Saturation    â”‚ â€¢ Cart Size     â”‚ â€¢ Network I/O   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ” Synthetic Monitoring:**
```yaml
# Synthetic tests Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
apiVersion: batch/v1
kind: CronJob
metadata:
  name: synthetic-test
spec:
  schedule: "*/5 * * * *"  # ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 5 Ğ¼Ğ¸Ğ½ÑƒÑ‚
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: test
            image: curlimages/curl:latest
            command:
            - /bin/sh
            - -c
            - |
              # Health check
              RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" http://my-app/health)
              if [ $RESPONSE -ne 200 ]; then
                echo "Health check failed: $RESPONSE"
                exit 1
              fi
              
              # Performance test
              LATENCY=$(curl -s -o /dev/null -w "%{time_total}" http://my-app/api/users)
              echo "API latency: ${LATENCY}s"
              
              # Functional test
              curl -s -X POST -H "Content-Type: application/json" \
                -d '{"test": "data"}' \
                http://my-app/api/test
          restartPolicy: Never
```

---

## 5.4 ĞÑ‚Ğ»Ğ°Ğ´ĞºĞ° Ğ¿Ğ¾Ğ´Ğ¾Ğ² Ğ¸ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²

### ğŸ¯ Systematic Troubleshooting Approach

**ğŸ” Troubleshooting Workflow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            KUBERNETES TROUBLESHOOTING               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ 1. GATHER INFORMATION                               â”‚
â”‚    â”œâ”€ kubectl get pods -o wide                      â”‚
â”‚    â”œâ”€ kubectl describe pod <name>                   â”‚
â”‚    â””â”€ kubectl logs <pod> --previous                 â”‚
â”‚                                                     â”‚
â”‚ 2. CHECK RESOURCES                                  â”‚
â”‚    â”œâ”€ Resource requests/limits                      â”‚
â”‚    â”œâ”€ Node capacity                                 â”‚
â”‚    â””â”€ Storage availability                          â”‚
â”‚                                                     â”‚
â”‚ 3. VERIFY NETWORKING                                â”‚
â”‚    â”œâ”€ Service endpoints                             â”‚
â”‚    â”œâ”€ DNS resolution                                â”‚
â”‚    â””â”€ Network policies                              â”‚
â”‚                                                     â”‚
â”‚ 4. EXAMINE CONFIGURATION                            â”‚
â”‚    â”œâ”€ ConfigMaps/Secrets                           â”‚
â”‚    â”œâ”€ Environment variables                         â”‚
â”‚    â””â”€ Volume mounts                                 â”‚
â”‚                                                     â”‚
â”‚ 5. TEST CONNECTIVITY                                â”‚
â”‚    â”œâ”€ Pod-to-pod communication                      â”‚
â”‚    â”œâ”€ External dependencies                         â”‚
â”‚    â””â”€ Load balancer health                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ› Common Pod Issues Ğ¸ Ğ¸Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ

**1. ImagePullBackOff / ErrImagePull**
```bash
# Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°
kubectl describe pod <pod-name>

Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹:
â”œâ”€ ĞĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ¼Ñ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ°
â”œâ”€ ĞĞ±Ñ€Ğ°Ğ· Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² registry
â”œâ”€ ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ Ğ¿Ñ€Ğ°Ğ²Ğ° Ğ½Ğ° pull
â”œâ”€ Registry Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½
â””â”€ imagePullSecrets Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹

# Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ
kubectl create secret docker-registry my-secret \
  --docker-server=registry.example.com \
  --docker-username=myuser \
  --docker-password=mypass \
  --docker-email=email@example.com

# Ğ’ pod spec
spec:
  imagePullSecrets:
  - name: my-secret
```

**2. CrashLoopBackOff**
```bash
# ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ»Ğ¾Ğ³Ğ¸ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ°
kubectl logs <pod-name> --previous

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ exit code
kubectl describe pod <pod-name>

ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼:
â”œâ”€ Exit Code 0: ĞĞ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ
â”œâ”€ Exit Code 1: ĞĞ±Ñ‰Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°
â”œâ”€ Exit Code 125: Docker daemon error
â”œâ”€ Exit Code 126: ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼Ñ‹Ğ¹
â”œâ”€ Exit Code 127: ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½
â””â”€ Exit Code 137: SIGKILL (OOM Killer)
```

**3. Pending Pods**
```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ
kubectl describe pod <pod-name>

ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹ Pending:
â”œâ”€ Insufficient CPU/Memory
â”œâ”€ Node selector Ğ½Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚
â”œâ”€ Taints/Tolerations
â”œâ”€ PVC Ğ½Ğµ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ ÑĞ¼Ğ¾Ğ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½
â””â”€ Pod Security constraints

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ node capacity
kubectl describe nodes
kubectl top nodes
```

---

### ğŸŒ Network Troubleshooting

**ğŸ”§ Debugging Network Issues:**

```bash
# 1. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Service endpoints
kubectl get endpoints <service-name>

# 2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ DNS resolution
kubectl run debug --image=busybox -it --rm -- /bin/sh
nslookup <service-name>.<namespace>.svc.cluster.local

# 3. Test connectivity
kubectl exec -it <pod> -- wget -qO- http://<service>:<port>/health

# 4. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ iptables rules (Ğ½Ğ° node)
sudo iptables -t nat -L | grep <service-name>

# 5. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ kube-proxy logs
kubectl logs -n kube-system -l k8s-app=kube-proxy
```

**ğŸš« Network Policy Debugging:**
```yaml
# Test pod Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ connectivity
apiVersion: v1
kind: Pod
metadata:
  name: network-test
  labels:
    app: test
spec:
  containers:
  - name: netshoot
    image: nicolaka/netshoot
    command: ["/bin/sleep", "3600"]
    
---
# Temporary allow-all policy Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-all-test
spec:
  podSelector:
    matchLabels:
      app: test
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - {}
  egress:
  - {}
```

---

### ğŸ“Š Performance Debugging

**ğŸ” Resource Analysis:**

```bash
# 1. Top ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° resource usage
kubectl top pods --containers
kubectl top nodes

# 2. Metrics server query
kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes
kubectl get --raw /apis/metrics.k8s.io/v1beta1/pods

# 3. cAdvisor metrics (Ğ½Ğ° node)
curl http://localhost:4194/metrics

# 4. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ OOM kills
dmesg | grep -i "killed process"
journalctl -u kubelet | grep -i oom
```

**âš¡ Performance Optimization:**
```yaml
# Resource tuning Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: app
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"    # 2x requests
        cpu: "500m"        # Burst capability
    
    # JVM tuning Ğ´Ğ»Ñ Java Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹
    env:
    - name: JAVA_OPTS
      value: |
        -Xmx400m 
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=75.0
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=200
```

---

### ğŸ› ï¸ Advanced Debugging Tools

**1. kubectl debug command (1.18+)**
```bash
# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ debugging pod Ñ Ğ¾Ğ±Ñ‰Ğ¸Ğ¼Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
kubectl debug <pod-name> -it --image=ubuntu --share-processes --copy-to=debug-pod

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ sidecar container Ğº ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ¼Ñƒ Ğ¿Ğ¾Ğ´Ñƒ
kubectl debug <pod-name> -it --image=busybox --target=<container-name>

# Debug node Ñ‡ĞµÑ€ĞµĞ· privileged pod
kubectl debug node/<node-name> -it --image=ubuntu
```

**2. Ephemeral containers (1.23+)**
```bash
# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ephemeral container Ğº running pod
kubectl debug <pod-name> -it --image=busybox --target=<container>

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ´Ğ»Ñ prod debugging Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ğ°
kubectl debug production-app-123 -it \
  --image=nicolaka/netshoot \
  --target=app-container
```

**3. ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹**
```bash
# Go applications Ñ pprof
kubectl port-forward <pod> 6060:6060
go tool pprof http://localhost:6060/debug/pprof/profile

# Java applications Ñ JFR
kubectl exec <pod> -- jcmd <pid> JFR.start duration=60s filename=profile.jfr
kubectl cp <pod>:/path/to/profile.jfr ./profile.jfr
```

---

## 5.5 Health Checks Ğ¸ Probes

### ğŸ¯ Ğ¢Ğ¸Ğ¿Ñ‹ Probes Ğ² Kubernetes

**ğŸ¥ Ğ¢Ñ€Ğ¸ Ñ‚Ğ¸Ğ¿Ğ° health checks:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  KUBERNETES PROBES                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   LIVENESS      â”‚   READINESS     â”‚    STARTUP      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ĞšĞ¾Ğ³Ğ´Ğ° ÑƒĞ±Ğ¸Ñ‚ÑŒ     â”‚ ĞšĞ¾Ğ³Ğ´Ğ° Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ â”‚ ĞšĞ¾Ğ³Ğ´Ğ° Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ    â”‚
â”‚ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€       â”‚ Ñ‚Ñ€Ğ°Ñ„Ğ¸Ğº          â”‚ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ â”‚
â”‚                 â”‚                 â”‚                 â”‚
â”‚ â€¢ Deadlock      â”‚ â€¢ Initializationâ”‚ â€¢ Slow start    â”‚
â”‚ â€¢ Memory leak   â”‚ â€¢ Dependencies  â”‚ â€¢ Legacy apps   â”‚
â”‚ â€¢ Corruption    â”‚ â€¢ Load balancer â”‚ â€¢ Migration     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**â±ï¸ Lifecycle Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ probes:**
```
POD STARTUP SEQUENCE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                     â”‚
â”‚ 1. Container starts                                 â”‚
â”‚    â”‚                                                â”‚
â”‚    â–¼                                                â”‚
â”‚ 2. Startup Probe (ĞµÑĞ»Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½)                   â”‚
â”‚    â”‚ â”€â”€ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ÑÑ Ğ´Ğ¾ ÑƒÑĞ¿ĞµÑ…Ğ°                       â”‚
â”‚    â”‚ â”€â”€ Ğ‘Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒĞµÑ‚ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ probes                     â”‚
â”‚    â–¼                                                â”‚
â”‚ 3. Liveness + Readiness Probes                     â”‚
â”‚    â”‚ â”€â”€ Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾                        â”‚
â”‚    â”‚ â”€â”€ ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ÑÑ‚ Ğ²ÑÑ Ğ¶Ğ¸Ğ·Ğ½ÑŒ Ğ¿Ğ¾Ğ´Ğ°                   â”‚
â”‚    â–¼                                                â”‚
â”‚ 4. Pod Ready Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ°                 â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ”§ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Probes

**HTTP Health Check Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€:**
```yaml
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: web-app
    image: nginx
    ports:
    - containerPort: 80
    
    # Liveness Probe - Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞº Ğ¿Ñ€Ğ¸ ÑĞ±Ğ¾Ğµ
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
        httpHeaders:
        - name: Custom-Header
          value: health-check
      initialDelaySeconds: 30    # Ğ–Ğ´Ğ°Ñ‚ÑŒ 30Ñ Ğ¿Ğ¾ÑĞ»Ğµ ÑÑ‚Ğ°Ñ€Ñ‚Ğ°
      periodSeconds: 10          # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑÑ‚ÑŒ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 10Ñ
      timeoutSeconds: 5          # Timeout Ğ½Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
      failureThreshold: 3        # 3 Ğ½ĞµÑƒĞ´Ğ°Ñ‡Ğ¸ = restart
      successThreshold: 1        # 1 ÑƒÑĞ¿ĞµÑ… = healthy
    
    # Readiness Probe - Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ· Service
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
    
    # Startup Probe - Ğ´Ğ»Ñ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾ ÑÑ‚Ğ°Ñ€Ñ‚ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹
    startupProbe:
      httpGet:
        path: /startup
        port: 8080
      initialDelaySeconds: 0
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 30       # 30 * 10s = 5 Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ½Ğ° ÑÑ‚Ğ°Ñ€Ñ‚
      successThreshold: 1
```

**TCP Ğ¸ Command Probes:**
```yaml
# TCP Socket probe
livenessProbe:
  tcpSocket:
    port: 5432
  initialDelaySeconds: 15
  periodSeconds: 10

# Command execution probe  
readinessProbe:
  exec:
    command:
    - /bin/sh
    - -c
    - "pg_isready -U $POSTGRES_USER -d $POSTGRES_DB"
  initialDelaySeconds: 5
  periodSeconds: 5
```

---

### ğŸ’¡ Best Practices Ğ´Ğ»Ñ Health Checks

**ğŸ¯ Design Principles:**

```
Ğ­Ğ¤Ğ¤Ğ•ĞšĞ¢Ğ˜Ğ’ĞĞ«Ğ• HEALTH CHECKS:
â”œâ”€ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ (< 1 ÑĞµĞºÑƒĞ½Ğ´Ğ°)
â”œâ”€ Ğ›ĞµĞ³ĞºĞ¾Ğ²ĞµÑĞ½Ñ‹Ğµ (Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ CPU/Memory)
â”œâ”€ Ğ¡Ğ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ (Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ)
â”œâ”€ Ğ”ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ (ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹)
â””â”€ Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğµ (Ğ½Ğµ Ğ¼ĞµĞ½ÑÑÑ‚ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ)

ĞŸĞ›ĞĞ¥Ğ˜Ğ• ĞŸĞ ĞĞšĞ¢Ğ˜ĞšĞ˜:
â”œâ”€ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ² liveness
â”œâ”€ Ğ¢ÑĞ¶ĞµĞ»Ñ‹Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ (Ğ¿Ğ¾Ğ»Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ‘Ğ”)
â”œâ”€ ĞĞµĞ´ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‚ĞµÑÑ‚Ñ‹
â”œâ”€ Ğ¡Ğ°Ğ¹Ğ´-ÑÑ„Ñ„ĞµĞºÑ‚Ñ‹ Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞµ
â””â”€ Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ°Ğ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½Ñ‹Ğµ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚Ñ‹
```

**ğŸ¥ Health Check Endpoints design:**

```go
// ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Go HTTP health checks
func healthHandler(w http.ResponseWriter, r *http.Request) {
    // Liveness: Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
    if !app.IsAlive() {
        http.Error(w, "Service not alive", http.StatusServiceUnavailable)
        return
    }
    
    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(map[string]string{
        "status": "UP",
        "timestamp": time.Now().ISO8601(),
        "version": app.Version,
    })
}

func readinessHandler(w http.ResponseWriter, r *http.Request) {
    checks := map[string]string{}
    healthy := true
    
    // Database connectivity
    if err := db.Ping(); err != nil {
        checks["database"] = "DOWN: " + err.Error()
        healthy = false
    } else {
        checks["database"] = "UP"
    }
    
    // Cache connectivity  
    if err := cache.Ping(); err != nil {
        checks["cache"] = "DOWN: " + err.Error()
        healthy = false
    } else {
        checks["cache"] = "UP"
    }
    
    status := "UP"
    httpStatus := http.StatusOK
    if !healthy {
        status = "DOWN"
        httpStatus = http.StatusServiceUnavailable
    }
    
    w.WriteHeader(httpStatus)
    json.NewEncoder(w).Encode(map[string]interface{}{
        "status": status,
        "checks": checks,
        "timestamp": time.Now().ISO8601(),
    })
}
```

---

### ğŸš¨ Graceful Shutdown Patterns

**âš°ï¸ ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹:**

```yaml
# Pod Ñ graceful shutdown
apiVersion: v1
kind: Pod
spec:
  terminationGracePeriodSeconds: 60  # Ğ’Ñ€ĞµĞ¼Ñ Ğ½Ğ° graceful shutdown
  containers:
  - name: app
    image: myapp:latest
    
    # Preemptive scaling down
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            # Ğ¡Ğ½ÑÑ‚ÑŒ Ñ load balancer
            curl -X POST http://localhost:8080/admin/stop-accepting-requests
            # Ğ”Ğ¾Ğ¶Ğ´Ğ°Ñ‚ÑŒÑÑ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
            sleep 15
            # Graceful shutdown
            kill -TERM 1
    
    # Readiness probe Ğ´Ğ»Ñ Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ· LB
    readinessProbe:
      httpGet:
        path: /health/ready
        port: 8080
      periodSeconds: 1
      failureThreshold: 1  # Ğ‘Ñ‹ÑÑ‚Ñ€Ğ¾ Ğ¸ÑĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ· LB
```

**ğŸ”„ Graceful Shutdown Implementation (Go):**
```go
package main

import (
    "context"
    "net/http"
    "os"
    "os/signal"
    "syscall"
    "time"
)

func main() {
    server := &http.Server{Addr: ":8080"}
    
    // Graceful shutdown
    go func() {
        sigint := make(chan os.Signal, 1)
        signal.Notify(sigint, os.Interrupt, syscall.SIGTERM)
        <-sigint
        
        // Shutdown with timeout
        ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
        defer cancel()
        
        log.Println("Shutting down server...")
        if err := server.Shutdown(ctx); err != nil {
            log.Printf("Server shutdown error: %v", err)
        }
    }()
    
    // Start server
    if err := server.ListenAndServe(); err != http.ErrServerClosed {
        log.Printf("Server error: %v", err)
    }
    
    log.Println("Server stopped")
}
```

---

## ğŸ“ Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ±Ğ»Ğ¾ĞºĞ°

ĞŸĞ¾ÑĞ»Ğµ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ±Ğ»Ğ¾ĞºĞ° Ğ²Ñ‹ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ:

âœ… **ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°** Ñ Prometheus Ğ¸ Grafana  
âœ… **Ğ¦ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ** Ğ¸ structured logging  
âœ… **Distributed tracing** Ğ¸ APM ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸  
âœ… **Systematic troubleshooting** Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹  
âœ… **Health checks** Ğ¸ graceful shutdown patterns  
âœ… **Performance optimization** Ğ´Ğ»Ñ production

**ğŸ¯ Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑˆĞ°Ğ³:** ĞŸÑ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ comprehensive observability stack Ğ² production-Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğ¸.

---

## ğŸ“š ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ

**ğŸ”¬ Ğ›Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:**

1. **Ğ Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ monitoring stack:**
   - Prometheus + Grafana + AlertManager
   - ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ custom metrics Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
   - Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ñ‹ Ğ´Ğ»Ñ SLI/SLO

2. **ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:**
   - ELK Stack Ğ¸Ğ»Ğ¸ Loki + Grafana
   - Structured logging Ğ² Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸
   - Log parsing Ğ¸ alerting

3. **Ğ’Ğ½ĞµĞ´Ñ€Ğ¸Ñ‚ÑŒ distributed tracing:**
   - OpenTelemetry instrumentation
   - Jaeger deployment
   - Performance optimization Ğ¿Ğ¾ traces

4. **Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ comprehensive troubleshooting guide:**
   - Runbook Ğ´Ğ»Ñ Ñ‚Ğ¸Ğ¿Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼
   - Automation Ğ´Ğ»Ñ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¸
   - Emergency response procedures

---

## ğŸ“– Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµÑÑƒÑ€ÑÑ‹

**Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ:**
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [OpenTelemetry Documentation](https://opentelemetry.io/docs/)

**Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹:**
- [kube-prometheus](https://github.com/prometheus-operator/kube-prometheus)
- [Jaeger Operator](https://github.com/jaegertracing/jaeger-operator)
- [Fluentd](https://www.fluentd.org/) / [Fluent Bit](https://fluentbit.io/)

**ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ°:**
- [Prometheus Monitoring Mixins](https://monitoring.mixins.dev/)
- [SRE Workbook](https://sre.google/workbook/table-of-contents/) Ğ¾Ñ‚ Googlelfdf