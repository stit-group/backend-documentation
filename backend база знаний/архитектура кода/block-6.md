# Ğ‘Ğ»Ğ¾Ğº 6: ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ

**Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** 5-6 Ğ½ĞµĞ´ĞµĞ»ÑŒ  
**Ğ¦ĞµĞ»ÑŒ:** ĞÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼

---

## ğŸ“Š Ğ’Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ² Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ

```
ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ â‰  ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ â”‚    â”‚ ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ â”‚
â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ      â”‚    â”‚ â€¢ Ğ Ğ¾ÑÑ‚ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ â”‚
â”‚ â€¢ ĞÑ‚Ğ·Ñ‹Ğ²Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ  â”‚    â”‚ â€¢ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ    â”‚
â”‚ â€¢ ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ½Ğ°Ñ    â”‚    â”‚   Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²      â”‚
â”‚   ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ   â”‚    â”‚ â€¢ Ğ“Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµâ”‚
â”‚                 â”‚    â”‚   Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸:**
- **Latency (Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ°)** - Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ½Ğ° ĞµĞ´Ğ¸Ğ½Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
- **Throughput (Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ½Ğ°Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ)** - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² ĞµĞ´Ğ¸Ğ½Ğ¸Ñ†Ñƒ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
- **Response Time** - Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ñ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ´Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
- **Scalability** - ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒÑÑ Ñ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸

---

## ğŸ” Ğ“Ğ»Ğ°Ğ²Ğ° 1: ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸

### 1.1 ĞœĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸

```
â”Œâ”€â”€â”€ Ğ˜Ğ—ĞœĞ•Ğ Ğ•ĞĞ˜Ğ• ĞŸĞ ĞĞ˜Ğ—Ğ’ĞĞ”Ğ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞĞ¡Ğ¢Ğ˜ â”€â”€â”€â”
â”‚                                    â”‚
â”‚  ğŸ“ˆ Ğ¡Ğ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ     â”‚
â”‚  â”œâ”€â”€ Load Testing                  â”‚
â”‚  â”œâ”€â”€ Stress Testing                â”‚
â”‚  â””â”€â”€ Spike Testing                 â”‚
â”‚                                    â”‚
â”‚  ğŸ“Š ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ â”‚
â”‚  â”œâ”€â”€ CPU Profiling                 â”‚
â”‚  â”œâ”€â”€ Memory Profiling              â”‚
â”‚  â””â”€â”€ I/O Profiling                 â”‚
â”‚                                    â”‚
â”‚  ğŸ¯ ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ² Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞµĞ½Ğµ        â”‚
â”‚  â”œâ”€â”€ APM Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹               â”‚
â”‚  â”œâ”€â”€ ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ            â”‚
â”‚  â””â”€â”€ ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¹ Ğ¾Ğ¿Ñ‹Ñ‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ ÑĞ·Ñ‹ĞºĞ°Ğ¼:

| Ğ¯Ğ·Ñ‹Ğº | CPU Profiler | Memory Profiler | ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ |
|------|-------------|----------------|-------------------|
| Java | JProfiler, YourKit | Eclipse MAT | JVisualVM, JConsole |
| C# | PerfView, dotTrace | JetBrains dotMemory | Application Insights |
| Python | cProfile, py-spy | memory_profiler | PyCharm Profiler |
| JavaScript | Chrome DevTools | Heap Snapshot | Node.js Inspector |
| Go | go tool pprof | Built-in profiler | Golang pprof |

### 1.2 ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ CPU

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² Python:**

```python
import cProfile
import pstats
from functools import wraps

def profile_performance(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        profiler = cProfile.Profile()
        profiler.enable()
        
        result = func(*args, **kwargs)
        
        profiler.disable()
        stats = pstats.Stats(profiler)
        stats.sort_stats('cumulative')
        stats.print_stats(10)  # Ğ¢Ğ¾Ğ¿ 10 Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹
        
        return result
    return wrapper

@profile_performance
def cpu_intensive_task():
    # Ğ’Ğ°Ñˆ ĞºĞ¾Ğ´ Ğ·Ğ´ĞµÑÑŒ
    pass
```

**ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:**

```
         ncalls  tottime  percall  cumtime  percall filename:lineno(function)
             1    0.000    0.000    2.500    2.500 <string>:1(<module>)
           100    0.005    0.000    2.500    0.025 algorithm.py:15(process_data)
         10000    1.200    0.000    2.495    0.000 utils.py:42(heavy_computation)
        100000    1.295    0.000    1.295    0.000 {built-in method builtins.sum}
```

**Ğ§Ñ‚Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ:**
- `tottime` - Ğ²Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ±ĞµĞ· Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²
- `cumtime` - Ğ¾Ğ±Ñ‰ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñ‹
- `ncalls` - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸

### 1.3 ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒÑ:**

```
â”Œâ”€â”€â”€ HEAP MEMORY STRUCTURE â”€â”€â”€â”
â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Young Generation  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚Eden â”‚Survivor â”‚  â”‚    â”‚
â”‚  â”‚  â”‚Spaceâ”‚  Space  â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Old Generation    â”‚    â”‚
â”‚  â”‚  (Tenured Space)    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Permanent/Metaspace â”‚    â”‚
â”‚  â”‚   (Class metadata)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ² Java:**

```java
public class MemoryMonitor {
    private static final MemoryMXBean memoryBean = 
        ManagementFactory.getMemoryMXBean();
    
    public static void printMemoryUsage() {
        MemoryUsage heapUsage = memoryBean.getHeapMemoryUsage();
        MemoryUsage nonHeapUsage = memoryBean.getNonHeapMemoryUsage();
        
        System.out.println("--- Memory Usage ---");
        System.out.printf("Heap: %d MB used / %d MB max%n", 
            heapUsage.getUsed() / 1024 / 1024,
            heapUsage.getMax() / 1024 / 1024);
        System.out.printf("Non-Heap: %d MB used%n", 
            nonHeapUsage.getUsed() / 1024 / 1024);
    }
    
    public static void forceGC() {
        System.gc();
        System.runFinalization();
    }
}
```

### 1.4 ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑƒĞ·ĞºĞ¸Ñ… Ğ¼ĞµÑÑ‚

**Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸:**

```
â”Œâ”€â”€â”€ OPTIMIZATION STRATEGIES â”€â”€â”€â”
â”‚                               â”‚
â”‚  ğŸ¯ ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ°Ñ           â”‚
â”‚  â”œâ”€â”€ Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ²  â”‚
â”‚  â”œâ”€â”€ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…         â”‚
â”‚  â””â”€â”€ Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ O(n)           â”‚
â”‚                               â”‚
â”‚  âš¡ ĞœĞ¸ĞºÑ€Ğ¾Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸          â”‚
â”‚  â”œâ”€â”€ Ğ˜Ğ·Ğ±ĞµĞ³Ğ°Ğ½Ğ¸Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ       â”‚
â”‚  â”‚   Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²                â”‚
â”‚  â”œâ”€â”€ ĞŸÑƒĞ»Ñ‹ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²            â”‚
â”‚  â””â”€â”€ ĞŸÑ€Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ñ‚Ğ¸Ğ¿Ñ‹         â”‚
â”‚                               â”‚
â”‚  ğŸ—ï¸ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ğ°Ñ             â”‚
â”‚  â”œâ”€â”€ ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ              â”‚
â”‚  â”œâ”€â”€ ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ            â”‚
â”‚  â””â”€â”€ Ğ Ğ°ÑĞ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°:**

```python
# âŒ ĞĞµÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ - O(nÂ²)
def find_duplicates_slow(items):
    duplicates = []
    for i in range(len(items)):
        for j in range(i + 1, len(items)):
            if items[i] == items[j] and items[i] not in duplicates:
                duplicates.append(items[i])
    return duplicates

# âœ… Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ - O(n)
def find_duplicates_fast(items):
    seen = set()
    duplicates = set()
    
    for item in items:
        if item in seen:
            duplicates.add(item)
        else:
            seen.add(item)
    
    return list(duplicates)
```

---

## ğŸ’¾ Ğ“Ğ»Ğ°Ğ²Ğ° 2: Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

### 2.1 Ğ£Ñ€Ğ¾Ğ²Ğ½Ğ¸ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

```
â”Œâ”€â”€â”€ CACHING LAYERS â”€â”€â”€â”
â”‚                      â”‚
â”‚  ğŸŒ Browser Cache    â”‚
â”‚  â”‚                  â”‚
â”‚  â†“                  â”‚
â”‚  ğŸ”„ CDN Cache        â”‚
â”‚  â”‚                  â”‚
â”‚  â†“                  â”‚
â”‚  ğŸš€ Reverse Proxy    â”‚
â”‚  â”‚   (Nginx/Varnish)â”‚
â”‚  â†“                  â”‚
â”‚  ğŸ’» Application Cacheâ”‚
â”‚  â”‚   (In-Memory)    â”‚
â”‚  â†“                  â”‚
â”‚  ğŸ—„ï¸ Database Cache   â”‚
â”‚  â”‚   (Query Cache)  â”‚
â”‚  â†“                  â”‚
â”‚  ğŸ’¿ Persistent Cache â”‚
â”‚     (Redis/Memcached)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Cache Patterns (ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ)

#### Cache-Aside (Lazy Loading)

```
â”Œâ”€â”€â”€ CACHE-ASIDE PATTERN â”€â”€â”€â”
â”‚                           â”‚
â”‚  Application              â”‚
â”‚       â”‚                  â”‚
â”‚       â”œâ”€1. Check Cache   â”‚
â”‚       â”‚                  â”‚
â”‚   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”              â”‚
â”‚   â”‚ Cache â”‚              â”‚
â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜              â”‚
â”‚       â”‚                  â”‚
â”‚       â”œâ”€2. Cache Miss    â”‚
â”‚       â”‚                  â”‚
â”‚       â”œâ”€3. Read from DB  â”‚
â”‚       â”‚                  â”‚
â”‚   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”              â”‚
â”‚   â”‚  DB   â”‚              â”‚
â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜              â”‚
â”‚       â”‚                  â”‚
â”‚       â””â”€4. Store in Cacheâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Cache-Aside:**

```python
import redis
import json
from typing import Optional

class CacheAside:
    def __init__(self, redis_client):
        self.cache = redis_client
        self.ttl = 3600  # 1 Ñ‡Ğ°Ñ
    
    def get_user(self, user_id: int) -> Optional[dict]:
        # 1. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞºÑÑˆ
        cache_key = f"user:{user_id}"
        cached_data = self.cache.get(cache_key)
        
        if cached_data:
            # Cache Hit
            return json.loads(cached_data)
        
        # 2. Cache Miss - Ğ¸Ğ´ĞµĞ¼ Ğ² Ğ‘Ğ”
        user = self.fetch_user_from_db(user_id)
        
        if user:
            # 3. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² ĞºÑÑˆ
            self.cache.setex(
                cache_key, 
                self.ttl, 
                json.dumps(user)
            )
        
        return user
    
    def update_user(self, user_id: int, user_data: dict):
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ‘Ğ”
        self.update_user_in_db(user_id, user_data)
        
        # Ğ˜Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ ĞºÑÑˆ
        cache_key = f"user:{user_id}"
        self.cache.delete(cache_key)
```

#### Write-Through Pattern

```
â”Œâ”€â”€â”€ WRITE-THROUGH PATTERN â”€â”€â”€â”
â”‚                             â”‚
â”‚  Application                â”‚
â”‚       â”‚                    â”‚
â”‚       â”œâ”€1. Write to Cache  â”‚
â”‚       â”‚                    â”‚
â”‚   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”                â”‚
â”‚   â”‚ Cache â”‚                â”‚
â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜                â”‚
â”‚       â”‚                    â”‚
â”‚       â”œâ”€2. Write to DB     â”‚
â”‚       â”‚    (Synchronous)   â”‚
â”‚   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”                â”‚
â”‚   â”‚  DB   â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                             â”‚
â”‚  + Consistency              â”‚
â”‚  - Higher latency           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Write-Behind (Write-Back) Pattern

```
â”Œâ”€â”€â”€ WRITE-BEHIND PATTERN â”€â”€â”€â”
â”‚                            â”‚
â”‚  Application               â”‚
â”‚       â”‚                   â”‚
â”‚       â”œâ”€1. Write to Cache â”‚
â”‚       â”‚    (Fast response)â”‚
â”‚   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”               â”‚
â”‚   â”‚ Cache â”‚               â”‚
â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”˜               â”‚
â”‚       â”‚                   â”‚
â”‚       â”œâ”€2. Async write    â”‚
â”‚       â”‚    to DB later    â”‚
â”‚   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”               â”‚
â”‚   â”‚  DB   â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                           â”‚
â”‚  + Low latency            â”‚
â”‚  - Risk of data loss      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾Ğµ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ĞºÑÑˆĞ°:**

```
â”Œâ”€â”€â”€ DISTRIBUTED CACHE TOPOLOGY â”€â”€â”€â”
â”‚                                  â”‚
â”‚     App1    App2    App3         â”‚
â”‚       â”‚       â”‚       â”‚          â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚               â”‚                  â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚        â”‚ Load Balancerâ”‚           â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚               â”‚                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚         â”‚         â”‚        â”‚
â”‚ â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”    â”‚
â”‚ â”‚Redis-1â”‚ â”‚Redis-2â”‚ â”‚Redis-3â”‚    â”‚
â”‚ â”‚Master â”‚ â”‚Master â”‚ â”‚Master â”‚    â”‚
â”‚ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜    â”‚
â”‚     â”‚         â”‚         â”‚        â”‚
â”‚ â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”    â”‚
â”‚ â”‚Redis-1â”‚ â”‚Redis-2â”‚ â”‚Redis-3â”‚    â”‚
â”‚ â”‚Replicaâ”‚ â”‚Replicaâ”‚ â”‚Replicaâ”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:**

```
â”Œâ”€â”€â”€ DATA DISTRIBUTION STRATEGIES â”€â”€â”€â”
â”‚                                    â”‚
â”‚  ğŸ”„ Consistent Hashing             â”‚
â”‚  â”œâ”€â”€ Ğ Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ     â”‚
â”‚  â”œâ”€â”€ ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ       â”‚
â”‚  â””â”€â”€ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ/ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑƒĞ·Ğ»Ğ¾Ğ²     â”‚
â”‚                                    â”‚
â”‚  ğŸ“Š Hash Partitioning              â”‚
â”‚  â”œâ”€â”€ key % number_of_nodes         â”‚
â”‚  â”œâ”€â”€ ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ñ‚Ğ° Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸           â”‚
â”‚  â””â”€â”€ ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿Ñ€Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ ÑƒĞ·Ğ»Ğ¾Ğ²  â”‚
â”‚                                    â”‚
â”‚  ğŸ¯ Range Partitioning             â”‚
â”‚  â”œâ”€â”€ Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ°Ğ¼     â”‚
â”‚  â”œâ”€â”€ Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ…  â”‚
â”‚  â””â”€â”€ Ğ Ğ¸ÑĞº Ğ½ĞµÑ€Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´.  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.4 Ğ˜Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ ĞºÑÑˆĞ°

**Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸:**

```python
class CacheInvalidation:
    def __init__(self, cache_client):
        self.cache = cache_client
    
    # 1. TTL-based (Time To Live)
    def set_with_ttl(self, key: str, value: str, ttl: int):
        """ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¸ÑÑ‚ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ñ‡ĞµÑ€ĞµĞ· TTL"""
        self.cache.setex(key, ttl, value)
    
    # 2. Tag-based invalidation
    def set_with_tags(self, key: str, value: str, tags: list):
        """Ğ˜Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ñ‚ĞµĞ³Ğ°Ğ¼"""
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        self.cache.set(key, value)
        
        # Ğ¡Ğ²ÑĞ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ Ñ‚ĞµĞ³Ğ°Ğ¼Ğ¸
        for tag in tags:
            tag_key = f"tag:{tag}"
            self.cache.sadd(tag_key, key)
    
    def invalidate_by_tag(self, tag: str):
        """Ğ˜Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ÑĞµ ĞºĞ»ÑÑ‡Ğ¸ Ñ Ñ‚ĞµĞ³Ğ¾Ğ¼"""
        tag_key = f"tag:{tag}"
        keys = self.cache.smembers(tag_key)
        
        if keys:
            # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
            self.cache.delete(*keys)
            # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ñ‚ĞµĞ³
            self.cache.delete(tag_key)
    
    # 3. Event-driven invalidation
    def on_user_updated(self, user_id: int):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ"""
        patterns = [
            f"user:{user_id}",
            f"user:{user_id}:*",
            f"friends:{user_id}",
            f"timeline:{user_id}"
        ]
        
        for pattern in patterns:
            keys = self.cache.keys(pattern)
            if keys:
                self.cache.delete(*keys)
```

---

## âš¡ Ğ“Ğ»Ğ°Ğ²Ğ° 3: ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

### 3.1 ĞœĞ¾Ğ´ĞµĞ»Ğ¸ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸

```
â”Œâ”€â”€â”€ CONCURRENCY MODELS â”€â”€â”€â”
â”‚                          â”‚
â”‚  ğŸ§µ Threading            â”‚
â”‚  â”œâ”€â”€ Preemptive         â”‚
â”‚  â”œâ”€â”€ Shared memory      â”‚
â”‚  â””â”€â”€ Context switching  â”‚
â”‚                          â”‚
â”‚  ğŸ”„ Event Loop           â”‚
â”‚  â”œâ”€â”€ Single-threaded    â”‚
â”‚  â”œâ”€â”€ Non-blocking I/O   â”‚
â”‚  â””â”€â”€ Callback queue     â”‚
â”‚                          â”‚
â”‚  ğŸ­ Actor Model          â”‚
â”‚  â”œâ”€â”€ Message passing    â”‚
â”‚  â”œâ”€â”€ Isolated state     â”‚
â”‚  â””â”€â”€ Fault tolerance    â”‚
â”‚                          â”‚
â”‚  âš™ï¸ Coroutines           â”‚
â”‚  â”œâ”€â”€ Cooperative        â”‚
â”‚  â”œâ”€â”€ Lightweight        â”‚
â”‚  â””â”€â”€ No stack switching â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Event Loop Architecture

```
â”Œâ”€â”€â”€ EVENT LOOP CYCLE â”€â”€â”€â”
â”‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Call Stack     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ function()â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Event Loop      â”‚ â”‚
â”‚  â”‚                   â”‚ â”‚
â”‚  â”‚  1. Timer Phase   â”‚ â”‚
â”‚  â”‚  2. Pending I/O   â”‚ â”‚
â”‚  â”‚  3. Poll Phase    â”‚ â”‚
â”‚  â”‚  4. Check Phase   â”‚ â”‚
â”‚  â”‚  5. Close Phase   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Callback Queue   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚cb1  â”‚cb2  â”‚..â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 Async/Await Patterns

**Python asyncio Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€:**

```python
import asyncio
import aiohttp
import time
from typing import List

class AsyncHttpClient:
    def __init__(self):
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.session.close()
    
    async def fetch_url(self, url: str) -> dict:
        """ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ HTTP Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ"""
        try:
            async with self.session.get(url) as response:
                return {
                    'url': url,
                    'status': response.status,
                    'data': await response.text()
                }
        except Exception as e:
            return {
                'url': url,
                'error': str(e)
            }
    
    async def fetch_multiple(self, urls: List[str]) -> List[dict]:
        """ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹"""
        tasks = [self.fetch_url(url) for url in urls]
        return await asyncio.gather(*tasks, return_exceptions=True)

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
async def main():
    urls = [
        'https://httpbin.org/delay/1',
        'https://httpbin.org/delay/2',
        'https://httpbin.org/delay/3',
    ]
    
    async with AsyncHttpClient() as client:
        start_time = time.time()
        results = await client.fetch_multiple(urls)
        end_time = time.time()
        
        print(f"Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¾ Ğ·Ğ° {end_time - start_time:.2f} ÑĞµĞºÑƒĞ½Ğ´")
        # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: ~3 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ 6 (1+2+3)

# Ğ—Ğ°Ğ¿ÑƒÑĞº
asyncio.run(main())
```

### 3.4 ĞĞµĞ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒÑÑ‰Ğ¸Ğ¹ I/O

**Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒÑÑ‰ĞµĞ³Ğ¾ Ğ¸ Ğ½ĞµĞ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒÑÑ‰ĞµĞ³Ğ¾ I/O:**

```
â”Œâ”€â”€â”€ BLOCKING I/O â”€â”€â”€â”     â”Œâ”€â”€â”€ NON-BLOCKING I/O â”€â”€â”€â”
â”‚                    â”‚     â”‚                        â”‚
â”‚  Thread 1          â”‚     â”‚  Event Loop            â”‚
â”‚  â”œâ”€â”€ Request A     â”‚     â”‚  â”œâ”€â”€ Start Request A   â”‚
â”‚  â”‚   (wait...)    â”‚     â”‚  â”œâ”€â”€ Start Request B   â”‚
â”‚  â”‚   (wait...)    â”‚     â”‚  â”œâ”€â”€ Start Request C   â”‚
â”‚  â”‚   Response A   â”‚     â”‚  â”‚                      â”‚
â”‚  â”‚                â”‚     â”‚  â”œâ”€â”€ Response A ready  â”‚
â”‚  Thread 2          â”‚     â”‚  â”œâ”€â”€ Response C ready  â”‚
â”‚  â”œâ”€â”€ Request B     â”‚     â”‚  â”œâ”€â”€ Response B ready  â”‚
â”‚  â”‚   (wait...)    â”‚     â”‚  â”‚                      â”‚
â”‚  â”‚   Response B   â”‚     â”‚  â””â”€â”€ All completed     â”‚
â”‚  â”‚                â”‚     â”‚                        â”‚
â”‚  Thread 3          â”‚     â”‚  Single Thread!       â”‚
â”‚  â”œâ”€â”€ Request C     â”‚     â”‚                        â”‚
â”‚  â”‚   (wait...)    â”‚     â”‚                        â”‚
â”‚  â”‚   Response C   â”‚     â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.5 Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Concurrency

**ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°Ğ¼Ğ¸:**

```python
import asyncio
from asyncio import Semaphore, Queue
from typing import Callable, Any

class ConcurrencyManager:
    def __init__(self, max_concurrent: int = 10):
        self.semaphore = Semaphore(max_concurrent)
        self.results_queue = Queue()
    
    async def limited_task(self, coro: Callable, *args, **kwargs):
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ĞµĞ¼ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸"""
        async with self.semaphore:
            return await coro(*args, **kwargs)
    
    async def producer_consumer_pattern(self):
        """ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½ ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ-ĞŸĞ¾Ñ‚Ñ€ĞµĞ±Ğ¸Ñ‚ĞµĞ»ÑŒ"""
        
        async def producer(queue: Queue):
            """ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡"""
            for i in range(100):
                await queue.put(f"task_{i}")
                await asyncio.sleep(0.1)
            
            # Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ
            await queue.put(None)
        
        async def consumer(queue: Queue, consumer_id: int):
            """ĞŸĞ¾Ñ‚Ñ€ĞµĞ±Ğ¸Ñ‚ĞµĞ»ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡"""
            while True:
                task = await queue.get()
                if task is None:
                    # ĞŸĞµÑ€ĞµĞ´Ğ°ĞµĞ¼ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ¸Ñ‚ĞµĞ»ÑĞ¼
                    await queue.put(None)
                    break
                
                # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ
                print(f"Consumer {consumer_id} processing {task}")
                await asyncio.sleep(0.5)
                queue.task_done()
        
        # ĞÑ‡ĞµÑ€ĞµĞ´ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡
        task_queue = Queue(maxsize=20)
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ñ Ğ¸ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ¸Ñ‚ĞµĞ»ĞµĞ¹
        await asyncio.gather(
            producer(task_queue),
            *[consumer(task_queue, i) for i in range(3)]
        )

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
async def example_usage():
    manager = ConcurrencyManager(max_concurrent=5)
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‡
    async def heavy_task(task_id: int):
        print(f"Starting task {task_id}")
        await asyncio.sleep(1)
        return f"Result {task_id}"
    
    # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ
    tasks = [
        manager.limited_task(heavy_task, i) 
        for i in range(20)
    ]
    
    results = await asyncio.gather(*tasks)
    print(f"Completed {len(results)} tasks")
```

---

## ğŸ“ˆ Ğ“Ğ»Ğ°Ğ²Ğ° 4: ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼

### 4.1 Ğ¢Ğ¸Ğ¿Ñ‹ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

```
â”Œâ”€â”€â”€ SCALING STRATEGIES â”€â”€â”€â”
â”‚                          â”‚
â”‚  â¬†ï¸ Vertical Scaling     â”‚
â”‚  (Scale Up)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Single Server   â”‚    â”‚
â”‚  â”‚                 â”‚    â”‚
â”‚  â”‚ CPU: 2â†’8 cores  â”‚    â”‚
â”‚  â”‚ RAM: 8â†’32 GB    â”‚    â”‚
â”‚  â”‚ SSD: 256â†’1TB    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â”‚
â”‚  â¡ï¸ Horizontal Scaling   â”‚
â”‚  (Scale Out)             â”‚
â”‚  â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”â”‚
â”‚  â”‚S1 â”‚ â”‚S2 â”‚ â”‚S3 â”‚ â”‚S4 â”‚â”‚
â”‚  â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜â”‚
â”‚    Load Balanced         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ²:**

| ĞÑĞ¿ĞµĞºÑ‚ | Vertical Scaling | Horizontal Scaling |
|--------|------------------|-------------------|
| **Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ** | ĞĞ¸Ğ·ĞºĞ°Ñ | Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ |
| **Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ** | Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ (ÑĞºÑĞ¿Ğ¾Ğ½ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ¾ÑÑ‚) | Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ğ°Ñ |
| **ĞÑ‚ĞºĞ°Ğ·Ğ¾ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ** | Single Point of Failure | Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ°Ñ |
| **Ğ›Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹** | Ğ¤Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ | Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ±ĞµĞ·Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ½Ğ¾Ğµ |
| **Ğ’Ñ€ĞµĞ¼Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ñ** | Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ğ°Ğ¿Ğ³Ñ€ĞµĞ¹Ğ´Ğ° | Rolling updates |

### 4.2 Load Balancing ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸

```
â”Œâ”€â”€â”€ LOAD BALANCING ALGORITHMS â”€â”€â”€â”
â”‚                                 â”‚
â”‚  ğŸ”„ Round Robin                 â”‚
â”‚  Request 1 â†’ Server 1           â”‚
â”‚  Request 2 â†’ Server 2           â”‚
â”‚  Request 3 â†’ Server 3           â”‚
â”‚  Request 4 â†’ Server 1 (cycle)   â”‚
â”‚                                 â”‚
â”‚  âš–ï¸ Weighted Round Robin        â”‚
â”‚  S1 (weight=3): 60% requests    â”‚
â”‚  S2 (weight=2): 40% requests    â”‚
â”‚                                 â”‚
â”‚  ğŸ“Š Least Connections           â”‚
â”‚  Route to server with fewest    â”‚
â”‚  active connections             â”‚
â”‚                                 â”‚
â”‚  ğŸ¯ IP Hash                     â”‚
â”‚  hash(client_ip) % server_count â”‚
â”‚  Sticky sessions                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Load Balancer:**

```
â”Œâ”€â”€â”€ MULTI-LAYER LOAD BALANCING â”€â”€â”€â”
â”‚                                  â”‚
â”‚          ğŸŒ Internet             â”‚
â”‚               â”‚                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚   DNS Load Balancer â”‚       â”‚
â”‚    â”‚   (Geographic)      â”‚       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚               â”‚                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚  L4 Load Balancer   â”‚       â”‚
â”‚    â”‚  (TCP/IP Layer)     â”‚       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚              â”‚ â”‚                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚  L7 Load Balancer   â”‚       â”‚
â”‚    â”‚  (Application Layer)â”‚       â”‚
â”‚    â””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜       â”‚
â”‚      â”‚                 â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”         â”Œâ”€â”€â”€â–¼â”€â”€â”€â”     â”‚
â”‚  â”‚App    â”‚   ...   â”‚App    â”‚     â”‚
â”‚  â”‚Server â”‚         â”‚Server â”‚     â”‚
â”‚  â”‚  1    â”‚         â”‚  N    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ³Ğ¾ Load Balancer:**

```python
import asyncio
import random
from typing import List, Dict
from dataclasses import dataclass
from enum import Enum

class LBAlgorithm(Enum):
    ROUND_ROBIN = "round_robin"
    LEAST_CONNECTIONS = "least_connections"
    WEIGHTED_ROUND_ROBIN = "weighted_round_robin"

@dataclass
class Server:
    host: str
    port: int
    weight: int = 1
    active_connections: int = 0
    is_healthy: bool = True

class LoadBalancer:
    def __init__(self, algorithm: LBAlgorithm = LBAlgorithm.ROUND_ROBIN):
        self.servers: List[Server] = []
        self.algorithm = algorithm
        self.current_index = 0
        self.weighted_index = 0
    
    def add_server(self, server: Server):
        self.servers.append(server)
    
    def get_next_server(self) -> Server:
        healthy_servers = [s for s in self.servers if s.is_healthy]
        
        if not healthy_servers:
            raise Exception("No healthy servers available")
        
        if self.algorithm == LBAlgorithm.ROUND_ROBIN:
            return self._round_robin(healthy_servers)
        elif self.algorithm == LBAlgorithm.LEAST_CONNECTIONS:
            return self._least_connections(healthy_servers)
        elif self.algorithm == LBAlgorithm.WEIGHTED_ROUND_ROBIN:
            return self._weighted_round_robin(healthy_servers)
    
    def _round_robin(self, servers: List[Server]) -> Server:
        server = servers[self.current_index % len(servers)]
        self.current_index += 1
        return server
    
    def _least_connections(self, servers: List[Server]) -> Server:
        return min(servers, key=lambda s: s.active_connections)
    
    def _weighted_round_robin(self, servers: List[Server]) -> Server:
        # ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ weighted round robin
        weighted_servers = []
        for server in servers:
            weighted_servers.extend([server] * server.weight)
        
        server = weighted_servers[self.weighted_index % len(weighted_servers)]
        self.weighted_index += 1
        return server
    
    async def health_check(self):
        """ĞŸĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ ÑĞµÑ€Ğ²ĞµÑ€Ğ¾Ğ²"""
        while True:
            for server in self.servers:
                try:
                    # ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸
                    reader, writer = await asyncio.wait_for(
                        asyncio.open_connection(server.host, server.port),
                        timeout=5.0
                    )
                    writer.close()
                    await writer.wait_closed()
                    server.is_healthy = True
                except:
                    server.is_healthy = False
            
            await asyncio.sleep(30)  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 30 ÑĞµĞºÑƒĞ½Ğ´
```

### 4.3 Database Sharding Ğ¸ Partitioning

**Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ ÑˆĞ°Ñ€Ğ´Ğ¸Ğ½Ğ³Ğ°:**

```
â”Œâ”€â”€â”€ SHARDING STRATEGIES â”€â”€â”€â”
â”‚                           â”‚
â”‚  ğŸ”¢ Range-based Sharding  â”‚
â”‚  Shard 1: user_id 1-1000  â”‚
â”‚  Shard 2: user_id 1001-2000â”‚
â”‚  Shard 3: user_id 2001-3000â”‚
â”‚                           â”‚
â”‚  #ï¸âƒ£ Hash-based Sharding   â”‚
â”‚  hash(user_id) % 3        â”‚
â”‚  Ğ Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ â”‚
â”‚                           â”‚
â”‚  ğŸ“Š Directory-based       â”‚
â”‚  Lookup service Ğ·Ğ½Ğ°ĞµÑ‚     â”‚
â”‚  Ğ³Ğ´Ğµ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑÑ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ key â”‚
â”‚                           â”‚
â”‚  ğŸŒ Geographic Sharding   â”‚
â”‚  US East, US West, Europe â”‚
â”‚  Ğ‘Ğ»Ğ¸Ğ·Ğ¾ÑÑ‚ÑŒ Ğº Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° ÑˆĞ°Ñ€Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ‘Ğ”:**

```
â”Œâ”€â”€â”€ SHARDED DATABASE ARCHITECTURE â”€â”€â”€â”
â”‚                                     â”‚
â”‚           Application               â”‚
â”‚               â”‚                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚    Shard Router     â”‚          â”‚
â”‚    â”‚  (Query Coordinator)â”‚          â”‚
â”‚    â””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜        â”‚
â”‚      â”‚         â”‚         â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”      â”‚
â”‚  â”‚Shard 1â”‚ â”‚Shard 2â”‚ â”‚Shard 3â”‚      â”‚
â”‚  â”‚       â”‚ â”‚       â”‚ â”‚       â”‚      â”‚
â”‚  â”‚Users  â”‚ â”‚Users  â”‚ â”‚Users  â”‚      â”‚
â”‚  â”‚1-1000 â”‚ â”‚1001-  â”‚ â”‚2001-  â”‚      â”‚
â”‚  â”‚       â”‚ â”‚2000   â”‚ â”‚3000   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚        Challenges           â”‚    â”‚
â”‚  â”‚ â€¢ Cross-shard queries       â”‚    â”‚
â”‚  â”‚ â€¢ Rebalancing shards        â”‚    â”‚
â”‚  â”‚ â€¢ Distributed transactions  â”‚    â”‚
â”‚  â”‚ â€¢ Hotspot avoidance         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Shard Router:**

```python
import hashlib
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class ShardConfig:
    shard_id: str
    connection_string: str
    weight: float = 1.0
    is_active: bool = True

class ShardRouter:
    def __init__(self):
        self.shards: Dict[str, ShardConfig] = {}
        self.hash_ring: List[tuple] = []  # (hash_value, shard_id)
        self.virtual_nodes = 150  # Ğ’Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑƒĞ·Ğ»Ñ‹ Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ
    
    def add_shard(self, shard: ShardConfig):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ğ´Ğ°"""
        self.shards[shard.shard_id] = shard
        self._rebuild_hash_ring()
    
    def remove_shard(self, shard_id: str):
        """Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑˆĞ°Ñ€Ğ´Ğ°"""
        if shard_id in self.shards:
            del self.shards[shard_id]
            self._rebuild_hash_ring()
    
    def _rebuild_hash_ring(self):
        """ĞŸĞµÑ€ĞµÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ»ÑŒÑ†Ğ° Ñ…ÑÑˆĞµĞ¹ (Consistent Hashing)"""
        self.hash_ring = []
        
        for shard_id in self.shards:
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑƒĞ·Ğ»Ñ‹ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ğ´Ğ°
            for i in range(self.virtual_nodes):
                virtual_key = f"{shard_id}:{i}"
                hash_value = int(hashlib.md5(virtual_key.encode()).hexdigest(), 16)
                self.hash_ring.append((hash_value, shard_id))
        
        # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ñ…ÑÑˆ-Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
        self.hash_ring.sort()
    
    def get_shard_for_key(self, key: str) -> Optional[ShardConfig]:
        """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑˆĞ°Ñ€Ğ´Ğ° Ğ´Ğ»Ñ ĞºĞ»ÑÑ‡Ğ°"""
        if not self.hash_ring:
            return None
        
        # Ğ¥ÑÑˆĞ¸Ñ€ÑƒĞµĞ¼ ĞºĞ»ÑÑ‡
        key_hash = int(hashlib.md5(str(key).encode()).hexdigest(), 16)
        
        # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ±Ğ»Ğ¸Ğ¶Ğ°Ğ¹ÑˆĞ¸Ğ¹ ÑƒĞ·ĞµĞ» Ğ² ĞºĞ¾Ğ»ÑŒÑ†Ğµ
        for hash_value, shard_id in self.hash_ring:
            if key_hash <= hash_value:
                return self.shards.get(shard_id)
        
        # Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°ÑˆĞ»Ğ¸, Ğ±ĞµÑ€ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ (ĞºĞ¾Ğ»ÑŒÑ†Ğ¾ Ğ·Ğ°Ğ¼Ñ‹ĞºĞ°ĞµÑ‚ÑÑ)
        return self.shards.get(self.hash_ring[0][1])
    
    def route_query(self, user_id: int, query: str) -> Dict[str, Any]:
        """ĞœĞ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğº Ğ½ÑƒĞ¶Ğ½Ğ¾Ğ¼Ñƒ ÑˆĞ°Ñ€Ğ´Ñƒ"""
        shard = self.get_shard_for_key(user_id)
        
        if not shard or not shard.is_active:
            raise Exception(f"No active shard found for user_id: {user_id}")
        
        return {
            'shard_id': shard.shard_id,
            'connection': shard.connection_string,
            'query': query
        }
    
    def get_shards_for_broadcast(self) -> List[ShardConfig]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ²ÑĞµÑ… Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ÑˆĞ°Ñ€Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ broadcast Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²"""
        return [shard for shard in self.shards.values() if shard.is_active]

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
router = ShardRouter()

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑˆĞ°Ñ€Ğ´Ñ‹
router.add_shard(ShardConfig("shard_1", "postgresql://db1:5432/users"))
router.add_shard(ShardConfig("shard_2", "postgresql://db2:5432/users"))
router.add_shard(ShardConfig("shard_3", "postgresql://db3:5432/users"))

# ĞœĞ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
user_id = 12345
route_info = router.route_query(user_id, "SELECT * FROM users WHERE id = ?")
print(f"Query for user {user_id} goes to {route_info['shard_id']}")
```

### 4.4 CAP Ñ‚ĞµĞ¾Ñ€ĞµĞ¼Ğ° Ğ¸ Eventual Consistency

```
â”Œâ”€â”€â”€ CAP THEOREM â”€â”€â”€â”
â”‚                   â”‚
â”‚  C - Consistency  â”‚
â”‚  â”‚               â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”    â”‚
â”‚  â””â”€â”€â”€â”€â”¤ CAP â”œâ”€â”€â”€â”€â”˜
â”‚       â””â”€â”¬â”€â”€â”€â”˜     
â”‚         â”‚         
â”‚  A - Availability â”‚
â”‚         â”‚         
â”‚         â”‚         
â”‚  P - Partition    â”‚
â”‚      Tolerance    â”‚
â”‚                   â”‚
â”‚  Choose any 2!    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ ĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸:**

| Ğ¢Ğ¸Ğ¿ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ | ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ | ĞŸĞ»ÑÑÑ‹ | ĞœĞ¸Ğ½ÑƒÑÑ‹ |
|-----|----------|---------|-------|--------|
| **Strong Consistency** | Ğ’ÑĞµ ÑƒĞ·Ğ»Ñ‹ Ğ²Ğ¸Ğ´ÑÑ‚ Ğ¾Ğ´Ğ½Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ | RDBMS, Zookeeper | ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ñ‚Ğ° | Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° |
| **Eventual Consistency** | Ğ£Ğ·Ğ»Ñ‹ ÑĞ¾Ğ¹Ğ´ÑƒÑ‚ÑÑ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ | DNS, Amazon S3 | Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ | Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¸ |
| **Weak Consistency** | ĞĞ¸ĞºĞ°ĞºĞ¸Ñ… Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ğ¹ | Memcached | ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ | ĞŸĞ¾Ñ‚ĞµÑ€Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… |
| **Causal Consistency** | ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ½Ğ¾-ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ | Social Media | Ğ˜Ğ½Ñ‚ÑƒĞ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ | Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ°Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ |

---

## ğŸ“Š Ğ“Ğ»Ğ°Ğ²Ğ° 5: ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

### 5.1 Batch vs Stream Processing

```
â”Œâ”€â”€â”€ DATA PROCESSING PARADIGMS â”€â”€â”€â”
â”‚                                 â”‚
â”‚  ğŸ“¦ Batch Processing            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Input Data              â”‚    â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚ â”‚ 1 â”‚ 2 â”‚ 3 â”‚ 4 â”‚ 5 â”‚   â”‚    â”‚
â”‚  â”‚ â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â”‚           â”‚             â”‚    â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”‚    â”‚
â”‚  â”‚    â”‚  Process    â”‚      â”‚    â”‚
â”‚  â”‚    â”‚  All Data   â”‚      â”‚    â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚
â”‚  â”‚           â”‚             â”‚    â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”‚    â”‚
â”‚  â”‚    â”‚   Output    â”‚      â”‚    â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                 â”‚
â”‚  ğŸŒŠ Stream Processing           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Input Stream            â”‚    â”‚
â”‚  â”‚ â”€â”€â†’1â”€â”€â†’2â”€â”€â†’3â”€â”€â†’4â”€â”€â†’5â”€â”€â†’ â”‚    â”‚
â”‚  â”‚     â”‚   â”‚   â”‚   â”‚   â”‚   â”‚    â”‚
â”‚  â”‚     â–¼   â–¼   â–¼   â–¼   â–¼   â”‚    â”‚
â”‚  â”‚  [Process each event]   â”‚    â”‚
â”‚  â”‚     â”‚   â”‚   â”‚   â”‚   â”‚   â”‚    â”‚
â”‚  â”‚     â–¼   â–¼   â–¼   â–¼   â–¼   â”‚    â”‚
â”‚  â”‚ â”€â”€â†’1'â”€â†’2'â”€â†’3'â”€â†’4'â”€â†’5'â”€â†’â”‚    â”‚
â”‚  â”‚ Output Stream           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 MapReduce Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ğ°

**ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ MapReduce:**

```
â”Œâ”€â”€â”€ MAPREDUCE WORKFLOW â”€â”€â”€â”
â”‚                          â”‚
â”‚  ğŸ“„ Input Data           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ File 1: [a,b,c] â”‚     â”‚
â”‚  â”‚ File 2: [d,e,f] â”‚     â”‚
â”‚  â”‚ File 3: [g,h,i] â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   MAP PHASE       â”‚   â”‚
â”‚  â”‚                   â”‚   â”‚
â”‚  â”‚ Mapper1â†’[(a,1)]   â”‚   â”‚
â”‚  â”‚ Mapper2â†’[(d,1)]   â”‚   â”‚
â”‚  â”‚ Mapper3â†’[(g,1)]   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  SHUFFLE & SORT   â”‚   â”‚
â”‚  â”‚                   â”‚   â”‚
â”‚  â”‚ Group by key      â”‚   â”‚
â”‚  â”‚ [(a,[1,1,1])]     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  REDUCE PHASE     â”‚   â”‚
â”‚  â”‚                   â”‚   â”‚
â”‚  â”‚ Reducerâ†’[(a,3)]   â”‚   â”‚
â”‚  â”‚ Output: counts    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ³Ğ¾ MapReduce:**

```python
from collections import defaultdict
from typing import List, Tuple, Callable, Any
import multiprocessing as mp
from functools import reduce

class MapReduceFramework:
    def __init__(self, num_workers: int = None):
        self.num_workers = num_workers or mp.cpu_count()
    
    def map_reduce(self, 
                   data: List[Any],
                   map_func: Callable,
                   reduce_func: Callable,
                   partition_func: Callable = None) -> dict:
        """
        Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ MapReduce Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
        """
        # MAP PHASE
        with mp.Pool(self.num_workers) as pool:
            map_results = pool.map(map_func, data)
        
        # Flatten Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°
        flattened = []
        for result in map_results:
            if isinstance(result, list):
                flattened.extend(result)
            else:
                flattened.append(result)
        
        # SHUFFLE & SORT PHASE
        grouped = defaultdict(list)
        for key, value in flattened:
            grouped[key].append(value)
        
        # REDUCE PHASE
        final_results = {}
        for key, values in grouped.items():
            final_results[key] = reduce_func(values)
        
        return final_results

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: Ğ¿Ğ¾Ğ´ÑÑ‡ĞµÑ‚ ÑĞ»Ğ¾Ğ² Ğ² Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ…
def word_count_mapper(document: str) -> List[Tuple[str, int]]:
    """Map Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´ÑÑ‡ĞµÑ‚Ğ° ÑĞ»Ğ¾Ğ²"""
    words = document.lower().split()
    return [(word, 1) for word in words]

def word_count_reducer(counts: List[int]) -> int:
    """Reduce Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ÑÑƒĞ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
    return sum(counts)

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
documents = [
    "hello world hello",
    "world of data processing",
    "hello data world"
]

framework = MapReduceFramework()
word_counts = framework.map_reduce(
    documents,
    word_count_mapper,
    word_count_reducer
)

print(word_counts)
# {'hello': 3, 'world': 3, 'of': 1, 'data': 2, 'processing': 1}
```

### 5.3 Data Pipeline Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹

**Lambda Architecture:**

```
â”Œâ”€â”€â”€ LAMBDA ARCHITECTURE â”€â”€â”€â”
â”‚                           â”‚
â”‚     ğŸ“¥ Data Sources       â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”   â”‚
â”‚     â”‚API  â”‚Logs â”‚IoT  â”‚   â”‚
â”‚     â””â”€â”€â”¬â”€â”€â”´â”€â”€â”¬â”€â”€â”´â”€â”€â”¬â”€â”€â”˜   â”‚
â”‚        â”‚     â”‚     â”‚      â”‚
â”‚        â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜      â”‚
â”‚              â”‚            â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚   Message Queue   â”‚  â”‚
â”‚    â”‚   (Kafka/Kinesis) â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â”‚
â”‚          â”‚         â”‚      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  â”‚
â”‚  â”‚ Batch   â”‚   â”‚Stream â”‚  â”‚
â”‚  â”‚ Layer   â”‚   â”‚Layer  â”‚  â”‚
â”‚  â”‚         â”‚   â”‚       â”‚  â”‚
â”‚  â”‚ HDFS/S3 â”‚   â”‚Storm/ â”‚  â”‚
â”‚  â”‚ +Spark  â”‚   â”‚Kafka  â”‚  â”‚
â”‚  â”‚         â”‚   â”‚Streamsâ”‚  â”‚
â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â”‚
â”‚      â”‚             â”‚      â”‚
â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚            â”‚              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚    â”‚ Serving Layer â”‚      â”‚
â”‚    â”‚   (NoSQL DB)  â”‚      â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Kappa Architecture (ÑƒĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ½Ğ°Ñ):**

```
â”Œâ”€â”€â”€ KAPPA ARCHITECTURE â”€â”€â”€â”
â”‚                          â”‚
â”‚     ğŸ“¥ Data Sources      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”  â”‚
â”‚     â”‚API  â”‚Logs â”‚IoT  â”‚  â”‚
â”‚     â””â”€â”€â”¬â”€â”€â”´â”€â”€â”¬â”€â”€â”´â”€â”€â”¬â”€â”€â”˜  â”‚
â”‚        â”‚     â”‚     â”‚     â”‚
â”‚        â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜     â”‚
â”‚              â”‚           â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚   Stream Processorâ”‚ â”‚
â”‚    â”‚   (Kafka Streams/ â”‚ â”‚
â”‚    â”‚    Apache Flink)  â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚              â”‚           â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚ Serving Layer     â”‚ â”‚
â”‚    â”‚ â€¢ Real-time views â”‚ â”‚
â”‚    â”‚ â€¢ Historical data â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚
â”‚  + ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ñ‚Ğ°              â”‚
â”‚  + Ğ•Ğ´Ğ¸Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ´            â”‚
â”‚  - Reprocessing ÑĞ»Ğ¾Ğ¶Ğ½ĞµĞµ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.4 Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ³Ğ¾ Stream Processor

```python
import asyncio
import json
from typing import Dict, List, Callable, Any
from collections import deque, defaultdict
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class StreamEvent:
    key: str
    value: Any
    timestamp: datetime
    partition: int = 0

class WindowedAggregator:
    """ĞĞ³Ñ€ĞµĞ³Ğ°Ñ‚Ğ¾Ñ€ Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¾ĞºĞ½Ğ°Ğ¼Ğ¸"""
    
    def __init__(self, window_size: timedelta, slide_interval: timedelta):
        self.window_size = window_size
        self.slide_interval = slide_interval
        self.windows: Dict[str, deque] = defaultdict(deque)
        self.aggregates: Dict[str, Any] = {}
    
    def add_event(self, event: StreamEvent):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ Ğ² Ğ¾ĞºĞ½Ğ°"""
        key = event.key
        self.windows[key].append(event)
        
        # Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ€Ñ‹Ñ… ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹
        cutoff_time = event.timestamp - self.window_size
        while (self.windows[key] and 
               self.windows[key][0].timestamp < cutoff_time):
            self.windows[key].popleft()
    
    def get_window_aggregate(self, key: str, agg_func: Callable) -> Any:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¾ĞºĞ½Ğ°"""
        if key not in self.windows:
            return None
        
        values = [event.value for event in self.windows[key]]
        return agg_func(values) if values else None

class StreamProcessor:
    """ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
    
    def __init__(self):
        self.processors: List[Callable] = []
        self.aggregators: Dict[str, WindowedAggregator] = {}
        self.state: Dict[str, Any] = {}
    
    def add_processor(self, func: Callable):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"""
        self.processors.append(func)
    
    def add_aggregator(self, name: str, aggregator: WindowedAggregator):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ‚Ğ¾Ñ€Ğ°"""
        self.aggregators[name] = aggregator
    
    async def process_stream(self, events: List[StreamEvent]):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹"""
        for event in events:
            # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ²ÑĞµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ñ‹
            processed_event = event
            for processor in self.processors:
                processed_event = await self._apply_processor(
                    processor, processed_event
                )
            
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ‚Ğ¾Ñ€Ñ‹
            for agg in self.aggregators.values():
                agg.add_event(processed_event)
            
            # Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
            await self._emit_results(processed_event)
    
    async def _apply_processor(self, processor: Callable, event: StreamEvent) -> StreamEvent:
        """ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ° Ğº ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ"""
        if asyncio.iscoroutinefunction(processor):
            return await processor(event)
        else:
            return processor(event)
    
    async def _emit_results(self, event: StreamEvent):
        """Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"""
        # ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ² Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹, Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ñ‚.Ğ´.
        print(f"Processed: {event.key} = {event.value} at {event.timestamp}")

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
async def main():
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€
    processor = StreamProcessor()
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸
    def filter_processor(event: StreamEvent) -> StreamEvent:
        if isinstance(event.value, (int, float)) and event.value > 0:
            return event
        return None
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸
    async def transform_processor(event: StreamEvent) -> StreamEvent:
        if event and isinstance(event.value, (int, float)):
            event.value = event.value * 2  # Ğ£Ğ¼Ğ½Ğ¾Ğ¶Ğ°ĞµĞ¼ Ğ½Ğ° 2
        return event
    
    processor.add_processor(filter_processor)
    processor.add_processor(transform_processor)
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ»ÑŒĞ·ÑÑ‰ĞµĞ³Ğ¾ Ğ¾ĞºĞ½Ğ°
    window_agg = WindowedAggregator(
        window_size=timedelta(minutes=5),
        slide_interval=timedelta(minutes=1)
    )
    processor.add_aggregator("sliding_window", window_agg)
    
    # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğµ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ
    events = []
    base_time = datetime.now()
    
    for i in range(10):
        event = StreamEvent(
            key=f"sensor_{i % 3}",
            value=i * 10,
            timestamp=base_time + timedelta(seconds=i * 30)
        )
        events.append(event)
    
    # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾Ñ‚Ğ¾Ğº
    await processor.process_stream(events)
    
    # Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ‚Ñ‹
    for sensor_id in ["sensor_0", "sensor_1", "sensor_2"]:
        avg_value = window_agg.get_window_aggregate(
            sensor_id, 
            lambda values: sum(values) / len(values)
        )
        print(f"Average for {sensor_id}: {avg_value}")

# Ğ—Ğ°Ğ¿ÑƒÑĞº
asyncio.run(main())
```

---

## ğŸ“ˆ Ğ“Ğ»Ğ°Ğ²Ğ° 6: ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¸ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµĞ¼Ğ¾ÑÑ‚ÑŒ

### 6.1 Ğ¢Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ»Ğ¿Ğ° Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµĞ¼Ğ¾ÑÑ‚Ğ¸

```
â”Œâ”€â”€â”€ THREE PILLARS OF OBSERVABILITY â”€â”€â”€â”
â”‚                                      â”‚
â”‚  ğŸ“Š METRICS                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ Ğ§Ğ¸ÑĞ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸      â”‚     â”‚
â”‚  â”‚ â€¢ Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ñ€ÑĞ´Ñ‹            â”‚     â”‚
â”‚  â”‚ â€¢ ĞĞ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ     â”‚     â”‚
â”‚  â”‚                             â”‚     â”‚
â”‚  â”‚ Examples:                   â”‚     â”‚
â”‚  â”‚ - Response time: 200ms      â”‚     â”‚
â”‚  â”‚ - Error rate: 0.1%          â”‚     â”‚
â”‚  â”‚ - CPU usage: 75%            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                      â”‚
â”‚  ğŸ“ LOGS                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸  â”‚     â”‚
â”‚  â”‚ â€¢ Ğ¡Ğ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ        â”‚     â”‚
â”‚  â”‚ â€¢ ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ    â”‚     â”‚
â”‚  â”‚                             â”‚     â”‚
â”‚  â”‚ Examples:                   â”‚     â”‚
â”‚  â”‚ - Error messages            â”‚     â”‚
â”‚  â”‚ - User actions              â”‚     â”‚
â”‚  â”‚ - System events             â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                      â”‚
â”‚  ğŸ” TRACES                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ ĞŸÑƒÑ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ñ‡ĞµÑ€ĞµĞ· ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒâ”‚     â”‚
â”‚  â”‚ â€¢ Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñ‹     â”‚     â”‚
â”‚  â”‚ â€¢ ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ½Ğ¾-ÑĞ»ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ ÑĞ²ÑĞ·Ğ¸â”‚     â”‚
â”‚  â”‚                             â”‚     â”‚
â”‚  â”‚ Examples:                   â”‚     â”‚
â”‚  â”‚ - Request flow              â”‚     â”‚
â”‚  â”‚ - Service dependencies      â”‚     â”‚
â”‚  â”‚ - Performance bottlenecks   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¸ Ğ¸Ñ… Ñ‚Ğ¸Ğ¿Ñ‹

**ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:**

| Ğ¢Ğ¸Ğ¿ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ | ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ | ĞšĞ¾Ğ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ |
|-------------|----------|---------|-------------------|
| **Counter** | Ğ’ÑĞµĞ³Ğ´Ğ° ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ | HTTP requests, errors | ĞŸĞ¾Ğ´ÑÑ‡ĞµÑ‚ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹ |
| **Gauge** | ĞœĞ¾Ğ¶ĞµÑ‚ Ñ€Ğ°ÑÑ‚Ğ¸/Ğ¿Ğ°Ğ´Ğ°Ñ‚ÑŒ | CPU usage, memory | Ğ¢ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ |
| **Histogram** | Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹ | Response times | ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ |
| **Summary** | ĞšĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ»Ğ¸ Ğ·Ğ° Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´ | 95th percentile latency | ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ |

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:**

```python
import time
import threading
from typing import Dict, List, Optional
from collections import defaultdict, deque
from dataclasses import dataclass
from datetime import datetime
import statistics

@dataclass
class MetricSample:
    value: float
    timestamp: float
    labels: Dict[str, str] = None

class MetricRegistry:
    """Ğ ĞµĞµÑÑ‚Ñ€ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ"""
    
    def __init__(self):
        self._metrics: Dict[str, 'BaseMetric'] = {}
        self._lock = threading.Lock()
    
    def counter(self, name: str, help_text: str = "") -> 'Counter':
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ/Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‡ĞµÑ‚Ñ‡Ğ¸ĞºĞ°"""
        return self._get_or_create(name, Counter, help_text)
    
    def gauge(self, name: str, help_text: str = "") -> 'Gauge':
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ/Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°"""
        return self._get_or_create(name, Gauge, help_text)
    
    def histogram(self, name: str, buckets: List[float] = None, help_text: str = "") -> 'Histogram':
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ/Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ³Ğ¸ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹"""
        buckets = buckets or [0.1, 0.5, 1.0, 2.5, 5.0, 10.0]
        return self._get_or_create(name, Histogram, help_text, buckets=buckets)
    
    def _get_or_create(self, name: str, metric_class, help_text: str, **kwargs):
        with self._lock:
            if name not in self._metrics:
                self._metrics[name] = metric_class(name, help_text, **kwargs)
            return self._metrics[name]
    
    def collect_all(self) -> Dict[str, List[MetricSample]]:
        """Ğ¡Ğ±Ğ¾Ñ€ Ğ²ÑĞµÑ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº"""
        result = {}
        with self._lock:
            for name, metric in self._metrics.items():
                result[name] = metric.collect()
        return result

class BaseMetric:
    def __init__(self, name: str, help_text: str):
        self.name = name
        self.help_text = help_text
        self._lock = threading.Lock()
    
    def collect(self) -> List[MetricSample]:
        raise NotImplementedError

class Counter(BaseMetric):
    """Ğ¡Ñ‡ĞµÑ‚Ñ‡Ğ¸Ğº - Ğ²ÑĞµĞ³Ğ´Ğ° ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ"""
    
    def __init__(self, name: str, help_text: str):
        super().__init__(name, help_text)
        self._value = 0.0
    
    def inc(self, amount: float = 1.0, labels: Dict[str, str] = None):
        """Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ ÑÑ‡ĞµÑ‚Ñ‡Ğ¸ĞºĞ°"""
        if amount < 0:
            raise ValueError("Counter can only increase")
        
        with self._lock:
            self._value += amount
    
    def collect(self) -> List[MetricSample]:
        with self._lock:
            return [MetricSample(self._value, time.time())]

class Gauge(BaseMetric):
    """Ğ˜Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ - Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ¸ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°Ñ‚ÑŒÑÑ"""
    
    def __init__(self, name: str, help_text: str):
        super().__init__(name, help_text)
        self._value = 0.0
    
    def set(self, value: float, labels: Dict[str, str] = None):
        """Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ"""
        with self._lock:
            self._value = value
    
    def inc(self, amount: float = 1.0):
        """Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ"""
        with self._lock:
            self._value += amount
    
    def dec(self, amount: float = 1.0):
        """Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞµĞ½Ğ¸Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ"""
        with self._lock:
            self._value -= amount
    
    def collect(self) -> List[MetricSample]:
        with self._lock:
            return [MetricSample(self._value, time.time())]

class Histogram(BaseMetric):
    """Ğ“Ğ¸ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹"""
    
    def __init__(self, name: str, help_text: str, buckets: List[float]):
        super().__init__(name, help_text)
        self.buckets = sorted(buckets)
        self._bucket_counts = [0] * len(buckets)
        self._count = 0
        self._sum = 0.0
        self._samples = deque(maxlen=1000)  # ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 1000 Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ²
    
    def observe(self, value: float, labels: Dict[str, str] = None):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ñ"""
        with self._lock:
            self._count += 1
            self._sum += value
            self._samples.append(value)
            
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ bucket'Ñ‹
            for i, bucket_limit in enumerate(self.buckets):
                if value <= bucket_limit:
                    self._bucket_counts[i] += 1
    
    def collect(self) -> List[MetricSample]:
        with self._lock:
            samples = []
            timestamp = time.time()
            
            # Bucket counts
            for i, (bucket_limit, count) in enumerate(zip(self.buckets, self._bucket_counts)):
                samples.append(MetricSample(
                    count, 
                    timestamp, 
                    {"le": str(bucket_limit)}
                ))
            
            # Total count and sum
            samples.append(MetricSample(self._count, timestamp, {"type": "count"}))
            samples.append(MetricSample(self._sum, timestamp, {"type": "sum"}))
            
            # Percentiles
            if self._samples:
                sorted_samples = sorted(self._samples)
                p50 = statistics.median(sorted_samples)
                p95 = sorted_samples[int(0.95 * len(sorted_samples))]
                p99 = sorted_samples[int(0.99 * len(sorted_samples))]
                
                samples.extend([
                    MetricSample(p50, timestamp, {"quantile": "0.5"}),
                    MetricSample(p95, timestamp, {"quantile": "0.95"}),
                    MetricSample(p99, timestamp, {"quantile": "0.99"})
                ])
            
            return samples

# Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞµÑÑ‚Ñ€ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
METRICS = MetricRegistry()

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
class MetricsExample:
    def __init__(self):
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        self.request_count = METRICS.counter(
            "http_requests_total", 
            "Total HTTP requests"
        )
        self.active_users = METRICS.gauge(
            "active_users_current",
            "Currently active users"
        )
        self.response_time = METRICS.histogram(
            "http_request_duration_seconds",
            "HTTP request duration in seconds",
            buckets=[0.1, 0.5, 1.0, 2.5, 5.0]
        )
    
    def handle_request(self, path: str):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° HTTP Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸"""
        start_time = time.time()
        
        try:
            # Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ ÑÑ‡ĞµÑ‚Ñ‡Ğ¸Ğº Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
            self.request_count.inc()
            
            # Ğ˜Ğ¼Ğ¸Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ
            time.sleep(0.1)
            
            # Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
            duration = time.time() - start_time
            self.response_time.observe(duration)
            
        except Exception as e:
            # ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
            error_counter = METRICS.counter("http_errors_total")
            error_counter.inc()
            raise
    
    def user_login(self):
        """ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ·Ğ°Ğ»Ğ¾Ğ³Ğ¸Ğ½Ğ¸Ğ»ÑÑ"""
        self.active_users.inc()
    
    def user_logout(self):
        """ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ñ€Ğ°Ğ·Ğ»Ğ¾Ğ³Ğ¸Ğ½Ğ¸Ğ»ÑÑ"""
        self.active_users.dec()
```

### 6.3 Structured Logging

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:**

```
â”Œâ”€â”€â”€ LOGGING ARCHITECTURE â”€â”€â”€â”
â”‚                            â”‚
â”‚  Application               â”‚
â”‚       â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Logger  â”‚              â”‚
â”‚  â”‚ (JSON)  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â”‚
â”‚       â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Agent   â”‚              â”‚
â”‚  â”‚(Fluentd/â”‚              â”‚
â”‚  â”‚Filebeat)â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â”‚
â”‚       â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Message â”‚              â”‚
â”‚  â”‚ Queue   â”‚              â”‚
â”‚  â”‚(Kafka)  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â”‚
â”‚       â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”              â”‚
â”‚  â”‚Log Storeâ”‚              â”‚
â”‚  â”‚(ELK/    â”‚              â”‚
â”‚  â”‚ Loki)   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ³ĞµÑ€Ğ°:**

```python
import json
import logging
import time
from typing import Dict, Any, Optional
from datetime import datetime
import traceback
import uuid
from contextvars import ContextVar

# ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ´Ğ»Ñ trace ID
trace_id_var: ContextVar[Optional[str]] = ContextVar('trace_id', default=None)

class StructuredLogger:
    """Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ»Ğ¾Ğ³Ğ³ĞµÑ€ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ JSON"""
    
    def __init__(self, name: str, level: int = logging.INFO):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ JSON formatter
        handler = logging.StreamHandler()
        handler.setFormatter(JsonFormatter())
        self.logger.addHandler(handler)
        
        self.base_context = {
            "service": "myapp",
            "version": "1.0.0"
        }
    
    def _create_log_entry(self, level: str, message: str, **kwargs) -> Dict[str, Any]:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ»Ğ¾Ğ³Ğ°"""
        entry = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": level,
            "message": message,
            "trace_id": trace_id_var.get(),
            **self.base_context,
            **kwargs
        }
        
        # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ None Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
        return {k: v for k, v in entry.items() if v is not None}
    
    def info(self, message: str, **kwargs):
        entry = self._create_log_entry("INFO", message, **kwargs)
        self.logger.info(json.dumps(entry))
    
    def warning(self, message: str, **kwargs):
        entry = self._create_log_entry("WARNING", message, **kwargs)
        self.logger.warning(json.dumps(entry))
    
    def error(self, message: str, error: Exception = None, **kwargs):
        entry = self._create_log_entry("ERROR", message, **kwargs)
        
        if error:
            entry.update({
                "error_type": type(error).__name__,
                "error_message": str(error),
                "stack_trace": traceback.format_exc()
            })
        
        self.logger.error(json.dumps(entry))
    
    def debug(self, message: str, **kwargs):
        entry = self._create_log_entry("DEBUG", message, **kwargs)
        self.logger.debug(json.dumps(entry))

class JsonFormatter(logging.Formatter):
    """JSON Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‚ĞµÑ€ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğ³Ğ¾ logging"""
    
    def format(self, record):
        # Ğ•ÑĞ»Ğ¸ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ ÑƒĞ¶Ğµ JSON, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ
        try:
            json.loads(record.getMessage())
            return record.getMessage()
        except:
            # Ğ•ÑĞ»Ğ¸ Ğ½Ğµ JSON, ÑĞ¾Ğ·Ğ´Ğ°ĞµĞ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ
            log_entry = {
                "timestamp": datetime.fromtimestamp(record.created).isoformat(),
                "level": record.levelname,
                "message": record.getMessage(),
                "module": record.module,
                "function": record.funcName,
                "line": record.lineno
            }
            
            if record.exc_info:
                log_entry["stack_trace"] = self.formatException(record.exc_info)
            
            return json.dumps(log_entry)

class RequestTracker:
    """Ğ¢Ñ€ĞµĞºĞµÑ€ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼"""
    
    def __init__(self, logger: StructuredLogger):
        self.logger = logger
    
    def __enter__(self):
        # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ trace ID
        self.trace_id = str(uuid.uuid4())
        trace_id_var.set(self.trace_id)
        
        self.start_time = time.time()
        self.logger.info("Request started", trace_id=self.trace_id)
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        duration = time.time() - self.start_time
        
        if exc_type:
            self.logger.error(
                "Request failed",
                duration_ms=duration * 1000,
                error_type=exc_type.__name__,
                trace_id=self.trace_id
            )
        else:
            self.logger.info(
                "Request completed",
                duration_ms=duration * 1000,
                trace_id=self.trace_id
            )
        
        trace_id_var.set(None)

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
logger = StructuredLogger("web_service")

def handle_user_request(user_id: int, action: str):
    """ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼"""
    with RequestTracker(logger):
        try:
            logger.info(
                "Processing user action",
                user_id=user_id,
                action=action,
                ip_address="192.168.1.100"
            )
            
            # Ğ˜Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹
            if action == "error":
                raise ValueError("Something went wrong")
            
            logger.info(
                "Action completed successfully",
                user_id=user_id,
                action=action
            )
            
        except Exception as e:
            logger.error("Failed to process action", error=e, user_id=user_id)
            raise

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
handle_user_request(12345, "login")
```

### 6.4 Distributed Tracing

**ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ‚Ñ€ĞµĞ¹ÑĞ¸Ğ½Ğ³Ğ°:**

```
â”Œâ”€â”€â”€ DISTRIBUTED TRACE â”€â”€â”€â”
â”‚                         â”‚
â”‚  Frontend               â”‚
â”‚      â”‚ GET /api/user    â”‚
â”‚      â”‚ Span A           â”‚
â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
â”‚            â”‚            â”‚
â”‚  API Gateway            â”‚
â”‚      â”‚ Span B           â”‚
â”‚      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      â”‚ /auth/validate   â”‚
â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
â”‚            â”‚            â”‚
â”‚  Auth Service           â”‚
â”‚      â”‚ Span C           â”‚
â”‚      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      â”‚ /users/profile   â”‚
â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
â”‚            â”‚            â”‚
â”‚  User Service           â”‚
â”‚      â”‚ Span D           â”‚
â”‚      â”œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      â”‚ DB Query         â”‚
â”‚      â”‚ Span E           â”‚
â”‚      â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         â”‚
â”‚  Trace = Aâ†’Bâ†’Câ†’Dâ†’E      â”‚
â”‚  Parent-Child relations â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ³Ğ¾ Ñ‚Ñ€ĞµĞ¹ÑĞµÑ€Ğ°:**

```python
import time
import uuid
from typing import Dict, Optional, List
from dataclasses import dataclass, field
from contextvars import ContextVar
from datetime import datetime

@dataclass
class Span:
    """Span Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¾Ğ´Ğ½Ñƒ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ² trace"""
    trace_id: str
    span_id: str
    parent_span_id: Optional[str]
    operation_name: str
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None
    tags: Dict[str, str] = field(default_factory=dict)
    logs: List[Dict] = field(default_factory=list)
    
    @property
    def duration_ms(self) -> Optional[float]:
        if self.end_time:
            return (self.end_time - self.start_time) * 1000
        return None
    
    def set_tag(self, key: str, value: str):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞ³Ğ° Ğº span'Ñƒ"""
        self.tags[key] = value
    
    def log(self, message: str, **kwargs):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ»Ğ¾Ğ³-Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğº span'Ñƒ"""
        log_entry = {
            "timestamp": time.time(),
            "message": message,
            **kwargs
        }
        self.logs.append(log_entry)
    
    def finish(self):
        """Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ span'Ğ°"""
        self.end_time = time.time()

# ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ trace/span
current_trace_id: ContextVar[Optional[str]] = ContextVar('trace_id', default=None)
current_span: ContextVar[Optional[Span]] = ContextVar('span', default=None)

class Tracer:
    """ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ distributed tracer"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
        self.spans: List[Span] = []
    
    def start_trace(self, operation_name: str) -> Span:
        """ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ trace"""
        trace_id = str(uuid.uuid4())
        span_id = str(uuid.uuid4())
        
        span = Span(
            trace_id=trace_id,
            span_id=span_id,
            parent_span_id=None,
            operation_name=operation_name
        )
        
        span.set_tag("service.name", self.service_name)
        
        current_trace_id.set(trace_id)
        current_span.set(span)
        
        self.spans.append(span)
        return span
    
    def start_span(self, operation_name: str, parent_span: Optional[Span] = None) -> Span:
        """ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ span Ğ² Ñ€Ğ°Ğ¼ĞºĞ°Ñ… ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ³Ğ¾ trace"""
        trace_id = current_trace_id.get()
        parent = parent_span or current_span.get()
        
        if not trace_id:
            return self.start_trace(operation_name)
        
        span_id = str(uuid.uuid4())
        parent_span_id = parent.span_id if parent else None
        
        span = Span(
            trace_id=trace_id,
            span_id=span_id,
            parent_span_id=parent_span_id,
            operation_name=operation_name
        )
        
        span.set_tag("service.name", self.service_name)
        
        current_span.set(span)
        self.spans.append(span)
        return span
    
    def get_trace_context(self) -> Dict[str, str]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ğ¼Ğ¸"""
        span = current_span.get()
        if span:
            return {
                "trace-id": span.trace_id,
                "span-id": span.span_id
            }
        return {}
    
    def inject_context(self, trace_id: str, parent_span_id: str):
        """Ğ’Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸Ğ· Ğ²Ğ½ĞµÑˆĞ½ĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°"""
        current_trace_id.set(trace_id)
        # ĞœĞ¾Ğ¶Ğ½Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ dummy span Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°
    
    def finish_span(self, span: Optional[Span] = None):
        """Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ span'Ğ°"""
        target_span = span or current_span.get()
        if target_span:
            target_span.finish()
    
    def export_traces(self) -> List[Dict]:
        """Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ²ÑĞµÑ… traces Ğ² JSON Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ"""
        traces = {}
        
        # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ spans Ğ¿Ğ¾ trace_id
        for span in self.spans:
            if span.trace_id not in traces:
                traces[span.trace_id] = []
            
            traces[span.trace_id].append({
                "span_id": span.span_id,
                "parent_span_id": span.parent_span_id,
                "operation_name": span.operation_name,
                "start_time": span.start_time,
                "end_time": span.end_time,
                "duration_ms": span.duration_ms,
                "tags": span.tags,
                "logs": span.logs
            })
        
        return [{"trace_id": tid, "spans": spans} for tid, spans in traces.items()]

class TracedOperation:
    """ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ‚Ñ€ĞµĞ¹ÑĞ¸Ğ½Ğ³Ğ°"""
    
    def __init__(self, tracer: Tracer, operation_name: str, **tags):
        self.tracer = tracer
        self.operation_name = operation_name
        self.tags = tags
        self.span = None
    
    def __enter__(self):
        self.span = self.tracer.start_span(self.operation_name)
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚ĞµĞ³Ğ¸
        for key, value in self.tags.items():
            self.span.set_tag(key, str(value))
        
        return self.span
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.span.set_tag("error", "true")
            self.span.set_tag("error.type", exc_type.__name__)
            self.span.log("error", message=str(exc_val))
        
        self.tracer.finish_span(self.span)

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
tracer = Tracer("user-service")

def get_user_profile(user_id: int):
    """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ñ Ñ‚Ñ€ĞµĞ¹ÑĞ¸Ğ½Ğ³Ğ¾Ğ¼"""
    
    # ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ span
    with TracedOperation(tracer, "get_user_profile", user_id=user_id) as span:
        span.log("Starting user profile retrieval")
        
        # Span Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ĞºÑÑˆĞ°
        with TracedOperation(tracer, "cache_lookup") as cache_span:
            cache_span.set_tag("cache.key", f"user:{user_id}")
            # Ğ˜Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ĞºÑÑˆĞ°
            time.sleep(0.01)
            cache_hit = False
            cache_span.set_tag("cache.hit", str(cache_hit).lower())
        
        if not cache_hit:
            # Span Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğº Ğ‘Ğ”
            with TracedOperation(tracer, "database_query") as db_span:
                db_span.set_tag("db.type", "postgresql")
                db_span.set_tag("db.statement", "SELECT * FROM users WHERE id = ?")
                
                # Ğ˜Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğº Ğ‘Ğ”
                time.sleep(0.05)
                db_span.log("Query executed successfully")
        
        span.log("User profile retrieved successfully")
        return {"user_id": user_id, "name": "John Doe"}

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
def simulate_request():
    """Ğ˜Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°"""
    
    # ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ trace
    with TracedOperation(tracer, "handle_user_request") as root_span:
        root_span.set_tag("http.method", "GET")
        root_span.set_tag("http.url", "/api/users/123")
        
        # Ğ’Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ»Ğ¾Ğ³Ğ¸ĞºÑƒ
        user = get_user_profile(123)
        
        root_span.set_tag("http.status_code", "200")
        root_span.log("Request completed successfully")

# Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
simulate_request()

# Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ traces
traces = tracer.export_traces()
print(json.dumps(traces, indent=2))
```

### 6.5 SLI/SLO/SLA Framework

**ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸:**

```
â”Œâ”€â”€â”€ RELIABILITY PYRAMID â”€â”€â”€â”
â”‚                           â”‚
â”‚        ğŸ“‹ SLA             â”‚
â”‚   Service Level Agreement â”‚
â”‚   (External commitment)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ "99.9% uptime"      â”‚  â”‚
â”‚  â”‚ "< 200ms response"  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚            â–²              â”‚
â”‚        ğŸ“Š SLO             â”‚
â”‚  Service Level Objective  â”‚
â”‚   (Internal target)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ "99.95% success"    â”‚  â”‚
â”‚  â”‚ "95th % < 150ms"    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚            â–²              â”‚
â”‚        ğŸ“ˆ SLI             â”‚
â”‚  Service Level Indicator  â”‚
â”‚    (Measurement)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Success rate        â”‚  â”‚
â”‚  â”‚ Response time       â”‚  â”‚
â”‚  â”‚ Error budget        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ SLI/SLO Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°:**

```python
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from collections import deque, defaultdict
from datetime import datetime, timedelta
import statistics

@dataclass
class SLIConfig:
    """ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Service Level Indicator"""
    name: str
    metric_name: str
    good_threshold: Optional[float] = None
    bad_threshold: Optional[float] = None
    is_latency_metric: bool = False

@dataclass
class SLOConfig:
    """ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Service Level Objective"""
    name: str
    sli_name: str
    target_percentage: float  # 99.9
    window_days: int = 30

class SLITracker:
    """Ğ¢Ñ€ĞµĞºĞµÑ€ Ğ´Ğ»Ñ Service Level Indicators"""
    
    def __init__(self):
        self.measurements: Dict[str, deque] = defaultdict(lambda: deque(maxlen=10000))
        self.configs: Dict[str, SLIConfig] = {}
    
    def register_sli(self, config: SLIConfig):
        """Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ SLI"""
        self.configs[config.name] = config
    
    def record_measurement(self, sli_name: str, value: float, timestamp: Optional[float] = None):
        """Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ"""
        if timestamp is None:
            timestamp = time.time()
        
        self.measurements[sli_name].append({
            'value': value,
            'timestamp': timestamp
        })
    
    def calculate_sli(self, sli_name: str, window_minutes: int = 60) -> Optional[float]:
        """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ SLI Ğ·Ğ° ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´"""
        if sli_name not in self.configs:
            return None
        
        config = self.configs[sli_name]
        measurements = self.measurements[sli_name]
        
        if not measurements:
            return None
        
        # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
        cutoff_time = time.time() - (window_minutes * 60)
        recent_measurements = [
            m for m in measurements 
            if m['timestamp'] >= cutoff_time
        ]
        
        if not recent_measurements:
            return None
        
        values = [m['value'] for m in recent_measurements]
        
        if config.is_latency_metric:
            # Ğ”Ğ»Ñ Ğ»Ğ°Ñ‚ĞµĞ½ÑĞ¸ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ğ¸Ğ»ÑŒ
            return statistics.quantile(values, 0.95) if values else None
        else:
            # Ğ”Ğ»Ñ availability ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
            if config.good_threshold is not None:
                good_count = sum(1 for v in values if v >= config.good_threshold)
            elif config.bad_threshold is not None:
                good_count = sum(1 for v in values if v < config.bad_threshold)
            else:
                good_count = sum(1 for v in values if v > 0)
            
            return (good_count / len(values)) * 100 if values else 0

class SLOMonitor:
    """ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€ Service Level Objectives"""
    
    def __init__(self, sli_tracker: SLITracker):
        self.sli_tracker = sli_tracker
        self.slos: Dict[str, SLOConfig] = {}
        self.error_budgets: Dict[str, float] = {}
    
    def register_slo(self, config: SLOConfig):
        """Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ SLO"""
        self.slos[config.name] = config
        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ error budget (100% - target%)
        self.error_budgets[config.name] = 100.0 - config.target_percentage
    
    def check_slo_compliance(self, slo_name: str) -> Dict[str, float]:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ñ SLO"""
        if slo_name not in self.slos:
            return {}
        
        slo = self.slos[slo_name]
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ SLI
        current_sli = self.sli_tracker.calculate_sli(slo.sli_name)
        
        if current_sli is None:
            return {"status": "no_data"}
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ğº error budget
        if current_sli >= slo.target_percentage:
            compliance_status = "compliant"
            error_budget_used = 0.0
        else:
            compliance_status = "breach"
            error_budget_used = slo.target_percentage - current_sli
        
        error_budget_remaining = self.error_budgets[slo_name] - error_budget_used
        
        return {
            "status": compliance_status,
            "current_sli": current_sli,
            "target_slo": slo.target_percentage,
            "error_budget_used": error_budget_used,
            "error_budget_remaining": error_budget_remaining,
            "error_budget_usage_percent": (error_budget_used / self.error_budgets[slo_name]) * 100
        }
    
    def get_error_budget_burn_rate(self, slo_name: str, window_hours: int = 1) -> float:
        """Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ ÑĞ¶Ğ¸Ğ³Ğ°Ğ½Ğ¸Ñ error budget"""
        if slo_name not in self.slos:
            return 0.0
        
        # Ğ£Ğ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ - Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ historical data
        compliance = self.check_slo_compliance(slo_name)
        if compliance.get("status") == "breach":
            # Ğ•ÑĞ»Ğ¸ SLO Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½, ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ ÑĞ¶Ğ¸Ğ³Ğ°Ğ½Ğ¸Ñ
            return compliance.get("error_budget_used", 0.0) / window_hours
        
        return 0.0

class ReliabilityDashboard:
    """Dashboard Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸"""
    
    def __init__(self, sli_tracker: SLITracker, slo_monitor: SLOMonitor):
        self.sli_tracker = sli_tracker
        self.slo_monitor = slo_monitor
    
    def generate_report(self) -> Dict:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ¾ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "slis": {},
            "slos": {},
            "alerts": []
        }
        
        # SLI Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        for sli_name in self.sli_tracker.configs:
            report["slis"][sli_name] = {
                "current_value": self.sli_tracker.calculate_sli(sli_name),
                "1h_value": self.sli_tracker.calculate_sli(sli_name, 60),
                "24h_value": self.sli_tracker.calculate_sli(sli_name, 1440)
            }
        
        # SLO Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        for slo_name in self.slo_monitor.slos:
            compliance = self.slo_monitor.check_slo_compliance(slo_name)
            burn_rate = self.slo_monitor.get_error_budget_burn_rate(slo_name)
            
            report["slos"][slo_name] = {
                **compliance,
                "error_budget_burn_rate": burn_rate
            }
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ°Ğ»ĞµÑ€Ñ‚Ğ¾Ğ²
            if compliance.get("status") == "breach":
                report["alerts"].append({
                    "type": "slo_breach",
                    "slo": slo_name,
                    "severity": "high",
                    "message": f"SLO {slo_name} breached: {compliance.get('current_sli', 0):.2f}% < {compliance.get('target_slo', 0):.2f}%"
                })
            
            # ĞĞ»ĞµÑ€Ñ‚ Ğ¾ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ¼ ÑĞ¶Ğ¸Ğ³Ğ°Ğ½Ğ¸Ğ¸ error budget
            error_budget_usage = compliance.get("error_budget_usage_percent", 0)
            if error_budget_usage > 50:
                report["alerts"].append({
                    "type": "error_budget_burn",
                    "slo": slo_name,
                    "severity": "medium",
                    "message": f"High error budget usage: {error_budget_usage:.1f}%"
                })
        
        return report

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
def main():
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ‚Ñ€ĞµĞºĞµÑ€ Ğ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€
    sli_tracker = SLITracker()
    slo_monitor = SLOMonitor(sli_tracker)
    dashboard = ReliabilityDashboard(sli_tracker, slo_monitor)
    
    # Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ SLI
    sli_tracker.register_sli(SLIConfig(
        name="api_availability",
        metric_name="http_success_rate",
        good_threshold=200,  # HTTP status < 400
        bad_threshold=400
    ))
    
    sli_tracker.register_sli(SLIConfig(
        name="api_latency",
        metric_name="response_time_95p",
        is_latency_metric=True
    ))
    
    # Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ SLO
    slo_monitor.register_slo(SLOConfig(
        name="api_availability_slo",
        sli_name="api_availability",
        target_percentage=99.9,
        window_days=30
    ))
    
    slo_monitor.register_slo(SLOConfig(
        name="api_latency_slo",
        sli_name="api_latency",
        target_percentage=95.0,  # 95% Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² < threshold
        window_days=30
    ))
    
    # Ğ˜Ğ¼Ğ¸Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ
    import random
    for i in range(1000):
        # Availability measurements (HTTP status codes)
        status_code = 200 if random.random() > 0.005 else 500  # 99.5% success rate
        sli_tracker.record_measurement("api_availability", status_code)
        
        # Latency measurements (response time in ms)
        latency = random.lognormvariate(4.0, 0.5)  # ~55ms median, some outliers
        sli_tracker.record_measurement("api_latency", latency)
        
        time.sleep(0.001)  # ĞĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ°Ñ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ°
    
    # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ñ‚Ñ‡ĞµÑ‚
    report = dashboard.generate_report()
    print(json.dumps(report, indent=2))

if __name__ == "__main__":
    main()
```

---

## ğŸ¯ ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ

### Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 1: ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ

```python
# Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ
def slow_function(data_list):
    result = []
    for i in range(len(data_list)):
        for j in range(len(data_list)):
            if i != j and data_list[i] == data_list[j]:
                result.append(data_list[i])
    return list(set(result))

# Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:
# 1. ĞŸÑ€Ğ¾Ğ²ĞµÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
# 2. ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ ÑƒĞ·ĞºĞ¸Ğµ Ğ¼ĞµÑÑ‚Ğ°
# 3. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ
# 4. Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ
```

### Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 2: ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

```python
# Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ¾Ğµ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
class UserService:
    def get_user_by_id(self, user_id: int):
        # ĞœĞµĞ´Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº Ğ‘Ğ”
        time.sleep(0.1)  
        return {"id": user_id, "name": f"User{user_id}"}
    
    def get_user_friends(self, user_id: int):
        # ĞÑ‡ĞµĞ½ÑŒ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
        time.sleep(0.5)  
        return [f"friend_{i}" for i in range(5)]

# Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:
# 1. Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ L1 ĞºÑÑˆ (in-memory)
# 2. Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ L2 ĞºÑÑˆ (Redis)
# 3. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ cache-aside pattern
# 4. Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ TTL Ğ¸ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ
```

### Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 3: ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

```python
# Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: ÑĞ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Ğ´Ğ»Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
class ChatService:
    def send_message(self, from_user: int, to_user: int, message: str):
        pass
    
    def get_chat_history(self, user1: int, user2: int):
        pass
    
    def get_user_chats(self, user_id: int):
        pass

# Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:
# 1. ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° 1M+ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹
# 2. Ğ“Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
# 3. Ğ¨Ğ°Ñ€Ğ´Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑĞ¼
# 4. Load balancing ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ
# 5. ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… Ñ‡Ğ°Ñ‚Ğ¾Ğ²
```

---

## ğŸ“š Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµÑÑƒÑ€ÑÑ‹

### ĞšĞ½Ğ¸Ğ³Ğ¸
- **"Designing Data-Intensive Applications"** - Martin Kleppmann
- **"High Performance MySQL"** - Baron Schwartz
- **"Building Microservices"** - Sam Newman
- **"Site Reliability Engineering"** - Google SRE Team

### Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹
- **ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:** JProfiler, py-spy, perf, Chrome DevTools
- **ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³:** Prometheus, Grafana, ELK Stack, Jaeger
- **ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:** Redis, Memcached, Hazelcast, Apache Ignite
- **Load Testing:** JMeter, Artillery, k6, Gatling

### ĞĞ½Ğ»Ğ°Ğ¹Ğ½ Ñ€ĞµÑÑƒÑ€ÑÑ‹
- High Scalability (highscalability.com)
- Engineering blogs: Netflix, Uber, Airbnb, GitHub
- SRE Resources (sre.google)
- Performance testing guides

---

## âœ… Ğ§ĞµĞº-Ğ»Ğ¸ÑÑ‚ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°

ĞŸĞ¾ÑĞ»Ğµ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ»Ğ¾ĞºĞ° Ğ²Ñ‹ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ ÑƒĞ¼ĞµÑ‚ÑŒ:

**ğŸ“Š ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:**
- [ ] ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑŒ bottlenecks
- [ ] Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹ Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
- [ ] ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ memory usage Ğ¸ CPU utilization
- [ ] Ğ˜Ğ·Ğ¼ĞµÑ€ÑÑ‚ÑŒ Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸

**ğŸ’¾ ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:**
- [ ] ĞŸÑ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
- [ ] Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ cache patterns
- [ ] Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾Ğµ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
- [ ] Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹ ĞºÑÑˆĞ°

**âš¡ ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ:**
- [ ] ĞŸÑ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµĞ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒÑÑ‰Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹
- [ ] Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ async/await patterns
- [ ] Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ concurrency Ğ¸ parallelism
- [ ] Ğ˜Ğ·Ğ±ĞµĞ³Ğ°Ñ‚ÑŒ race conditions Ğ¸ deadlocks

**ğŸ“ˆ ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:**
- [ ] Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²ĞµÑ€Ñ‚Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¸ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
- [ ] ĞŸÑ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ load balancing ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸
- [ ] Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ñ‹Ğ²Ğ°Ñ‚ÑŒ database sharding
- [ ] ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ CAP Ñ‚ĞµĞ¾Ñ€ĞµĞ¼Ñƒ Ğ¸ consistency models

**ğŸ“Š Ğ‘Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:**
- [ ] Ğ Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ°Ñ‚ÑŒ batch Ğ¸ stream processing
- [ ] ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒ MapReduce Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ñƒ
- [ ] ĞŸÑ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ data pipelines
- [ ] Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ Lambda Ğ¸ Kappa Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°Ğ¼Ğ¸

**ğŸ” ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³:**
- [ ] Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸, Ğ»Ğ¾Ğ³Ğ¸ Ğ¸ Ñ‚Ñ€ĞµĞ¹ÑÑ‹
- [ ] ĞŸÑ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ observability ÑĞ¸ÑÑ‚ĞµĞ¼
- [ ] ĞĞ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°Ñ‚ÑŒ distributed tracing
- [ ] ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑÑ‚ÑŒ Ğ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ‚ÑŒ SLI/SLO/SLA

**Ğ’Ñ€ĞµĞ¼Ñ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ:** 5-6 Ğ½ĞµĞ´ĞµĞ»ÑŒ Ğ¿Ñ€Ğ¸ 15-20 Ñ‡Ğ°ÑĞ°Ñ… Ğ² Ğ½ĞµĞ´ĞµĞ»Ñ  
**Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚:** Ğ’Ñ‹ÑĞ¾ĞºĞ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼