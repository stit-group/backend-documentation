# System Design: Блок 3 - Надежность и отказоустойчивость

**Продолжительность:** 3-4 недели  
**Цель:** Создавать системы, которые работают стабильно в условиях сбоев  
**Временные затраты:** 8-10 часов в неделю

---

## 📋 Содержание блока

1. [Неделя 11-12: Теория надежности](#неделя-11-12-теория-надежности)
2. [Неделя 13: Backup и Recovery](#неделя-13-backup-и-recovery)
3. [Неделя 14: Распределенная консистентность](#неделя-14-распределенная-консистентность)
4. [Контрольные задания](#контрольные-задания-блока-3)

---

## Неделя 11-12: Теория надежности

### Глава 3.1: CAP теорема и компромиссы консистентности

**Время:** 3 часа теории + 2 часа практики

#### 🎯 Цели обучения
- Понять фундаментальные ограничения распределенных систем
- Научиться делать осознанный выбор между консистентностью и доступностью
- Применять CAP теорему при проектировании архитектуры

#### 📖 Теоретическая часть

**CAP теорема** - одна из самых важных концепций в распределенных системах. Она утверждает, что в любой распределенной системе можно гарантировать только два из трех свойств:

```
┌─────────────────────────────────────────┐
│              CAP ТЕОРЕМА                │
├─────────────────────────────────────────┤
│                                         │
│    C - Consistency (Консистентность)    │
│    A - Availability (Доступность)       │
│    P - Partition Tolerance (Устойчи-    │
│        вость к разделению сети)         │
│                                         │
│  В условиях сетевого разделения можно   │
│  выбрать только: CA, CP или AP          │
└─────────────────────────────────────────┘
```

#### 🔍 Детальный разбор свойств

**1. Consistency (Консистентность)**
```
        Клиент 1 ──┐
                   ├──► [Запись X=5] ──► Узел A ═══ Узел B
        Клиент 2 ──┘                              ║
                                                  ║
        Клиент 3 ────────► [Чтение X] ────────► Узел C
                                                  ║
        Результат: X=5 (гарантированно последнее значение)
```

Все узлы видят одни и те же данные в одно и то же время.

**2. Availability (Доступность)**
```
        Запрос ──► Узел A (РАБОТАЕТ) ──► Ответ ✓
        Запрос ──► Узел B (ОТКАЗАЛ)  ──► Ответ ✓ (от другого узла)
        Запрос ──► Узел C (РАБОТАЕТ) ──► Ответ ✓
        
        Гарантия: система всегда отвечает на запросы
```

Система остается операционной и отвечает на запросы.

**3. Partition Tolerance (Устойчивость к разделению)**
```
        Дата-центр 1          |   СЕТЕВОЙ   |    Дата-центр 2
                             |   РАЗРЫВ    |
        ┌─────────────┐      |             |    ┌─────────────┐
        │   Узел A    │◄─────┼─────────────┼────┤   Узел B    │
        │             │      |             |    │             │
        └─────────────┘      |             |    └─────────────┘
                             |             |
        Система продолжает работать в обеих частях
```

Система продолжает функционировать при сетевых разделениях.

#### 🎭 CAP в реальном мире

**CP системы (жертвуют доступностью)**
```
Банковская система:
┌──────────────────────────────────────┐
│ Запрос: Перевод $1000                │
├──────────────────────────────────────┤
│ Узел A: Баланс = $500               │
│ Узел B: Недоступен (сеть разорвана) │
├──────────────────────────────────────┤
│ Решение: ОТКЛОНИТЬ операцию          │
│ Причина: Нельзя гарантировать        │
│          консистентность             │
└──────────────────────────────────────┘
```

**AP системы (жертвуют консистентностью)**
```
Социальная сеть:
┌──────────────────────────────────────┐
│ Действие: Лайк поста                 │
├──────────────────────────────────────┤
│ Узел A: Показывает 100 лайков        │
│ Узел B: Показывает 99 лайков         │
├──────────────────────────────────────┤
│ Решение: ПРИНЯТЬ обе версии          │
│ Причина: Временная несогласованность │
│          лучше недоступности         │
└──────────────────────────────────────┘
```

#### 📊 Сравнение подходов: ACID vs BASE

**ACID (Традиционные БД)**
```
──────────────────────────────────────
A - Atomicity     | Все или ничего
C - Consistency   | Данные всегда валидны
I - Isolation     | Транзакции изолированы
D - Durability    | Изменения сохраняются
──────────────────────────────────────
Пример: PostgreSQL, MySQL
```

**BASE (Распределенные системы)**
```
──────────────────────────────────────
BA - Basically Available    | Система доступна
S  - Soft state             | Состояние может меняться
E  - Eventual consistency   | Консистентность со временем
──────────────────────────────────────
Пример: Cassandra, DynamoDB
```

#### 🏗️ Практические примеры выбора

**1. Amazon DynamoDB (AP система)**
```
Сценарий: Пользователь добавляет товар в корзину
┌─────────────────────────────────────────────────────┐
│                СЕТЕВОЕ РАЗДЕЛЕНИЕ                   │
├─────────────────────┬───────────────────────────────┤
│    Регион US-East   │        Регион EU-West         │
│                     │                               │
│  Корзина: [A, B, C] │     Корзина: [A, B]          │
│  Действие: +D       │     Действие: +E              │
│  Результат: [A,B,C,D]│    Результат: [A,B,E]        │
└─────────────────────┴───────────────────────────────┘
│                                                     │
│  После восстановления связи:                        │
│  Итоговая корзина: [A, B, C, D, E]                 │
│  (Merge стратегия)                                  │
└─────────────────────────────────────────────────────┘
```

**2. Банковская система (CP система)**
```
Сценарий: Снятие денег с банкомата
┌─────────────────────────────────────────────────────┐
│                СЕТЕВОЕ РАЗДЕЛЕНИЕ                   │
├─────────────────────┬───────────────────────────────┤
│   Банкомат в Москве │    Центральная БД в СПб       │
│                     │                               │
│  Запрос: Снять 5000₽│    Баланс: 10000₽            │
│  Статус связи: ❌   │    Статус: Недоступен         │
│  Решение: ОТКАЗАТЬ  │                               │
└─────────────────────┴───────────────────────────────┘
│                                                     │
│  Результат: Операция заблокирована до               │
│             восстановления связи                    │
└─────────────────────────────────────────────────────┘
```

#### 🔄 Eventual Consistency модели

**1. Strong Eventual Consistency**
```
Время ──────────────────────────────────►
     
Узел A: [X=1] ──► [X=2] ──► [X=3] ──► [X=3]
Узел B: [X=1] ──► [X=1] ──► [X=2] ──► [X=3]
Узел C: [X=1] ──► [X=1] ──► [X=1] ──► [X=3]
                           
                     Точка конвергенции ▲
```

**2. Causal Consistency**
```
Операции с причинно-следственной связью выполняются в порядке:

Пользователь A: Создает пост    ──► Редактирует пост
                     │                    │
                     ▼                    ▼
Пользователь B: Видит пост      ──► Видит изменения
```

#### 💡 Практическое задание 3.1

**Задача:** Спроектируйте CAP стратегию для следующих систем:

1. **Онлайн-игра (MMO)**
   - Требования: Низкая задержка, множество игроков
   - Ваш выбор: ___________
   - Обоснование: ___________

2. **Система медицинских записей**
   - Требования: Точность данных, жизненно важная информация
   - Ваш выбор: ___________
   - Обоснование: ___________

3. **CDN для статического контента**
   - Требования: Глобальное распределение, быстрая доставка
   - Ваш выбор: ___________
   - Обоснование: ___________

---

### Глава 3.2: Паттерны отказоустойчивости

**Время:** 3 часа теории + 3 часа практики

#### 🎯 Цели обучения
- Изучить основные паттерны для обработки сбоев
- Реализовать Circuit Breaker и Retry логику
- Понять принципы изоляции ресурсов

#### 🛡️ Circuit Breaker Pattern

Один из самых важных паттернов для предотвращения каскадных сбоев.

```
                    CIRCUIT BREAKER STATES
    ┌─────────────────────────────────────────────────────────┐
    │                                                         │
    │    CLOSED                OPEN               HALF-OPEN   │
    │   ┌─────────┐           ┌─────────┐        ┌─────────┐  │
    │   │ Запросы │──────────►│ Запросы │        │ Пробные │  │
    │   │проходят │           │блокируются       │запросы  │  │
    │   │         │           │         │        │         │  │
    │   └─────────┘           └─────────┘        └─────────┘  │
    │        │                     ▲                  │       │
    │        │                     │                  │       │
    │        │ Сбои превысили       │                  │       │
    │        │ пороговое значение   │ Таймаут истек    │       │
    │        ▼                     │                  ▼       │
    │   ┌─────────┐                │             ┌─────────┐  │
    │   │  Ошибки │                │             │ Запросы │  │
    │   │ подсчи- │                │             │успешны? │  │
    │   │ тываются│                │             │         │  │
    │   └─────────┘                │             └─────────┘  │
    │                              │                  │       │
    │                              │                  │       │
    │                              └──────────────────┘       │
    │                                     ДА                  │
    └─────────────────────────────────────────────────────────┘
```

**Алгоритм работы:**

```python
class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout=60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
        self.last_failure_time = None
    
    def call(self, func):
        if self.state == "OPEN":
            if time.now() - self.last_failure_time > self.timeout:
                self.state = "HALF_OPEN"
                self.failure_count = 0
            else:
                raise CircuitBreakerOpenException()
        
        try:
            result = func()
            if self.state == "HALF_OPEN":
                self.state = "CLOSED"
            self.failure_count = 0
            return result
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.now()
            
            if self.failure_count >= self.failure_threshold:
                self.state = "OPEN"
            
            raise e
```

#### 🔄 Retry Patterns с Exponential Backoff

```
            RETRY STRATEGY WITH EXPONENTIAL BACKOFF
    ┌───────────────────────────────────────────────────────────┐
    │                                                           │
    │  Попытка 1 ──[FAIL]──► Ждем 1 сек ──► Попытка 2          │
    │                                           │               │
    │                                       [FAIL]             │
    │                                           │               │
    │                                           ▼               │
    │                               Ждем 2 сек ──► Попытка 3   │
    │                                               │           │
    │                                           [FAIL]         │
    │                                               │           │
    │                                               ▼           │
    │                                   Ждем 4 сек ──► И т.д.  │
    │                                                           │
    │  Формула: delay = base_delay * 2^(attempt - 1) + jitter  │
    └───────────────────────────────────────────────────────────┘
```

**Реализация с jitter для предотвращения thundering herd:**

```python
import random
import time

class RetryStrategy:
    def __init__(self, max_attempts=5, base_delay=1, max_delay=300):
        self.max_attempts = max_attempts
        self.base_delay = base_delay
        self.max_delay = max_delay
    
    def retry_with_backoff(self, func):
        for attempt in range(1, self.max_attempts + 1):
            try:
                return func()
            except Exception as e:
                if attempt == self.max_attempts:
                    raise e
                
                # Exponential backoff с jitter
                delay = min(
                    self.base_delay * (2 ** (attempt - 1)),
                    self.max_delay
                )
                
                # Добавляем случайность (jitter) ±25%
                jitter = delay * 0.25 * (random.random() * 2 - 1)
                final_delay = delay + jitter
                
                time.sleep(final_delay)
```

#### 🏰 Bulkhead Pattern (Изоляция ресурсов)

Принцип разделения ресурсов для предотвращения каскадных сбоев:

```
              BULKHEAD PATTERN EXAMPLE
    ┌─────────────────────────────────────────────────────┐
    │                 WEB SERVER                          │
    ├─────────────────────────────────────────────────────┤
    │                                                     │
    │  Thread Pool 1     Thread Pool 2     Thread Pool 3 │
    │  ┌───────────┐     ┌───────────┐     ┌───────────┐  │
    │  │   API     │     │  Reports  │     │   Admin   │  │
    │  │ Requests  │     │Generation │     │Interface  │  │
    │  │           │     │           │     │           │  │
    │  │ 50 threads│     │ 20 threads│     │ 10 threads│  │
    │  └───────────┘     └───────────┘     └───────────┘  │
    │                                                     │
    └─────────────────────────────────────────────────────┘
    
    Если Reports зависнут, API продолжит работать!
```

**Типы изоляции:**

1. **Thread Pool Isolation**
```
Service A ──► Thread Pool A (10 threads)
Service B ──► Thread Pool B (15 threads)  
Service C ──► Thread Pool C (5 threads)
```

2. **Connection Pool Isolation**
```
User DB ──► Connection Pool 1 (20 connections)
Log DB  ──► Connection Pool 2 (5 connections)
Cache   ──► Connection Pool 3 (30 connections)
```

3. **Resource Isolation**
```
CPU: 4 cores ──► Service A (2 cores), Service B (2 cores)
Memory: 16GB ──► Service A (8GB), Service B (8GB)
```

#### ⚡ Timeout Configuration

```
                    TIMEOUT HIERARCHY
    ┌─────────────────────────────────────────────────────┐
    │                                                     │
    │  Client Request (30s timeout)                       │
    │    │                                                │
    │    ▼                                                │
    │  Load Balancer (25s timeout)                        │
    │    │                                                │
    │    ▼                                                │
    │  Application Server (20s timeout)                   │
    │    │                                                │
    │    ▼                                                │
    │  Database Query (15s timeout)                       │
    │    │                                                │
    │    ▼                                                │
    │  Network Socket (10s timeout)                       │
    │                                                     │
    └─────────────────────────────────────────────────────┘
    
    Принцип: Каждый уровень должен иметь меньший timeout
```

#### 🎪 Комбинирование паттернов

```
                    RESILIENCE PATTERNS STACK
    ┌─────────────────────────────────────────────────────┐
    │                                                     │
    │  ┌─ Circuit Breaker ─────────────────────────────┐  │
    │  │                                               │  │
    │  │  ┌─ Retry with Backoff ──────────────────┐    │  │
    │  │  │                                       │    │  │
    │  │  │  ┌─ Timeout ──────────────────────┐   │    │  │
    │  │  │  │                                │   │    │  │
    │  │  │  │     Actual Service Call        │   │    │  │
    │  │  │  │                                │   │    │  │
    │  │  │  └────────────────────────────────┘   │    │  │
    │  │  └───────────────────────────────────────┘    │  │
    │  └───────────────────────────────────────────────┘  │
    │                                                     │
    └─────────────────────────────────────────────────────┘
```

#### 💡 Практическое задание 3.2

**Задача 1: Реализация Circuit Breaker**
Реализуйте Circuit Breaker для HTTP клиента с следующими требованиями:
- Порог ошибок: 5 неудачных запросов за 10 секунд
- Время восстановления: 30 секунд
- Состояния: CLOSED, OPEN, HALF_OPEN

**Задача 2: Retry стратегия**
Спроектируйте retry логику для:
1. Отправки email (временные сбои SMTP)
2. Загрузки файлов в S3 (сетевые проблемы)
3. Обновления кэша Redis (кратковременная недоступность)

**Задача 3: Bulkhead дизайн**
Разработайте схему изоляции ресурсов для микросервиса с функциями:
- REST API для пользователей (высокая нагрузка)
- Генерация отчетов (ресурсоемкие операции)
- Административная панель (низкая нагрузка)

---

## Неделя 13: Backup и Recovery

### Глава 3.3: Резервное копирование и восстановление

**Время:** 2 часа теории + 3 часа практики

#### 🎯 Цели обучения
- Понять различные стратегии резервного копирования
- Рассчитать RTO и RPO для разных сценариев
- Спроектировать backup стратегию для критических систем

#### 📊 Стратегии резервного копирования

```
                    BACKUP STRATEGIES COMPARISON
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  FULL BACKUP (Полное резервное копирование)                 │
    │  ┌─────────────────────────────────────────────────────────┐ │
    │  │ Понедельник: [■■■■■■■■■■] Все данные (100GB)          │ │
    │  │ Плюсы: Простое восстановление                           │ │
    │  │ Минусы: Много места, долгое создание                    │ │
    │  └─────────────────────────────────────────────────────────┘ │
    │                                                             │
    │  INCREMENTAL BACKUP (Инкрементное)                          │
    │  ┌─────────────────────────────────────────────────────────┐ │
    │  │ Пн: [■■■■■■■■■■] Full (100GB)                          │ │
    │  │ Вт: [■■] Изменения с Пн (5GB)                          │ │
    │  │ Ср: [■] Изменения с Вт (2GB)                           │ │
    │  │ Чт: [■■■] Изменения с Ср (8GB)                         │ │
    │  │ Плюсы: Быстро, мало места                               │ │
    │  │ Минусы: Сложное восстановление                          │ │
    │  └─────────────────────────────────────────────────────────┘ │
    │                                                             │
    │  DIFFERENTIAL BACKUP (Дифференциальное)                     │
    │  ┌─────────────────────────────────────────────────────────┐ │
    │  │ Пн: [■■■■■■■■■■] Full (100GB)                          │ │
    │  │ Вт: [■■] Изменения с Пн (5GB)                          │ │
    │  │ Ср: [■■■] Все изменения с Пн (7GB)                     │ │
    │  │ Чт: [■■■■■] Все изменения с Пн (15GB)                  │ │
    │  │ Плюсы: Простое восстановление                           │ │
    │  │ Минусы: Растущий размер                                 │ │
    │  └─────────────────────────────────────────────────────────┘ │
    └─────────────────────────────────────────────────────────────┘
```

#### 🎯 RTO и RPO метрики

**RTO (Recovery Time Objective)** - Максимально допустимое время восстановления
**RPO (Recovery Point Objective)** - Максимально допустимые потери данных

```
                        RTO vs RPO VISUALIZATION
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  Время ────────────────────────────────────────────────►    │
    │                                                             │
    │  ┌─── Нормальная работа ───┐  ┌─── Восстановление ───┐     │
    │  │                         │  │                       │     │
    │  │    [Данные]             │  │                       │     │
    │  │         │               │  │                       │     │
    │  │         ▼               │  │                       │     │
    │  │    [Backup каждые       │  │                       │     │
    │  │     15 минут]           │  │                       │     │
    │  │                         │  │                       │     │
    │  └─────────────────────────┘  └───────────────────────┘     │
    │           ▲                           ▲              ▲      │
    │       Последний              Авария            Восстанов.   │
    │       backup                                                │
    │                                                             │
    │           ◄─── RPO = 15 мин ───►                            │
    │                                ◄─── RTO = 2 часа ───►      │
    └─────────────────────────────────────────────────────────────┘
```

**Примеры RTO/RPO для разных систем:**

```
┌─────────────────────┬─────────────┬─────────────┬──────────────┐
│      Система        │     RTO     │     RPO     │   Стоимость  │
├─────────────────────┼─────────────┼─────────────┼──────────────┤
│ Критичный банкинг   │   < 1 мин   │   < 1 мин   │   Очень выс. │
│ E-commerce          │   < 30 мин  │   < 15 мин  │   Высокая    │
│ Корпоративный сайт  │   < 4 часа  │   < 1 час   │   Средняя    │
│ Аналитика/Отчеты    │   < 24 часа │   < 24 часа │   Низкая     │
│ Архивные данные     │   < 1 неделя│   < 1 день  │   Очень низк.│
└─────────────────────┴─────────────┴─────────────┴──────────────┘
```

#### 🌡️ Hot vs Cold Backup

```
                    BACKUP TEMPERATURE COMPARISON
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  HOT BACKUP (Горячее резервирование)                        │
    │  ┌─────────────────────────────────────────────────────────┐ │
    │  │                                                         │ │
    │  │  Primary DB ═══► Replica DB                             │ │
    │  │  [ACTIVE]        [STANDBY]                              │ │
    │  │      │               │                                  │ │
    │  │      │ Real-time     │ Ready to                         │ │
    │  │      │ sync          │ take over                        │ │
    │  │      ▼               ▼                                  │ │
    │  │  Приложения      [Мгновенное                           │ │
    │  │                   переключение]                        │ │
    │  │                                                         │ │
    │  │  RTO: Секунды/Минуты  |  RPO: Секунды                  │ │
    │  │  Стоимость: $$$$      |  Сложность: Высокая            │ │
    │  └─────────────────────────────────────────────────────────┘ │
    │                                                             │
    │  WARM BACKUP (Теплое резервирование)                        │
    │  ┌─────────────────────────────────────────────────────────┐ │
    │  │                                                         │ │
    │  │  Primary DB ──► Backup Files                            │ │
    │  │  [ACTIVE]       [PERIODIC SYNC]                         │ │
    │  │      │               │                                  │ │
    │  │      │ Hourly        │ Need to start                    │ │
    │  │      │ backup        │ services                         │ │
    │  │      ▼               ▼                                  │ │
    │  │  Приложения      [Восстановление                       │ │
    │  │                   + запуск]                            │ │
    │  │                                                         │ │
    │  │  RTO: Минуты/Часы     |  RPO: Часы                     │ │
    │  │  Стоимость: $$$       |  Сложность: Средняя            │ │
    │  └─────────────────────────────────────────────────────────┘ │
    │                                                             │
    │  COLD BACKUP (Холодное резервирование)                      │
    │  ┌─────────────────────────────────────────────────────────┐ │
    │  │                                                         │ │
    │  │  Primary DB ──► Archive Storage                         │ │
    │  │  [ACTIVE]       [OFFLINE]                               │ │
    │  │      │               │                                  │ │
    │  │      │ Daily         │ Need to restore                  │ │
    │  │      │ backup        │ everything                       │ │
    │  │      ▼               ▼                                  │ │
    │  │  Приложения      [Полное                               │ │
    │  │                   восстановление]                      │ │
    │  │                                                         │ │
    │  │  RTO: Часы/Дни        |  RPO: Дни                      │ │
    │  │  Стоимость: $         |  Сложность: Низкая             │ │
    │  └─────────────────────────────────────────────────────────┘ │
    └─────────────────────────────────────────────────────────────┘
```

#### 🌍 Cross-Region Backup стратегии

```
                MULTI-REGION BACKUP ARCHITECTURE
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  ┌─── Primary Region (us-east-1) ────┐                      │
    │  │                                   │                      │
    │  │  [Production DB] ──┐               │                      │
    │  │         │          │               │                      │
    │  │         ▼          ▼               │                      │
    │  │  [Local Backup] [Streaming         │                      │
    │  │                  Replication] ─────┼──────────────┐       │
    │  │                                   │              │       │
    │  └───────────────────────────────────┘              │       │
    │                                                     │       │
    │  ┌─── Backup Region (us-west-2) ────┐               │       │
    │  │                                  │               │       │
    │  │           ┌──────────────────────┼───────────────┘       │
    │  │           ▼                      │                       │
    │  │  [Replica DB] ──► [Backup        │                       │
    │  │                   Storage]       │                       │
    │  │                                  │                       │
    │  └──────────────────────────────────┘                       │
    │                                                             │
    │  ┌─── Archive Region (eu-west-1) ───┐                       │
    │  │                                  │                       │
    │  │  [Long-term Archive Storage]     │                       │
    │  │  - Снапшоты раз в неделю         │                       │
    │  │  - Retention: 7 лет              │                       │
    │  │  - Glacier Deep Archive          │                       │
    │  │                                  │                       │
    │  └──────────────────────────────────┘                       │
    └─────────────────────────────────────────────────────────────┘
```

#### 💡 Практическое задание 3.3

**Задача: Backup стратегия для интернет-банка**

Спроектируйте комплексную backup стратегию со следующими требованиями:

**Компоненты системы:**
- Основная БД транзакций (PostgreSQL, 500GB)
- Пользовательские данные (MongoDB, 200GB)
- Документы и файлы (S3, 50TB)
- Логи операций (ClickHouse, 100GB/день)

**Требования:**
- RTO для транзакций: < 5 минут
- RPO для транзакций: < 30 секунд
- RTO для документов: < 1 час
- RPO для документов: < 4 часа
- Compliance: хранение 7 лет
- Бюджет: $10,000/месяц

**Что нужно спроектировать:**
1. Схему резервирования для каждого компонента
2. Географическое распределение backup'ов
3. Процедуры восстановления
4. Календарь тестирования восстановления
5. Мониторинг backup процессов

---

### Глава 3.4: Disaster Recovery планирование

**Время:** 2 часа теории + 2 часа практики

#### 🎯 Цели обучения
- Различать DR и Business Continuity
- Создать comprehensive DR план
- Спроектировать multi-region архитектуру

#### 🆚 Disaster Recovery vs Business Continuity

```
              DR vs BC COMPARISON MATRIX
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │                 DISASTER RECOVERY                           │
    │  ┌─────────────────────────────────────────────────────────┐ │
    │  │                                                         │ │
    │  │  FOCUS: Технологическое восстановление                  │ │
    │  │  SCOPE: IT системы и данные                             │ │
    │  │  GOAL:  Восстановить IT операции                        │ │
    │  │                                                         │ │
    │  │  ┌─ Что включает: ──────────────────────────────────┐   │ │
    │  │  │ • Backup и restore процедуры                    │   │ │
    │  │  │ • Failover в другой дата-центр                  │   │ │
    │  │  │ • Восстановление баз данных                     │   │ │
    │  │  │ • Запуск приложений в DR сайте                  │   │ │
    │  │  └─────────────────────────────────────────────────┘   │ │
    │  └─────────────────────────────────────────────────────────┘ │
    │                                                             │
    │               BUSINESS CONTINUITY                           │
    │  ┌─────────────────────────────────────────────────────────┐ │
    │  │                                                         │ │
    │  │  FOCUS: Операционная непрерывность                      │ │
    │  │  SCOPE: Весь бизнес-процесс                             │ │
    │  │  GOAL:  Продолжить работу компании                      │ │
    │  │                                                         │ │
    │  │  ┌─ Что включает: ──────────────────────────────────┐   │ │
    │  │  │ • Альтернативные рабочие места                  │   │ │
    │  │  │ • Запасные поставщики                           │   │ │
    │  │  │ • Временные процессы                            │   │ │
    │  │  │ • Коммуникация с клиентами                      │   │ │
    │  │  │ • DR как часть BC                               │   │ │
    │  │  └─────────────────────────────────────────────────┘   │ │
    │  └─────────────────────────────────────────────────────────┘ │
    └─────────────────────────────────────────────────────────────┘
```

#### 🏗️ Multi-Region архитектуры

**1. Active-Passive (Failover)**
```
                    ACTIVE-PASSIVE ARCHITECTURE
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  ┌─── PRIMARY REGION ────────┐  ┌─── DR REGION ──────────┐  │
    │  │                           │  │                        │  │
    │  │  Users ──► Load Balancer  │  │  [Standby Services]    │  │
    │  │               │           │  │         │              │  │
    │  │               ▼           │  │         │              │  │
    │  │        [App Servers]      │  │         │              │  │
    │  │               │           │  │         │              │  │
    │  │               ▼           │  │         │              │  │
    │  │        [Primary DB] ──────┼──┼────► [Replica DB]     │  │
    │  │                           │  │                        │  │
    │  │        [Monitoring]       │  │    [Health Checks]     │  │
    │  │               │           │  │                        │  │
    │  │               ▼           │  │                        │  │
    │  │         ┌─ Alert ─┐       │  │                        │  │
    │  │         │ Failure │       │  │                        │  │
    │  │         └─────────┘       │  │                        │  │
    │  └───────────────────────────┘  └────────────────────────┘  │
    │                                                             │
    │  Переключение:                                              │
    │  1. Обнаружение отказа (1-2 мин)                            │
    │  2. Промоция replica в master (2-5 мин)                     │
    │  3. Запуск приложений (5-10 мин)                            │
    │  4. DNS переключение (2-5 мин)                              │
    │                                                             │
    │  Общее RTO: 10-22 минуты                                    │
    └─────────────────────────────────────────────────────────────┘
```

**2. Active-Active (Load Distribution)**
```
                    ACTIVE-ACTIVE ARCHITECTURE
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │            ┌─── Global Load Balancer ───┐                   │
    │            │     (Route53, CloudFlare)  │                   │
    │            └──────────┬─────────────────┘                   │
    │                       │                                     │
    │          ┌────────────┼────────────┐                        │
    │          ▼                         ▼                        │
    │  ┌─── REGION 1 ────┐        ┌─── REGION 2 ────┐           │
    │  │                 │        │                 │           │
    │  │ 50% трафика     │        │ 50% трафика     │           │
    │  │                 │        │                 │           │
    │  │ [App Servers]   │        │ [App Servers]   │           │
    │  │       │         │        │       │         │           │
    │  │       ▼         │        │       ▼         │           │
    │  │ [Database] ◄────┼────────┼─── [Database]   │           │
    │  │             sync│        │             │   │           │
    │  └─────────────────┘        └─────────────────┘           │
    │                                                             │
    │  Преимущества:                                              │
    │  • Нет простоя при отказе региона                           │
    │  • Лучшая производительность (ближе к пользователям)        │
    │  • Эффективное использование ресурсов                       │
    │                                                             │
    │  Сложности:                                                 │
    │  • Синхронизация данных между регионами                     │
    │  • Разрешение конфликтов                                    │
    │  • Сложность развертывания                                  │
    └─────────────────────────────────────────────────────────────┘
```

#### 🧪 DR тестирование стратегии

```
                    DR TESTING PYRAMID
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │                   [FULL DR DRILL]                           │
    │               ╱───────────────────╲                         │
    │             ╱  • Полное переключение ╲                      │
    │           ╱    • Все системы           ╲                    │
    │         ╱      • Реальный трафик         ╲                  │
    │       ╱        • 1-2 раза в год           ╲                 │
    │     ╱────────────────────────────────────────╲               │
    │                                                             │
    │              [PARTIAL FAILOVER TEST]                        │
    │           ╱──────────────────────────────╲                  │
    │         ╱   • Критичные системы           ╲                 │
    │       ╱     • Изолированная среда           ╲                │
    │     ╱       • Ежемесячно                     ╲               │
    │   ╱───────────────────────────────────────────╲              │
    │                                                             │
    │            [COMPONENT RECOVERY TEST]                        │
    │        ╱────────────────────────────────────╲               │
    │      ╱      • Отдельные компоненты           ╲              │
    │    ╱        • Автоматизированные тесты        ╲             │
    │  ╱          • Еженедельно                      ╲            │
    │╱──────────────────────────────────────────────────╲         │
    │                                                             │
    │              [BACKUP VERIFICATION]                          │
    │    ╱────────────────────────────────────────────────╲       │
    │  ╱           • Проверка backup'ов                    ╲      │
    │ ╱            • Тестовое восстановление                ╲     │
    │╱             • Ежедневно                               ╲    │
    │────────────────────────────────────────────────────────╲    │
    └─────────────────────────────────────────────────────────────┘
```

#### 📋 DR Plan компоненты

**1. Contact Matrix**
```
┌─────────────────┬────────────────┬─────────────────┬──────────────┐
│     Роль        │      Имя       │    Телефон      │    Email     │
├─────────────────┼────────────────┼─────────────────┼──────────────┤
│ DR Commander    │ Alice Johnson  │ +1-555-0101    │ alice@...    │
│ Tech Lead       │ Bob Smith      │ +1-555-0102    │ bob@...      │
│ DB Admin        │ Carol Davis    │ +1-555-0103    │ carol@...    │
│ Network Admin   │ Dave Wilson    │ +1-555-0104    │ dave@...     │
│ Business Lead   │ Eve Brown      │ +1-555-0105    │ eve@...      │
└─────────────────┴────────────────┴─────────────────┴──────────────┘
```

**2. System Inventory**
```
┌─────────────────┬──────────────┬─────────────┬──────────────────┐
│     Система     │   Priority   │     RTO     │       RPO        │
├─────────────────┼──────────────┼─────────────┼──────────────────┤
│ Core Banking    │   Critical   │   5 min     │   30 sec         │
│ Customer Portal │   High       │   30 min    │   15 min         │
│ Reporting       │   Medium     │   4 hours   │   1 hour         │
│ Archive         │   Low        │   24 hours  │   24 hours       │
└─────────────────┴──────────────┴─────────────┴──────────────────┘
```

**3. Runbook Example**
```markdown
## DR Procedure: Database Failover

### Prerequisites
- [ ] Confirm primary DB is unreachable
- [ ] Verify replica is healthy
- [ ] Get approval from DR Commander

### Steps
1. **Stop application traffic** (ETA: 2 min)
   ```bash
   kubectl scale deployment app --replicas=0
   ```

2. **Promote replica to master** (ETA: 3 min)
   ```sql
   SELECT pg_promote();
   ```

3. **Update connection strings** (ETA: 2 min)
   - Update DNS: db.company.com → replica-ip
   - Update app configs

4. **Restart applications** (ETA: 5 min)
   ```bash
   kubectl scale deployment app --replicas=10
   ```

5. **Verify functionality** (ETA: 3 min)
   - Run health checks
   - Test critical paths

### Rollback
If issues occur, follow rollback procedure...
```

#### 💡 Практическое задание 3.4

**Проект: DR план для SaaS платформы**

Создайте comprehensive DR план для SaaS компании со следующими характеристиками:

**Архитектура:**
- 3-tier web приложение (React, Node.js, PostgreSQL)
- Микросервисы для payment, notification, analytics
- Redis для кэширования и сессий
- S3 для file storage
- CloudFront CDN

**Требования:**
- Поддержка 50,000 активных пользователей
- Доходы $100,000/час во время пиковых нагрузок
- Compliance: SOC2, PCI DSS
- SLA: 99.9% uptime

**Deliverables:**
1. **DR Strategy Document**
   - RTO/RPO для каждого компонента
   - Active-passive vs active-active обоснование
   - Cost-benefit анализ

2. **Technical Architecture**
   - Multi-region deployment схема
   - Network connectivity план
   - Data replication стратегия

3. **Operational Runbooks**
   - Step-by-step failover процедуры
   - Rollback планы
   - Communication templates

4. **Testing Schedule**
   - Quarterly full DR drills
   - Monthly component tests
   - Weekly backup verification

---

## Неделя 14: Распределенная консистентность

### Глава 3.5: Distributed Consensus (Raft, Paxos)

**Время:** 4 часа теории + 2 часа практики

#### 🎯 Цели обучения
- Понять фундаментальные проблемы consensus в распределенных системах
- Изучить алгоритмы Raft и Paxos
- Применить consensus в реальных системах

#### 🏛️ Проблема византийских генералов

Классическая задача, иллюстрирующая сложности достижения консенсуса:

```
            BYZANTINE GENERALS PROBLEM
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │        Генерал A ────────────► Генерал B                    │
    │          │                       │                         │
    │          │ "Атакуем на рассвете"  │                         │
    │          │                       │                         │
    │          ▼                       ▼                         │
    │      [Решение]                [Решение]                     │
    │                                                             │
    │  Проблемы:                                                  │
    │  1. Сообщения могут потеряться                              │
    │  2. Узлы могут выйти из строя                               │
    │  3. Некоторые узлы могут быть "византийскими"               │
    │     (отправлять противоречивые сообщения)                   │
    │                                                             │
    │  Цель: Все честные узлы должны прийти к одному решению      │
    └─────────────────────────────────────────────────────────────┘
```

**В контексте distributed systems:**
- **Генералы** = Узлы в кластере
- **Атака** = Принятие решения (commit транзакции, выбор лидера)
- **Предатели** = Узлы с ошибками или злонамеренные узлы

#### ⛳ Raft Consensus Algorithm

Raft предназначен для понимания и реализации. Основные роли узлов:

```
                        RAFT NODE STATES
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  FOLLOWER              CANDIDATE             LEADER         │
    │  ┌─────────┐           ┌─────────┐          ┌─────────┐     │
    │  │ Получает│           │Проводит │          │Обслужи- │     │
    │  │логи от  │           │выборы   │          │вает     │     │
    │  │лидера   │           │лидера   │          │клиентов │     │
    │  └─────────┘           └─────────┘          └─────────┘     │
    │       │                    ▲ │                   │         │
    │       │                    │ │                   │         │
    │       │ Timeout/           │ │ Получает          │         │
    │       │ No heartbeat       │ │ больше голосов    │         │
    │       │                    │ │                   │         │
    │       ▼                    │ ▼                   │         │
    │  [Становится              [Становится            │         │
    │   кандидатом]              лидером]              │         │
    │                                                   │         │
    │       ▲                                           │         │
    │       │                                           │         │
    │       │ Обнаруживает нового лидера                │         │
    │       │ или больший term                          │         │
    │       └───────────────────────────────────────────┘         │
    └─────────────────────────────────────────────────────────────┘
```

**Leader Election Process:**

```
                    RAFT LEADER ELECTION
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  Term 1:                                                    │
    │  Node A (Leader) ──► Node B (Follower) ──► Node C (Follower)│
    │         │                   │                    │          │
    │         │ Heartbeat         │ Heartbeat          │          │
    │         ▼                   ▼                    ▼          │
    │      [OK]                [OK]                 [OK]          │
    │                                                             │
    │  Term 2: (Node A отказывает)                                │
    │  Node A (Down) ──X  Node B (Follower) ──► Node C (Follower) │
    │                             │                    │          │
    │                             │ Timeout!           │          │
    │                             ▼                    ▼          │
    │                       [Candidate]         [Candidate]       │
    │                             │                    │          │
    │                             │ Vote Request       │          │
    │                             ▼                    ▼          │
    │                       [Starts election]   [Starts election]│
    │                                                             │
    │  Term 3: (Node B выигрывает)                                │
    │  Node A (Down) ──X  Node B (Leader) ◄──── Node C (Follower) │
    │                             │                    │          │
    │                             │ I'm the leader     │          │
    │                             ▼                    ▼          │
    │                       [Служит клиентам]    [Следует лидеру] │
    └─────────────────────────────────────────────────────────────┘
```

**Log Replication:**

```
                        RAFT LOG REPLICATION
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  Client Request: SET x=5                                    │
    │         │                                                   │
    │         ▼                                                   │
    │  ┌─── Leader ───┐                                           │
    │  │   Term: 3    │                                           │
    │  │   Log: [1,2,3]│ ──┐                                      │
    │  │   +[SET x=5] │   │                                      │
    │  └──────────────┘   │                                      │
    │                     │                                      │
    │                     │ AppendEntries RPC                    │
    │                     │                                      │
    │          ┌──────────┼──────────┐                           │
    │          ▼                     ▼                           │
    │  ┌─── Follower A ───┐   ┌─── Follower B ───┐              │
    │  │   Term: 3        │   │   Term: 3        │              │
    │  │   Log: [1,2,3]   │   │   Log: [1,2,3]   │              │
    │  │   +[SET x=5]     │   │   +[SET x=5]     │              │
    │  └──────────────────┘   └──────────────────┘              │
    │          │                     │                           │
    │          │ Success             │ Success                   │
    │          ▼                     ▼                           │
    │      [Commit]               [Commit]                       │
    │                                                             │
    │  Когда majority подтвердит, лидер коммитит запись          │
    │  и отвечает клиенту: OK                                     │
    └─────────────────────────────────────────────────────────────┘
```

#### 🗳️ Paxos Protocol основы

Paxos сложнее для понимания, но более общий алгоритм:

```
                        PAXOS PHASES
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  PHASE 1: PREPARE                                           │
    │  ┌─────────────────────────────────────────────────────────┐ │
    │  │                                                         │ │
    │  │  Proposer ──► "Prepare(n)" ──► Acceptors                │ │
    │  │     │                              │                    │ │
    │  │     │                              ▼                    │ │
    │  │     │                         [Обещают не               │ │
    │  │     │                          принимать               │ │
    │  │     │                          предложения             │ │
    │  │     │                          с номером < n]          │ │
    │  │     │                              │                    │ │
    │  │     ◄────── "Promise(n, v)" ◄──────┘                    │ │
    │  │                                                         │ │
    │  └─────────────────────────────────────────────────────────┘ │
    │                                                             │
    │  PHASE 2: ACCEPT                                            │
    │  ┌─────────────────────────────────────────────────────────┐ │
    │  │                                                         │ │
    │  │  Proposer ──► "Accept(n, v)" ──► Acceptors              │ │
    │  │     │                              │                    │ │
    │  │     │                              ▼                    │ │
    │  │     │                         [Принимают               │ │
    │  │     │                          значение v              │ │
    │  │     │                          с номером n]            │ │
    │  │     │                              │                    │ │
    │  │     ◄────── "Accepted(n, v)" ◄─────┘                    │ │
    │  │                                                         │ │
    │  └─────────────────────────────────────────────────────────┘ │
    │                                                             │
    │  Значение выбрано, когда majority acceptors его приняли     │
    └─────────────────────────────────────────────────────────────┘
```

#### 🔄 Consensus в реальных системах

**etcd (Raft-based)**
```
Kubernetes Control Plane:
┌──────────────────────────────────────────────┐
│               etcd Cluster                   │
├──────────────────────────────────────────────┤
│                                              │
│  Node 1 (Leader)   Node 2      Node 3       │
│  ┌─────────────┐   ┌─────────┐  ┌─────────┐   │
│  │ API Server  │   │ Follower│  │ Follower│   │
│  │ Scheduler   │   │         │  │         │   │
│  │ Controller  │   │         │  │         │   │
│  └─────────────┘   └─────────┘  └─────────┘   │
│         │                                    │
│         ▼                                    │
│  [Cluster State]                             │
│  - Pods, Services, etc.                      │
│  - Configuration                             │
│  - Secrets                                   │
└──────────────────────────────────────────────┘
```

**Apache Kafka (Custom Consensus)**
```
Kafka Cluster:
┌──────────────────────────────────────────────┐
│              ZooKeeper Ensemble              │
├──────────────────────────────────────────────┤
│  Node 1        Node 2        Node 3          │
│ (Leader)     (Follower)   (Follower)         │
└──────────────────────────────────────────────┘
         │
         ▼
┌──────────────────────────────────────────────┐
│                Kafka Brokers                 │
├──────────────────────────────────────────────┤
│  Broker 1      Broker 2      Broker 3       │
│  ┌─────────┐   ┌─────────┐   ┌─────────┐     │
│  │Topic A  │   │Topic A  │   │Topic A  │     │
│  │Partition│   │Partition│   │Partition│     │
│  │1(Leader)│   │1(Replica)│   │1(Replica)│     │
│  └─────────┘   └─────────┘   └─────────┘     │
└──────────────────────────────────────────────┘

Consensus используется для:
- Выбор controller broker
- Partition leader election
- Cluster membership
```

#### 💡 Практическое задание 3.5

**Симуляция Raft алгоритма**

Создайте step-by-step симуляцию Raft election в следующем сценарии:

**Начальное состояние:**
- 5 узлов: A, B, C, D, E
- Узел A - текущий лидер (term=3)
- Остальные - followers

**Сценарий отказов:**
1. t=0: Узел A внезапно отключается
2. t=5: Узлы B и C одновременно начинают выборы
3. t=10: Узел D получает vote requests от B и C
4. t=15: Сетевая партиция: {B,C} отделяются от {D,E}
5. t=25: Партиция восстанавливается
6. t=30: Узел A возвращается

**Задачи:**
1. Проследите изменение term numbers
2. Покажите кто становится лидером на каждом этапе
3. Объясните как разрешается split-brain ситуация
4. Определите минимальное время недоступности системы

---

### Глава 3.6: Eventual Consistency и ACID

**Время:** 2 часа теории + 2 часа практики

#### 🎯 Цели обучения
- Понять различные уровни консистентности
- Изучить стратегии разрешения конфликтов
- Применить CRDT для distributed systems

#### 📊 Spectrum консистентности

```
                CONSISTENCY SPECTRUM
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │ STRONG ◄─────────────────────────────────────────► WEAK     │
    │                                                             │
    │ ┌─────────┬─────────┬─────────┬─────────┬─────────────────┐ │
    │ │ Strict  │ Strong  │ Causal  │Session  │ Eventual        │ │
    │ │ Serial  │ Consist │ Consist │ Consist │ Consistency     │ │
    │ └─────────┼─────────┼─────────┼─────────┼─────────────────┤ │
    │           │         │         │         │                 │ │
    │ • Global  │• Read   │• Cause- │• Read   │• Will converge  │ │
    │   ordering│  your   │  effect │  your   │  eventually     │ │
    │ • Real-   │  writes │  order  │  writes │• No guarantees  │ │
    │   time    │• Linear │  kept   │• Mono-  │  on timing      │ │
    │           │  history│         │  tonic  │• Weak ordering  │ │
    │           │         │         │  reads  │                 │ │
    │           │         │         │         │                 │ │
    │ Examples: │Examples:│Examples:│Examples:│ Examples:       │ │
    │ • Single  │• RDBMS  │• Git    │• Web    │ • DNS           │ │
    │   machine │  ACID   │• Email  │  apps   │ • Social feeds  │ │
    │ • Spanner │• etcd   │  thread │• Shopping│ • Gaming scores │ │
    └───────────┴─────────┴─────────┴─────────┴─────────────────┘ │
    └─────────────────────────────────────────────────────────────┘
```

#### 🔗 Vector Clocks и Logical Timestamps

Для отслеживания cause-effect отношений в распределенных системах:

```
                    VECTOR CLOCKS EXAMPLE
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  Process A: [1,0,0] ──► [2,0,0] ──► [3,1,0] ──► [4,1,0]    │
    │                              │           ▲                  │
    │                              │           │                  │
    │                              │ msg1      │ msg2             │
    │                              │           │                  │
    │                              ▼           │                  │
    │  Process B: [0,1,0] ──► [1,2,0] ──► [1,3,0] ──► [1,4,2]    │
    │                                       │           ▲         │
    │                                       │           │         │
    │                                       │ msg3      │ msg4    │
    │                                       │           │         │
    │                                       ▼           │         │
    │  Process C: [0,0,1] ──► [0,0,2] ──► [1,3,3] ──► [1,4,4]    │
    │                                                             │
    │  Правила обновления vector clock:                           │
    │  1. Increment своего элемента при локальном событии         │
    │  2. При получении сообщения:                                │
    │     - Взять максимум по каждому элементу                    │
    │     - Increment своего элемента                             │
    └─────────────────────────────────────────────────────────────┘
```

**Использование для conflict detection:**

```python
class VectorClock:
    def __init__(self, processes):
        self.clock = {p: 0 for p in processes}
        self.process_id = None
    
    def tick(self):
        """Локальное событие"""
        self.clock[self.process_id] += 1
    
    def update(self, other_clock):
        """Получение сообщения от другого процесса"""
        for process in self.clock:
            self.clock[process] = max(
                self.clock[process], 
                other_clock.get(process, 0)
            )
        self.tick()
    
    def happens_before(self, other):
        """Проверка причинно-следственной связи"""
        return (all(self.clock[p] <= other.clock[p] for p in self.clock) 
                and any(self.clock[p] < other.clock[p] for p in self.clock))
    
    def concurrent(self, other):
        """События параллельны (конфликт возможен)"""
        return not (self.happens_before(other) or other.happens_before(self))
```

#### 🔀 Conflict Resolution стратегии

**1. Last Writer Wins (LWW)**
```
                    LAST WRITER WINS
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  Node A: x = 5  (timestamp: 10:00:01)                      │
    │  Node B: x = 7  (timestamp: 10:00:03)                      │
    │  Node C: x = 2  (timestamp: 10:00:02)                      │
    │                                                             │
    │  Результат: x = 7 (последняя по времени запись)            │
    │                                                             │
    │  Проблемы:                                                  │
    │  • Синхронизация часов                                     │
    │  • Потеря данных                                            │
    │  • Не подходит для критичных операций                      │
    └─────────────────────────────────────────────────────────────┘
```

**2. Multi-Value Resolution**
```
                    MULTI-VALUE RESOLUTION
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  Конфликтующие записи:                                      │
    │  User.email = ["alice@old.com", "alice@new.com"]           │
    │                                                             │
    │  Application logic:                                         │
    │  1. Показать пользователю оба значения                     │
    │  2. Позволить выбрать правильное                            │
    │  3. Сохранить выбор как разрешение конфликта               │
    │                                                             │
    │  Применение:                                                │
    │  • Amazon DynamoDB                                          │
    │  • Riak                                                     │
    │  • CouchDB                                                  │
    └─────────────────────────────────────────────────────────────┘
```

**3. Semantic Resolution**
```
                    SEMANTIC RESOLUTION
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  Операции:                                                  │
    │  Node A: counter += 3                                       │
    │  Node B: counter += 5                                       │
    │                                                             │
    │  Базовое значение: counter = 10                             │
    │                                                             │
    │  Неправильно (LWW): counter = 15                            │
    │  Правильно (семантика): counter = 10 + 3 + 5 = 18          │
    │                                                             │
    │  Другие примеры:                                            │
    │  • Set union/intersection                                   │
    │  • Shopping cart merge                                      │
    │  • Document collaboration                                   │
    └─────────────────────────────────────────────────────────────┘
```

#### 🧬 CRDT (Conflict-free Replicated Data Types)

**G-Counter (Grow-only Counter)**
```
                        G-COUNTER CRDT
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  Replica A: [A:5, B:2, C:0] = 7                            │
    │  Replica B: [A:3, B:3, C:1] = 7                            │
    │  Replica C: [A:4, B:2, C:2] = 8                            │
    │                                                             │
    │  Merge = max по каждому элементу:                           │
    │  Result:    [A:5, B:3, C:2] = 10                           │
    │                                                             │
    │  Свойства:                                                  │
    │  • Коммутативность: merge(A,B) = merge(B,A)                │
    │  • Ассоциативность: merge(A,merge(B,C)) = merge(merge(A,B),C)│
    │  • Идемпотентность: merge(A,A) = A                         │
    └─────────────────────────────────────────────────────────────┘
```

**PN-Counter (Increment/Decrement Counter)**
```python
class PNCounter:
    def __init__(self, replica_id):
        self.replica_id = replica_id
        self.p_counter = {}  # Increments
        self.n_counter = {}  # Decrements
    
    def increment(self):
        if self.replica_id not in self.p_counter:
            self.p_counter[self.replica_id] = 0
        self.p_counter[self.replica_id] += 1
    
    def decrement(self):
        if self.replica_id not in self.n_counter:
            self.n_counter[self.replica_id] = 0
        self.n_counter[self.replica_id] += 1
    
    def value(self):
        p_sum = sum(self.p_counter.values())
        n_sum = sum(self.n_counter.values())
        return p_sum - n_sum
    
    def merge(self, other):
        # Element-wise maximum
        for replica in other.p_counter:
            self.p_counter[replica] = max(
                self.p_counter.get(replica, 0),
                other.p_counter[replica]
            )
        
        for replica in other.n_counter:
            self.n_counter[replica] = max(
                self.n_counter.get(replica, 0),
                other.n_counter[replica]
            )
```

**OR-Set (Observed-Remove Set)**
```python
class ORSet:
    def __init__(self):
        self.elements = {}  # element -> set of unique tags
        self.removed = set()  # tags of removed elements
    
    def add(self, element):
        unique_tag = f"{element}_{uuid.uuid4()}"
        if element not in self.elements:
            self.elements[element] = set()
        self.elements[element].add(unique_tag)
    
    def remove(self, element):
        if element in self.elements:
            self.removed.update(self.elements[element])
    
    def contains(self, element):
        if element not in self.elements:
            return False
        # Element exists if it has tags not in removed set
        return bool(self.elements[element] - self.removed)
    
    def merge(self, other):
        # Union of elements and their tags
        for element, tags in other.elements.items():
            if element not in self.elements:
                self.elements[element] = set()
            self.elements[element].update(tags)
        
        # Union of removed tags
        self.removed.update(other.removed)
```

#### 🌐 Реальные примеры Eventual Consistency

**Amazon DynamoDB**
```
                    DYNAMODB EVENTUAL CONSISTENCY
    ┌─────────────────────────────────────────────────────────────┐
    │                                                             │
    │  Write Request                                              │
    │       │                                                     │
    │       ▼                                                     │
    │  ┌─ Primary ─┐     ┌─ Replica 1 ─┐     ┌─ Replica 2 ─┐    │
    │  │ us-east-1a│ ──► │ us-east-1b  │ ──► │ us-east-1c  │    │
    │  │  [Data]   │     │   [Data]    │     │   [Data]    │    │
    │  └───────────┘     └─────────────┘     └─────────────┘    │
    │       │                   │                   │            │
    │       ▼                   ▼                   ▼            │
    │  [Immediately        [Eventually         [Eventually      │
    │   consistent]         consistent]        consistent]      │
    │                                                             │
    │  Read Consistency:                                          │
    │  • Eventually Consistent Reads (default)                   │
    │  • Strongly Consistent Reads (optional, higher latency)    │
    └─────────────────────────────────────────────────────────────┘
```

**Cassandra Tunable Consistency**
```
┌─────────────────┬─────────────┬─────────────┬──────────────────┐
│ Consistency     │ Write Nodes │ Read Nodes  │ Guarantee        │
├─────────────────┼─────────────┼─────────────┼──────────────────┤
│ ANY             │     1       │    N/A      │ Может потерять   │
│ ONE             │     1       │     1       │ Eventual         │
│ QUORUM          │  N/2 + 1    │  N/2 + 1    │ Strong если      │
│                 │             │             │ W + R > N        │
│ ALL             │     N       │     N       │ Strong но медл.  │
└─────────────────┴─────────────┴─────────────┴──────────────────┘
```

#### 💡 Практическое задание 3.6

**Проект: Distributed Shopping Cart**

Спроектируйте eventually consistent shopping cart систему со следующими требованиями:

**Функциональность:**
- Добавление/удаление товаров
- Изменение количества
- Работа offline
- Синхронизация между устройствами

**Технические требования:**
- Eventual consistency
- Conflict resolution для одновременного редактирования
- CRDT-based решение
- Поддержка network partitions

**Deliverables:**
1. **Data Model Design**
   ```
   ShoppingCart CRDT структура:
   - Items: OR-Set с quantity counters
   - User operations: add, remove, update quantity
   - Merge semantics при синхронизации
   ```

2. **Conflict Resolution Logic**
   - Сценарий: Пользователь добавляет товар на телефоне и планшете одновременно
   - Решение: Semantic merge (сложение количества)
   - Implementation в коде

3. **Network Partition Handling**
   - Offline mode поведение
   - Синхронизация при восстановлении связи
   - Пользовательский интерфейс для conflict resolution

4. **Testing Scenarios**
   - Unit tests для CRDT operations
   - Integration tests для network partitions
   - Performance tests для large carts

---

## Контрольные задания блока 3

### 🎯 Итоговый проект: Отказоустойчивая система онлайн-банкинга

**Контекст:** Проектирование высоконадежной системы для регионального банка с 500,000 клиентов и оборотом $10M/день.

#### 📋 Требования системы

**Функциональные требования:**
- Просмотр баланса и истории транзакций
- Переводы между счетами (внутренние и внешние)
- Платежи за услуги
- Управление депозитами
- Кредитные операции

**Нефункциональные требования:**
- Availability: 99.95% (≈ 4 часа downtime в год)
- RTO: < 5 минут для критичных операций
- RPO: < 30 секунд для финансовых данных
- Compliance: PCI DSS, SOX
- Throughput: 10,000 TPS в пик
- Latency: < 100ms для запросов баланса

#### 🏗️ Архитектурные компоненты для анализа

**1. Core Banking System**
- Транзакционная БД (ACID требования)
- Account management сервис
- Transaction processing engine
- Real-time fraud detection

**2. Integration Layer**
- External payment processors
- Regulatory reporting systems
- Credit bureaus
- Third-party APIs

**3. Customer Channels**
- Web banking platform
- Mobile applications
- ATM network
- Call center systems

#### 📝 Задания для выполнения

**Задание 1: CAP Analysis и Trade-offs** *(2 часа)*

Проанализируйте CAP выборы для каждого компонента:

```
┌─────────────────────┬─────────────┬─────────────┬──────────────┐
│     Компонент       │ CAP выбор   │ Обоснование │ Trade-offs   │
├─────────────────────┼─────────────┼─────────────┼──────────────┤
│ Account balances    │     ?       │     ?       │      ?       │
│ Transaction history │     ?       │     ?       │      ?       │
│ User preferences    │     ?       │     ?       │      ?       │
│ Fraud detection     │     ?       │     ?       │      ?       │
│ Audit logs          │     ?       │     ?       │      ?       │
└─────────────────────┴─────────────┴─────────────┴──────────────┘
```

**Задание 2: Fault Tolerance Patterns** *(3 часа)*

Реализуйте resilience patterns для каждого сценария:

1. **Payment Processing Circuit Breaker**
   ```python
   class PaymentCircuitBreaker:
       # Implement circuit breaker for external payment APIs
       # Requirements:
       # - 5 failures in 30 seconds triggers OPEN
       # - 60 second timeout before HALF_OPEN
       # - Fallback to queued processing
   ```

2. **Database Retry Strategy**
   - Exponential backoff для temporary connection failures
   - Different strategies для read vs write operations
   - Maximum retry limits для different error types

3. **Bulkhead Design**
   - Separate thread pools для user queries vs batch processing
   - Resource isolation между channel types
   - Circuit breakers на уровне сервисов

**Задание 3: Backup и Recovery Plan** *(4 часа)*

Создайте comprehensive DR стратегию:

1. **RTO/RPO Analysis**
   ```
   ┌─────────────────┬─────────────┬─────────────┬──────────────┐
   │    Data Type    │     RTO     │     RPO     │   Strategy   │
   ├─────────────────┼─────────────┼─────────────┼──────────────┤
   │ Account data    │   5 min     │  30 sec     │      ?       │
   │ Transactions    │   5 min     │  30 sec     │      ?       │
   │ User sessions   │   30 min    │  15 min     │      ?       │
   │ Configuration   │   1 hour    │  1 hour     │      ?       │
   │ Analytics       │   24 hours  │  24 hours   │      ?       │
   └─────────────────┴─────────────┴─────────────┴──────────────┘
   ```

2. **Multi-Region Architecture**
   - Primary: us-east-1, Secondary: us-west-2
   - Data replication strategy
   - Failover procedures
   - Failback planning

3. **DR Testing Schedule**
   - Monthly: Database restore tests
   - Quarterly: Full region failover
   - Annually: Complete disaster simulation

**Задание 4: Consistency Design** *(3 hours)*

Проработайте consistency requirements:

1. **Strong Consistency Scenarios**
   - Account balance updates
   - Money transfers
   - Credit limit changes

2. **Eventual Consistency Acceptable**
   - User preference updates
   - Marketing data
   - Analytics aggregations

3. **Conflict Resolution**
   - User updating profile от different devices
   - Admin changes vs user changes
   - System updates vs user actions

#### 🎯 Deliverables

**1. Architecture Diagram** 
```
- High-level system architecture
- Data flow диаграммы
- Failure scenarios и recovery paths
- Network topology и security boundaries
```

**2. Resilience Design Document**
```markdown
## Fault Tolerance Strategy

### Circuit Breakers
- Implementation details
- Threshold configurations
- Monitoring и alerting

### Retry Policies
- Service-specific strategies
- Backoff algorithms
- Timeout configurations

### Bulkhead Patterns
- Resource isolation design
- Thread pool configurations
- Connection pool management
```

**3. DR Runbook**
```markdown
## Disaster Recovery Procedures

### Detection
- Monitoring alerts
- Escalation procedures
- Decision criteria

### Response
- Step-by-step recovery procedures
- Rollback plans
- Communication templates
```

**4. Testing Plan**
```
- Unit tests для resilience patterns
- Integration tests для failover scenarios
- Chaos engineering experiments
- Performance testing under degraded conditions
```

#### 📊 Оценочные критерии

**Техническая глубина (40%)**
- Правильное применение CAP теоремы
- Реалистичные RTO/RPO targets
- Comprehensive failure analysis

**Практическая реализуемость (30%)**
- Учет budget constraints
- Operational complexity
- Technology stack alignment

**Compliance и Security (20%)**
- PCI DSS requirements
- Audit trail preservation
- Data encryption strategies

**Документация и Презентация (10%)**
- Clarity архитектурных решений
- Justification of trade-offs
- Completeness of runbooks

#### 🎭 Симуляция сценариев отказов

**Сценарий 1: Primary Database Failure**
```
Timeline:
T+0:00 - Primary DB server crashes
T+0:01 - Health checks detect failure
T+0:02 - Circuit breakers activate
T+0:03 - Replica promotion begins
T+0:05 - Application restart с new connection strings
T+0:06 - Service fully restored

Ваша задача: Detailed analysis каждого шага
```

**Сценарий 2: Cross-Region Network Partition**
```
Timeline:
T+0:00 - Network partition between regions
T+0:01 - West region continues serving traffic
T+0:02 - East region declares emergency mode
T+0:30 - Manual decision to fail over to West
T+2:00 - Full traffic migration completed

Вопросы для анализа:
- Data consistency implications
- Decision making process
- Customer communication strategy
```

**Сценарий 3: Cascading Service Failures**
```
Root cause: High load на fraud detection service
Effect 1: Payment processing slows down
Effect 2: Database connections exhausted
Effect 3: Login service becomes unavailable
Effect 4: Customer support systems fail

Challenge: Design circuit breakers to prevent cascade
```

---

### 🎖️ Итоговая оценка блока

**Проходной балл: 80/100**

**Критерии оценки:**
- **CAP Analysis (25 points):** Правильное понимание trade-offs
- **Resilience Patterns (25 points):** Practical implementation
- **DR Planning (25 points):** Comprehensive recovery strategy  
- **Consistency Design (15 points):** Appropriate consistency choices
- **Documentation (10 points):** Clear communication of design decisions

**Дополнительные баллы (+10):**
- Innovative solutions
- Advanced patterns (CRDT, Consensus)
- Cost optimization strategies
- Automation scripts

---

## 📚 Дополнительные ресурсы

### Книги для углубленного изучения
- **"Designing Data-Intensive Applications"** - Martin Kleppmann (Chapters 5-9)
- **"Release It!"** - Michael Nygard (Stability Patterns)
- **"Building Secure and Reliable Systems"** - Google SRE Team

### Online ресурсы
- **Jepsen.io** - Distributed systems testing
- **Papers We Love** - Academic papers по distributed consensus
- **High Scalability** - Real-world reliability case studies

### Практические инструменты
- **Chaos Monkey** - Netflix fault injection
- **Gremlin** - Chaos engineering platform
- **Consul** - Service discovery с health checking

### Video курсы
- **MIT 6.824** - Distributed Systems
- **University of Washington CSE552** - Distributed Systems

---

**🎓 Результат блока:** После завершения этого блока вы сможете проектировать высоконадежные системы, которые gracefully справляются с различными типами сбоев, и принимать обоснованные решения о trade-offs между консистентностью, доступностью и устойчивостью к разделению сети.