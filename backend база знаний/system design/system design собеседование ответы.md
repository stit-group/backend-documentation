# System Design Interview: –ü–æ–¥—Ä–æ–±–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–æ–¥–∞

*Comprehensive –≥–∞–π–¥ —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏ –¥–ª—è backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤*

---

## üéØ 1. –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### **–í–æ–ø—Ä–æ—Å: –°–ø—Ä–æ–µ–∫—Ç–∏—Ä—É–π—Ç–µ —Å–∏—Å—Ç–µ–º—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ 1M RPS**

#### **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:**

```yaml
# Load Balancer Configuration (Nginx)
upstream backend {
    least_conn;
    server app1:8080 weight=3;
    server app2:8080 weight=3;
    server app3:8080 weight=2;
    keepalive 32;
}

server {
    location / {
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }
}
```

#### **Auto-scaling logic:**

```python
# Auto-scaling decision engine
class AutoScaler:
    def __init__(self):
        self.cpu_threshold = 70
        self.memory_threshold = 80
        self.response_time_threshold = 500  # ms
    
    def should_scale_up(self, metrics):
        return (metrics.cpu > self.cpu_threshold or 
                metrics.memory > self.memory_threshold or
                metrics.avg_response_time > self.response_time_threshold)
    
    def calculate_instances(self, current_rps, target_rps_per_instance=1000):
        # –£—á–∏—Ç—ã–≤–∞–µ–º –∑–∞–ø–∞—Å 20% –¥–ª—è –ø–∏–∫–æ–≤—ã—Ö –Ω–∞–≥—Ä—É–∑–æ–∫
        needed_instances = int((current_rps * 1.2) / target_rps_per_instance)
        return max(needed_instances, 2)  # –º–∏–Ω–∏–º—É–º 2 –∏–Ω—Å—Ç–∞–Ω—Å–∞
```

#### **Trade-offs –∞–Ω–∞–ª–∏–∑:**

| –ü–æ–¥—Ö–æ–¥ | –ü–ª—é—Å—ã | –ú–∏–Ω—É—Å—ã | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|--------|-------|--------|-------------------|
| **Horizontal scaling** | Fault tolerance, linear scale | Complexity, eventual consistency | High traffic, stateless apps |
| **Vertical scaling** | Simplicity, strong consistency | Single point of failure, cost | Monoliths, ACID requirements |
| **Hybrid approach** | Best of both worlds | Complex management | Enterprise applications |

---

## üöÄ 2. –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã

### **–í–æ–ø—Ä–æ—Å: –ö–∞–∫ —Ä–∞–∑–±–∏—Ç—å –º–æ–Ω–æ–ª–∏—Ç –Ω–∞ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã?**

#### **Domain-driven –ø–æ–¥—Ö–æ–¥:**

```python
# Service boundary definition
class OrderService:
    """Manages order lifecycle and business logic"""
    
    async def create_order(self, order_data):
        # 1. Validate order
        if not self.validate_order(order_data):
            raise OrderValidationError()
        
        # 2. Reserve inventory (sync call)
        inventory_reserved = await self.inventory_service.reserve_items(
            order_data.items
        )
        
        # 3. Process payment (async)
        payment_event = PaymentRequestEvent(
            order_id=order.id,
            amount=order.total_amount
        )
        await self.event_bus.publish(payment_event)
        
        # 4. Create order in pending state
        return await self.order_repository.create(order_data)

# Event-driven communication
class EventBus:
    async def publish(self, event):
        # –ù–∞–¥–µ–∂–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞ —á–µ—Ä–µ–∑ message queue
        await self.message_queue.send(
            topic=event.type,
            message=event.serialize(),
            retry_policy=ExponentialBackoff(max_retries=3)
        )
```

#### **Service communication patterns:**

```python
# Saga pattern –¥–ª—è distributed transactions
class OrderSaga:
    def __init__(self):
        self.steps = [
            ('inventory', 'reserve_items'),
            ('payment', 'charge_card'),
            ('shipping', 'create_shipment'),
            ('notification', 'send_confirmation')
        ]
    
    async def execute(self, order_data):
        completed_steps = []
        
        try:
            for service, action in self.steps:
                result = await self.call_service(service, action, order_data)
                completed_steps.append((service, action, result))
                
        except Exception as e:
            # Compensating actions –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
            await self.rollback(completed_steps)
            raise SagaExecutionError(f"Failed at {service}.{action}")
    
    async def rollback(self, completed_steps):
        for service, action, result in reversed(completed_steps):
            compensating_action = f"cancel_{action}"
            await self.call_service(service, compensating_action, result)
```

#### **API Gateway pattern:**

```python
# Rate limiting and routing
class APIGateway:
    def __init__(self):
        self.rate_limiter = TokenBucket()
        self.circuit_breaker = CircuitBreaker()
    
    async def route_request(self, request):
        # 1. Authentication & Authorization
        user = await self.authenticate(request.headers['Authorization'])
        if not self.authorize(user, request.path):
            return Response(status=403)
        
        # 2. Rate limiting
        if not self.rate_limiter.allow_request(user.id):
            return Response(status=429)
        
        # 3. Service discovery and routing
        service = self.discover_service(request.path)
        
        # 4. Circuit breaker protection
        return await self.circuit_breaker.call(
            service.handle_request, request
        )
```

---

## üíæ 3. –î–∞–Ω–Ω—ã–µ –∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å

### **–í–æ–ø—Ä–æ—Å: SQL vs NoSQL - –∫–∞–∫ –≤—ã–±—Ä–∞—Ç—å?**

#### **Decision matrix:**

```python
class DatabaseSelector:
    def choose_database(self, requirements):
        score_sql = 0
        score_nosql = 0
        
        # ACID requirements
        if requirements.needs_transactions:
            score_sql += 3
        
        # Schema flexibility
        if requirements.schema_changes_frequent:
            score_nosql += 2
        
        # Scale requirements
        if requirements.read_scale > 10000:
            score_nosql += 2
        
        # Consistency requirements
        if requirements.consistency_level == 'strong':
            score_sql += 3
        elif requirements.consistency_level == 'eventual':
            score_nosql += 2
            
        return 'SQL' if score_sql > score_nosql else 'NoSQL'
```

#### **Sharding strategies:**

```python
# Hash-based sharding
class ShardManager:
    def __init__(self, shard_count=16):
        self.shard_count = shard_count
        self.shards = [f"shard_{i}" for i in range(shard_count)]
    
    def get_shard(self, user_id):
        # Consistent hashing
        shard_index = hash(str(user_id)) % self.shard_count
        return self.shards[shard_index]
    
    def redistribute_shards(self, new_shard_count):
        # –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–º–µ—â–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        migration_plan = []
        for old_shard in range(self.shard_count):
            new_shard = old_shard % new_shard_count
            if old_shard != new_shard:
                migration_plan.append((old_shard, new_shard))
        return migration_plan

# Range-based sharding –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
class TimeBasedSharding:
    def get_shard(self, timestamp):
        # –ü–æ –º–µ—Å—è—Ü–∞–º –¥–ª—è log –¥–∞–Ω–Ω—ã—Ö
        year_month = timestamp.strftime('%Y_%m')
        return f"logs_{year_month}"
```

#### **CAP theorem –≤ –¥–µ–π—Å—Ç–≤–∏–∏:**

```python
# Eventual consistency –ø—Ä–∏–º–µ—Ä
class EventuallyConsistentCache:
    def __init__(self):
        self.local_cache = {}
        self.write_queue = asyncio.Queue()
        self.sync_interval = 30  # —Å–µ–∫—É–Ω–¥
    
    async def write(self, key, value):
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ —Å—Ä–∞–∑—É (Available)
        self.local_cache[key] = value
        
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º (Eventually Consistent)
        await self.write_queue.put((key, value, time.time()))
        
    async def sync_worker(self):
        while True:
            try:
                key, value, timestamp = await self.write_queue.get()
                # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
                await self.persistent_store.write(key, value)
                
            except NetworkError:
                # Partition tolerance - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å
                # Retry –ø–æ–∑–∂–µ
                await asyncio.sleep(self.sync_interval)
                await self.write_queue.put((key, value, timestamp))
```

---

## ‚ö° 4. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### **Multi-level caching strategy:**

```python
class CacheManager:
    def __init__(self):
        self.l1_cache = {}  # In-memory
        self.l2_cache = RedisClient()  # Distributed
        self.l3_cache = CDNClient()  # Edge
    
    async def get(self, key):
        # L1: Application cache
        if key in self.l1_cache:
            return self.l1_cache[key]
        
        # L2: Redis cache
        value = await self.l2_cache.get(key)
        if value:
            self.l1_cache[key] = value  # Populate L1
            return value
        
        # L3: Database
        value = await self.database.get(key)
        if value:
            # Populate all cache levels
            self.l1_cache[key] = value
            await self.l2_cache.set(key, value, ttl=3600)
            return value
        
        return None
    
    async def invalidate(self, key):
        # Invalidate all levels
        self.l1_cache.pop(key, None)
        await self.l2_cache.delete(key)
        await self.l3_cache.purge(key)
```

#### **Cache warming strategy:**

```python
class CacheWarmer:
    async def warm_popular_content(self):
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
        popular_items = await self.analytics.get_trending_items(limit=1000)
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ–≤
        tasks = [
            self.cache_manager.preload(item.id, item.data)
            for item in popular_items
        ]
        
        await asyncio.gather(*tasks, return_exceptions=True)
    
    async def predictive_warming(self, user_id):
        # ML-based –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —á—Ç–æ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        predictions = await self.ml_service.predict_user_interests(user_id)
        
        for item_id in predictions[:50]:  # Top 50 predictions
            await self.cache_manager.preload(item_id)
```

---

## üõ°Ô∏è 5. –û—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å

### **Circuit Breaker pattern:**

```python
class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout=60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN
    
    async def call(self, func, *args, **kwargs):
        if self.state == 'OPEN':
            if time.time() - self.last_failure_time > self.timeout:
                self.state = 'HALF_OPEN'
            else:
                raise CircuitBreakerOpenError()
        
        try:
            result = await func(*args, **kwargs)
            
            # Success - reset failure count
            if self.state == 'HALF_OPEN':
                self.state = 'CLOSED'
            self.failure_count = 0
            
            return result
            
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()
            
            if self.failure_count >= self.failure_threshold:
                self.state = 'OPEN'
            
            raise e
```

#### **Retry with exponential backoff:**

```python
class RetryManager:
    async def execute_with_retry(self, func, max_retries=3, base_delay=1):
        for attempt in range(max_retries + 1):
            try:
                return await func()
                
            except TransientError as e:
                if attempt == max_retries:
                    raise e
                
                # Exponential backoff —Å jitter
                delay = base_delay * (2 ** attempt)
                jitter = random.uniform(0.1, 0.9)
                await asyncio.sleep(delay * jitter)
                
            except PermanentError:
                # –ù–µ —Ä–µ—Ç—Ä–∞–∏–º permanent –æ—à–∏–±–∫–∏
                raise
```

#### **Graceful degradation:**

```python
class FeatureToggle:
    def __init__(self):
        self.features = {
            'recommendations': {'enabled': True, 'fallback': 'popular_items'},
            'real_time_notifications': {'enabled': True, 'fallback': 'email_digest'},
            'advanced_search': {'enabled': True, 'fallback': 'basic_search'}
        }
    
    async def get_recommendations(self, user_id):
        if self.is_enabled('recommendations'):
            try:
                return await self.ml_service.get_recommendations(user_id)
            except ServiceUnavailable:
                # Fallback to simple logic
                return await self.get_popular_items()
        else:
            return await self.get_popular_items()
    
    def is_enabled(self, feature):
        return self.features.get(feature, {}).get('enabled', False)
```

---

## üìä 6. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏

### **Application metrics:**

```python
class MetricsCollector:
    def __init__(self):
        self.counters = defaultdict(int)
        self.timers = defaultdict(list)
        self.gauges = defaultdict(float)
    
    @contextmanager
    def time_operation(self, operation_name):
        start_time = time.time()
        try:
            yield
        finally:
            duration = time.time() - start_time
            self.timers[operation_name].append(duration)
            
            # SLA monitoring
            if duration > self.get_sla_threshold(operation_name):
                self.counters[f"{operation_name}_sla_violations"] += 1
    
    async def export_metrics(self):
        return {
            'counters': dict(self.counters),
            'timers_p95': {
                name: np.percentile(times, 95) 
                for name, times in self.timers.items()
            },
            'gauges': dict(self.gauges)
        }

# Usage example
@metrics.time_operation('user_authentication')
async def authenticate_user(token):
    # Implementation
    pass
```

#### **Health checks:**

```python
class HealthChecker:
    def __init__(self):
        self.checks = {
            'database': self.check_database,
            'redis': self.check_redis,
            'external_api': self.check_external_services
        }
    
    async def health_status(self):
        results = {}
        overall_healthy = True
        
        for name, check_func in self.checks.items():
            try:
                await asyncio.wait_for(check_func(), timeout=5.0)
                results[name] = {'status': 'healthy', 'response_time': '< 5s'}
            except Exception as e:
                results[name] = {'status': 'unhealthy', 'error': str(e)}
                overall_healthy = False
        
        return {
            'status': 'healthy' if overall_healthy else 'degraded',
            'checks': results,
            'timestamp': datetime.utcnow().isoformat()
        }
```

---

## üé™ 7. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏

### **Social Feed Generation:**

```python
class FeedGenerator:
    def __init__(self):
        self.fan_out_threshold = 1000  # followers
    
    async def generate_feed(self, user_id, limit=50):
        # Hybrid pull/push approach
        user = await self.user_service.get_user(user_id)
        
        if user.followers_count > self.fan_out_threshold:
            # Pull model –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            return await self.pull_feed(user_id, limit)
        else:
            # Push model –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            return await self.get_precomputed_feed(user_id, limit)
    
    async def pull_feed(self, user_id, limit):
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ–¥–ø–∏—Å–æ–∫
        following = await self.get_following(user_id)
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ—Å—Ç—ã
        tasks = [
            self.get_recent_posts(followed_id, limit=10)
            for followed_id in following[:100]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
        ]
        
        all_posts = await asyncio.gather(*tasks)
        
        # Merge –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        merged_posts = sorted(
            [post for posts in all_posts for post in posts],
            key=lambda x: x.created_at,
            reverse=True
        )
        
        return merged_posts[:limit]
```

### **Real-time Chat System:**

```python
class ChatServer:
    def __init__(self):
        self.connections = {}  # user_id -> websocket
        self.rooms = defaultdict(set)  # room_id -> {user_ids}
    
    async def handle_message(self, websocket, message):
        data = json.loads(message)
        
        if data['type'] == 'join_room':
            await self.join_room(websocket, data['room_id'], data['user_id'])
        
        elif data['type'] == 'send_message':
            await self.broadcast_message(data['room_id'], data)
    
    async def broadcast_message(self, room_id, message):
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∫–æ–º–Ω–∞—Ç—ã
        participants = self.rooms[room_id]
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞
        tasks = []
        for user_id in participants:
            if user_id in self.connections:
                websocket = self.connections[user_id]
                tasks.append(self.send_safe(websocket, message))
        
        await asyncio.gather(*tasks, return_exceptions=True)
        
        # Persist message –¥–ª—è offline –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        await self.message_store.save(message)
    
    async def send_safe(self, websocket, message):
        try:
            await websocket.send(json.dumps(message))
        except ConnectionClosed:
            # Cleanup disconnected user
            await self.cleanup_connection(websocket)
```

---

## üö® –¢–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏ —Ä–µ—à–µ–Ω–∏—è

### **1. Overengineering:**
```python
# ‚ùå –ü–ª–æ—Ö–æ: Premature optimization
class UserService:
    def __init__(self):
        self.cache = RedisCluster(nodes=50)
        self.database = ShardedDatabase(shards=100)
        self.event_bus = KafkaCluster(brokers=20)

# ‚úÖ –•–æ—Ä–æ—à–æ: Start simple, scale when needed
class UserService:
    def __init__(self):
        self.database = PostgreSQL()
        self.cache = Redis()  # Single instance
    
    def get_user(self, user_id):
        # –ü—Ä–æ—Å—Ç–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
        cached = self.cache.get(f"user:{user_id}")
        if cached:
            return json.loads(cached)
        
        user = self.database.get_user(user_id)
        self.cache.setex(f"user:{user_id}", 3600, json.dumps(user))
        return user
```

### **2. Ignoring CAP theorem:**
```python
# ‚ùå –ü–ª–æ—Ö–æ: Expecting strong consistency everywhere
async def transfer_money(from_account, to_account, amount):
    # –≠—Ç–æ –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ distributed —Å–∏—Å—Ç–µ–º–µ
    await self.accounts_db.decrease_balance(from_account, amount)
    await self.accounts_db.increase_balance(to_account, amount)

# ‚úÖ –•–æ—Ä–æ—à–æ: Use transactions or sagas
async def transfer_money(from_account, to_account, amount):
    async with self.database.transaction():
        await self.accounts_db.decrease_balance(from_account, amount)
        await self.accounts_db.increase_balance(to_account, amount)
```

---

## üéØ –ö–ª—é—á–µ–≤—ã–µ takeaways

1. **–í—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π—Ç–µ —Å –ø—Ä–æ—Å—Ç–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è** - –ø—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ—Ä–µ–Ω—å –∑–ª–∞
2. **–£—á–∏—Ç—ã–≤–∞–π—Ç–µ trade-offs** - –Ω–µ—Ç —Å–µ—Ä–µ–±—Ä—è–Ω–æ–π –ø—É–ª–∏, –≤—Å–µ —Ä–µ—à–µ–Ω–∏—è –∏–º–µ—é—Ç –∫–æ–º–ø—Ä–æ–º–∏—Å—Å—ã  
3. **–î—É–º–∞–π—Ç–µ –æ failure modes** - —á—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –∫–æ–≥–¥–∞ —á—Ç–æ-—Ç–æ —Å–ª–æ–º–∞–µ—Ç—Å—è?
4. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞** - –Ω–µ–ª—å–∑—è —É–ª—É—á—à–∏—Ç—å —Ç–æ, —á—Ç–æ –Ω–µ –∏–∑–º–µ—Ä—è–µ—à—å
5. **–ó–Ω–∞–π—Ç–µ —Å–≤–æ–∏ numbers** - latency, throughput, storage requirements

**–ü–æ–º–Ω–∏—Ç–µ:** –õ—É—á—à–∏–π system design - —Ç–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ—à–∞–µ—Ç –±–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á–∏ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π complexity!