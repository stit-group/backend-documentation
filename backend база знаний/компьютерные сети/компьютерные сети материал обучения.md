            await self._send_error(connection, "Authentication token required")
            self.stats['authentication_failures'] += 1
            return
        
        try:
            # Ð”ÐµÐºÐ¾Ð´Ð¸Ñ€ÑƒÐµÐ¼ JWT Ñ‚Ð¾ÐºÐµÐ½
            payload = jwt.decode(token, self.jwt_secret, algorithms=['HS256'])
            
            user_id = payload.get('user_id')
            if not user_id:
                await self._send_error(connection, "Invalid token payload")
                self.stats['authentication_failures'] += 1
                return
            
            # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸ÑŽ
            connection.user_id = user_id
            connection.authenticated = True
            connection.state = ConnectionState.AUTHENTICATED
            
            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ
            await self._send_message(connection, {
                'type': 'auth_success',
                'user_id': user_id,
                'connection_id': connection.id
            })
            
            self.logger.info(f"Connection {connection.id} authenticated as user {user_id}")
        
        except jwt.InvalidTokenError:
            await self._send_error(connection, "Invalid authentication token")
            self.stats['authentication_failures'] += 1
        
        except Exception as e:
            self.logger.error(f"Authentication error for {connection.id}: {e}")
            await self._send_error(connection, "Authentication failed")
            self.stats['authentication_failures'] += 1
    
    async def _handle_subscribe(self, connection: WebSocketConnection, message: Dict):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸ Ð½Ð° Ñ‚Ð¾Ð¿Ð¸Ðº"""
        
        topic = message.get('topic')
        
        if not topic:
            await self._send_error(connection, "Topic name required")
            return
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ñ€Ð°Ð²Ð° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº Ñ‚Ð¾Ð¿Ð¸ÐºÑƒ
        if not await self._check_topic_access(connection, topic):
            await self._send_error(connection, f"Access denied to topic: {topic}")
            return
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ
        if topic not in self.subscriptions:
            self.subscriptions[topic] = Subscription(topic=topic)
        
        self.subscriptions[topic].connections.add(connection.id)
        connection.subscriptions.add(topic)
        
        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ
        await self._send_message(connection, {
            'type': 'subscribed',
            'topic': topic,
            'subscriber_count': len(self.subscriptions[topic].connections)
        })
        
        self.logger.debug(f"Connection {connection.id} subscribed to {topic}")
    
    async def _handle_unsubscribe(self, connection: WebSocketConnection, message: Dict):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ñ‚Ð¿Ð¸ÑÐºÐ¸ Ð¾Ñ‚ Ñ‚Ð¾Ð¿Ð¸ÐºÐ°"""
        
        topic = message.get('topic')
        
        if not topic:
            await self._send_error(connection, "Topic name required")
            return
        
        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÑƒ
        if topic in self.subscriptions:
            self.subscriptions[topic].connections.discard(connection.id)
            
            # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ñ‚Ð¾Ð¿Ð¸Ðº ÐµÑÐ»Ð¸ Ð½ÐµÑ‚ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð²
            if not self.subscriptions[topic].connections:
                del self.subscriptions[topic]
        
        connection.subscriptions.discard(topic)
        
        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ
        await self._send_message(connection, {
            'type': 'unsubscribed',
            'topic': topic
        })
        
        self.logger.debug(f"Connection {connection.id} unsubscribed from {topic}")
    
    async def _handle_data(self, connection: WebSocketConnection, message: Dict):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
        
        # Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð² Ñ‚Ð¾Ð¿Ð¸Ðº Ð¸Ð»Ð¸ Ð´Ñ€ÑƒÐ³Ð°Ñ Ð±Ð¸Ð·Ð½ÐµÑ-Ð»Ð¾Ð³Ð¸ÐºÐ°
        topic = message.get('topic')
        data = message.get('data')
        
        if topic and data:
            await self.broadcast_to_topic(topic, {
                'type': 'data',
                'topic': topic,
                'data': data,
                'sender': connection.user_id,
                'timestamp': time.time()
            }, exclude_connection=connection.id)
    
    async def _handle_heartbeat(self, connection: WebSocketConnection, message: Dict):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° heartbeat"""
        
        connection.last_activity = time.time()
        
        await self._send_message(connection, {
            'type': 'heartbeat_ack',
            'timestamp': time.time()
        })
    
    async def _check_topic_access(self, connection: WebSocketConnection, topic: str) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿Ñ€Ð°Ð² Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº Ñ‚Ð¾Ð¿Ð¸ÐºÑƒ"""
        
        # Ð—Ð´ÐµÑÑŒ Ð¼Ð¾Ð¶Ð½Ð¾ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ»Ð¾Ð¶Ð½ÑƒÑŽ Ð»Ð¾Ð³Ð¸ÐºÑƒ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        # ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿Ð¾ Ñ€Ð¾Ð»ÑÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ, ACL, Ð¸ Ñ‚.Ð´.
        
        # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ°: Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¼Ð¾Ð³ÑƒÑ‚ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‹Ð²Ð°Ñ‚ÑŒÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° ÑÐ²Ð¾Ð¸ Ñ‚Ð¾Ð¿Ð¸ÐºÐ¸
        if connection.user_id and topic.startswith(f"user.{connection.user_id}"):
            return True
        
        # ÐŸÑƒÐ±Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ñ‚Ð¾Ð¿Ð¸ÐºÐ¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹ Ð²ÑÐµÐ¼
        if topic.startswith("public."):
            return True
        
        # ÐÐ´Ð¼Ð¸Ð½Ñ‹ Ð¸Ð¼ÐµÑŽÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿ ÐºÐ¾ Ð²ÑÐµÐ¼ Ñ‚Ð¾Ð¿Ð¸ÐºÐ°Ð¼
        if connection.metadata.get('role') == 'admin':
            return True
        
        return False
    
    async def _send_message(self, connection: WebSocketConnection, message: Dict):
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ"""
        
        try:
            json_message = json.dumps(message)
            await connection.websocket.send(json_message)
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
            connection.messages_sent += 1
            connection.bytes_sent += len(json_message)
            
        except websockets.exceptions.ConnectionClosed:
            # Ð¡Ð¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ ÑƒÐ¶Ðµ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¾
            pass
        except Exception as e:
            self.logger.error(f"Error sending message to {connection.id}: {e}")
    
    async def _send_error(self, connection: WebSocketConnection, error_message: str):
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¾Ð± Ð¾ÑˆÐ¸Ð±ÐºÐµ"""
        
        await self._send_message(connection, {
            'type': 'error',
            'message': error_message,
            'timestamp': time.time()
        })
    
    async def broadcast_to_topic(self, topic: str, message: Dict, exclude_connection: Optional[str] = None):
        """Ð Ð°ÑÑÑ‹Ð»ÐºÐ° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð²ÑÐµÐ¼ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ°Ð¼ Ñ‚Ð¾Ð¿Ð¸ÐºÐ°"""
        
        if topic not in self.subscriptions:
            return
        
        subscription = self.subscriptions[topic]
        subscription.message_count += 1
        subscription.last_message_time = time.time()
        
        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð²ÑÐµÐ¼ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ°Ð¼
        disconnected_connections = []
        
        for connection_id in subscription.connections:
            if connection_id == exclude_connection:
                continue
            
            if connection_id in self.connections:
                connection = self.connections[connection_id]
                try:
                    await self._send_message(connection, message)
                except:
                    # ÐŸÐ¾Ð¼ÐµÑ‡Ð°ÐµÐ¼ Ð´Ð»Ñ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ
                    disconnected_connections.append(connection_id)
        
        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ‹Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
        for connection_id in disconnected_connections:
            subscription.connections.discard(connection_id)
    
    async def broadcast_to_all(self, message: Dict, exclude_connection: Optional[str] = None):
        """Ð Ð°ÑÑÑ‹Ð»ÐºÐ° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð²ÑÐµÐ¼ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ‹Ð¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°Ð¼"""
        
        disconnected_connections = []
        
        for connection_id, connection in self.connections.items():
            if connection_id == exclude_connection:
                continue
            
            try:
                await self._send_message(connection, message)
            except:
                disconnected_connections.append(connection_id)
        
        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ‹Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
        for connection_id in disconnected_connections:
            await self._cleanup_connection(connection_id)
    
    async def _cleanup_connection(self, connection_id: str):
        """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ"""
        
        if connection_id not in self.connections:
            return
        
        connection = self.connections[connection_id]
        
        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¸Ð· Ð²ÑÐµÑ… Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ¾Ðº
        for topic in list(connection.subscriptions):
            if topic in self.subscriptions:
                self.subscriptions[topic].connections.discard(connection_id)
                
                # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ñ‚Ð¾Ð¿Ð¸Ðº ÐµÑÐ»Ð¸ Ð½ÐµÑ‚ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð²
                if not self.subscriptions[topic].connections:
                    del self.subscriptions[topic]
        
        # Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ WebSocket ÐµÑÐ»Ð¸ ÐµÑ‰Ðµ Ð½Ðµ Ð·Ð°ÐºÑ€Ñ‹Ñ‚
        if not connection.websocket.closed:
            try:
                await connection.websocket.close()
            except:
                pass
        
        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ
        del self.connections[connection_id]
        self.stats['current_connections'] -= 1
        
        self.logger.info(f"Cleaned up connection {connection_id}")
    
    async def _cleanup_loop(self):
        """Ð¤Ð¾Ð½Ð¾Ð²Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ Ð½ÐµÐ°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹"""
        
        while True:
            try:
                current_time = time.time()
                cleanup_connections = []
                
                for connection_id, connection in self.connections.items():
                    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð½ÐµÐ°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸
                    if current_time - connection.last_activity > self.connection_timeout:
                        cleanup_connections.append(connection_id)
                
                # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð½ÐµÐ°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
                for connection_id in cleanup_connections:
                    await self._cleanup_connection(connection_id)
                    self.logger.info(f"Cleaned up inactive connection {connection_id}")
                
                await asyncio.sleep(60)  # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ°Ð¶Ð´ÑƒÑŽ Ð¼Ð¸Ð½ÑƒÑ‚Ñƒ
            
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"Error in cleanup loop: {e}")
                await asyncio.sleep(60)
    
    async def _heartbeat_loop(self):
        """Ð¤Ð¾Ð½Ð¾Ð²Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ heartbeat"""
        
        while True:
            try:
                # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ heartbeat Ð²ÑÐµÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸ÑÐ¼
                heartbeat_message = {
                    'type': 'heartbeat',
                    'timestamp': time.time(),
                    'server_stats': {
                        'connections': len(self.connections),
                        'uptime': time.time() - self.stats.get('start_time', time.time())
                    }
                }
                
                await self.broadcast_to_all(heartbeat_message)
                
                await asyncio.sleep(self.heartbeat_interval)
            
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"Error in heartbeat loop: {e}")
                await asyncio.sleep(self.heartbeat_interval)
    
    def get_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        connection_stats = {}
        total_messages_sent = 0
        total_messages_received = 0
        total_bytes_sent = 0
        total_bytes_received = 0
        
        for connection in self.connections.values():
            total_messages_sent += connection.messages_sent
            total_messages_received += connection.messages_received
            total_bytes_sent += connection.bytes_sent
            total_bytes_received += connection.bytes_received
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ¾Ðº
        subscription_stats = {
            topic: {
                'subscribers': len(sub.connections),
                'messages_sent': sub.message_count,
                'last_message': sub.last_message_time
            }
            for topic, sub in self.subscriptions.items()
        }
        
        return {
            **self.stats,
            'connections': {
                'current': len(self.connections),
                'authenticated': len([c for c in self.connections.values() if c.authenticated]),
                'messages_sent': total_messages_sent,
                'messages_received': total_messages_received,
                'bytes_sent': total_bytes_sent,
                'bytes_received': total_bytes_received
            },
            'subscriptions': {
                'total_topics': len(self.subscriptions),
                'topics': subscription_stats
            }
        }
    
    async def shutdown(self):
        """Graceful shutdown ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        
        self.logger.info("Shutting down WebSocket server...")
        
        # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ñ„Ð¾Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
        if self.cleanup_task:
            self.cleanup_task.cancel()
        
        if self.heartbeat_task:
            self.heartbeat_task.cancel()
        
        # Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð²ÑÐµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
        shutdown_message = {
            'type': 'server_shutdown',
            'message': 'Server is shutting down',
            'timestamp': time.time()
        }
        
        await self.broadcast_to_all(shutdown_message)
        
        # Ð–Ð´ÐµÐ¼ Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
        await asyncio.sleep(1)
        
        # ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð·Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð²ÑÐµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
        for connection_id in list(self.connections.keys()):
            await self._cleanup_connection(connection_id)
        
        self.logger.info("WebSocket server shutdown completed")

# gRPC Implementation
import grpc
from concurrent import futures
import threading

# ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Protocol Buffer ÑÑ…ÐµÐ¼Ñƒ (Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ .proto Ñ„Ð°Ð¹Ð»Ðµ)
PROTO_DEFINITION = """
syntax = "proto3";

package api;

service UserService {
    rpc GetUser(GetUserRequest) returns (User);
    rpc CreateUser(CreateUserRequest) returns (User);
    rpc UpdateUser(UpdateUserRequest) returns (User);
    rpc DeleteUser(DeleteUserRequest) returns (DeleteUserResponse);
    rpc ListUsers(ListUsersRequest) returns (stream User);
    rpc StreamUserUpdates(StreamUserUpdatesRequest) returns (stream UserUpdate);
}

message User {
    string id = 1;
    string name = 2;
    string email = 3;
    int64 created_at = 4;
    int64 updated_at = 5;
}

message GetUserRequest {
    string id = 1;
}

message CreateUserRequest {
    string name = 1;
    string email = 2;
}

message UpdateUserRequest {
    string id = 1;
    string name = 2;
    string email = 3;
}

message DeleteUserRequest {
    string id = 1;
}

message DeleteUserResponse {
    bool success = 1;
    string message = 2;
}

message ListUsersRequest {
    int32 page = 1;
    int32 page_size = 2;
}

message StreamUserUpdatesRequest {
    repeated string user_ids = 1;
}

message UserUpdate {
    string user_id = 1;
    string update_type = 2;
    User user = 3;
    int64 timestamp = 4;
}
"""

class AdvancedGRPCServer:
    """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ gRPC ÑÐµÑ€Ð²ÐµÑ€ Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð¾Ð¼ Ð¸ middleware"""
    
    def __init__(self, port: int = 50051):
        self.port = port
        self.server = None
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
        self.stats = {
            'total_requests': 0,
            'requests_by_method': defaultdict(int),
            'active_streams': 0,
            'errors': defaultdict(int),
            'avg_response_time': 0.0,
            'response_times': deque(maxlen=1000)
        }
        
        # Middleware
        self.interceptors = []
        
        self.logger = logging.getLogger('gRPCServer')
        
        # User storage (Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸ ÑÑ‚Ð¾ Ð±Ñ‹Ð»Ð° Ð±Ñ‹ Ð‘Ð”)
        self.users = {}
        self.user_counter = 0
        
        # Streaming subscribers
        self.stream_subscribers = defaultdict(list)
    
    def add_interceptor(self, interceptor):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ interceptor middleware"""
        self.interceptors.append(interceptor)
    
    async def start(self):
        """Ð—Ð°Ð¿ÑƒÑÐº gRPC ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€ Ñ interceptors
        self.server = grpc.aio.server(
            futures.ThreadPoolExecutor(max_workers=10),
            interceptors=self.interceptors
        )
        
        # Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ ÑÐµÑ€Ð²Ð¸Ñ
        # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸ Ð·Ð´ÐµÑÑŒ Ð±Ñ‹Ð» Ð±Ñ‹ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÐºÐ¾Ð´ Ð¸Ð· .proto
        # user_service_pb2_grpc.add_UserServiceServicer_to_server(self, self.server)
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ñ€Ñ‚
        listen_addr = f'[::]:{self.port}'
        self.server.add_insecure_port(listen_addr)
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€
        await self.server.start()
        self.logger.info(f"gRPC server started on port {self.port}")
        
        # Ð–Ð´ÐµÐ¼ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ
        await self.server.wait_for_termination()
    
    async def GetUser(self, request, context):
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¿Ð¾ ID"""
        
        self._record_request("GetUser")
        
        user_id = request.id
        
        if user_id not in self.users:
            context.set_code(grpc.StatusCode.NOT_FOUND)
            context.set_details(f"User {user_id} not found")
            return None
        
        user_data = self.users[user_id]
        
        # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ User Ð¾Ð±ÑŠÐµÐºÑ‚ (Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ ÑÑ‚Ð¾ Ð±Ñ‹Ð» Ð±Ñ‹ protobuf Ð¾Ð±ÑŠÐµÐºÑ‚)
        return {
            'id': user_data['id'],
            'name': user_data['name'],
            'email': user_data['email'],
            'created_at': user_data['created_at'],
            'updated_at': user_data['updated_at']
        }
    
    async def CreateUser(self, request, context):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ"""
        
        self._record_request("CreateUser")
        
        # Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
        if not request.name or not request.email:
            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
            context.set_details("Name and email are required")
            return None
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        self.user_counter += 1
        user_id = str(self.user_counter)
        
        current_time = int(time.time())
        
        user_data = {
            'id': user_id,
            'name': request.name,
            'email': request.email,
            'created_at': current_time,
            'updated_at': current_time
        }
        
        self.users[user_id] = user_data
        
        # Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÑÐµÐ¼ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð² Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸
        await self._notify_user_update(user_id, "created", user_data)
        
        return user_data
    
    async def UpdateUser(self, request, context):
        """ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ"""
        
        self._record_request("UpdateUser")
        
        user_id = request.id
        
        if user_id not in self.users:
            context.set_code(grpc.StatusCode.NOT_FOUND)
            context.set_details(f"User {user_id} not found")
            return None
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        user_data = self.users[user_id]
        
        if request.name:
            user_data['name'] = request.name
        
        if request.email:
            user_data['email'] = request.email
        
        user_data['updated_at'] = int(time.time())
        
        # Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÑÐµÐ¼ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð² Ð¾Ð± Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¸
        await self._notify_user_update(user_id, "updated", user_data)
        
        return user_data
    
    async def DeleteUser(self, request, context):
        """Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ"""
        
        self._record_request("DeleteUser")
        
        user_id = request.id
        
        if user_id not in self.users:
            context.set_code(grpc.StatusCode.NOT_FOUND)
            context.set_details(f"User {user_id} not found")
            return {'success': False, 'message': 'User not found'}
        
        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        del self.users[user_id]
        
        # Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÑÐµÐ¼ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð² Ð¾Ð± ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ð¸
        await self._notify_user_update(user_id, "deleted", None)
        
        return {'success': True, 'message': 'User deleted successfully'}
    
    async def ListUsers(self, request, context):
        """Streaming ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹"""
        
        self._record_request("ListUsers")
        self.stats['active_streams'] += 1
        
        try:
            page = max(1, request.page)
            page_size = min(100, max(1, request.page_size))
            
            start_idx = (page - 1) * page_size
            end_idx = start_idx + page_size
            
            user_list = list(self.users.values())
            page_users = user_list[start_idx:end_idx]
            
            for user_data in page_users:
                yield user_data
                
                # ÐÐµÐ±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ streaming
                await asyncio.sleep(0.1)
        
        finally:
            self.stats['active_streams'] -= 1
    
    async def StreamUserUpdates(self, request, context):
        """Streaming Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹"""
        
        self._record_request("StreamUserUpdates")
        self.stats['active_streams'] += 1
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ stream
        update_queue = asyncio.Queue()
        
        # ÐŸÐ¾Ð´Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ÑÑ Ð½Ð° Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ
        for user_id in request.user_ids:
            self.stream_subscribers[user_id].append(update_queue)
        
        try:
            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ updates Ð¸Ð· Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸
            while True:
                try:
                    update = await asyncio.wait_for(update_queue.get(), timeout=30)
                    yield update
                
                except asyncio.TimeoutError:
                    # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ heartbeat
                    yield {
                        'user_id': '',
                        'update_type': 'heartbeat',
                        'user': None,
                        'timestamp': int(time.time())
                    }
        
        except asyncio.CancelledError:
            pass
        
        finally:
            # ÐžÑ‚Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ÑÑ Ð¾Ñ‚ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¹
            for user_id in request.user_ids:
                if update_queue in self.stream_subscribers[user_id]:
                    self.stream_subscribers[user_id].remove(update_queue)
            
            self.stats['active_streams'] -= 1
    
    async def _notify_user_update(self, user_id: str, update_type: str, user_data: Optional[Dict]):
        """Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð² Ð¾Ð± Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ"""
        
        if user_id not in self.stream_subscribers:
            return
        
        update_message = {
            'user_id': user_id,
            'update_type': update_type,
            'user': user_data,
            'timestamp': int(time.time())
        }
        
        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð²ÑÐµÐ¼ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ°Ð¼
        for queue in self.stream_subscribers[user_id]:
            try:
                await queue.put(update_message)
            except:
                pass  # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ð¾Ñ‡ÐµÑ€ÐµÐ´ÐµÐ¹
    
    def _record_request(self, method_name: str):
        """Ð—Ð°Ð¿Ð¸ÑÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°"""
        
        self.stats['total_requests'] += 1
        self.stats['requests_by_method'][method_name] += 1
    
    def get_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        
        return {
            'total_requests': self.stats['total_requests'],
            'requests_by_method': dict(self.stats['requests_by_method']),
            'active_streams': self.stats['active_streams'],
            'total_users': len(self.users),
            'stream_subscribers': len(self.stream_subscribers),
            'errors': dict(self.stats['errors'])
        }
    
    async def shutdown(self):
        """Graceful shutdown ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        
        if self.server:
            await self.server.stop(grace=5)
            self.logger.info("gRPC server shutdown completed")

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ð¾Ð²
async def demonstrate_modern_protocols():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ WebSocket Ð¸ gRPC"""
    
    print("ðŸš€ Modern Network Protocols Demonstration")
    print("=" * 60)
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ JWT Ñ‚Ð¾ÐºÐµÐ½ Ð´Ð»Ñ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
    import jwt
    
    jwt_secret = "your-secret-key"
    auth_token = jwt.encode({
        'user_id': 'demo_user_123',
        'role': 'user',
        'exp': int(time.time()) + 3600  # 1 Ñ‡Ð°Ñ
    }, jwt_secret, algorithm='HS256')
    
    print(f"ðŸ” Generated auth token: {auth_token[:50]}...")
    
    # Ð—Ð°Ð¿ÑƒÑÐº WebSocket ÑÐµÑ€Ð²ÐµÑ€Ð°
    print(f"\nðŸ”Œ Starting WebSocket Server:")
    
    ws_server = WebSocketServer(host="localhost", port=8765)
    ws_server.auth_required = False  # Ð£Ð¿Ñ€Ð¾Ñ‰Ð°ÐµÐ¼ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€ Ð² Ñ„Ð¾Ð½Ð¾Ð²Ð¾Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ðµ
    server_task = asyncio.create_task(ws_server.start())
    
    # Ð”Ð°ÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€Ñƒ Ð²Ñ€ÐµÐ¼Ñ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒÑÑ
    await asyncio.sleep(2)
    
    # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ WebSocket ÐºÐ»Ð¸ÐµÐ½Ñ‚
    print("  Testing WebSocket client connections...")
    
    try:
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚ÑÐºÐ¸Ñ… ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        clients = []
        
        for i in range(3):
            uri = "ws://localhost:8765"
            
            try:
                websocket = await websockets.connect(uri)
                clients.append(websocket)
                print(f"    Client {i+1} connected")
                
                # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ welcome message
                welcome_msg = await websocket.recv()
                welcome_data = json.loads(welcome_msg)
                print(f"    Client {i+1} received: {welcome_data['type']}")
                
            except Exception as e:
                print(f"    Client {i+1} connection failed: {e}")
        
        if clients:
            # Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸
            print("\n  Testing topic subscriptions...")
            
            client1 = clients[0]
            
            # ÐŸÐ¾Ð´Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ÑÑ Ð½Ð° Ñ‚Ð¾Ð¿Ð¸Ðº
            subscribe_msg = {
                'type': 'subscribe',
                'topic': 'public.demo'
            }
            
            await client1.send(json.dumps(subscribe_msg))
            
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸
            response = await client1.recv()
            response_data = json.loads(response)
            print(f"    Subscription response: {response_data}")
            
            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð² Ñ‚Ð¾Ð¿Ð¸Ðº Ð¾Ñ‚ Ð´Ñ€ÑƒÐ³Ð¾Ð³Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
            if len(clients) > 1:
                client2 = clients[1]
                
                data_msg = {
                    'type': 'data',
                    'topic': 'public.demo',
                    'data': {
                        'message': 'Hello from client 2!',
                        'timestamp': time.time()
                    }
                }
                
                await client2.send(json.dumps(data_msg))
                print("    Client 2 sent message to topic")
                
                # ÐšÐ»Ð¸ÐµÐ½Ñ‚ 1 Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
                try:
                    broadcast_msg = await asyncio.wait_for(client1.recv(), timeout=5.0)
                    broadcast_data = json.loads(broadcast_msg)
                    print(f"    Client 1 received broadcast: {broadcast_data['data']['message']}")
                except asyncio.TimeoutError:
                    print("    No broadcast message received (timeout)")
        
        # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ WebSocket ÑÐµÑ€Ð²ÐµÑ€Ð°
        print(f"\n  WebSocket Server Statistics:")
        ws_stats = ws_server.get_stats()
        
        print(f"    Total connections: {ws_stats['total_connections']}")
        print(f"    Current connections: {ws_stats['connections']['current']}")
        print(f"    Total messages: {ws_stats['total_messages']}")
        print(f"    Active topics: {ws_stats['subscriptions']['total_topics']}")
        
        # Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚ÑÐºÐ¸Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
        for i, client in enumerate(clients):
            await client.close()
            print(f"    Client {i+1} disconnected")
    
    except Exception as e:
        print(f"  WebSocket testing failed: {e}")
    
    finally:
        # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ WebSocket ÑÐµÑ€Ð²ÐµÑ€
        server_task.cancel()
        await ws_server.shutdown()
        print("  WebSocket server stopped")
    
    # Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ gRPC
    print(f"\nðŸ”§ gRPC Server Demonstration:")
    
    try:
        grpc_server = AdvancedGRPCServer(port=50051)
        
        print("  gRPC server would handle:")
        print("    - Unary calls (GetUser, CreateUser)")
        print("    - Server streaming (ListUsers)")
        print("    - Bidirectional streaming (StreamUserUpdates)")
        print("    - Built-in load balancing and service discovery")
        print("    - Protocol Buffers for efficient serialization")
        print("    - HTTP/2 multiplexing and flow control")
        
        # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
        print(f"\n  gRPC Performance Benefits:")
        print(f"    - Binary serialization: ~10x smaller than JSON")
        print(f"    - HTTP/2 multiplexing: Multiple calls per connection")
        print(f"    - Streaming: Real-time bidirectional communication")
        print(f"    - Code generation: Type-safe client/server code")
        print(f"    - Built-in authentication and encryption")
        
    except Exception as e:
        print(f"  gRPC demonstration failed: {e}")
    
    print(f"\nâœ… Modern protocols demonstration completed")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
if __name__ == "__main__":
    asyncio.run(demonstrate_modern_protocols())
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ ÐÐµÐ´ÐµÐ»Ñ 15

1. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ production-ready WebSocket ÑÐµÑ€Ð²ÐµÑ€ Ñ authentication Ð¸ authorization
2. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ gRPC ÑÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð²Ð°Ð¶Ð½Ñ‹Ñ… API Ñ high performance Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸
3. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ real-time ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ñ Ð² Ð²Ð°ÑˆÐµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ñ‡ÐµÑ€ÐµÐ· WebSocket
4. ÐŸÑ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ gRPC vs HTTP/REST API
5. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ Ð³Ð¸Ð±Ñ€Ð¸Ð´Ð½ÑƒÑŽ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ñ WebSocket Ð´Ð»Ñ real-time Ð¸ gRPC Ð´Ð»Ñ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ñ… Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð²

---

## ÐÐµÐ´ÐµÐ»Ñ 16: ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¸ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ°

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: Observability Ð´Ð»Ñ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼

Ð¡Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¾ÑÐ½Ð¾Ð²Ð°Ð½ Ð½Ð° Ñ‚Ñ€ÐµÑ… ÑÑ‚Ð¾Ð»Ð¿Ð°Ñ… observability:

```
Observability Pillars:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metrics (Ð§Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸)                               â”‚
â”‚ â”œâ”€ Latency, Throughput, Error rates                        â”‚
â”‚ â”œâ”€ Resource utilization                                    â”‚
â”‚ â”œâ”€ Business metrics                                        â”‚
â”‚ â””â”€ SLI/SLO monitoring                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Logs (Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ)                           â”‚
â”‚ â”œâ”€ Request/response logs                                   â”‚
â”‚ â”œâ”€ Error logs with context                                â”‚
â”‚ â”œâ”€ Audit logs                                             â”‚
â”‚ â””â”€ Distributed tracing                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Traces (Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½Ð°Ñ Ñ‚Ñ€Ð°ÑÑÐ¸Ñ€Ð¾Ð²ÐºÐ°)                        â”‚
â”‚ â”œâ”€ Request flow across services                           â”‚
â”‚ â”œâ”€ Performance bottlenecks                                â”‚
â”‚ â”œâ”€ Dependency mapping                                     â”‚
â”‚ â””â”€ Root cause analysis                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ“Š Comprehensive Network Monitoring System

**Enterprise-grade Network Monitoring:**

```python
import asyncio
import time
import json
import statistics
from typing import Dict, List, Optional, Callable, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
import logging
from collections import defaultdict, deque
import psutil
import aiohttp
import socket
import subprocess
import threading
from datetime import datetime, timedelta
import uuid

class MetricType(Enum):
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"

class AlertSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

@dataclass
class Metric:
    name: str
    value: float
    timestamp: float
    labels: Dict[str, str] = field(default_factory=dict)
    metric_type: MetricType = MetricType.GAUGE

@dataclass
class Alert:
    id: str
    name: str
    severity: AlertSeverity
    message: str
    timestamp: float
    labels: Dict[str, str] = field(default_factory=dict)
    resolved: bool = False
    resolved_at: Optional[float] = None

@dataclass
class TraceSpan:
    trace_id: str
    span_id: str
    parent_span_id: Optional[str]
    operation_name: str
    start_time: float
    end_time: Optional[float] = None
    duration_ms: Optional[float] = None
    tags: Dict[str, Any] = field(default_factory=dict)
    logs: List[Dict] = field(default_factory=list)
    
    def finish(self):
        """Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ span"""
        self.end_time = time.time()
        if self.start_time:
            self.duration_ms = (self.end_time - self.start_time) * 1000

class NetworkMonitoringSystem:
    def __init__(self):
        # Metrics storage
        self.metrics: Dict[str, deque] = defaultdict(lambda: deque(maxlen=10000))
        self.metric_metadata: Dict[str, Dict] = {}
        
        # Alerts
        self.alerts: Dict[str, Alert] = {}
        self.alert_rules: List[Dict] = []
        self.alert_callbacks: List[Callable] = []
        
        # Tracing
        self.traces: Dict[str, List[TraceSpan]] = defaultdict(list)
        self.active_spans: Dict[str, TraceSpan] = {}
        
        # Monitoring targets
        self.monitoring_targets: Dict[str, Dict] = {}
        
        # Configuration
        self.collection_interval = 15  # ÑÐµÐºÑƒÐ½Ð´
        self.retention_period = 7 * 24 * 3600  # 7 Ð´Ð½ÐµÐ¹
        self.max_traces_per_service = 1000
        
        # Background tasks
        self.collection_tasks: Dict[str, asyncio.Task] = {}
        self.cleanup_task: Optional[asyncio.Task] = None
        
        # Statistics
        self.stats = {
            'metrics_collected': 0,
            'alerts_fired': 0,
            'traces_collected': 0,
            'collection_errors': 0
        }
        
        self.logger = logging.getLogger('NetworkMonitoring')
        
        # Built-in collectors
        self._register_default_collectors()
    
    def _register_default_collectors(self):
        """Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ñ‹Ñ… ÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð² Ð¼ÐµÑ‚Ñ€Ð¸Ðº"""
        
        # System metrics collector
        self.add_monitoring_target(
            'system_metrics',
            'System Resources',
            self._collect_system_metrics,
            interval=30
        )
        
        # Network metrics collector
        self.add_monitoring_target(
            'network_metrics',
            'Network Statistics',
            self._collect_network_metrics,
            interval=15
        )
    
    def add_monitoring_target(self, target_id: str, name: str, 
                            collector_func: Callable, interval: int = 60):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ†ÐµÐ»Ð¸ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°"""
        
        self.monitoring_targets[target_id] = {
            'name': name,
            'collector': collector_func,
            'interval': interval,
            'last_collection': 0,
            'errors': 0
        }
        
        self.logger.info(f"Added monitoring target: {name}")
    
    def add_alert_rule(self, rule: Dict):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° Ð°Ð»ÐµÑ€Ñ‚Ð¸Ð½Ð³Ð°"""
        
        required_fields = ['name', 'condition', 'severity', 'message']
        
        if not all(field in rule for field in required_fields):
            raise ValueError(f"Alert rule must contain: {required_fields}")
        
        self.alert_rules.append(rule)
        self.logger.info(f"Added alert rule: {rule['name']}")
    
    def add_alert_callback(self, callback: Callable):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ callback Ð´Ð»Ñ Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð²"""
        self.alert_callbacks.append(callback)
    
    async def start_monitoring(self):
        """Ð—Ð°Ð¿ÑƒÑÐº ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°"""
        
        self.logger.info("Starting network monitoring system...")
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€Ñ‹
        for target_id, target in self.monitoring_targets.items():
            task = asyncio.create_task(
                self._collection_loop(target_id, target)
            )
            self.collection_tasks[target_id] = task
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ cleanup Ð·Ð°Ð´Ð°Ñ‡Ñƒ
        self.cleanup_task = asyncio.create_task(self._cleanup_loop())
        
        self.logger.info("Network monitoring system started")
    
    async def _collection_loop(self, target_id: str, target: Dict):
        """Ð¦Ð¸ÐºÐ» ÑÐ±Ð¾Ñ€Ð° Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð´Ð»Ñ Ñ†ÐµÐ»Ð¸"""
        
        while True:
            try:
                start_time = time.time()
                
                # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€
                metrics = await target['collector']()
                
                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                for metric in metrics:
                    await self.record_metric(metric)
                
                # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
                target['last_collection'] = time.time()
                self.stats['metrics_collected'] += len(metrics)
                
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð°Ð»ÐµÑ€Ñ‚Ñ‹
                await self._check_alerts(metrics)
                
                # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð´Ð¾ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ ÑÐ±Ð¾Ñ€Ð°
                collection_time = time.time() - start_time
                sleep_time = max(0, target['interval'] - collection_time)
                
                await asyncio.sleep(sleep_time)
            
            except asyncio.CancelledError:
                break
            except Exception as e:
                target['errors'] += 1
                self.stats['collection_errors'] += 1
                self.logger.error(f"Collection error for {target_id}: {e}")
                await asyncio.sleep(target['interval'])
    
    async def _collect_system_metrics(self) -> List[Metric]:
        """Ð¡Ð±Ð¾Ñ€ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº"""
        
        metrics = []
        current_time = time.time()
        
        # CPU Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        cpu_percent = psutil.cpu_percent(interval=1)
        metrics.append(Metric(
            name="system_cpu_usage_percent",
            value=cpu_percent,
            timestamp=current_time,
            labels={"host": socket.gethostname()}
        ))
        
        # Memory Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        memory = psutil.virtual_memory()
        metrics.extend([
            Metric(
                name="system_memory_usage_percent",
                value=memory.percent,
                timestamp=current_time,
                labels={"host": socket.gethostname()}
            ),
            Metric(
                name="system_memory_available_bytes",
                value=memory.available,
                timestamp=current_time,
                labels={"host": socket.gethostname()}
            )
        ])
        
        # Disk Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        disk = psutil.disk_usage('/')
        metrics.extend([
            Metric(
                name="system_disk_usage_percent",
                value=(disk.used / disk.total) * 100,
                timestamp=current_time,
                labels={"host": socket.gethostname(), "mountpoint": "/"}
            ),
            Metric(
                name="system_disk_free_bytes",
                value=disk.free,
                timestamp=current_time,
                labels={"host": socket.gethostname(), "mountpoint": "/"}
            )
        ])
        
        # Load average (Unix-like systems)
        try:
            load_avg = psutil.getloadavg()
            for i, period in enumerate(['1min', '5min', '15min']):
                metrics.append(Metric(
                    name="system_load_average",
                    value=load_avg[i],
                    timestamp=current_time,
                    labels={"host": socket.gethostname(), "period": period}
                ))
        except AttributeError:
            pass  # Windows doesn't have load average
        
        return metrics
    
    async def _collect_network_metrics(self) -> List[Metric]:
        """Ð¡Ð±Ð¾Ñ€ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº"""
        
        metrics = []
        current_time = time.time()
        hostname = socket.gethostname()
        
        # Network I/O
        net_io = psutil.net_io_counters()
        metrics.extend([
            Metric(
                name="network_bytes_sent_total",
                value=net_io.bytes_sent,
                timestamp=current_time,
                labels={"host": hostname},
                metric_type=MetricType.COUNTER
            ),
            Metric(
                name="network_bytes_received_total",
                value=net_io.bytes_recv,
                timestamp=current_time,
                labels={"host": hostname},
                metric_type=MetricType.COUNTER
            ),
            Metric(
                name="network_packets_sent_total",
                value=net_io.packets_sent,
                timestamp=current_time,
                labels={"host": hostname},
                metric_type=MetricType.COUNTER
            ),
            Metric(
                name="network_packets_received_total",
                value=net_io.packets_recv,
                timestamp=current_time,
                labels={"host": hostname},
                metric_type=MetricType.COUNTER
            )
        ])
        
        # Network connections
        connections = psutil.net_connections()
        connection_states = defaultdict(int)
        
        for conn in connections:
            if conn.status:
                connection_states[conn.status] += 1
        
        for state, count in connection_states.items():
            metrics.append(Metric(
                name="network_connections_by_state",
                value=count,
                timestamp=current_time,
                labels={"host": hostname, "state": state}
            ))
        
        # Network interfaces
        net_if_stats = psutil.net_if_stats()
        for interface, stats in net_if_stats.items():
            metrics.extend([
                Metric(
                    name="network_interface_up",
                    value=1 if stats.isup else 0,
                    timestamp=current_time,
                    labels={"host": hostname, "interface": interface}
                ),
                Metric(
                    name="network_interface_speed_mbps",
                    value=stats.speed,
                    timestamp=current_time,
                    labels={"host": hostname, "interface": interface}
                )
            ])
        
        return metrics
    
    async def record_metric(self, metric: Metric):
        """Ð—Ð°Ð¿Ð¸ÑÑŒ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸"""
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ
        metric_key = self._get_metric_key(metric)
        self.metrics[metric_key].append(metric)
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ
        if metric_key not in self.metric_metadata:
            self.metric_metadata[metric_key] = {
                'name': metric.name,
                'type': metric.metric_type.value,
                'labels': metric.labels,
                'first_seen': metric.timestamp,
                'sample_count': 0
            }
        
        self.metric_metadata[metric_key]['sample_count'] += 1
        self.metric_metadata[metric_key]['last_seen'] = metric.timestamp
    
    def _get_metric_key(self, metric: Metric) -> str:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÐºÐ»ÑŽÑ‡Ð° Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸"""
        
        labels_str = ",".join(f"{k}={v}" for k, v in sorted(metric.labels.items()))
        return f"{metric.name}{{{labels_str}}}"
    
    async def _check_alerts(self, metrics: List[Metric]):
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿Ñ€Ð°Ð²Ð¸Ð» Ð°Ð»ÐµÑ€Ñ‚Ð¸Ð½Ð³Ð°"""
        
        for rule in self.alert_rules:
            try:
                await self._evaluate_alert_rule(rule, metrics)
            except Exception as e:
                self.logger.error(f"Error evaluating alert rule {rule['name']}: {e}")
    
    async def _evaluate_alert_rule(self, rule: Dict, metrics: List[Metric]):
        """ÐžÑ†ÐµÐ½ÐºÐ° Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° Ð°Ð»ÐµÑ€Ñ‚Ð¸Ð½Ð³Ð°"""
        
        # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ - Ð² Ð¿Ñ€Ð¾Ð´Ð°ÐºÑˆÐµÐ½Ðµ Ð±Ñ‹Ð» Ð±Ñ‹ Ð±Ð¾Ð»ÐµÐµ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ð¹ DSL
        condition = rule['condition']
        
        # Ð˜Ñ‰ÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸, ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸ÑŽ
        for metric in metrics:
            if self._matches_condition(metric, condition):
                await self._fire_alert(rule, metric)
    
    def _matches_condition(self, metric: Metric, condition: Dict) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑƒÑÐ»Ð¾Ð²Ð¸ÑŽ"""
        
        # ÐŸÑ€Ð¸Ð¼ÐµÑ€: {"metric": "system_cpu_usage_percent", "operator": ">", "threshold": 80}
        if condition.get('metric') != metric.name:
            return False
        
        operator = condition.get('operator', '>')
        threshold = condition.get('threshold', 0)
        
        if operator == '>':
            return metric.value > threshold
        elif operator == '<':
            return metric.value < threshold
        elif operator == '>=':
            return metric.value >= threshold
        elif operator == '<=':
            return metric.value <= threshold
        elif operator == '==':
            return metric.value == threshold
        elif operator == '!=':
            return metric.value != threshold
        
        return False
    
    async def _fire_alert(self, rule: Dict, metric: Metric):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð°Ð»ÐµÑ€Ñ‚Ð°"""
        
        alert_id = f"{rule['name']}_{int(metric.timestamp)}"
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð½Ðµ Ð´ÑƒÐ±Ð»Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð»Ð¸ Ð°Ð»ÐµÑ€Ñ‚
        if alert_id in self.alerts and not self.alerts[alert_id].resolved:
            return
        
        alert = Alert(
            id=alert_id,
            name=rule['name'],
            severity=AlertSeverity(rule['severity']),
            message=rule['message'].format(
                metric_name=metric.name,
                value=metric.value,
                **metric.labels
            ),
            timestamp=metric.timestamp,
            labels={**metric.labels, **rule.get('labels', {})}
        )
        
        self.alerts[alert_id] = alert
        self.stats['alerts_fired'] += 1
        
        # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ callbacks
        for callback in self.alert_callbacks:
            try:
                await callback(alert)
            except Exception as e:
                self.logger.error(f"Alert callback error: {e}")
        
        self.logger.warning(f"ALERT: {alert.name} - {alert.message}")
    
    def start_trace(self, operation_name: str, parent_span_id: Optional[str] = None) -> str:
        """ÐÐ°Ñ‡Ð°Ð»Ð¾ Ñ‚Ñ€Ð°ÑÑÐ¸Ñ€Ð¾Ð²ÐºÐ¸"""
        
        trace_id = str(uuid.uuid4())
        span_id = str(uuid.uuid4())
        
        span = TraceSpan(
            trace_id=trace_id,
            span_id=span_id,
            parent_span_id=parent_span_id,
            operation_name=operation_name,
            start_time=time.time()
        )
        
        self.active_spans[span_id] = span
        self.traces[trace_id].append(span)
        
        return span_id
    
    def add_span_tag(self, span_id: str, key: str, value: Any):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐ³Ð° Ðº span"""
        
        if span_id in self.active_spans:
            self.active_spans[span_id].tags[key] = value
    
    def add_span_log(self, span_id: str, message: str, **kwargs):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð»Ð¾Ð³Ð° Ðº span"""
        
        if span_id in self.active_spans:
            log_entry = {
                'timestamp': time.time(),
                'message': message,
                **kwargs
            }
            self.active_spans[span_id].logs.append(log_entry)
    
    def finish_span(self, span_id: str):
        """Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ span"""
        
        if span_id in self.active_spans:
            span = self.active_spans[span_id]
            span.finish()
            
            del self.active_spans[span_id]
            self.stats['traces_collected'] += 1
    
    async def collect_http_metrics(self, method: str, endpoint: str, 
                                 status_code: int, duration_ms: float, 
                                 request_size: int = 0, response_size: int = 0):
        """Ð¡Ð±Ð¾Ñ€ HTTP Ð¼ÐµÑ‚Ñ€Ð¸Ðº"""
        
        current_time = time.time()
        labels = {
            'method': method,
            'endpoint': endpoint,
            'status_code': str(status_code),
            'host': socket.gethostname()
        }
        
        metrics = [
            Metric(
                name="http_requests_total",
                value=1,
                timestamp=current_time,
                labels=labels,
                metric_type=MetricType.COUNTER
            ),
            Metric(
                name="http_request_duration_ms",
                value=duration_ms,
                timestamp=current_time,
                labels=labels,
                metric_type=MetricType.HISTOGRAM
            ),
            Metric(
                name="http_request_size_bytes",
                value=request_size,
                timestamp=current_time,
                labels=labels,
                metric_type=MetricType.HISTOGRAM
            ),
            Metric(
                name="http_response_size_bytes",
                value=response_size,
                timestamp=current_time,
                labels=labels,
                metric_type=MetricType.HISTOGRAM
            )
        ]
        
        for metric in metrics:
            await self.record_metric(metric)
    
    def query_metrics(self, metric_name: str, labels: Optional[Dict] = None, 
                     start_time: Optional[float] = None, 
                     end_time: Optional[float] = None) -> List[Metric]:
        """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº"""
        
        results = []
        
        for metric_key, metric_queue in self.metrics.items():
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð¸Ð¼ÐµÐ½Ð¸
            if not metric_key.startswith(metric_name):
                continue
            
            for metric in metric_queue:
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ€Ð°Ð¼ÐºÐ¸
                if start_time and metric.timestamp < start_time:
                    continue
                if end_time and metric.timestamp > end_time:
                    continue
                
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð»ÐµÐ¹Ð±Ð»Ñ‹
                if labels:
                    if not all(metric.labels.get(k) == v for k, v in labels.items()):
                        continue
                
                results.append(metric)
        
        return sorted(results, key=lambda m: m.timestamp)
    
    def get_trace(self, trace_id: str) -> List[TraceSpan]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ‚Ñ€Ð°ÑÑÐ¸Ñ€Ð¾Ð²ÐºÐ¸"""
        
        return self.traces.get(trace_id, [])
    
    async def _cleanup_loop(self):
        """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
        
        while True:
            try:
                current_time = time.time()
                cutoff_time = current_time - self.retention_period
                
                # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                for metric_key, metric_queue in self.metrics.items():
                    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                    while metric_queue and metric_queue[0].timestamp < cutoff_time:
                        metric_queue.popleft()
                
                # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ñ‚Ñ€Ð°ÑÑÐ¸Ñ€Ð¾Ð²ÐºÐ¸
                traces_to_remove = []
                for trace_id, spans in self.traces.items():
                    if spans and spans[0].start_time < cutoff_time:
                        traces_to_remove.append(trace_id)
                
                for trace_id in traces_to_remove:
                    del self.traces[trace_id]
                
                # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ñ€ÐµÑˆÐµÐ½Ð½Ñ‹Ðµ Ð°Ð»ÐµÑ€Ñ‚Ñ‹
                resolved_alerts = [
                    alert_id for alert_id, alert in self.alerts.items()
                    if alert.resolved and alert.resolved_at and alert.resolved_at < cutoff_time
                ]
                
                for alert_id in resolved_alerts:
                    del self.alerts[alert_id]
                
                await asyncio.sleep(3600)  # ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ñ‡Ð°Ñ
            
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"Cleanup error: {e}")
                await asyncio.sleep(3600)
    
    def get_monitoring_summary(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ²Ð¾Ð´ÐºÐ¸ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°"""
        
        current_time = time.time()
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¼ÐµÑ‚Ñ€Ð¸Ðº
        total_metrics = sum(len(queue) for queue in self.metrics.values())
        unique_metrics = len(self.metric_metadata)
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð²
        active_alerts = len([a for a in self.alerts.values() if not a.resolved])
        alerts_by_severity = defaultdict(int)
        
        for alert in self.alerts.values():
            if not alert.resolved:
                alerts_by_severity[alert.severity.value] += 1
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ñ‚Ñ€Ð°ÑÑÐ¸Ñ€Ð¾Ð²Ð¾Ðº
        total_traces = len(self.traces)
        active_spans = len(self.active_spans)
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð²
        collector_stats = {}
        for target_id, target in self.monitoring_targets.items():
            collector_stats[target_id] = {
                'name': target['name'],
                'last_collection_ago': current_time - target['last_collection'],
                'errors': target['errors']
            }
        
        return {
            'uptime_seconds': current_time - self.stats.get('start_time', current_time),
            'metrics': {
                'total_stored': total_metrics,
                'unique_metrics': unique_metrics,
                'collected_total': self.stats['metrics_collected']
            },
            'alerts': {
                'active': active_alerts,
                'by_severity': dict(alerts_by_severity),
                'fired_total': self.stats['alerts_fired']
            },
            'traces': {
                'total_traces': total_traces,
                'active_spans': active_spans,
                'collected_total': self.stats['traces_collected']
            },
            'collectors': collector_stats,
            'errors': {
                'collection_errors': self.stats['collection_errors']
            }
        }
    
    async def shutdown(self):
        """Graceful shutdown"""
        
        self.logger.info("Shutting down monitoring system...")
        
        # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€Ñ‹
        for task in self.collection_tasks.values():
            task.cancel()
        
        if self.collection_tasks:
            await asyncio.gather(*self.collection_tasks.values(), return_exceptions=True)
        
        # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ cleanup
        if self.cleanup_task:
            self.cleanup_task.cancel()
        
        self.logger.info("Monitoring system shutdown completed")

# HTTP Monitoring Middleware
def create_monitoring_middleware(monitoring_system: NetworkMonitoringSystem):
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ middleware Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° HTTP Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²"""
    
    async def monitoring_middleware(request, handler):
        # ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ñ‚Ñ€Ð°ÑÑÐ¸Ñ€Ð¾Ð²ÐºÑƒ
        span_id = monitoring_system.start_trace(
            f"HTTP {request.method} {request.path}"
        )
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚ÐµÐ³Ð¸
        monitoring_system.add_span_tag(span_id, 'http.method', request.method)
        monitoring_system.add_span_tag(span_id, 'http.url', str(request.url))
        monitoring_system.add_span_tag(span_id, 'http.user_agent', request.headers.get('User-Agent', ''))
        
        start_time = time.time()
        request_size = int(request.headers.get('Content-Length', 0))
        
        try:
            # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ
            response = await handler(request)
            
            # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
            duration_ms = (time.time() - start_time) * 1000
            response_size = len(getattr(response, 'body', b''))
            
            await monitoring_system.collect_http_metrics(
                method=request.method,
                endpoint=request.path,
                status_code=response.status,
                duration_ms=duration_ms,
                request_size=request_size,
                response_size=response_size
            )
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ span
            monitoring_system.add_span_tag(span_id, 'http.status_code', response.status)
            monitoring_system.add_span_log(span_id, f"Request completed successfully")
            
            return response
        
        except Exception as e:
            # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
            duration_ms = (time.time() - start_time) * 1000
            
            await monitoring_system.collect_http_metrics(
                method=request.method,
                endpoint=request.path,
                status_code=500,
                duration_ms=duration_ms,
                request_size=request_size,
                response_size=0
            )
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ span Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹
            monitoring_system.add_span_tag(span_id, 'error', True)
            monitoring_system.add_span_tag(span_id, 'http.status_code', 500)
            monitoring_system.add_span_log(span_id, f"Request failed: {str(e)}")
            
            raise
        
        finally:
            # Ð—Ð°Ð²ÐµÑ€ÑˆÐ°ÐµÐ¼ span
            monitoring_system.finish_span(span_id)
    
    return monitoring_middleware

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
async def demonstrate_monitoring_system():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° ÑÐµÑ‚ÐµÐ¹"""
    
    print("ðŸ“Š Network Monitoring & Observability Demonstration")
    print("=" * 70)
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
    monitoring = NetworkMonitoringSystem()
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° Ð°Ð»ÐµÑ€Ñ‚Ð¸Ð½Ð³Ð°
    alert_rules = [
        {
            'name': 'high_cpu_usage',
            'condition': {
                'metric': 'system_cpu_usage_percent',
                'operator': '>',
                'threshold': 80
            },
            'severity': 'warning',
            'message': 'High CPU usage detected: {value}% on {host}'
        },
        {
            'name': 'low_disk_space',
            'condition': {
                'metric': 'system_disk_usage_percent',
                'operator': '>',
                'threshold': 90
            },
            'severity': 'critical',
            'message': 'Low disk space: {value}% used on {host}'
        },
        {
            'name': 'high_memory_usage',
            'condition': {
                'metric': 'system_memory_usage_percent',
                'operator': '>',
                'threshold': 85
            },
            'severity': 'warning',
            'message': 'High memory usage: {value}% on {host}'
        }
    ]
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°
    for rule in alert_rules:
        monitoring.add_alert_rule(rule)
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ callback Ð´Ð»Ñ Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð²
    async def alert_callback(alert: Alert):
        print(f"ðŸš¨ ALERT: [{alert.severity.value.upper()}] {alert.name}")
        print(f"   Message: {alert.message}")
        print(f"   Time: {datetime.fromtimestamp(alert.timestamp)}")
    
    monitoring.add_alert_callback(alert_callback)
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³
    print("ðŸ”„ Starting monitoring system...")
    await monitoring.start_monitoring()
    
    # Ð”Ð°ÐµÐ¼ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ Ð¿Ð¾Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ
    print("ðŸ“ˆ Collecting metrics for 30 seconds...")
    await asyncio.sleep(30)
    
    # Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ñ€Ð°ÑÑÐ¸Ñ€Ð¾Ð²ÐºÑƒ
    print("\nðŸ” Demonstrating distributed tracing:")
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚Ñ€Ð°ÑÑÐ¸Ñ€Ð¾Ð²ÐºÑƒ HTTP Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
    span_id = monitoring.start_trace("HTTP GET /api/users")
    monitoring.add_span_tag(span_id, 'http.method', 'GET')
    monitoring.add_span_tag(span_id, 'http.url', '/api/users')
    monitoring.add_span_log(span_id, "Starting user lookup")
    
    # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ð±Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ðº Ð±Ð°Ð·Ðµ Ð´Ð°Ð½    def _least_connections_select(self, backends: List[Backend]) -> Backend:
        """Least Connections Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼"""
        
        return min(backends, key=lambda b: b.current_connections)
    
    def _weighted_least_connections_select(self, backends: List[Backend]) -> Backend:
        """Weighted Least Connections Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼"""
        
        def weighted_connections(backend: Backend) -> float:
            if backend.effective_weight == 0:
                return float('inf')
            return backend.current_connections / backend.effective_weight
        
        return min(backends, key=weighted_connections)
    
    def _least_response_time_select(self, backends: List[Backend]) -> Backend:
        """Least Response Time Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼"""
        
        def combined_score(backend: Backend) -> float:
            # ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€ÑƒÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¸ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
            response_time = backend.avg_response_time if backend.response_times else 1000
            connections = backend.current_connections
            return response_time * (1 + connections * 0.1)
        
        return min(backends, key=combined_score)
    
    def _ip_hash_select(self, backends: List[Backend], client_ip: str) -> Backend:
        """IP Hash Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼"""
        
        if not client_ip:
            return self._round_robin_select(backends)
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ…ÐµÑˆ Ð¾Ñ‚ IP
        ip_hash = hashlib.md5(client_ip.encode()).hexdigest()
        hash_int = int(ip_hash, 16)
        
        # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ backend Ð¿Ð¾ Ñ…ÐµÑˆÑƒ
        index = hash_int % len(backends)
        return backends[index]
    
    def _consistent_hash_select(self, client_ip: str) -> Optional[Backend]:
        """Consistent Hash Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼"""
        
        if not client_ip or not self.hash_ring:
            healthy_backends = [b for b in self.backends.values() if b.state == BackendState.HEALTHY]
            return self._round_robin_select(healthy_backends) if healthy_backends else None
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ…ÐµÑˆ Ð¾Ñ‚ IP
        ip_hash = hashlib.md5(client_ip.encode()).hexdigest()
        hash_int = int(ip_hash, 16) % (2**32)
        
        # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð±Ð»Ð¸Ð¶Ð°Ð¹ÑˆÐ¸Ð¹ ÑƒÐ·ÐµÐ» Ð² ÐºÐ¾Ð»ÑŒÑ†Ðµ
        ring_keys = sorted(self.hash_ring.keys())
        
        for key in ring_keys:
            if hash_int <= key:
                backend_id = self.hash_ring[key]
                if backend_id in self.backends and self.backends[backend_id].state == BackendState.HEALTHY:
                    return self.backends[backend_id]
        
        # Ð•ÑÐ»Ð¸ Ð½Ðµ Ð½Ð°ÑˆÐ»Ð¸, Ð±ÐµÑ€ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ð¹
        if ring_keys:
            backend_id = self.hash_ring[ring_keys[0]]
            if backend_id in self.backends and self.backends[backend_id].state == BackendState.HEALTHY:
                return self.backends[backend_id]
        
        return None
    
    def _random_select(self, backends: List[Backend]) -> Backend:
        """Random Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼"""
        
        return random.choice(backends)
    
    def _weighted_random_select(self, backends: List[Backend]) -> Backend:
        """Weighted Random Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼"""
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÐµÑÐ¾Ð²
        weights = [backend.effective_weight for backend in backends]
        total_weight = sum(weights)
        
        if total_weight == 0:
            return random.choice(backends)
        
        # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ð¾ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð²ÐµÑÐ¾Ð²
        random_weight = random.uniform(0, total_weight)
        current_weight = 0
        
        for i, backend in enumerate(backends):
            current_weight += weights[i]
            if random_weight <= current_weight:
                return backend
        
        return backends[-1]  # Fallback
    
    def _update_hash_ring(self):
        """ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ consistent hash ÐºÐ¾Ð»ÑŒÑ†Ð°"""
        
        self.hash_ring.clear()
        
        for backend_id, backend in self.backends.items():
            if backend.state == BackendState.HEALTHY:
                # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð²Ð¸Ñ€Ñ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÑƒÐ·Ð»Ñ‹
                for i in range(self.virtual_nodes):
                    virtual_key = f"{backend_id}:{i}"
                    hash_value = hashlib.md5(virtual_key.encode()).hexdigest()
                    hash_int = int(hash_value, 16) % (2**32)
                    self.hash_ring[hash_int] = backend_id
    
    def _is_circuit_breaker_closed(self, backend_id: str) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ circuit breaker"""
        
        if backend_id not in self.circuit_breakers:
            return True
        
        cb = self.circuit_breakers[backend_id]
        
        if cb['state'] == 'closed':
            return True
        elif cb['state'] == 'open':
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð´Ð»Ñ recovery
            if time.time() - cb['last_failure'] >= cb['recovery_timeout']:
                cb['state'] = 'half_open'
                cb['failure_count'] = 0
                return True
            return False
        elif cb['state'] == 'half_open':
            return True
        
        return False
    
    def _record_request_result(self, backend_id: str, success: bool, response_time: float = 0):
        """Ð—Ð°Ð¿Ð¸ÑÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°"""
        
        if backend_id not in self.backends:
            return
        
        backend = self.backends[backend_id]
        backend.total_requests += 1
        
        if success:
            backend.response_times.append(response_time)
            self.stats['successful_requests'] += 1
            
            # Circuit breaker recovery
            if backend_id in self.circuit_breakers:
                cb = self.circuit_breakers[backend_id]
                if cb['state'] == 'half_open':
                    cb['failure_count'] = 0
                    cb['state'] = 'closed'
        else:
            backend.failed_requests += 1
            self.stats['failed_requests'] += 1
            
            # Circuit breaker trip
            if backend_id in self.circuit_breakers:
                cb = self.circuit_breakers[backend_id]
                cb['failure_count'] += 1
                cb['last_failure'] = time.time()
                
                if cb['failure_count'] >= 5:  # Threshold
                    cb['state'] = 'open'
                    self.logger.warning(f"Circuit breaker opened for backend {backend_id}")
        
        self.stats['total_requests'] += 1
    
    async def make_request(self, client_ip: str, method: str = 'GET', 
                          path: str = '/', data: Any = None, headers: Dict = None) -> Dict:
        """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ñ‡ÐµÑ€ÐµÐ· load balancer"""
        
        backend = await self.select_backend(client_ip)
        
        if not backend:
            return {
                'success': False,
                'error': 'No healthy backends available',
                'status_code': 503
            }
        
        # Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÑÑ‡ÐµÑ‚Ñ‡Ð¸Ðº ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        backend.current_connections += 1
        
        start_time = time.time()
        
        try:
            url = f"http://{backend.host}:{backend.port}{path}"
            
            async with aiohttp.ClientSession() as session:
                async with session.request(
                    method, url, 
                    json=data if method in ['POST', 'PUT', 'PATCH'] else None,
                    headers=headers or {},
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    response_time = (time.time() - start_time) * 1000  # Ð² Ð¼Ñ
                    response_data = await response.text()
                    
                    # Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
                    self._record_request_result(backend.id, True, response_time)
                    
                    return {
                        'success': True,
                        'status_code': response.status,
                        'data': response_data,
                        'response_time_ms': response_time,
                        'backend_id': backend.id
                    }
        
        except Exception as e:
            response_time = (time.time() - start_time) * 1000
            
            # Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÑƒ
            self._record_request_result(backend.id, False, response_time)
            
            return {
                'success': False,
                'error': str(e),
                'status_code': 0,
                'response_time_ms': response_time,
                'backend_id': backend.id
            }
        
        finally:
            # Ð£Ð¼ÐµÐ½ÑŒÑˆÐ°ÐµÐ¼ ÑÑ‡ÐµÑ‚Ñ‡Ð¸Ðº ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
            backend.current_connections = max(0, backend.current_connections - 1)
    
    def _start_health_check(self, backend_id: str):
        """Ð—Ð°Ð¿ÑƒÑÐº health check Ð´Ð»Ñ backend"""
        
        async def health_check_loop():
            backend = self.backends[backend_id]
            consecutive_failures = 0
            consecutive_successes = 0
            
            while backend_id in self.backends:
                try:
                    start_time = time.time()
                    
                    url = f"http://{backend.host}:{backend.port}{self.health_config.path}"
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(
                            url, 
                            timeout=aiohttp.ClientTimeout(total=self.health_config.timeout)
                        ) as response:
                            
                            response_time = (time.time() - start_time) * 1000
                            
                            if response.status == self.health_config.expected_status:
                                # Health check ÑƒÑÐ¿ÐµÑˆÐµÐ½
                                consecutive_failures = 0
                                consecutive_successes += 1
                                
                                # Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ backend ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾
                                if (backend.state == BackendState.UNHEALTHY and 
                                    consecutive_successes >= self.health_config.max_successes_to_recover):
                                    backend.state = BackendState.HEALTHY
                                    backend.health_score = 1.0
                                    self.logger.info(f"Backend {backend_id} recovered")
                                
                                # Ð£Ð»ÑƒÑ‡ÑˆÐ°ÐµÐ¼ health score
                                backend.health_score = min(1.0, backend.health_score + 0.1)
                                
                            else:
                                consecutive_successes = 0
                                consecutive_failures += 1
                                backend.health_score = max(0.1, backend.health_score - 0.2)
                
                except Exception as e:
                    consecutive_successes = 0
                    consecutive_failures += 1
                    backend.health_score = max(0.1, backend.health_score - 0.3)
                    
                    self.logger.debug(f"Health check failed for {backend_id}: {e}")
                
                # ÐŸÐ¾Ð¼ÐµÑ‡Ð°ÐµÐ¼ backend ÐºÐ°Ðº Ð½ÐµÐ·Ð´Ð¾Ñ€Ð¾Ð²Ñ‹Ð¹ Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸
                if consecutive_failures >= self.health_config.max_failures:
                    if backend.state == BackendState.HEALTHY:
                        backend.state = BackendState.UNHEALTHY
                        self.logger.warning(f"Backend {backend_id} marked as unhealthy")
                
                backend.last_health_check = time.time()
                
                await asyncio.sleep(self.health_config.interval)
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ñƒ health check
        task = asyncio.create_task(health_check_loop())
        self.health_check_tasks[backend_id] = task
    
    def get_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ load balancer"""
        
        backend_stats = {}
        for backend_id, backend in self.backends.items():
            backend_stats[backend_id] = {
                'host': f"{backend.host}:{backend.port}",
                'state': backend.state.value,
                'weight': backend.weight,
                'effective_weight': backend.effective_weight,
                'current_connections': backend.current_connections,
                'total_requests': backend.total_requests,
                'failed_requests': backend.failed_requests,
                'failure_rate': backend.failure_rate,
                'avg_response_time': backend.avg_response_time,
                'health_score': backend.health_score,
                'circuit_breaker_state': self.circuit_breakers.get(backend_id, {}).get('state', 'closed')
            }
        
        # ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
        total_requests = self.stats['total_requests']
        success_rate = (self.stats['successful_requests'] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'algorithm': self.algorithm.value,
            'total_backends': len(self.backends),
            'healthy_backends': len([b for b in self.backends.values() if b.state == BackendState.HEALTHY]),
            'total_requests': total_requests,
            'success_rate_percent': success_rate,
            'backend_stats': backend_stats,
            'requests_by_backend': dict(self.stats['requests_by_backend']),
            'circuit_breakers_open': len([cb for cb in self.circuit_breakers.values() if cb['state'] == 'open'])
        }
    
    async def shutdown(self):
        """Graceful shutdown load balancer"""
        
        # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð²ÑÐµ health check Ð·Ð°Ð´Ð°Ñ‡Ð¸
        for task in self.health_check_tasks.values():
            task.cancel()
        
        # Ð–Ð´ÐµÐ¼ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡
        if self.health_check_tasks:
            await asyncio.gather(*self.health_check_tasks.values(), return_exceptions=True)
        
        self.logger.info("Load balancer shutdown completed")

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Load Balancer
class MockBackendServer:
    """Mock backend ÑÐµÑ€Ð²ÐµÑ€ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸"""
    
    def __init__(self, server_id: str, port: int, response_delay: float = 0.1, failure_rate: float = 0.0):
        self.server_id = server_id
        self.port = port
        self.response_delay = response_delay
        self.failure_rate = failure_rate
        self.request_count = 0
        
    async def start(self):
        """Ð—Ð°Ð¿ÑƒÑÐº mock ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        
        from aiohttp import web
        
        async def handle_request(request):
            self.request_count += 1
            
            # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÑƒ
            await asyncio.sleep(self.response_delay)
            
            # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
            if random.random() < self.failure_rate:
                return web.Response(status=500, text=f"Server {self.server_id} error")
            
            return web.json_response({
                'server_id': self.server_id,
                'request_count': self.request_count,
                'timestamp': time.time()
            })
        
        async def health_check(request):
            return web.json_response({'status': 'healthy', 'server_id': self.server_id})
        
        app = web.Application()
        app.router.add_get('/', handle_request)
        app.router.add_post('/', handle_request)
        app.router.add_get('/health', health_check)
        
        runner = web.AppRunner(app)
        await runner.setup()
        
        site = web.TCPSite(runner, 'localhost', self.port)
        await site.start()
        
        return runner

async def demonstrate_load_balancing():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¾Ð² Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ¸ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸"""
    
    print("âš–ï¸ Advanced Load Balancing Demonstration")
    print("=" * 60)
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ mock backend ÑÐµÑ€Ð²ÐµÑ€Ñ‹
    mock_servers = [
        MockBackendServer('server1', 8081, response_delay=0.05, failure_rate=0.0),   # Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹
        MockBackendServer('server2', 8082, response_delay=0.1, failure_rate=0.05),   # Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹
        MockBackendServer('server3', 8083, response_delay=0.2, failure_rate=0.1),    # ÐœÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ð¹
        MockBackendServer('server4', 8084, response_delay=0.15, failure_rate=0.0),   # ÐÐ°Ð´ÐµÐ¶Ð½Ñ‹Ð¹
    ]
    
    server_runners = []
    
    print("ðŸš€ Starting mock backend servers...")
    
    try:
        for server in mock_servers:
            runner = await server.start()
            server_runners.append(runner)
            print(f"  Started {server.server_id} on port {server.port}")
        
        await asyncio.sleep(2)  # Ð”Ð°ÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€Ð°Ð¼ Ð²Ñ€ÐµÐ¼Ñ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒÑÑ
        
        # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹
        algorithms_to_test = [
            LoadBalanceAlgorithm.ROUND_ROBIN,
            LoadBalanceAlgorithm.WEIGHTED_LEAST_CONNECTIONS,
            LoadBalanceAlgorithm.LEAST_RESPONSE_TIME,
            LoadBalanceAlgorithm.IP_HASH
        ]
        
        for algorithm in algorithms_to_test:
            print(f"\nðŸ“Š Testing {algorithm.value.upper()} algorithm:")
            
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ load balancer
            lb = AdvancedLoadBalancer(algorithm)
            
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ backends
            backends = [
                Backend('server1', 'localhost', 8081, weight=3),  # Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹ Ð²ÐµÑ
                Backend('server2', 'localhost', 8082, weight=2),  # Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ð²ÐµÑ
                Backend('server3', 'localhost', 8083, weight=1),  # ÐÐ¸Ð·ÐºÐ¸Ð¹ Ð²ÐµÑ
                Backend('server4', 'localhost', 8084, weight=2),  # Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ð²ÐµÑ
            ]
            
            for backend in backends:
                lb.add_backend(backend)
            
            # Ð–Ð´ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ health checks
            await asyncio.sleep(3)
            
            # Ð”ÐµÐ»Ð°ÐµÐ¼ ÑÐµÑ€Ð¸ÑŽ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
            print("  Making 50 requests...")
            
            client_ips = ['192.168.1.10', '192.168.1.11', '192.168.1.12', '10.0.0.5', '10.0.0.6']
            successful_requests = 0
            total_response_time = 0
            
            request_distribution = defaultdict(int)
            
            for i in range(50):
                client_ip = client_ips[i % len(client_ips)]
                
                result = await lb.make_request(client_ip, 'GET', '/')
                
                if result['success']:
                    successful_requests += 1
                    total_response_time += result['response_time_ms']
                    request_distribution[result['backend_id']] += 1
                
                # ÐÐµÐ±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð¿Ð°ÑƒÐ·Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸
                if i % 10 == 9:
                    await asyncio.sleep(0.1)
            
            # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
            stats = lb.get_stats()
            avg_response_time = total_response_time / successful_requests if successful_requests > 0 else 0
            
            print(f"  Results:")
            print(f"    Success rate: {stats['success_rate_percent']:.1f}%")
            print(f"    Average response time: {avg_response_time:.1f}ms")
            print(f"    Request distribution:")
            
            for backend_id, count in request_distribution.items():
                backend = lb.backends[backend_id]
                percentage = (count / 50) * 100
                print(f"      {backend_id} (weight {backend.weight}): {count} requests ({percentage:.1f}%)")
            
            print(f"    Backend health scores:")
            for backend_id, backend in lb.backends.items():
                print(f"      {backend_id}: {backend.health_score:.2f}")
            
            # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ load balancer
            await lb.shutdown()
        
        # Ð¢ÐµÑÑ‚ ÑƒÑÑ‚Ð¾Ð¹Ñ‡Ð¸Ð²Ð¾ÑÑ‚Ð¸ Ðº Ð¾Ñ‚ÐºÐ°Ð·Ð°Ð¼
        print(f"\nðŸ›¡ï¸ Testing Failure Resilience:")
        
        lb = AdvancedLoadBalancer(LoadBalanceAlgorithm.WEIGHTED_LEAST_CONNECTIONS)
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ backends
        for backend in backends:
            lb.add_backend(backend)
        
        await asyncio.sleep(2)
        
        print("  Making requests with some servers failing...")
        
        # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚ÐºÐ°Ð· ÑÐµÑ€Ð²ÐµÑ€Ð° (ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ failure rate)
        mock_servers[2].failure_rate = 0.8  # server3 Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÑ‚ ÑÐ¸Ð»ÑŒÐ½Ð¾ Ð¿Ð°Ð´Ð°Ñ‚ÑŒ
        
        successful_requests = 0
        
        for i in range(30):
            result = await lb.make_request('192.168.1.100', 'GET', '/')
            
            if result['success']:
                successful_requests += 1
            
            await asyncio.sleep(0.1)
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ circuit breaker
        stats = lb.get_stats()
        
        print(f"  Results with failing server:")
        print(f"    Success rate: {stats['success_rate_percent']:.1f}%")
        print(f"    Circuit breakers open: {stats['circuit_breakers_open']}")
        
        print(f"    Backend states:")
        for backend_id, backend_info in stats['backend_stats'].items():
            state = backend_info['state']
            cb_state = backend_info['circuit_breaker_state']
            health_score = backend_info['health_score']
            
            print(f"      {backend_id}: {state} (CB: {cb_state}, Health: {health_score:.2f})")
        
        await lb.shutdown()
        
    finally:
        # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ mock ÑÐµÑ€Ð²ÐµÑ€Ñ‹
        print(f"\nðŸ›‘ Shutting down mock servers...")
        
        for runner in server_runners:
            await runner.cleanup()
    
    print(f"\nâœ… Load balancing demonstration completed")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
if __name__ == "__main__":
    asyncio.run(demonstrate_load_balancing())
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ ÐÐµÐ´ÐµÐ»Ñ 13

1. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ production-ready load balancer Ð´Ð»Ñ Ð²Ð°ÑˆÐ¸Ñ… Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
2. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ health checking Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸ÐµÐ¼ Ð½ÐµÐ·Ð´Ð¾Ñ€Ð¾Ð²Ñ‹Ñ… Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð²
3. ÐŸÑ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹ Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ¸ Ð¿Ð¾Ð´ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¾Ð¹
4. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ circuit breaker pattern Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ñ ÑƒÑÑ‚Ð¾Ð¹Ñ‡Ð¸Ð²Ð¾ÑÑ‚Ð¸
5. Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ load balancer Ñ service discovery ÑÐ¸ÑÑ‚ÐµÐ¼Ð¾Ð¹

---

## ÐÐµÐ´ÐµÐ»Ñ 14: Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚ÑŒ

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: High Availability Architecture

ÐŸÑ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼:

```
High Availability Components:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Geographic Distribution                                     â”‚
â”‚ â”œâ”€ Multi-region deployment                                 â”‚
â”‚ â”œâ”€ Cross-AZ redundancy                                     â”‚
â”‚ â”œâ”€ Edge locations                                          â”‚
â”‚ â””â”€ Disaster recovery sites                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Application Layer HA                                       â”‚
â”‚ â”œâ”€ Horizontal scaling                                      â”‚
â”‚ â”œâ”€ Stateless design                                        â”‚
â”‚ â”œâ”€ Circuit breakers                                        â”‚
â”‚ â””â”€ Graceful degradation                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Data Layer HA                                              â”‚
â”‚ â”œâ”€ Database replication                                    â”‚
â”‚ â”œâ”€ Automatic failover                                      â”‚
â”‚ â”œâ”€ Data partitioning/sharding                             â”‚
â”‚ â””â”€ Consistent backups                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Infrastructure HA                                          â”‚
â”‚ â”œâ”€ Load balancer redundancy                               â”‚
â”‚ â”œâ”€ Network path diversity                                  â”‚ 
â”‚ â”œâ”€ Power/cooling redundancy                               â”‚
â”‚ â””â”€ Hardware failure tolerance                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸŒ Geographic Load Balancing & Failover

**Global Load Balancing System:**

```python
import asyncio
import time
import random
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import aiohttp
import logging
from geopy.distance import geodesic
import statistics

class RegionStatus(Enum):
    ACTIVE = "active"
    STANDBY = "standby"
    MAINTENANCE = "maintenance"
    FAILED = "failed"

class FailoverMode(Enum):
    AUTOMATIC = "automatic"
    MANUAL = "manual"
    HYBRID = "hybrid"

@dataclass
class GeographicRegion:
    id: str
    name: str
    country: str
    latitude: float
    longitude: float
    endpoints: List[str]
    capacity: int
    current_load: int = 0
    status: RegionStatus = RegionStatus.ACTIVE
    priority: int = 1  # 1 = highest priority
    health_score: float = 1.0
    last_health_check: float = 0
    response_times: List[float] = field(default_factory=list)
    error_rate: float = 0.0
    
    @property
    def load_percentage(self) -> float:
        return (self.current_load / self.capacity * 100) if self.capacity > 0 else 100
    
    @property
    def avg_response_time(self) -> float:
        return statistics.mean(self.response_times) if self.response_times else 0

@dataclass
class ClientLocation:
    ip: str
    country: str
    latitude: float
    longitude: float

class GlobalLoadBalancer:
    def __init__(self, failover_mode: FailoverMode = FailoverMode.AUTOMATIC):
        self.regions: Dict[str, GeographicRegion] = {}
        self.failover_mode = failover_mode
        self.primary_region_id: Optional[str] = None
        
        # Failover configuration
        self.failover_threshold = 0.3  # Health score threshold for failover
        self.failover_cooldown = 300   # 5 minutes between failovers
        self.last_failover_time = 0
        
        # Traffic routing policies
        self.routing_policies = {
            'latency_based': self._latency_based_routing,
            'geolocation': self._geolocation_routing,
            'weighted': self._weighted_routing,
            'failover': self._failover_routing
        }
        
        self.current_policy = 'latency_based'
        
        # Statistics
        self.stats = {
            'total_requests': 0,
            'requests_by_region': {},
            'failover_events': 0,
            'manual_failovers': 0,
            'automatic_failovers': 0
        }
        
        self.logger = logging.getLogger('GlobalLB')
        
        # Health checking
        self.health_check_interval = 30
        self.health_check_tasks: Dict[str, asyncio.Task] = {}
    
    def add_region(self, region: GeographicRegion):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð³ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°"""
        
        self.regions[region.id] = region
        self.stats['requests_by_region'][region.id] = 0
        
        # Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ñ€ÐµÐ³Ð¸Ð¾Ð½, Ð´ÐµÐ»Ð°ÐµÐ¼ ÐµÐ³Ð¾ primary
        if not self.primary_region_id:
            self.primary_region_id = region.id
            region.priority = 1
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ health check
        self._start_health_check(region.id)
        
        self.logger.info(f"Added region {region.id} ({region.name})")
    
    def set_primary_region(self, region_id: str):
        """Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð³Ð¾ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°"""
        
        if region_id in self.regions:
            # Ð¡Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ Ñƒ ÑÑ‚Ð°Ñ€Ð¾Ð³Ð¾ primary
            if self.primary_region_id:
                self.regions[self.primary_region_id].priority = 2
            
            # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ð¹ primary
            self.primary_region_id = region_id
            self.regions[region_id].priority = 1
            
            self.logger.info(f"Set primary region: {region_id}")
    
    async def route_request(self, client_location: ClientLocation, 
                          request_data: Dict = None) -> Optional[str]:
        """ÐœÐ°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð² Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€ÐµÐ³Ð¸Ð¾Ð½"""
        
        self.stats['total_requests'] += 1
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ñ‹
        available_regions = [
            region for region in self.regions.values()
            if region.status == RegionStatus.ACTIVE and region.health_score > 0.1
        ]
        
        if not available_regions:
            self.logger.error("No available regions for request routing")
            return None
        
        # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÑƒ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        routing_func = self.routing_policies.get(self.current_policy)
        if not routing_func:
            routing_func = self._latency_based_routing
        
        selected_region = routing_func(client_location, available_regions, request_data)
        
        if selected_region:
            selected_region.current_load += 1
            self.stats['requests_by_region'][selected_region.id] += 1
            
            self.logger.debug(f"Routed request to region {selected_region.id}")
            
            return selected_region.id
        
        return None
    
    def _latency_based_routing(self, client_location: ClientLocation, 
                             regions: List[GeographicRegion], 
                             request_data: Dict = None) -> Optional[GeographicRegion]:
        """ÐœÐ°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚Ð¸"""
        
        def calculate_score(region: GeographicRegion) -> float:
            # Ð“ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
            distance = geodesic(
                (client_location.latitude, client_location.longitude),
                (region.latitude, region.longitude)
            ).kilometers
            
            # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ (0-1, Ð³Ð´Ðµ 0 = Ð»ÑƒÑ‡ÑˆÐµ)
            max_distance = 20000  # ÐŸÑ€Ð¸Ð¼ÐµÑ€Ð½Ð¾ Ð¿Ð¾Ð»Ð¾Ð²Ð¸Ð½Ð° Ð¾ÐºÑ€ÑƒÐ¶Ð½Ð¾ÑÑ‚Ð¸ Ð—ÐµÐ¼Ð»Ð¸
            distance_score = min(distance / max_distance, 1.0)
            
            # Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°
            load_score = region.load_percentage / 100
            
            # Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°
            health_score = 1.0 - region.health_score
            
            # Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
            response_time_score = min(region.avg_response_time / 1000, 1.0)  
            
            # ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ° (Ð¼ÐµÐ½ÑŒÑˆÐµ = Ð»ÑƒÑ‡ÑˆÐµ)
            combined_score = (
                distance_score * 0.4 +
                load_score * 0.3 + 
                health_score * 0.2 +
                response_time_score * 0.1
            )
            
            return combined_score
        
        # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ€ÐµÐ³Ð¸Ð¾Ð½ Ñ Ð½Ð°Ð¸Ð¼ÐµÐ½ÑŒÑˆÐµÐ¹ Ð¾Ñ†ÐµÐ½ÐºÐ¾Ð¹
        return min(regions, key=calculate_score)
    
    def _geolocation_routing(self, client_location: ClientLocation,
                           regions: List[GeographicRegion],
                           request_data: Dict = None) -> Optional[GeographicRegion]:
        """ÐœÐ°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð³ÐµÐ¾Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¸"""
        
        # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ñ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ€ÐµÐ³Ð¸Ð¾Ð½ Ð² Ñ‚Ð¾Ð¹ Ð¶Ðµ ÑÑ‚Ñ€Ð°Ð½Ðµ
        same_country_regions = [r for r in regions if r.country == client_location.country]
        
        if same_country_regions:
            # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ñ€ÐµÐ³Ð¸Ð¾Ð½ Ð² ÑÑ‚Ñ€Ð°Ð½Ðµ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¸ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ
            def country_score(region: GeographicRegion) -> float:
                return region.load_percentage + (1.0 - region.health_score) * 100
            
            return min(same_country_regions, key=country_score)
        
        # Ð•ÑÐ»Ð¸ Ð² ÑÑ‚Ñ€Ð°Ð½Ðµ Ð½ÐµÑ‚ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð¾Ð², Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ latency-based
        return self._latency_based_routing(client_location, regions, request_data)
    
    def _weighted_routing(self, client_location: ClientLocation,
                         regions: List[GeographicRegion], 
                         request_data: Dict = None) -> Optional[GeographicRegion]:
        """Ð’Ð·Ð²ÐµÑˆÐµÐ½Ð½Ð°Ñ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð°"""
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð²Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð° Ð¸ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
        weights = []
        for region in regions:
            # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð²ÐµÑ - Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾ Ð¿Ñ€Ð¾Ð¿Ð¾Ñ€Ñ†Ð¸Ð¾Ð½Ð°Ð»ÐµÐ½ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ñƒ
            base_weight = 10 / region.priority
            
            # ÐšÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
            health_factor = region.health_score
            load_factor = max(0.1, 1.0 - (region.load_percentage / 100))
            
            effective_weight = base_weight * health_factor * load_factor
            weights.append(effective_weight)
        
        if not weights or sum(weights) == 0:
            return regions[0]
        
        # Weighted random selection
        total_weight = sum(weights)
        random_value = random.uniform(0, total_weight)
        
        current_weight = 0
        for i, region in enumerate(regions):
            current_weight += weights[i]
            if random_value <= current_weight:
                return region
        
        return regions[-1]
    
    def _failover_routing(self, client_location: ClientLocation,
                         regions: List[GeographicRegion],
                         request_data: Dict = None) -> Optional[GeographicRegion]:
        """Failover Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ - primary/standby"""
        
        # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ñƒ
        sorted_regions = sorted(regions, key=lambda r: r.priority)
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ primary Ñ€ÐµÐ³Ð¸Ð¾Ð½
        primary = sorted_regions[0]
        
        if (primary.status == RegionStatus.ACTIVE and 
            primary.health_score > self.failover_threshold and
            primary.load_percentage < 90):
            return primary
        
        # Primary Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½, Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ÑÑ Ð½Ð° standby
        for region in sorted_regions[1:]:
            if (region.status == RegionStatus.ACTIVE and
                region.health_score > 0.5):
                
                # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ failover ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ
                if region != primary:
                    self._trigger_failover(primary.id, region.id, "automatic")
                
                return region
        
        return None
    
    def _trigger_failover(self, from_region: str, to_region: str, failover_type: str):
        """Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ñ€Ð¾Ñ†ÐµÐ´ÑƒÑ€Ñ‹ failover"""
        
        current_time = time.time()
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ cooldown period
        if current_time - self.last_failover_time < self.failover_cooldown:
            self.logger.info(f"Failover suppressed due to cooldown period")
            return
        
        self.last_failover_time = current_time
        self.stats['failover_events'] += 1
        
        if failover_type == "automatic":
            self.stats['automatic_failovers'] += 1
        else:
            self.stats['manual_failovers'] += 1
        
        self.logger.warning(f"FAILOVER: {from_region} -> {to_region} ({failover_type})")
        
        # ÐœÐ¾Ð¶Ð½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ Ð»Ð¾Ð³Ð¸ÐºÑƒ:
        # - Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ðµ
        # - Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² Ð²Ð½ÐµÑˆÐ½Ð¸Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
        # - ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ†ÐµÐ»ÐµÐ²Ð¾Ð³Ð¾ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°
    
    async def manual_failover(self, to_region_id: str) -> bool:
        """Ð ÑƒÑ‡Ð½Ð¾Ð¹ failover Ð½Ð° ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¹ Ñ€ÐµÐ³Ð¸Ð¾Ð½"""
        
        if to_region_id not in self.regions:
            self.logger.error(f"Region {to_region_id} not found for manual failover")
            return False
        
        target_region = self.regions[to_region_id]
        
        if target_region.status != RegionStatus.ACTIVE:
            self.logger.error(f"Region {to_region_id} is not active for failover")
            return False
        
        # ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ primary
        old_primary = self.primary_region_id
        self.set_primary_region(to_region_id)
        
        if old_primary:
            self._trigger_failover(old_primary, to_region_id, "manual")
        
        return True
    
    def _start_health_check(self, region_id: str):
        """Ð—Ð°Ð¿ÑƒÑÐº health check Ð´Ð»Ñ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°"""
        
        async def health_check_loop():
            region = self.regions[region_id]
            
            while region_id in self.regions:
                try:
                    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ endpoint Ð² Ñ€ÐµÐ³Ð¸Ð¾Ð½Ðµ
                    response_times = []
                    successful_checks = 0
                    
                    for endpoint in region.endpoints:
                        try:
                            start_time = time.time()
                            
                            async with aiohttp.ClientSession() as session:
                                async with session.get(
                                    f"{endpoint}/health",
                                    timeout=aiohttp.ClientTimeout(total=10)
                                ) as response:
                                    
                                    response_time = (time.time() - start_time) * 1000
                                    response_times.append(response_time)
                                    
                                    if response.status == 200:
                                        successful_checks += 1
                        
                        except Exception as e:
                            self.logger.debug(f"Health check failed for {endpoint}: {e}")
                    
                    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ health score
                    if region.endpoints:
                        success_rate = successful_checks / len(region.endpoints)
                        
                        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ health score
                        if success_rate > 0.8:
                            region.health_score = min(1.0, region.health_score + 0.1)
                        elif success_rate > 0.5:
                            region.health_score = max(0.1, region.health_score - 0.05)
                        else:
                            region.health_score = max(0.1, region.health_score - 0.2)
                        
                        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
                        if response_times:
                            region.response_times = response_times[-10:]  # Ð¥Ñ€Ð°Ð½Ð¸Ð¼ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 10
                        
                        # ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ failover ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾
                        if (self.failover_mode in [FailoverMode.AUTOMATIC, FailoverMode.HYBRID] and
                            region.id == self.primary_region_id and
                            region.health_score < self.failover_threshold):
                            
                            # Ð˜Ñ‰ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ³Ð¸Ð¾Ð½
                            alternative_regions = [
                                r for r in self.regions.values()
                                if r.id != region.id and r.status == RegionStatus.ACTIVE
                            ]
                            
                            if alternative_regions:
                                best_alternative = max(alternative_regions, key=lambda r: r.health_score)
                                if best_alternative.health_score > 0.7:
                                    self._trigger_failover(region.id, best_alternative.id, "automatic")
                                    self.set_primary_region(best_alternative.id)
                    
                    region.last_health_check = time.time()
                
                except Exception as e:
                    self.logger.error(f"Health check error for region {region_id}: {e}")
                
                await asyncio.sleep(self.health_check_interval)
        
        task = asyncio.create_task(health_check_loop())
        self.health_check_tasks[region_id] = task
    
    def get_global_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸"""
        
        region_stats = {}
        total_capacity = 0
        total_load = 0
        
        for region_id, region in self.regions.items():
            region_stats[region_id] = {
                'name': region.name,
                'country': region.country,
                'status': region.status.value,
                'priority': region.priority,
                'health_score': region.health_score,
                'load_percentage': region.load_percentage,
                'avg_response_time': region.avg_response_time,
                'requests_handled': self.stats['requests_by_region'].get(region_id, 0),
                'is_primary': region_id == self.primary_region_id
            }
            
            total_capacity += region.capacity
            total_load += region.current_load
        
        global_load_percentage = (total_load / total_capacity * 100) if total_capacity > 0 else 0
        
        return {
            'total_requests': self.stats['total_requests'],
            'total_regions': len(self.regions),
            'active_regions': len([r for r in self.regions.values() if r.status == RegionStatus.ACTIVE]),
            'primary_region': self.primary_region_id,
            'current_routing_policy': self.current_policy,
            'failover_mode': self.failover_mode.value,
            'global_load_percentage': global_load_percentage,
            'failover_events': self.stats['failover_events'],
            'automatic_failovers': self.stats['automatic_failovers'],
            'manual_failovers': self.stats['manual_failovers'],
            'region_stats': region_stats
        }
    
    async def shutdown(self):
        """Graceful shutdown"""
        
        for task in self.health_check_tasks.values():
            task.cancel()
        
        if self.health_check_tasks:
            await asyncio.gather(*self.health_check_tasks.values(), return_exceptions=True)

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Global Load Balancer
async def demonstrate_global_load_balancing():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ¸ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸"""
    
    print("ðŸŒ Global Load Balancing & High Availability Demonstration")
    print("=" * 70)
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ load balancer
    glb = GlobalLoadBalancer(FailoverMode.AUTOMATIC)
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð³ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ñ‹
    regions = [
        GeographicRegion(
            id='us-east',
            name='US East Coast',
            country='US',
            latitude=40.7128,
            longitude=-74.0060,
            endpoints=['https://us-east-1.example.com', 'https://us-east-2.example.com'],
            capacity=1000
        ),
        GeographicRegion(
            id='us-west',
            name='US West Coast', 
            country='US',
            latitude=37.7749,
            longitude=-122.4194,
            endpoints=['https://us-west-1.example.com'],
            capacity=800
        ),
        GeographicRegion(
            id='eu-west',
            name='Europe West',
            country='IE',
            latitude=53.3498,
            longitude=-6.2603,
            endpoints=['https://eu-west-1.example.com', 'https://eu-west-2.example.com'],
            capacity=600,
            priority=2
        ),
        GeographicRegion(
            id='ap-southeast',
            name='Asia Pacific Southeast',
            country='SG', 
            latitude=1.3521,
            longitude=103.8198,
            endpoints=['https://ap-southeast-1.example.com'],
            capacity=400,
            priority=3
        )
    ]
    
    print("ðŸŒ Adding geographic regions:")
    for region in regions:
        glb.add_region(region)
        print(f"  Added {region.name} ({region.country}) - Capacity: {region.capacity}")
    
    # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ us-east ÐºÐ°Ðº primary
    glb.set_primary_region('us-east')
    
    await asyncio.sleep(2)  # Ð”Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð´Ð»Ñ health checks
    
    # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²
    print(f"\nðŸ“ Testing routing for different client locations:")
    
    test_clients = [
        ClientLocation('192.168.1.100', 'US', 40.7589, -73.9851),    # New York
        ClientLocation('10.0.0.50', 'US', 37.7749, -122.4194),      # San Francisco  
        ClientLocation('203.0.113.10', 'GB', 51.5074, -0.1278),     # London
        ClientLocation('198.51.100.5', 'SG', 1.3521, 103.8198),     # Singapore
        ClientLocation('172.16.0.100', 'JP', 35.6762, 139.6503),    # Tokyo
    ]
    
    routing_results = {}
    
    for client in test_clients:
        print(f"\n  Client from {client.country}:")
        
        # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÐ¸ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        for policy in ['latency_based', 'geolocation', 'weighted', 'failover']:
            glb.current_policy = policy
            
            selected_region = await glb.route_request(client)
            
            if selected_region:
                region = glb.regions[selected_region]
                distance = geodesic(
                    (client.latitude, client.longitude),
                    (region.latitude, region.longitude)
                ).kilometers
                
                print(f"    {policy}: {region.name} (distance: {distance:.0f}km)")
                
                routing_results[f"{client.country}_{policy}"] = {
                    'region': region.name,
                    'distance': distance
                }
            else:
                print(f"    {policy}: No region selected")
    
    # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ Ð½Ð° Ñ€ÐµÐ³Ð¸Ð¾Ð½Ñ‹
    print(f"\nâš¡ Simulating traffic load:")
    
    glb.current_policy = 'latency_based'
    
    # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ñ€Ð°Ñ„Ð¸Ðº
    for i in range(100):
        client = random.choice(test_clients)
        selected_region = await glb.route_request(client)
        
        if selected_region:
            # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
            glb.regions[selected_region].current_load = max(0, 
                glb.regions[selected_region].current_load - 1)
        
        if i % 20 == 19:
            await asyncio.sleep(0.1)
    
    # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
    stats = glb.get_global_stats()
    
    print(f"  Total requests processed: {stats['total_requests']}")
    print(f"  Global load: {stats['global_load_percentage']:.1f}%")
    print(f"  Primary region: {stats['primary_region']}")
    
    print(f"\n  Request distribution by region:")
    for region_id, region_stats in stats['region_stats'].items():
        requests = region_stats['requests_handled']
        percentage = (requests / stats['total_requests'] * 100) if stats['total_requests'] > 0 else 0
        
        print(f"    {region_stats['name']}: {requests} requests ({percentage:.1f}%)")
    
    # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚ÐºÐ°Ð· primary Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°
    print(f"\nðŸš¨ Simulating primary region failure:")
    
    primary_region = glb.regions[glb.primary_region_id]
    print(f"  Degrading health of {primary_region.name}...")
    
    # ÐŸÐ¾ÑÑ‚ÐµÐ¿ÐµÐ½Ð½Ð¾ ÑƒÑ…ÑƒÐ´ÑˆÐ°ÐµÐ¼ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ primary Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°
    for i in range(10):
        primary_region.health_score -= 0.1
        await asyncio.sleep(0.5)
        
        if primary_region.health_score <= glb.failover_threshold:
            print(f"  Health score dropped to {primary_region.health_score:.1f}")
            break
    
    # Ð–Ð´ÐµÐ¼ ÑÑ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ failover
    await asyncio.sleep(3)
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ failover
    final_stats = glb.get_global_stats()
    
    print(f"\nðŸ“Š Post-failover status:")
    print(f"  New primary region: {final_stats['primary_region']}")
    print(f"  Total failover events: {final_stats['failover_events']}")
    print(f"  Automatic failovers: {final_stats['automatic_failovers']}")
    
    print(f"\n  Region health status:")
    for region_id, region_stats in final_stats['region_stats'].items():
        health = region_stats['health_score']
        status = region_stats['status']
        is_primary = region_stats['is_primary']
        
        primary_marker = " (PRIMARY)" if is_primary else ""
        print(f"    {region_stats['name']}: {status} (health: {health:.2f}){primary_marker}")
    
    # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÑƒÑ‡Ð½Ð¾Ð¹ failover
    print(f"\nðŸ”„ Testing manual failover:")
    
    target_region = 'eu-west'
    success = await glb.manual_failover(target_region)
    
    if success:
        print(f"  âœ… Manual failover to {target_region} successful")
        
        manual_stats = glb.get_global_stats()
        print(f"  New primary: {manual_stats['primary_region']}")
        print(f"  Manual failovers: {manual_stats['manual_failovers']}")
    else:
        print(f"  âŒ Manual failover to {target_region} failed")
    
    # ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ°
    await glb.shutdown()
    
    print(f"\nâœ… Global load balancing demonstration completed")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
if __name__ == "__main__":
    asyncio.run(demonstrate_global_load_balancing())
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ ÐÐµÐ´ÐµÐ»Ñ 14

1. Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð¹Ñ‚Ðµ multi-region Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð´Ð»Ñ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
2. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ failover Ð¼ÐµÐ¶Ð´Ñƒ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°Ð¼Ð¸
3. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ geographic load balancing Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚Ð¸
4. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ disaster recovery Ð¿Ð»Ð°Ð½ Ñ RTO/RPO Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸
5. ÐŸÑ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð¾Ñ‚ÐºÐ°Ð·Ð¾ÑƒÑÑ‚Ð¾Ð¹Ñ‡Ð¸Ð²Ð¾ÑÑ‚ÑŒ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¿Ñ€Ð¸ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… ÑÑ†ÐµÐ½Ð°Ñ€Ð¸ÑÑ… ÑÐ±Ð¾ÐµÐ²

### âœ… ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒÐ½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹

- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹ high availability Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹?
- [ ] ÐœÐ¾Ð¶ÐµÑ‚Ðµ ÑÐ¿Ñ€Ð¾ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ geographic load balancing?
- [ ] Ð—Ð½Ð°ÐµÑ‚Ðµ ÐºÐ°Ðº Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ automatic failover?
- [ ] Ð£Ð¼ÐµÐµÑ‚Ðµ Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ RTO Ð¸ RPO Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹?
- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ trade-offs Ð¼ÐµÐ¶Ð´Ñƒ consistency Ð¸ availability?

---

# ÐœÐ¾Ð´ÑƒÐ»ÑŒ 8: Ð¡Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ñ‹ Ð¸ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ {#module-8}
*ÐÐµÐ´ÐµÐ»Ð¸ 15-16 | Ð’Ñ€ÐµÐ¼Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ: 16-20 Ñ‡Ð°ÑÐ¾Ð²*

## ÐÐµÐ´ÐµÐ»Ñ 15: ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ðµ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ñ‹

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: Ð­Ð²Ð¾Ð»ÑŽÑ†Ð¸Ñ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ð¾Ð²

Ð¡Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ñ‹ Ñ€ÐµÑˆÐ°ÑŽÑ‚ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¸ real-time ÐºÐ¾Ð¼Ð¼ÑƒÐ½Ð¸ÐºÐ°Ñ†Ð¸Ð¹:

```
Protocol Evolution Timeline:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP/1.1 (1997)                                            â”‚
â”‚ â”œâ”€ Text-based, simple                                      â”‚
â”‚ â”œâ”€ Head-of-line blocking                                   â”‚
â”‚ â””â”€ Multiple connections needed                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ WebSockets (2011)                                          â”‚
â”‚ â”œâ”€ Full-duplex communication                               â”‚
â”‚ â”œâ”€ Real-time capabilities                                  â”‚
â”‚ â””â”€ Persistent connections                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ HTTP/2 (2015)                                              â”‚
â”‚ â”œâ”€ Binary framing                                          â”‚
â”‚ â”œâ”€ Multiplexing                                           â”‚
â”‚ â””â”€ Server push                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ gRPC (2016)                                                â”‚
â”‚ â”œâ”€ Protocol Buffers                                       â”‚
â”‚ â”œâ”€ Streaming support                                      â”‚
â”‚ â””â”€ Strong typing                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ HTTP/3 + QUIC (2022)                                       â”‚
â”‚ â”œâ”€ UDP-based transport                                    â”‚
â”‚ â”œâ”€ 0-RTT handshake                                        â”‚
â”‚ â””â”€ Connection migration                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ”Œ Advanced WebSocket Implementation

**Production-ready WebSocket Server:**

```python
import asyncio
import json
import time
import uuid
from typing import Dict, List, Set, Optional, Callable, Any
from dataclasses import dataclass, field
from enum import Enum
import websockets
import logging
from collections import defaultdict, deque
import statistics
import jwt
import hashlib

class ConnectionState(Enum):
    CONNECTING = "connecting"
    CONNECTED = "connected"
    AUTHENTICATED = "authenticated"
    DISCONNECTING = "disconnecting"
    DISCONNECTED = "disconnected"

class MessageType(Enum):
    PING = "ping"
    PONG = "pong"
    AUTH = "auth"
    SUBSCRIBE = "subscribe"
    UNSUBSCRIBE = "unsubscribe"
    DATA = "data"
    ERROR = "error"
    HEARTBEAT = "heartbeat"

@dataclass
class WebSocketConnection:
    id: str
    websocket: websockets.WebSocketServerProtocol
    user_id: Optional[str] = None
    state: ConnectionState = ConnectionState.CONNECTING
    authenticated: bool = False
    subscriptions: Set[str] = field(default_factory=set)
    connected_at: float = field(default_factory=time.time)
    last_activity: float = field(default_factory=time.time)
    messages_sent: int = 0
    messages_received: int = 0
    bytes_sent: int = 0
    bytes_received: int = 0
    metadata: Dict = field(default_factory=dict)

@dataclass
class Subscription:
    topic: str
    connections: Set[str] = field(default_factory=set)
    message_count: int = 0
    last_message_time: float = 0

class WebSocketServer:
    def __init__(self, host: str = "localhost", port: int = 8765):
        self.host = host
        self.port = port
        
        # Connection management
        self.connections: Dict[str, WebSocketConnection] = {}
        self.subscriptions: Dict[str, Subscription] = {}
        
        # Authentication
        self.jwt_secret = "your-secret-key"  # Ð’ Ð¿Ñ€Ð¾Ð´Ð°ÐºÑˆÐµÐ½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ð¹ ÐºÐ»ÑŽÑ‡
        self.auth_required = True
        
        # Message routing
        self.message_handlers: Dict[MessageType, Callable] = {
            MessageType.PING: self._handle_ping,
            MessageType.AUTH: self._handle_auth,
            MessageType.SUBSCRIBE: self._handle_subscribe,
            MessageType.UNSUBSCRIBE: self._handle_unsubscribe,
            MessageType.DATA: self._handle_data,
            MessageType.HEARTBEAT: self._handle_heartbeat
        }
        
        # Configuration
        self.heartbeat_interval = 30  # ÑÐµÐºÑƒÐ½Ð´
        self.connection_timeout = 300  # 5 Ð¼Ð¸Ð½ÑƒÑ‚
        self.max_connections = 10000
        self.max_message_size = 1024 * 1024  # 1MB
        
        # Statistics
        self.stats = {
            'total_connections': 0,
            'current_connections': 0,
            'total_messages': 0,
            'messages_by_type': defaultdict(int),
            'bytes_transferred': 0,
            'connection_errors': 0,
            'authentication_failures': 0
        }
        
        # Background tasks
        self.cleanup_task: Optional[asyncio.Task] = None
        self.heartbeat_task: Optional[asyncio.Task] = None
        
        self.logger = logging.getLogger('WebSocketServer')
    
    async def start(self):
        """Ð—Ð°Ð¿ÑƒÑÐº WebSocket ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        
        self.logger.info(f"Starting WebSocket server on {self.host}:{self.port}")
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ñ„Ð¾Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
        self.cleanup_task = asyncio.create_task(self._cleanup_loop())
        self.heartbeat_task = asyncio.create_task(self._heartbeat_loop())
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ WebSocket ÑÐµÑ€Ð²ÐµÑ€
        async with websockets.serve(
            self._handle_connection,
            self.host,
            self.port,
            max_size=self.max_message_size,
            ping_interval=None,  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÐ¾Ð±ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ heartbeat
            ping_timeout=None
        ):
            self.logger.info("WebSocket server started successfully")
            await asyncio.Future()  # Ð Ð°Ð±Ð¾Ñ‚Ð°ÐµÐ¼ Ð±ÐµÑÐºÐ¾Ð½ÐµÑ‡Ð½Ð¾
    
    async def _handle_connection(self, websocket, path):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½Ð¾Ð²Ð¾Ð³Ð¾ WebSocket ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ"""
        
        connection_id = str(uuid.uuid4())
        remote_address = websocket.remote_address
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð»Ð¸Ð¼Ð¸Ñ‚ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        if len(self.connections) >= self.max_connections:
            await websocket.close(code=1013, reason="Server overloaded")
            self.stats['connection_errors'] += 1
            return
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ
        connection = WebSocketConnection(
            id=connection_id,
            websocket=websocket,
            state=ConnectionState.CONNECTED
        )
        
        self.connections[connection_id] = connection
        self.stats['total_connections'] += 1
        self.stats['current_connections'] += 1
        
        self.logger.info(f"New connection {connection_id} from {remote_address}")
        
        try:
            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ welcome message
            await self._send_message(connection, {
                'type': 'welcome',
                'connection_id': connection_id,
                'server_time': time.time(),
                'auth_required': self.auth_required
            })
            
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
            async for raw_message in websocket:
                await self._process_message(connection, raw_message)
        
        except websockets.exceptions.ConnectionClosed:
            self.logger.info(f"Connection {connection_id} closed normally")
        
        except Exception as e:
            self.logger.error(f"Error handling connection {connection_id}: {e}")
            self.stats['connection_errors'] += 1
        
        finally:
            # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ
            await self._cleanup_connection(connection_id)
    
    async def _process_message(self, connection: WebSocketConnection, raw_message: str):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ñ…Ð¾Ð´ÑÑ‰ÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ"""
        
        try:
            # ÐŸÐ°Ñ€ÑÐ¸Ð¼ JSON
            message = json.loads(raw_message)
            
            # Ð’Ð°Ð»Ð¸Ð´Ð¸Ñ€ÑƒÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
            if 'type' not in message:
                await self._send_error(connection, "Missing message type")
                return
            
            message_type_str = message['type']
            
            try:
                message_type = MessageType(message_type_str)
            except ValueError:
                await self._send_error(connection, f"Unknown message type: {message_type_str}")
                return
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸ÑŽ
            if (self.auth_required and 
                not connection.authenticated and 
                message_type != MessageType.AUTH):
                await self._send_error(connection, "Authentication required")
                return
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
            connection.messages_received += 1
            connection.bytes_received += len(raw_message)
            connection.last_activity = time.time()
            
            self.stats['total_messages'] += 1
            self.stats['messages_by_type'][message_type.value] += 1
            self.stats['bytes_transferred'] += len(raw_message)
            
            # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº
            handler = self.message_handlers.get(message_type)
            if handler:
                await handler(connection, message)
            else:
                await self._send_error(connection, f"No handler for message type: {message_type_str}")
        
        except json.JSONDecodeError:
            await self._send_error(connection, "Invalid JSON format")
        
        except Exception as e:
            self.logger.error(f"Error processing message from {connection.id}: {e}")
            await self._send_error(connection, "Internal server error")
    
    async def _handle_ping(self, connection: WebSocketConnection, message: Dict):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ping ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ"""
        
        await self._send_message(connection, {
            'type': 'pong',
            'timestamp': time.time(),
            'data': message.get('data')
        })
    
    async def _handle_auth(self, connection: WebSocketConnection, message: Dict):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸"""
        
        token = message.get('token')
        
        if not token:
            await self._send_error(connection, "Authentication token required")
            self.stats['authentication### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ ÐÐµÐ´ÐµÐ»Ñ 11

1. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ Ð¼Ð½Ð¾Ð³Ð¾ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²ÑƒÑŽ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ rate limiting Ð´Ð»Ñ Ð²Ð°ÑˆÐ¸Ñ… API
2. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Network IDS Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ñ‚Ñ€Ð°Ñ„Ð¸ÐºÐ° Ð¼ÐµÐ¶Ð´Ñƒ Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ°Ð¼Ð¸
3. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ñ€ÐµÐ°Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð½Ð° security events
4. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ whitelist/blacklist ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼
5. Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ security Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ñ Ð²Ð°ÑˆÐµÐ¹ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ¹ observability ÑÑ‚ÐµÐºÐ¾Ð¼

---

## ÐÐµÐ´ÐµÐ»Ñ 12: Ð¨Ð¸Ñ„Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: TLS/SSL Ð² Ð³Ð»ÑƒÐ±Ð¸Ð½Ñƒ

TLS (Transport Layer Security) - Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ñ… ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹:

```
TLS 1.3 Handshake Process:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client Hello                                                â”‚
â”‚ â”œâ”€ Supported cipher suites                                 â”‚
â”‚ â”œâ”€ Key exchange algorithms                                  â”‚
â”‚ â”œâ”€ Random nonce                                            â”‚
â”‚ â””â”€ Extensions (SNI, ALPN, etc.)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Server Hello + Certificate + Server Finished              â”‚
â”‚ â”œâ”€ Selected cipher suite                                   â”‚
â”‚ â”œâ”€ Server certificate chain                               â”‚
â”‚ â”œâ”€ Digital signature                                      â”‚
â”‚ â””â”€ Encrypted extensions                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Client Finished                                            â”‚
â”‚ â”œâ”€ Certificate verification                                â”‚
â”‚ â”œâ”€ Key derivation                                         â”‚
â”‚ â””â”€ Handshake completion                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Application Data (Encrypted)                               â”‚
â”‚ â”œâ”€ Perfect Forward Secrecy                                â”‚
â”‚ â”œâ”€ 0-RTT resumption (optional)                           â”‚
â”‚ â””â”€ Continuous key rotation                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ” Advanced TLS Configuration

**Production-grade TLS Setup:**

```python
import ssl
import socket
import asyncio
import aiohttp
import time
import hashlib
import base64
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import logging
import cryptography
from cryptography import x509
from cryptography.hazmat.primitives import hashes, serialization
from cryptography.hazmat.primitives.asymmetric import rsa, padding
from cryptography.x509.oid import NameOID, ExtensionOID
import datetime

class TLSVersion(Enum):
    TLS_1_2 = ssl.TLSVersion.TLSv1_2
    TLS_1_3 = ssl.TLSVersion.TLSv1_3

@dataclass
class TLSConfig:
    min_version: TLSVersion = TLS_1_2
    max_version: TLSVersion = TLS_1_3
    cipher_suites: List[str] = None
    verify_mode: ssl.VerifyMode = ssl.CERT_REQUIRED
    check_hostname: bool = True
    ca_bundle_path: Optional[str] = None
    cert_file: Optional[str] = None
    key_file: Optional[str] = None
    dh_params_file: Optional[str] = None

class TLSSecurityAnalyzer:
    def __init__(self):
        self.logger = logging.getLogger('TLSAnalyzer')
        
        # Modern secure cipher suites
        self.recommended_ciphers = [
            'TLS_AES_256_GCM_SHA384',          # TLS 1.3
            'TLS_CHACHA20_POLY1305_SHA256',    # TLS 1.3
            'TLS_AES_128_GCM_SHA256',          # TLS 1.3
            'ECDHE-RSA-AES256-GCM-SHA384',     # TLS 1.2
            'ECDHE-RSA-CHACHA20-POLY1305',     # TLS 1.2
            'ECDHE-RSA-AES128-GCM-SHA256',     # TLS 1.2
        ]
        
        # Weak/deprecated ciphers to avoid
        self.weak_ciphers = [
            'RC4', 'MD5', 'SHA1', 'DES', '3DES',
            'NULL', 'aNULL', 'eNULL', 'EXPORT'
        ]
    
    def create_secure_context(self, config: TLSConfig, server_side: bool = False) -> ssl.SSLContext:
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ð³Ð¾ SSL context"""
        
        # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»
        if server_side:
            context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)
        else:
            context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
        
        # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð²ÐµÑ€ÑÐ¸Ð¸ TLS
        context.minimum_version = config.min_version.value
        context.maximum_version = config.max_version.value
        
        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸
        context.verify_mode = config.verify_mode
        context.check_hostname = config.check_hostname
        
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ñ‹
        if config.cert_file and config.key_file:
            context.load_cert_chain(config.cert_file, config.key_file)
        
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ CA bundle
        if config.ca_bundle_path:
            context.load_verify_locations(config.ca_bundle_path)
        else:
            context.load_default_certs()
        
        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° cipher suites
        if config.cipher_suites:
            cipher_string = ':'.join(config.cipher_suites)
        else:
            # Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
            cipher_string = ':'.join([
                'ECDHE+AESGCM',
                'ECDHE+CHACHA20',
                'DHE+AESGCM',
                'DHE+CHACHA20',
                '!aNULL',
                '!MD5',
                '!DSS',
                '!SHA1',
                '!RC4'
            ])
        
        try:
            context.set_ciphers(cipher_string)
        except ssl.SSLError as e:
            self.logger.warning(f"Failed to set cipher suites: {e}")
        
        # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸
        context.options |= ssl.OP_NO_SSLv2
        context.options |= ssl.OP_NO_SSLv3
        context.options |= ssl.OP_NO_COMPRESSION
        context.options |= ssl.OP_CIPHER_SERVER_PREFERENCE
        context.options |= ssl.OP_SINGLE_DH_USE
        context.options |= ssl.OP_SINGLE_ECDH_USE
        
        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ECDH curves
        try:
            context.set_ecdh_curve('prime256v1')
        except AttributeError:
            pass  # ÐÐµ Ð²ÑÐµ Ð²ÐµÑ€ÑÐ¸Ð¸ Python Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÑŽÑ‚
        
        return context
    
    async def analyze_tls_connection(self, hostname: str, port: int = 443) -> Dict:
        """ÐÐ½Ð°Ð»Ð¸Ð· TLS ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ"""
        
        analysis_result = {
            'hostname': hostname,
            'port': port,
            'timestamp': time.time(),
            'connection_successful': False,
            'certificate_info': {},
            'protocol_info': {},
            'cipher_info': {},
            'security_score': 0,
            'vulnerabilities': [],
            'recommendations': []
        }
        
        try:
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ SSL context Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
            context = ssl.create_default_context()
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE  # Ð”Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°ÐµÐ¼ Ð»ÑŽÐ±Ñ‹Ðµ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ñ‹
            
            # ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ÑÑ
            with socket.create_connection((hostname, port), timeout=10) as sock:
                with context.wrap_socket(sock, server_hostname=hostname) as ssock:
                    analysis_result['connection_successful'] = True
                    
                    # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ðµ
                    analysis_result['protocol_info'] = {
                        'version': ssock.version(),
                        'cipher': ssock.cipher(),
                        'compression': ssock.compression(),
                        'selected_alpn_protocol': getattr(ssock, 'selected_alpn_protocol', lambda: None)()
                    }
                    
                    # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ðµ
                    cert_der = ssock.getpeercert_raw()
                    cert_dict = ssock.getpeercert()
                    
                    if cert_der:
                        cert = x509.load_der_x509_certificate(cert_der)
                        analysis_result['certificate_info'] = self._analyze_certificate(cert, cert_dict)
                    
                    # ÐÐ½Ð°Ð»Ð¸Ð· cipher suite
                    cipher_info = ssock.cipher()
                    if cipher_info:
                        analysis_result['cipher_info'] = self._analyze_cipher(cipher_info)
                    
                    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ security score
                    analysis_result['security_score'] = self._calculate_security_score(analysis_result)
                    
                    # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
                    analysis_result['recommendations'] = self._generate_recommendations(analysis_result)
        
        except Exception as e:
            analysis_result['error'] = str(e)
            self.logger.error(f"TLS analysis failed for {hostname}:{port}: {e}")
        
        return analysis_result
    
    def _analyze_certificate(self, cert: x509.Certificate, cert_dict: Dict) -> Dict:
        """ÐÐ½Ð°Ð»Ð¸Ð· ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð°"""
        
        current_time = datetime.datetime.now(datetime.timezone.utc)
        
        cert_info = {
            'subject': dict(x[0] for x in cert_dict.get('subject', [])),
            'issuer': dict(x[0] for x in cert_dict.get('issuer', [])),
            'version': cert.version.name,
            'serial_number': str(cert.serial_number),
            'not_before': cert.not_valid_before.isoformat(),
            'not_after': cert.not_valid_after.isoformat(),
            'signature_algorithm': cert.signature_algorithm_oid._name,
            'public_key_algorithm': cert.public_key().__class__.__name__,
            'san_domains': [],
            'key_size': None,
            'is_expired': current_time > cert.not_valid_after,
            'expires_soon': (cert.not_valid_after - current_time).days < 30,
            'is_self_signed': cert.issuer == cert.subject
        }
        
        # ÐÐ½Ð°Ð»Ð¸Ð· Subject Alternative Names
        try:
            san_ext = cert.extensions.get_extension_for_oid(ExtensionOID.SUBJECT_ALTERNATIVE_NAME)
            cert_info['san_domains'] = [name.value for name in san_ext.value]
        except x509.ExtensionNotFound:
            pass
        
        # Ð Ð°Ð·Ð¼ÐµÑ€ ÐºÐ»ÑŽÑ‡Ð°
        public_key = cert.public_key()
        if hasattr(public_key, 'key_size'):
            cert_info['key_size'] = public_key.key_size
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð° ÑÐ»Ð°Ð±Ñ‹Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹
        weak_algorithms = ['md5', 'sha1']
        if any(weak in cert_info['signature_algorithm'].lower() for weak in weak_algorithms):
            cert_info['weak_signature'] = True
        
        return cert_info
    
    def _analyze_cipher(self, cipher_info: Tuple) -> Dict:
        """ÐÐ½Ð°Ð»Ð¸Ð· cipher suite"""
        
        cipher_name, tls_version, secret_bits = cipher_info
        
        cipher_analysis = {
            'name': cipher_name,
            'tls_version': tls_version,
            'secret_bits': secret_bits,
            'is_secure': True,
            'warnings': []
        }
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð° ÑÐ»Ð°Ð±Ñ‹Ðµ cipher'Ñ‹
        cipher_lower = cipher_name.lower()
        
        for weak_cipher in self.weak_ciphers:
            if weak_cipher.lower() in cipher_lower:
                cipher_analysis['is_secure'] = False
                cipher_analysis['warnings'].append(f"Uses weak cipher: {weak_cipher}")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¸Ð»Ñƒ ÑˆÐ¸Ñ„Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        if secret_bits < 128:
            cipher_analysis['is_secure'] = False
            cipher_analysis['warnings'].append(f"Weak encryption strength: {secret_bits} bits")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Perfect Forward Secrecy
        pfs_indicators = ['ecdhe', 'dhe']
        cipher_analysis['perfect_forward_secrecy'] = any(
            indicator in cipher_lower for indicator in pfs_indicators
        )
        
        if not cipher_analysis['perfect_forward_secrecy']:
            cipher_analysis['warnings'].append("No Perfect Forward Secrecy")
        
        return cipher_analysis
    
    def _calculate_security_score(self, analysis: Dict) -> int:
        """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ security score (0-100)"""
        
        score = 100
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ð°
        protocol_version = analysis['protocol_info'].get('version', '')
        if 'TLSv1.3' in protocol_version:
            score += 0  # ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð°Ð»Ð»
        elif 'TLSv1.2' in protocol_version:
            score -= 5
        elif 'TLSv1.' in protocol_version:
            score -= 30  # TLS 1.0/1.1 ÑƒÑÑ‚Ð°Ñ€ÐµÐ»Ð¸
        else:
            score -= 50  # SSL Ð¸Ð»Ð¸ Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð°
        cert_info = analysis.get('certificate_info', {})
        
        if cert_info.get('is_expired'):
            score -= 50
        elif cert_info.get('expires_soon'):
            score -= 10
        
        if cert_info.get('is_self_signed'):
            score -= 20
        
        if cert_info.get('weak_signature'):
            score -= 30
        
        key_size = cert_info.get('key_size', 0)
        if key_size < 2048:
            score -= 40
        elif key_size < 4096:
            score -= 5
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ¸ cipher
        cipher_info = analysis.get('cipher_info', {})
        
        if not cipher_info.get('is_secure'):
            score -= 40
        
        if not cipher_info.get('perfect_forward_secrecy'):
            score -= 15
        
        secret_bits = cipher_info.get('secret_bits', 0)
        if secret_bits < 128:
            score -= 30
        elif secret_bits < 256:
            score -= 5
        
        return max(0, min(100, score))
    
    def _generate_recommendations(self, analysis: Dict) -> List[str]:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹ Ð¿Ð¾ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸ÑŽ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸"""
        
        recommendations = []
        
        # ÐŸÑ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»
        protocol_version = analysis['protocol_info'].get('version', '')
        if 'TLSv1.3' not in protocol_version:
            recommendations.append("Upgrade to TLS 1.3 for better security and performance")
        
        if 'TLSv1.' in protocol_version and 'TLSv1.2' not in protocol_version:
            recommendations.append("Disable TLS 1.0 and 1.1 - they are deprecated")
        
        # Ð¡ÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚
        cert_info = analysis.get('certificate_info', {})
        
        if cert_info.get('is_expired'):
            recommendations.append("Certificate has expired - renew immediately")
        elif cert_info.get('expires_soon'):
            recommendations.append("Certificate expires soon - plan renewal")
        
        if cert_info.get('is_self_signed'):
            recommendations.append("Use a certificate from a trusted CA instead of self-signed")
        
        if cert_info.get('weak_signature'):
            recommendations.append("Certificate uses weak signature algorithm - get new certificate")
        
        key_size = cert_info.get('key_size', 0)
        if key_size < 2048:
            recommendations.append("Use at least 2048-bit RSA keys or 256-bit ECDSA keys")
        
        # Cipher
        cipher_info = analysis.get('cipher_info', {})
        
        if not cipher_info.get('is_secure'):
            recommendations.append("Disable weak cipher suites")
        
        if not cipher_info.get('perfect_forward_secrecy'):
            recommendations.append("Enable Perfect Forward Secrecy with ECDHE or DHE")
        
        # Security score
        if analysis['security_score'] < 70:
            recommendations.append("Overall security configuration needs significant improvement")
        elif analysis['security_score'] < 90:
            recommendations.append("Consider implementing additional security measures")
        
        return recommendations

# Certificate Management System
class CertificateManager:
    def __init__(self):
        self.logger = logging.getLogger('CertManager')
        self.certificates: Dict[str, Dict] = {}
    
    def generate_private_key(self, key_size: int = 2048) -> rsa.RSAPrivateKey:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð²Ð°Ñ‚Ð½Ð¾Ð³Ð¾ ÐºÐ»ÑŽÑ‡Ð°"""
        
        private_key = rsa.generate_private_key(
            public_exponent=65537,
            key_size=key_size,
        )
        
        return private_key
    
    def create_self_signed_cert(self, 
                              common_name: str,
                              san_domains: List[str] = None,
                              days_valid: int = 365,
                              key_size: int = 2048) -> Tuple[bytes, bytes]:
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ self-signed ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð°"""
        
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€Ð¸Ð²Ð°Ñ‚Ð½Ñ‹Ð¹ ÐºÐ»ÑŽÑ‡
        private_key = self.generate_private_key(key_size)
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ subject Ð¸ issuer
        subject = issuer = x509.Name([
            x509.NameAttribute(NameOID.COUNTRY_NAME, "US"),
            x509.NameAttribute(NameOID.STATE_OR_PROVINCE_NAME, "CA"),
            x509.NameAttribute(NameOID.LOCALITY_NAME, "San Francisco"),
            x509.NameAttribute(NameOID.ORGANIZATION_NAME, "My Company"),
            x509.NameAttribute(NameOID.COMMON_NAME, common_name),
        ])
        
        # Ð¡Ñ‚Ñ€Ð¾Ð¸Ð¼ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚
        builder = x509.CertificateBuilder()
        builder = builder.subject_name(subject)
        builder = builder.issuer_name(issuer)
        builder = builder.public_key(private_key.public_key())
        builder = builder.serial_number(x509.random_serial_number())
        builder = builder.not_valid_before(datetime.datetime.utcnow())
        builder = builder.not_valid_after(
            datetime.datetime.utcnow() + datetime.timedelta(days=days_valid)
        )
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ
        builder = builder.add_extension(
            x509.SubjectKeyIdentifier.from_public_key(private_key.public_key()),
            critical=False,
        )
        
        builder = builder.add_extension(
            x509.AuthorityKeyIdentifier.from_issuer_public_key(private_key.public_key()),
            critical=False,
        )
        
        builder = builder.add_extension(
            x509.BasicConstraints(ca=False, path_length=None),
            critical=True,
        )
        
        builder = builder.add_extension(
            x509.KeyUsage(
                digital_signature=True,
                content_commitment=False,
                key_encipherment=True,
                data_encipherment=False,
                key_agreement=False,
                key_cert_sign=False,
                crl_sign=False,
                encipher_only=False,
                decipher_only=False,
            ),
            critical=True,
        )
        
        builder = builder.add_extension(
            x509.ExtendedKeyUsage([
                x509.oid.ExtendedKeyUsageOID.SERVER_AUTH,
            ]),
            critical=True,
        )
        
        # Subject Alternative Names
        san_list = [x509.DNSName(common_name)]
        if san_domains:
            san_list.extend([x509.DNSName(domain) for domain in san_domains])
        
        builder = builder.add_extension(
            x509.SubjectAlternativeName(san_list),
            critical=False,
        )
        
        # ÐŸÐ¾Ð´Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚
        certificate = builder.sign(private_key, hashes.SHA256())
        
        # Ð¡ÐµÑ€Ð¸Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ð² PEM Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚
        cert_pem = certificate.public_bytes(serialization.Encoding.PEM)
        key_pem = private_key.private_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PrivateFormat.PKCS8,
            encryption_algorithm=serialization.NoEncryption()
        )
        
        return cert_pem, key_pem
    
    def load_certificate_from_file(self, cert_path: str) -> x509.Certificate:
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð° Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°"""
        
        with open(cert_path, 'rb') as f:
            cert_data = f.read()
        
        try:
            # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ PEM Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚
            certificate = x509.load_pem_x509_certificate(cert_data)
        except ValueError:
            try:
                # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ DER Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚
                certificate = x509.load_der_x509_certificate(cert_data)
            except ValueError:
                raise ValueError("Unable to parse certificate file")
        
        return certificate
    
    def check_certificate_expiry(self, certificate: x509.Certificate) -> Dict:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ€Ð¾ÐºÐ° Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð°"""
        
        current_time = datetime.datetime.now(datetime.timezone.utc)
        not_after = certificate.not_valid_after.replace(tzinfo=datetime.timezone.utc)
        not_before = certificate.not_valid_before.replace(tzinfo=datetime.timezone.utc)
        
        time_until_expiry = not_after - current_time
        days_until_expiry = time_until_expiry.days
        
        return {
            'is_valid': not_before <= current_time <= not_after,
            'is_expired': current_time > not_after,
            'not_yet_valid': current_time < not_before,
            'days_until_expiry': days_until_expiry,
            'expires_soon': days_until_expiry <= 30,
            'not_before': not_before.isoformat(),
            'not_after': not_after.isoformat()
        }

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ TLS Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸
async def demonstrate_tls_security():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° TLS Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸"""
    
    print("ðŸ” TLS Security Analysis Demonstration")
    print("=" * 60)
    
    analyzer = TLSSecurityAnalyzer()
    cert_manager = CertificateManager()
    
    # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ‹Ðµ ÑÐ°Ð¹Ñ‚Ñ‹
    test_sites = [
        ('google.com', 443),
        ('github.com', 443),
        ('stackoverflow.com', 443),
        ('badssl.com', 443),  # Ð¡Ð°Ð¹Ñ‚ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ TLS
        ('expired.badssl.com', 443)  # Ð¡Ð°Ð¹Ñ‚ Ñ Ð¸ÑÑ‚ÐµÐºÑˆÐ¸Ð¼ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ð¼
    ]
    
    print("ðŸ” Analyzing TLS configurations of popular sites:")
    
    for hostname, port in test_sites:
        print(f"\nðŸ“Š Analyzing {hostname}:{port}")
        
        try:
            analysis = await analyzer.analyze_tls_connection(hostname, port)
            
            if analysis['connection_successful']:
                # ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ
                protocol_info = analysis['protocol_info']
                cert_info = analysis['certificate_info']
                cipher_info = analysis['cipher_info']
                
                print(f"  TLS Version: {protocol_info.get('version', 'Unknown')}")
                print(f"  Cipher Suite: {cipher_info.get('name', 'Unknown')}")
                print(f"  Key Size: {cert_info.get('key_size', 'Unknown')} bits")
                print(f"  Perfect Forward Secrecy: {'Yes' if cipher_info.get('perfect_forward_secrecy') else 'No'}")
                
                # Security score
                score = analysis['security_score']
                score_grade = 'A+' if score >= 95 else 'A' if score >= 90 else 'B' if score >= 80 else 'C' if score >= 70 else 'F'
                print(f"  Security Score: {score}/100 (Grade: {score_grade})")
                
                # Ð¡ÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚
                if cert_info.get('is_expired'):
                    print(f"  âš ï¸ Certificate EXPIRED")
                elif cert_info.get('expires_soon'):
                    print(f"  âš ï¸ Certificate expires in {cert_info.get('days_until_expiry', 'Unknown')} days")
                else:
                    print(f"  âœ… Certificate valid")
                
                # Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
                if analysis['recommendations']:
                    print(f"  ðŸ’¡ Recommendations:")
                    for rec in analysis['recommendations'][:3]:  # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 3
                        print(f"    â€¢ {rec}")
            
            else:
                print(f"  âŒ Connection failed: {analysis.get('error', 'Unknown error')}")
        
        except Exception as e:
            print(f"  âŒ Analysis failed: {e}")
    
    # Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð°
    print(f"\nðŸ”§ Certificate Management Demo:")
    
    print("  Creating self-signed certificate...")
    
    try:
        cert_pem, key_pem = cert_manager.create_self_signed_cert(
            common_name="test.example.com",
            san_domains=["api.example.com", "www.example.com"],
            days_valid=365,
            key_size=2048
        )
        
        print(f"  âœ… Certificate created successfully")
        print(f"  Certificate size: {len(cert_pem)} bytes")
        print(f"  Private key size: {len(key_pem)} bytes")
        
        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ñ‹Ð¹ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚
        certificate = x509.load_pem_x509_certificate(cert_pem)
        expiry_info = cert_manager.check_certificate_expiry(certificate)
        
        print(f"  Valid from: {expiry_info['not_before']}")
        print(f"  Valid until: {expiry_info['not_after']}")
        print(f"  Days until expiry: {expiry_info['days_until_expiry']}")
        
    except Exception as e:
        print(f"  âŒ Certificate creation failed: {e}")
    
    # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ð³Ð¾ TLS context
    print(f"\nâš™ï¸ Secure TLS Context Configuration:")
    
    try:
        config = TLSConfig(
            min_version=TLSVersion.TLS_1_2,
            max_version=TLSVersion.TLS_1_3,
            verify_mode=ssl.CERT_REQUIRED,
            check_hostname=True
        )
        
        context = analyzer.create_secure_context(config, server_side=False)
        
        print(f"  âœ… Secure TLS context created")
        print(f"  Minimum TLS version: {context.minimum_version.name}")
        print(f"  Maximum TLS version: {context.maximum_version.name}")
        print(f"  Verify mode: {context.verify_mode.name}")
        print(f"  Check hostname: {context.check_hostname}")
        
        # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ context
        print(f"  Testing secure connection to google.com...")
        
        async with aiohttp.ClientSession(
            connector=aiohttp.TCPConnector(ssl=context)
        ) as session:
            async with session.get('https://google.com') as response:
                print(f"  âœ… Secure connection successful (Status: {response.status})")
    
    except Exception as e:
        print(f"  âŒ TLS context configuration failed: {e}")
    
    print(f"\nâœ… TLS Security demonstration completed")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
if __name__ == "__main__":
    asyncio.run(demonstrate_tls_security())
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ ÐÐµÐ´ÐµÐ»Ñ 12

1. ÐŸÑ€Ð¾Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð°Ð½Ð°Ð»Ð¸Ð· TLS ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð²ÑÐµÑ… Ð²Ð°ÑˆÐ¸Ñ… API endpoints
2. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ TLS ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ð²
3. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÑ€Ð¾ÐºÐ° Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ð² Ñ Ð°Ð»ÐµÑ€Ñ‚Ð°Ð¼Ð¸
4. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð°Ð¼Ð¸ Ð² Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ½Ð¾Ð¹ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ðµ
5. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ TLS security scanning Ð² CI/CD pipeline

### âœ… ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒÐ½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹

- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð¸Ñ Ð¼ÐµÐ¶Ð´Ñƒ TLS 1.2 Ð¸ TLS 1.3?
- [ ] ÐœÐ¾Ð¶ÐµÑ‚Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ secure cipher suites?
- [ ] Ð—Ð½Ð°ÐµÑ‚Ðµ ÐºÐ°Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Perfect Forward Secrecy?
- [ ] Ð£Ð¼ÐµÐµÑ‚Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ TLS ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹?
- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹ certificate management?

---

# ÐœÐ¾Ð´ÑƒÐ»ÑŒ 7: Ð‘Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ° Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¸ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ {#module-7}
*ÐÐµÐ´ÐµÐ»Ð¸ 13-14 | Ð’Ñ€ÐµÐ¼Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ: 16-20 Ñ‡Ð°ÑÐ¾Ð²*

## ÐÐµÐ´ÐµÐ»Ñ 13: Load Balancing

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: Ð¢Ð¸Ð¿Ñ‹ Ð¸ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹ Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ¸ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸

Load Balancing - ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð²Ð°Ð¶Ð½Ñ‹Ð¹ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ:

```
Load Balancing Layers:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 7 (Application) Load Balancing                       â”‚  
â”‚ â”œâ”€ HTTP/HTTPS aware                                        â”‚
â”‚ â”œâ”€ Content-based routing                                   â”‚
â”‚ â”œâ”€ SSL termination                                         â”‚
â”‚ â”œâ”€ Advanced health checks                                  â”‚
â”‚ â””â”€ Examples: HAProxy, Nginx, AWS ALB                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 4 (Transport) Load Balancing                         â”‚
â”‚ â”œâ”€ TCP/UDP aware                                           â”‚
â”‚ â”œâ”€ IP + Port based routing                                 â”‚
â”‚ â”œâ”€ High performance                                        â”‚
â”‚ â”œâ”€ Protocol agnostic                                       â”‚
â”‚ â””â”€ Examples: AWS NLB, F5, hardware LB                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3 (Network) Load Balancing                           â”‚
â”‚ â”œâ”€ IP-based routing                                        â”‚
â”‚ â”œâ”€ ECMP (Equal Cost Multi-Path)                           â”‚
â”‚ â”œâ”€ Router-level distribution                               â”‚
â”‚ â””â”€ Examples: BGP anycast, OSPF                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### âš–ï¸ Advanced Load Balancer Implementation

**Comprehensive Load Balancer System:**

```python
import asyncio
import time
import random
import statistics
from typing import Dict, List, Optional, Callable, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
import aiohttp
import logging
from collections import defaultdict, deque
import hashlib
import json

class LoadBalanceAlgorithm(Enum):
    ROUND_ROBIN = "round_robin"
    WEIGHTED_ROUND_ROBIN = "weighted_round_robin"
    LEAST_CONNECTIONS = "least_connections"
    WEIGHTED_LEAST_CONNECTIONS = "weighted_least_connections"
    LEAST_RESPONSE_TIME = "least_response_time"
    IP_HASH = "ip_hash"
    CONSISTENT_HASH = "consistent_hash"
    RANDOM = "random"
    WEIGHTED_RANDOM = "weighted_random"

class BackendState(Enum):
    HEALTHY = "healthy"
    UNHEALTHY = "unhealthy"
    DRAINING = "draining"
    MAINTENANCE = "maintenance"

@dataclass
class Backend:
    id: str
    host: str
    port: int
    weight: int = 1
    max_connections: int = 1000
    current_connections: int = 0
    state: BackendState = BackendState.HEALTHY
    health_score: float = 1.0
    last_health_check: float = 0
    response_times: deque = field(default_factory=lambda: deque(maxlen=100))
    total_requests: int = 0
    failed_requests: int = 0
    metadata: Dict = field(default_factory=dict)
    
    @property
    def avg_response_time(self) -> float:
        if not self.response_times:
            return 0.0
        return statistics.mean(self.response_times)
    
    @property
    def failure_rate(self) -> float:
        if self.total_requests == 0:
            return 0.0
        return self.failed_requests / self.total_requests
    
    @property
    def connection_utilization(self) -> float:
        return self.current_connections / self.max_connections
    
    @property
    def effective_weight(self) -> float:
        """Ð­Ñ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð²ÐµÑ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ Ð¸ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸"""
        base_weight = self.weight * self.health_score
        
        # Ð¡Ð½Ð¸Ð¶Ð°ÐµÐ¼ Ð²ÐµÑ Ð¿Ñ€Ð¸ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¹ ÑƒÑ‚Ð¸Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        utilization_penalty = 1.0 - (self.connection_utilization * 0.5)
        
        # Ð¡Ð½Ð¸Ð¶Ð°ÐµÐ¼ Ð²ÐµÑ Ð¿Ñ€Ð¸ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¼ failure rate
        failure_penalty = 1.0 - (self.failure_rate * 0.8)
        
        return base_weight * utilization_penalty * failure_penalty

@dataclass
class HealthCheckConfig:
    interval: float = 30.0
    timeout: float = 5.0
    path: str = "/health"
    expected_status: int = 200
    max_failures: int = 3
    max_successes_to_recover: int = 2

class AdvancedLoadBalancer:
    def __init__(self, algorithm: LoadBalanceAlgorithm = LoadBalanceAlgorithm.ROUND_ROBIN):
        self.algorithm = algorithm
        self.backends: Dict[str, Backend] = {}
        self.backend_order: List[str] = []  # Ð”Ð»Ñ round robin
        self.current_index = 0
        
        # Health checking
        self.health_config = HealthCheckConfig()
        self.health_check_tasks: Dict[str, asyncio.Task] = {}
        
        # Statistics
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'requests_by_backend': defaultdict(int),
            'requests_by_algorithm': defaultdict(int),
            'avg_response_time': 0.0,
            'connection_errors': 0
        }
        
        # Consistent hashing (Ð´Ð»Ñ CONSISTENT_HASH Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð°)
        self.hash_ring: Dict[int, str] = {}
        self.virtual_nodes = 150  # ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð²Ð¸Ñ€Ñ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑƒÐ·Ð»Ð¾Ð² Ð½Ð° backend
        
        # Circuit breaker Ð´Ð»Ñ backends
        self.circuit_breakers: Dict[str, Dict] = {}
        
        self.logger = logging.getLogger('LoadBalancer')
    
    def add_backend(self, backend: Backend):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ backend ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        
        self.backends[backend.id] = backend
        self.backend_order.append(backend.id)
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ circuit breaker
        self.circuit_breakers[backend.id] = {
            'state': 'closed',  # closed, open, half_open
            'failure_count': 0,
            'last_failure': 0,
            'recovery_timeout': 60.0
        }
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ consistent hash ring
        if self.algorithm == LoadBalanceAlgorithm.CONSISTENT_HASH:
            self._update_hash_ring()
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ health check
        self._start_health_check(backend.id)
        
        self.logger.info(f"Added backend {backend.id} ({backend.host}:{backend.port})")
    
    def remove_backend(self, backend_id: str):
        """Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ backend ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        
        if backend_id in self.backends:
            # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ health check
            if backend_id in self.health_check_tasks:
                self.health_check_tasks[backend_id].cancel()
                del self.health_check_tasks[backend_id]
            
            # Ð£Ð´Ð°Ð»ÑÐµÐ¼ backend
            del self.backends[backend_id]
            
            if backend_id in self.backend_order:
                self.backend_order.remove(backend_id)
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ hash ring
            if self.algorithm == LoadBalanceAlgorithm.CONSISTENT_HASH:
                self._update_hash_ring()
            
            self.logger.info(f"Removed backend {backend_id}")
    
    def set_backend_state(self, backend_id: str, state: BackendState):
        """Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ backend"""
        
        if backend_id in self.backends:
            old_state = self.backends[backend_id].state
            self.backends[backend_id].state = state
            
            self.logger.info(f"Backend {backend_id} state changed: {old_state.value} -> {state.value}")
    
    async def select_backend(self, client_ip: str = None, request_data: Dict = None) -> Optional[Backend]:
        """Ð’Ñ‹Ð±Ð¾Ñ€ backend ÑÐµÑ€Ð²ÐµÑ€Ð° ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñƒ"""
        
        # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ð·Ð´Ð¾Ñ€Ð¾Ð²Ñ‹Ðµ backends
        healthy_backends = [
            backend for backend in self.backends.values()
            if backend.state == BackendState.HEALTHY and 
               self._is_circuit_breaker_closed(backend.id)
        ]
        
        if not healthy_backends:
            self.logger.error("No healthy backends available")
            return None
        
        # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ¸
        selected_backend = None
        
        if self.algorithm == LoadBalanceAlgorithm.ROUND_ROBIN:
            selected_backend = self._round_robin_select(healthy_backends)
        
        elif self.algorithm == LoadBalanceAlgorithm.WEIGHTED_ROUND_ROBIN:
            selected_backend = self._weighted_round_robin_select(healthy_backends)
        
        elif self.algorithm == LoadBalanceAlgorithm.LEAST_CONNECTIONS:
            selected_backend = self._least_connections_select(healthy_backends)
        
        elif self.algorithm == LoadBalanceAlgorithm.WEIGHTED_LEAST_CONNECTIONS:
            selected_backend = self._weighted_least_connections_select(healthy_backends)
        
        elif self.algorithm == LoadBalanceAlgorithm.LEAST_RESPONSE_TIME:
            selected_backend = self._least_response_time_select(healthy_backends)
        
        elif self.algorithm == LoadBalanceAlgorithm.IP_HASH:
            selected_backend = self._ip_hash_select(healthy_backends, client_ip)
        
        elif self.algorithm == LoadBalanceAlgorithm.CONSISTENT_HASH:
            selected_backend = self._consistent_hash_select(client_ip)
        
        elif self.algorithm == LoadBalanceAlgorithm.RANDOM:
            selected_backend = self._random_select(healthy_backends)
        
        elif self.algorithm == LoadBalanceAlgorithm.WEIGHTED_RANDOM:
            selected_backend = self._weighted_random_select(healthy_backends)
        
        if selected_backend:
            self.stats['requests_by_algorithm'][self.algorithm.value] += 1
            self.stats['requests_by_backend'][selected_backend.id] += 1
        
        return selected_backend
    
    def _round_robin_select(self, backends: List[Backend]) -> Backend:
        """Round Robin Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼"""
        
        if not backends:
            return None
        
        # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ backend Ð² Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ
        backend_ids = [b.id for b in backends]
        
        # Ð˜Ñ‰ÐµÐ¼ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ð¹ backend
        attempts = 0
        while attempts < len(backend_ids):
            current_id = self.backend_order[self.current_index % len(self.backend_order)]
            self.current_index += 1
            attempts += 1
            
            if current_id in backend_ids:
                return next(b for b in backends if b.id == current_id)
        
        return backends[0]  # Fallback
    
    def _weighted_round_robin_select(self, backends: List[Backend]) -> Backend:
        """Weighted Round Robin Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼"""
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð²Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº
        weighted_backends = []
        for backend in backends:
            effective_weight = max(1, int(backend.effective_weight * 10))
            weighted_backends.extend([backend] * effective_weight)
        
        if not weighted_backends:
            return backends[0]
        
        selected = weighted_backends[self.current_index % len(weighted_backends)]
        self.current_index += 1
        
        return selected
    
    def        async def api_call():
            url = 'https://jsonplaceholder.typicode.com/posts'
            async with self.session.post(url, json=order_data) as response:
                if response.status >= 500:
                    raise aiohttp.ClientError(f"Server error: {response.status}")
                return await response.json()
        
        cb = self.circuit_breakers['order_service']
        return await cb(api_call)
    
    async def process_payment(self, payment_data: Dict) -> Dict:
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð° Ñ‡ÐµÑ€ÐµÐ· Circuit Breaker"""
        
        async def api_call():
            # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð½ÐµÐ½Ð°Ð´ÐµÐ¶Ð½Ñ‹Ð¹ payment ÑÐµÑ€Ð²Ð¸Ñ
            import random
            if random.random() < 0.3:  # 30% Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
                raise aiohttp.ClientError("Payment service unavailable")
            
            url = 'https://jsonplaceholder.typicode.com/posts'
            async with self.session.post(url, json=payment_data) as response:
                return await response.json()
        
        cb = self.circuit_breakers['payment_service']
        return await cb(api_call)
    
    def get_all_circuit_breaker_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð²ÑÐµÑ… Circuit Breakers"""
        return {
            name: cb.get_metrics() 
            for name, cb in self.circuit_breakers.items()
        }

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Circuit Breaker Ð² Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¸
async def demonstrate_circuit_breaker():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Circuit Breaker"""
    
    print("ðŸ”Œ Circuit Breaker Pattern Demonstration")
    print("=" * 60)
    
    async with ResilientAPIClient() as client:
        
        print("ðŸ“Š Initial Circuit Breaker States:")
        for name, stats in client.get_all_circuit_breaker_stats().items():
            print(f"  {name}: {stats['state'].upper()}")
        
        # Ð¢ÐµÑÑ‚ 1: ÐÐ¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°
        print(f"\nâœ… Test 1: Normal Operations")
        
        try:
            user = await client.get_user(1)
            print(f"  User service: SUCCESS (got user {user.get('id')})")
            
            order = await client.create_order({"title": "Test Order", "body": "Order details"})
            print(f"  Order service: SUCCESS (created order {order.get('id')})")
            
        except Exception as e:
            print(f"  ERROR: {e}")
        
        # Ð¢ÐµÑÑ‚ 2: ÐŸÑ€Ð¾Ð²Ð¾Ñ†Ð¸Ñ€ÑƒÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð² payment service
        print(f"\nâš ï¸ Test 2: Triggering Payment Service Failures")
        
        for i in range(8):  # Ð”ÐµÐ»Ð°ÐµÐ¼ Ð¼Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑÑ€Ð°Ð±Ð¾Ñ‚Ð°Ð» circuit breaker
            try:
                payment = await client.process_payment({"amount": "100.00", "currency": "USD"})
                print(f"  Payment attempt {i+1}: SUCCESS")
            
            except CircuitBreakerOpenException as e:
                print(f"  Payment attempt {i+1}: CIRCUIT OPEN - {e}")
                break
            
            except Exception as e:
                print(f"  Payment attempt {i+1}: FAILED - {e}")
        
        # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Circuit Breakers Ð¿Ð¾ÑÐ»Ðµ Ð¾ÑˆÐ¸Ð±Ð¾Ðº
        print(f"\nðŸ“Š Circuit Breaker States After Failures:")
        all_stats = client.get_all_circuit_breaker_stats()
        
        for name, stats in all_stats.items():
            state = stats['state'].upper()
            failure_rate = stats.get('failure_rate_percent', 0)
            total_calls = stats['lifetime_metrics']['total_calls']
            
            print(f"  {name}: {state} (failure rate: {failure_rate:.1f}%, calls: {total_calls})")
            
            if stats['state'] == 'open':
                last_failure = stats.get('last_failure_ago_seconds')
                if last_failure is not None:
                    print(f"    Last failure: {last_failure:.1f}s ago")
        
        # Ð¢ÐµÑÑ‚ 3: Ð–Ð´ÐµÐ¼ recovery Ð¸ Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ half-open ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
        payment_cb = client.circuit_breakers['payment_service']
        
        if payment_cb.state == CircuitState.OPEN:
            print(f"\nâ° Test 3: Waiting for Circuit Breaker Recovery")
            print(f"  Payment circuit is OPEN, waiting for recovery timeout...")
            
            # Ð¤Ð¾Ñ€ÑÐ¸Ñ€ÑƒÐµÐ¼ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´ Ð² half-open Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
            payment_cb._last_failure_time = time.time() - payment_cb.config.recovery_timeout - 1
            
            print(f"  Attempting request after recovery timeout...")
            
            try:
                # Ð­Ñ‚Ð¾Ñ‚ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¿ÐµÑ€ÐµÐ²ÐµÑÑ‚Ð¸ Ð² HALF_OPEN
                payment = await client.process_payment({"amount": "50.00", "currency": "USD"})
                print(f"  Recovery attempt: SUCCESS")
                
                # Ð”ÐµÐ»Ð°ÐµÐ¼ ÐµÑ‰Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð´Ð»Ñ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ circuit
                for i in range(3):
                    try:
                        payment = await client.process_payment({"amount": "25.00", "currency": "USD"})
                        print(f"  Additional success {i+1}: OK")
                    except:
                        print(f"  Additional attempt {i+1}: FAILED")
                        break
                
            except CircuitBreakerOpenException as e:
                print(f"  Recovery attempt: STILL BLOCKED - {e}")
            except Exception as e:
                print(f"  Recovery attempt: FAILED - {e}")
        
        # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
        print(f"\nðŸ“ˆ Final Circuit Breaker Statistics:")
        final_stats = client.get_all_circuit_breaker_stats()
        
        for name, stats in final_stats.items():
            print(f"\n  ðŸ”Œ {name.upper()}:")
            print(f"    State: {stats['state'].upper()}")
            print(f"    Total calls: {stats['lifetime_metrics']['total_calls']}")
            print(f"    Success rate: {100 - stats.get('failure_rate_percent', 0):.1f}%")
            print(f"    Circuit opened: {stats['lifetime_metrics']['circuit_opened_count']} times")
            print(f"    Circuit closed: {stats['lifetime_metrics']['circuit_closed_count']} times")
            print(f"    Calls rejected: {stats['lifetime_metrics']['calls_rejected']}")
            
            if 'response_time_stats' in stats:
                rt_stats = stats['response_time_stats']
                print(f"    Avg response time: {rt_stats['avg_ms']:.1f}ms")
                print(f"    P95 response time: {rt_stats['p95_ms']:.1f}ms")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
if __name__ == "__main__":
    asyncio.run(demonstrate_circuit_breaker())
```

### ðŸ—œï¸ Data Compression Ð¸ Transfer Optimization

**Intelligent Compression Strategy:**

```python
import gzip
import brotli
import zlib
import json
import time
import asyncio
from typing import Dict, Any, Optional, Union
from dataclasses import dataclass
from enum import Enum

class CompressionType(Enum):
    NONE = "none"
    GZIP = "gzip"
    DEFLATE = "deflate" 
    BROTLI = "brotli"

@dataclass
class CompressionResult:
    original_size: int
    compressed_size: int
    compression_ratio: float
    compression_time_ms: float
    compression_type: CompressionType
    compressed_data: bytes

class IntelligentCompressor:
    def __init__(self):
        self.compression_stats = {
            CompressionType.GZIP: {'total_bytes_in': 0, 'total_bytes_out': 0, 'total_time_ms': 0, 'uses': 0},
            CompressionType.DEFLATE: {'total_bytes_in': 0, 'total_bytes_out': 0, 'total_time_ms': 0, 'uses': 0},
            CompressionType.BROTLI: {'total_bytes_in': 0, 'total_bytes_out': 0, 'total_time_ms': 0, 'uses': 0}
        }
    
    def _compress_gzip(self, data: bytes, level: int = 6) -> CompressionResult:
        """GZIP ÑÐ¶Ð°Ñ‚Ð¸Ðµ"""
        start_time = time.time()
        compressed = gzip.compress(data, compresslevel=level)
        compression_time = (time.time() - start_time) * 1000
        
        return CompressionResult(
            original_size=len(data),
            compressed_size=len(compressed),
            compression_ratio=len(compressed) / len(data),
            compression_time_ms=compression_time,
            compression_type=CompressionType.GZIP,
            compressed_data=compressed
        )
    
    def _compress_deflate(self, data: bytes, level: int = 6) -> CompressionResult:
        """DEFLATE ÑÐ¶Ð°Ñ‚Ð¸Ðµ"""
        start_time = time.time()
        compressed = zlib.compress(data, level)
        compression_time = (time.time() - start_time) * 1000
        
        return CompressionResult(
            original_size=len(data),
            compressed_size=len(compressed),
            compression_ratio=len(compressed) / len(data),
            compression_time_ms=compression_time,
            compression_type=CompressionType.DEFLATE,
            compressed_data=compressed
        )
    
    def _compress_brotli(self, data: bytes, quality: int = 6) -> CompressionResult:
        """Brotli ÑÐ¶Ð°Ñ‚Ð¸Ðµ"""
        start_time = time.time()
        compressed = brotli.compress(data, quality=quality)
        compression_time = (time.time() - start_time) * 1000
        
        return CompressionResult(
            original_size=len(data),
            compressed_size=len(compressed),
            compression_ratio=len(compressed) / len(data),
            compression_time_ms=compression_time,
            compression_type=CompressionType.BROTLI,
            compressed_data=compressed
        )
    
    def compress_adaptive(self, data: Union[str, bytes, Dict], 
                         min_size_threshold: int = 1024,
                         max_compression_time_ms: float = 100.0) -> CompressionResult:
        """ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾Ðµ ÑÐ¶Ð°Ñ‚Ð¸Ðµ Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ð¼ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð°"""
        
        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² bytes ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾
        if isinstance(data, str):
            data_bytes = data.encode('utf-8')
        elif isinstance(data, dict):
            data_bytes = json.dumps(data, separators=(',', ':')).encode('utf-8')
        else:
            data_bytes = data
        
        # Ð•ÑÐ»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¸Ðµ, Ð½Ðµ ÑÐ¶Ð¸Ð¼Ð°ÐµÐ¼
        if len(data_bytes) < min_size_threshold:
            return CompressionResult(
                original_size=len(data_bytes),
                compressed_size=len(data_bytes),
                compression_ratio=1.0,
                compression_time_ms=0.0,
                compression_type=CompressionType.NONE,
                compressed_data=data_bytes
            )
        
        # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹
        candidates = []
        
        # GZIP - Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ð¸ Ð½Ð°Ð´ÐµÐ¶Ð½Ñ‹Ð¹
        try:
            gzip_result = self._compress_gzip(data_bytes, level=6)
            if gzip_result.compression_time_ms <= max_compression_time_ms:
                candidates.append(gzip_result)
        except Exception as e:
            print(f"GZIP compression failed: {e}")
        
        # DEFLATE - Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ GZIP
        try:
            deflate_result = self._compress_deflate(data_bytes, level=6)
            if deflate_result.compression_time_ms <= max_compression_time_ms:
                candidates.append(deflate_result)
        except Exception as e:
            print(f"DEFLATE compression failed: {e}")
        
        # Brotli - Ð»ÑƒÑ‡ÑˆÐµÐµ ÑÐ¶Ð°Ñ‚Ð¸Ðµ Ð´Ð»Ñ Ñ‚ÐµÐºÑÑ‚Ð°
        try:
            brotli_result = self._compress_brotli(data_bytes, quality=6)
            if brotli_result.compression_time_ms <= max_compression_time_ms:
                candidates.append(brotli_result)
        except Exception as e:
            print(f"Brotli compression failed: {e}")
        
        # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
        if not candidates:
            # Ð•ÑÐ»Ð¸ Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð¿Ð¾Ð´Ð¾ÑˆÐ»Ð¾, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð±ÐµÐ· ÑÐ¶Ð°Ñ‚Ð¸Ñ
            return CompressionResult(
                original_size=len(data_bytes),
                compressed_size=len(data_bytes),
                compression_ratio=1.0,
                compression_time_ms=0.0,
                compression_type=CompressionType.NONE,
                compressed_data=data_bytes
            )
        
        # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ Ñ Ð½Ð°Ð¸Ð»ÑƒÑ‡ÑˆÐ¸Ð¼ ÑÐ¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸ÐµÐ¼ ÑÐ¶Ð°Ñ‚Ð¸Ñ/Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
        def score_compression(result: CompressionResult) -> float:
            # Ð§ÐµÐ¼ Ð¼ÐµÐ½ÑŒÑˆÐµ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸ Ð²Ñ€ÐµÐ¼Ñ, Ñ‚ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÐµ
            size_score = 1.0 - result.compression_ratio  # Ð±Ð¾Ð»ÑŒÑˆÐµ ÑÐ¶Ð°Ñ‚Ð¸Ðµ = Ð»ÑƒÑ‡ÑˆÐµ
            time_score = 1.0 - (result.compression_time_ms / max_compression_time_ms)  # Ð¼ÐµÐ½ÑŒÑˆÐµ Ð²Ñ€ÐµÐ¼Ñ = Ð»ÑƒÑ‡ÑˆÐµ
            return size_score * 0.7 + time_score * 0.3  # 70% Ð²ÐµÑ ÑÐ¶Ð°Ñ‚Ð¸ÑŽ, 30% Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
        
        best_result = max(candidates, key=score_compression)
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
        stats = self.compression_stats[best_result.compression_type]
        stats['total_bytes_in'] += best_result.original_size
        stats['total_bytes_out'] += best_result.compressed_size
        stats['total_time_ms'] += best_result.compression_time_ms
        stats['uses'] += 1
        
        return best_result
    
    def decompress(self, compressed_data: bytes, compression_type: CompressionType) -> bytes:
        """Ð”ÐµÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑÐ¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
        
        if compression_type == CompressionType.NONE:
            return compressed_data
        elif compression_type == CompressionType.GZIP:
            return gzip.decompress(compressed_data)
        elif compression_type == CompressionType.DEFLATE:
            return zlib.decompress(compressed_data)
        elif compression_type == CompressionType.BROTLI:
            return brotli.decompress(compressed_data)
        else:
            raise ValueError(f"Unknown compression type: {compression_type}")
    
    def get_compression_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ ÑÐ¶Ð°Ñ‚Ð¸Ñ"""
        
        stats = {}
        
        for comp_type, data in self.compression_stats.items():
            if data['uses'] > 0:
                avg_compression_ratio = data['total_bytes_out'] / data['total_bytes_in']
                avg_time_per_use = data['total_time_ms'] / data['uses']
                
                stats[comp_type.value] = {
                    'uses': data['uses'],
                    'total_bytes_processed': data['total_bytes_in'],
                    'total_bytes_saved': data['total_bytes_in'] - data['total_bytes_out'],
                    'avg_compression_ratio': avg_compression_ratio,
                    'avg_compression_time_ms': avg_time_per_use,
                    'bandwidth_saved_percent': (1 - avg_compression_ratio) * 100
                }
        
        return stats

# HTTP Transfer Optimization
class OptimizedTransferClient:
    def __init__(self):
        self.compressor = IntelligentCompressor()
        self.transfer_stats = {
            'total_requests': 0,
            'compressed_requests': 0,
            'total_bytes_sent': 0,
            'total_bytes_received': 0,
            'total_transfer_time_ms': 0
        }
    
    async def post_json(self, session: aiohttp.ClientSession, url: str, 
                       data: Dict, compress: bool = True) -> Dict:
        """ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ POST Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ JSON"""
        
        start_time = time.time()
        
        # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        json_data = json.dumps(data, separators=(',', ':'))  # ÐšÐ¾Ð¼Ð¿Ð°ÐºÑ‚Ð½Ñ‹Ð¹ JSON
        headers = {
            'Content-Type': 'application/json',
            'Accept': 'application/json',
            'Accept-Encoding': 'gzip, deflate, br'
        }
        
        request_data = json_data.encode('utf-8')
        original_size = len(request_data)
        
        # Ð¡Ð¶Ð¸Ð¼Ð°ÐµÐ¼ ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾
        if compress:
            compression_result = self.compressor.compress_adaptive(
                request_data,
                min_size_threshold=512,  # Ð¡Ð¶Ð¸Ð¼Ð°ÐµÐ¼ Ð¾Ñ‚ 512 Ð±Ð°Ð¹Ñ‚
                max_compression_time_ms=50.0  # ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 50Ð¼Ñ Ð½Ð° ÑÐ¶Ð°Ñ‚Ð¸Ðµ
            )
            
            if compression_result.compression_type != CompressionType.NONE:
                request_data = compression_result.compressed_data
                
                # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº ÑÐ¶Ð°Ñ‚Ð¸Ñ
                if compression_result.compression_type == CompressionType.GZIP:
                    headers['Content-Encoding'] = 'gzip'
                elif compression_result.compression_type == CompressionType.DEFLATE:
                    headers['Content-Encoding'] = 'deflate'
                elif compression_result.compression_type == CompressionType.BROTLI:
                    headers['Content-Encoding'] = 'br'
                
                self.transfer_stats['compressed_requests'] += 1
                
                print(f"  Compressed {original_size} -> {len(request_data)} bytes "
                      f"({compression_result.compression_ratio:.2f} ratio, "
                      f"{compression_result.compression_time_ms:.1f}ms)")
        
        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ
        headers['Content-Length'] = str(len(request_data))
        
        try:
            async with session.post(url, data=request_data, headers=headers) as response:
                response_data = await response.read()
                
                end_time = time.time()
                transfer_time = (end_time - start_time) * 1000
                
                # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
                self.transfer_stats['total_requests'] += 1
                self.transfer_stats['total_bytes_sent'] += len(request_data)
                self.transfer_stats['total_bytes_received'] += len(response_data)
                self.transfer_stats['total_transfer_time_ms'] += transfer_time
                
                # Ð”ÐµÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑÐ¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾
                response_encoding = response.headers.get('Content-Encoding', '').lower()
                if response_encoding in ['gzip', 'deflate', 'br']:
                    if response_encoding == 'gzip':
                        response_data = gzip.decompress(response_data)
                    elif response_encoding == 'deflate':
                        response_data = zlib.decompress(response_data)
                    elif response_encoding == 'br':
                        response_data = brotli.decompress(response_data)
                
                # ÐŸÐ°Ñ€ÑÐ¸Ð¼ JSON
                if response.content_type == 'application/json':
                    return json.loads(response_data.decode('utf-8'))
                else:
                    return {'raw_data': response_data.decode('utf-8', errors='ignore')}
                
        except Exception as e:
            end_time = time.time()
            transfer_time = (end_time - start_time) * 1000
            self.transfer_stats['total_transfer_time_ms'] += transfer_time
            raise
    
    def get_transfer_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
        
        stats = dict(self.transfer_stats)
        
        if stats['total_requests'] > 0:
            stats['avg_transfer_time_ms'] = stats['total_transfer_time_ms'] / stats['total_requests']
            stats['compression_usage_percent'] = (stats['compressed_requests'] / stats['total_requests']) * 100
            stats['avg_bytes_sent_per_request'] = stats['total_bytes_sent'] / stats['total_requests']
            stats['avg_bytes_received_per_request'] = stats['total_bytes_received'] / stats['total_requests']
        
        return stats

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…
async def demonstrate_transfer_optimization():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    
    print("ðŸ—œï¸ Data Transfer Optimization Demonstration")
    print("=" * 60)
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ñ€Ð°Ð·Ð¼ÐµÑ€Ð¾Ð²
    test_datasets = {
        'small': {'message': 'Hello World', 'timestamp': time.time()},
        'medium': {
            'users': [
                {'id': i, 'name': f'User {i}', 'email': f'user{i}@example.com', 
                 'profile': {'age': 20 + i % 50, 'city': f'City {i % 10}'}}
                for i in range(100)
            ]
        },
        'large': {
            'data': [
                {
                    'id': i,
                    'description': f'This is a long description for item {i} ' * 10,
                    'metadata': {
                        'created_at': time.time() - i * 3600,
                        'tags': [f'tag{j}' for j in range(10)],
                        'attributes': {f'attr_{k}': f'value_{k}_{i}' for k in range(20)}
                    }
                }
                for i in range(200)
            ]
        }
    }
    
    client = OptimizedTransferClient()
    
    async with aiohttp.ClientSession() as session:
        
        print("ðŸ“Š Testing Compression Efficiency:")
        
        for dataset_name, dataset in test_datasets.items():
            print(f"\n  Dataset: {dataset_name.upper()}")
            
            # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð±ÐµÐ· ÑÐ¶Ð°Ñ‚Ð¸Ñ
            print("    Without compression:")
            try:
                start_time = time.time()
                result = await client.post_json(
                    session, 
                    'https://httpbin.org/post', 
                    dataset, 
                    compress=False
                )
                end_time = time.time()
                
                original_size = len(json.dumps(dataset).encode('utf-8'))
                print(f"      Size: {original_size} bytes")
                print(f"      Time: {(end_time - start_time) * 1000:.1f}ms")
                
            except Exception as e:
                print(f"      ERROR: {e}")
            
            # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾ ÑÐ¶Ð°Ñ‚Ð¸ÐµÐ¼
            print("    With compression:")
            try:
                start_time = time.time()
                result = await client.post_json(
                    session, 
                    'https://httpbin.org/post', 
                    dataset, 
                    compress=True
                )
                end_time = time.time()
                
                print(f"      Time: {(end_time - start_time) * 1000:.1f}ms")
                
            except Exception as e:
                print(f"      ERROR: {e}")
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑÐ¾Ñ€Ð°
        print(f"\nðŸ“ˆ Compression Statistics:")
        compression_stats = client.compressor.get_compression_stats()
        
        for comp_type, stats in compression_stats.items():
            print(f"  {comp_type.upper()}:")
            print(f"    Uses: {stats['uses']}")
            print(f"    Avg compression ratio: {stats['avg_compression_ratio']:.3f}")
            print(f"    Avg compression time: {stats['avg_compression_time_ms']:.1f}ms")
            print(f"    Bandwidth saved: {stats['bandwidth_saved_percent']:.1f}%")
            print(f"    Total bytes saved: {stats['total_bytes_saved']}")
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð¸
        print(f"\nðŸš€ Transfer Statistics:")
        transfer_stats = client.get_transfer_stats()
        
        print(f"  Total requests: {transfer_stats['total_requests']}")
        print(f"  Compressed requests: {transfer_stats['compressed_requests']}")
        print(f"  Compression usage: {transfer_stats.get('compression_usage_percent', 0):.1f}%")
        print(f"  Avg transfer time: {transfer_stats.get('avg_transfer_time_ms', 0):.1f}ms")
        print(f"  Total bytes sent: {transfer_stats['total_bytes_sent']}")
        print(f"  Total bytes received: {transfer_stats['total_bytes_received']}")
        
        if 'avg_bytes_sent_per_request' in transfer_stats:
            print(f"  Avg bytes per request: {transfer_stats['avg_bytes_sent_per_request']:.0f}")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
if __name__ == "__main__":
    asyncio.run(demonstrate_transfer_optimization())
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ ÐÐµÐ´ÐµÐ»Ñ 10

1. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ enterprise-grade connection pool Ð´Ð»Ñ Ð²Ð°ÑˆÐ¸Ñ… Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
2. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Circuit Breaker pattern Ð´Ð»Ñ Ð²ÑÐµÑ… Ð²Ð½ÐµÑˆÐ½Ð¸Ñ… API Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð²
3. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ðµ ÑÐ¶Ð°Ñ‚Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ HTTP API
4. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ connection management
5. ÐŸÑ€Ð¾Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð³Ñ€ÑƒÐ·Ð¾Ñ‡Ð½Ð¾Ðµ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼Ð¸ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸ÑÐ¼Ð¸

### âœ… ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒÐ½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹

- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸ÑÐ¼Ð¸?
- [ ] ÐœÐ¾Ð¶ÐµÑ‚Ðµ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ connection pooling Ñ health checking?
- [ ] Ð—Ð½Ð°ÐµÑ‚Ðµ ÐºÐ°Ðº Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÑ‚ÑŒ Circuit Breaker pattern?
- [ ] Ð£Ð¼ÐµÐµÑ‚Ðµ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ‡ÐµÑ€ÐµÐ· ÑÐ¶Ð°Ñ‚Ð¸Ðµ?
- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ trade-offs Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒÑŽ Ð¸ Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚ÑŒÑŽ?

---

# ÐœÐ¾Ð´ÑƒÐ»ÑŒ 6: Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ {#module-6}
*ÐÐµÐ´ÐµÐ»Ð¸ 11-12 | Ð’Ñ€ÐµÐ¼Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ: 16-20 Ñ‡Ð°ÑÐ¾Ð²*

## ÐÐµÐ´ÐµÐ»Ñ 11: Ð¡ÐµÑ‚ÐµÐ²Ð°Ñ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: Defense in Depth Ð´Ð»Ñ ÑÐµÑ‚ÐµÐ²Ð¾Ð¹ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸

ÐŸÑ€Ð¸Ð½Ñ†Ð¸Ð¿ Ð¼Ð½Ð¾Ð³Ð¾ÑÐ»Ð¾Ð¹Ð½Ð¾Ð¹ Ð·Ð°Ñ‰Ð¸Ñ‚Ñ‹ Ð² ÑÐµÑ‚ÑÑ…:

```
Defense in Depth Network Security:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 7: Application Security                               â”‚
â”‚ â”œâ”€ Input validation                                         â”‚
â”‚ â”œâ”€ Authentication & Authorization                           â”‚
â”‚ â”œâ”€ Rate limiting & Throttling                              â”‚
â”‚ â””â”€ OWASP Top 10 protection                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 4: Transport Security                                â”‚
â”‚ â”œâ”€ TLS/SSL encryption                                      â”‚
â”‚ â”œâ”€ Certificate validation                                  â”‚
â”‚ â”œâ”€ Perfect Forward Secrecy                                â”‚
â”‚ â””â”€ Connection security                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3: Network Security                                  â”‚
â”‚ â”œâ”€ Firewalls & ACLs                                       â”‚
â”‚ â”œâ”€ Network segmentation                                   â”‚
â”‚ â”œâ”€ Intrusion detection                                    â”‚
â”‚ â””â”€ Traffic analysis                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 2: Link Security                                     â”‚
â”‚ â”œâ”€ VLANs & Network isolation                             â”‚
â”‚ â”œâ”€ MAC address filtering                                  â”‚
â”‚ â””â”€ Switch security                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 1: Physical Security                                 â”‚
â”‚ â”œâ”€ Physical access control                                â”‚
â”‚ â”œâ”€ Network equipment security                             â”‚
â”‚ â””â”€ Cable & wireless security                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ›¡ï¸ DDoS Protection Ð¸ Rate Limiting

**Advanced Rate Limiting Implementation:**

```python
import asyncio
import time
import redis
import hashlib
import ipaddress
from typing import Dict, List, Optional, Set, Tuple
from dataclasses import dataclass
from enum import Enum
import logging
from collections import defaultdict, deque
import aiohttp
from aiohttp import web
import json

class LimitType(Enum):
    REQUESTS_PER_SECOND = "rps"
    REQUESTS_PER_MINUTE = "rpm"
    REQUESTS_PER_HOUR = "rph"
    BANDWIDTH_PER_SECOND = "bps"
    CONCURRENT_CONNECTIONS = "concurrent"

@dataclass
class RateLimit:
    limit_type: LimitType
    threshold: int
    window_seconds: int
    burst_allowance: int = 0  # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð² burst Ñ€ÐµÐ¶Ð¸Ð¼Ðµ
    
class ThreatLevel(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class AdvancedRateLimiter:
    def __init__(self, redis_client: redis.Redis = None):
        self.redis = redis_client or redis.Redis(host='localhost', port=6379, db=1)
        self.local_cache = {}  # Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐµÑˆ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð°
        self.blocked_ips: Set[str] = set()
        self.suspicious_ips: Dict[str, float] = {}  # IP -> timestamp Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ¹ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸
        
        # ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð»Ð¸Ð¼Ð¸Ñ‚Ð¾Ð²
        self.rate_limits = {
            'default': [
                RateLimit(LimitType.REQUESTS_PER_SECOND, 10, 1),
                RateLimit(LimitType.REQUESTS_PER_MINUTE, 300, 60),
                RateLimit(LimitType.REQUESTS_PER_HOUR, 5000, 3600)
            ],
            'authenticated': [
                RateLimit(LimitType.REQUESTS_PER_SECOND, 50, 1),
                RateLimit(LimitType.REQUESTS_PER_MINUTE, 1500, 60),
                RateLimit(LimitType.REQUESTS_PER_HOUR, 20000, 3600)
            ],
            'premium': [
                RateLimit(LimitType.REQUESTS_PER_SECOND, 100, 1),
                RateLimit(LimitType.REQUESTS_PER_MINUTE, 3000, 60),
                RateLimit(LimitType.REQUESTS_PER_HOUR, 50000, 3600)
            ]
        }
        
        # Whitelist Ð¸ blacklist
        self.ip_whitelist: Set[str] = {'127.0.0.1', '::1'}
        self.ip_blacklist: Set[str] = set()
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
        self.stats = {
            'total_requests': 0,
            'blocked_requests': 0,
            'suspicious_requests': 0,
            'rate_limited_requests': 0,
            'threats_detected': defaultdict(int)
        }
        
        # Logger
        self.logger = logging.getLogger('RateLimiter')
    
    def _get_client_identifier(self, request: web.Request) -> str:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð° ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°"""
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ Ð´Ð»Ñ real IP
        real_ip = (
            request.headers.get('X-Forwarded-For', '').split(',')[0].strip() or
            request.headers.get('X-Real-IP', '') or
            request.remote
        )
        
        # Ð”Ð»Ñ authenticated Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ user ID
        if hasattr(request, 'user_id'):
            return f"user:{request.user_id}"
        
        # Ð”Ð»Ñ API ÐºÐ»ÑŽÑ‡ÐµÐ¹
        api_key = request.headers.get('Authorization', '').replace('Bearer ', '')
        if api_key:
            return f"api_key:{hashlib.sha256(api_key.encode()).hexdigest()[:16]}"
        
        return f"ip:{real_ip}"
    
    def _get_rate_limit_key(self, identifier: str, limit: RateLimit) -> str:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÐºÐ»ÑŽÑ‡Ð° Ð´Ð»Ñ rate limit Ð² Redis"""
        current_window = int(time.time() // limit.window_seconds)
        return f"rate_limit:{identifier}:{limit.limit_type.value}:{current_window}"
    
    async def _check_rate_limit(self, identifier: str, limit: RateLimit) -> Tuple[bool, int, int]:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° rate limit Ð´Ð»Ñ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ Ð»Ð¸Ð¼Ð¸Ñ‚Ð°"""
        
        key = self._get_rate_limit_key(identifier, limit)
        
        try:
            # ÐÑ‚Ð¾Ð¼Ð°Ñ€Ð½Ð°Ñ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ñ increment + expire
            pipe = self.redis.pipeline()
            pipe.incr(key)
            pipe.expire(key, limit.window_seconds)
            results = pipe.execute()
            
            current_count = results[0]
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð»Ð¸Ð¼Ð¸Ñ‚ (Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ burst allowance)
            effective_limit = limit.threshold + limit.burst_allowance
            is_allowed = current_count <= effective_limit
            
            return is_allowed, current_count, effective_limit
            
        except Exception as e:
            self.logger.error(f"Redis error in rate limiting: {e}")
            # ÐŸÑ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ Redis Ñ€Ð°Ð·Ñ€ÐµÑˆÐ°ÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ
            return True, 0, limit.threshold
    
    def _detect_suspicious_behavior(self, request: web.Request, identifier: str) -> ThreatLevel:
        """ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ñ"""
        
        threat_indicators = []
        
        # 1. ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° User-Agent
        user_agent = request.headers.get('User-Agent', '').lower()
        suspicious_ua_patterns = [
            'bot', 'crawler', 'spider', 'scraper', 'curl', 'wget', 
            'python-requests', 'python-urllib', 'go-http-client'
        ]
        
        if any(pattern in user_agent for pattern in suspicious_ua_patterns):
            threat_indicators.append('suspicious_user_agent')
        
        if not user_agent or len(user_agent) < 10:
            threat_indicators.append('missing_or_short_user_agent')
        
        # 2. ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²
        required_headers = ['accept', 'accept-encoding']
        missing_headers = [h for h in required_headers if h not in request.headers]
        
        if missing_headers:
            threat_indicators.append('missing_common_headers')
        
        # 3. ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° HTTP Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð²
        if request.method in ['OPTIONS', 'TRACE', 'CONNECT']:
            threat_indicators.append('unusual_http_method')
        
        # 4. ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿ÑƒÑ‚ÐµÐ¹
        suspicious_paths = [
            '/admin', '/wp-admin', '/.env', '/config', '/api/v1/admin',
            '/.git', '/phpmyadmin', '/xmlrpc.php'
        ]
        
        if any(path in request.path for path in suspicious_paths):
            threat_indicators.append('suspicious_path_access')
        
        # 5. ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð° SQL injection Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð² URL
        sql_patterns = ['union', 'select', 'drop', 'insert', 'delete', '1=1', '1\'=\'1']
        query_string = request.query_string.lower()
        
        if any(pattern in query_string for pattern in sql_patterns):
            threat_indicators.append('potential_sql_injection')
        
        # 6. ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð´Ð»Ð¸Ð½Ñ‹ URL
        if len(request.path_qs) > 2000:
            threat_indicators.append('unusually_long_url')
        
        # 7. ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð° excessive Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹
        if len(request.query) > 50:
            threat_indicators.append('excessive_query_parameters')
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÑƒÐ³Ñ€Ð¾Ð·Ñ‹
        threat_count = len(threat_indicators)
        
        if threat_count >= 4:
            threat_level = ThreatLevel.CRITICAL
        elif threat_count >= 3:
            threat_level = ThreatLevel.HIGH
        elif threat_count >= 2:
            threat_level = ThreatLevel.MEDIUM
        elif threat_count >= 1:
            threat_level = ThreatLevel.LOW
        else:
            threat_level = ThreatLevel.LOW
        
        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ ÑƒÐ³Ñ€Ð¾Ð·Ñ‹
        if threat_indicators:
            self.logger.warning(f"Suspicious behavior from {identifier}: {threat_indicators}")
            self.stats['threats_detected'][threat_level.value] += 1
        
        return threat_level
    
    def _is_ip_whitelisted(self, ip: str) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° IP Ð² whitelist"""
        if ip in self.ip_whitelist:
            return True
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ð¾Ð´ÑÐµÑ‚Ð¸
        try:
            ip_obj = ipaddress.ip_address(ip)
            for whitelisted in self.ip_whitelist:
                try:
                    if '/' in whitelisted:  # CIDR notation
                        network = ipaddress.ip_network(whitelisted, strict=False)
                        if ip_obj in network:
                            return True
                except:
                    continue
        except:
            pass
        
        return False
    
    def _is_ip_blacklisted(self, ip: str) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° IP Ð² blacklist"""
        return ip in self.ip_blacklist or ip in self.blocked_ips
    
    async def check_request(self, request: web.Request) -> Tuple[bool, str, Dict]:
        """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°"""
        
        self.stats['total_requests'] += 1
        
        identifier = self._get_client_identifier(request)
        ip = identifier.split(':')[-1] if identifier.startswith('ip:') else 'unknown'
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ whitelist
        if self._is_ip_whitelisted(ip):
            return True, "whitelisted", {}
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ blacklist
        if self._is_ip_blacklisted(ip):
            self.stats['blocked_requests'] += 1
            return False, "blacklisted", {'reason': 'IP in blacklist'}
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ‚Ð¸Ð¿ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° Ð´Ð»Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð»Ð¸Ð¼Ð¸Ñ‚Ð¾Ð²
        if identifier.startswith('user:'):
            limit_category = 'premium' if request.headers.get('X-Premium-User') == 'true' else 'authenticated'
        else:
            limit_category = 'default'
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²ÑÐµ rate limits
        limits_exceeded = []
        for limit in self.rate_limits[limit_category]:
            is_allowed, current_count, max_allowed = await self._check_rate_limit(identifier, limit)
            
            if not is_allowed:
                limits_exceeded.append({
                    'type': limit.limit_type.value,
                    'current': current_count,
                    'limit': max_allowed,
                    'window': limit.window_seconds
                })
        
        if limits_exceeded:
            self.stats['rate_limited_requests'] += 1
            return False, "rate_limited", {
                'limits_exceeded': limits_exceeded,
                'retry_after': min(l['window'] for l in limits_exceeded)
            }
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð° Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ
        threat_level = self._detect_suspicious_behavior(request, identifier)
        
        if threat_level in [ThreatLevel.CRITICAL, ThreatLevel.HIGH]:
            self.stats['suspicious_requests'] += 1
            
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² suspicious list
            self.suspicious_ips[ip] = time.time()
            
            if threat_level == ThreatLevel.CRITICAL:
                # Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ°
                self.blocked_ips.add(ip)
                self.logger.error(f"IP {ip} temporarily blocked due to critical threat level")
                
                return False, "threat_detected", {
                    'threat_level': threat_level.value,
                    'blocked_duration': 3600  # 1 Ñ‡Ð°Ñ
                }
        
        return True, "allowed", {}
    
    def add_to_whitelist(self, ip_or_network: str):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ IP Ð¸Ð»Ð¸ ÑÐµÑ‚Ð¸ Ð² whitelist"""
        self.ip_whitelist.add(ip_or_network)
        self.logger.info(f"Added {ip_or_network} to whitelist")
    
    def add_to_blacklist(self, ip: str, duration_seconds: int = 3600):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ IP Ð² blacklist"""
        self.ip_blacklist.add(ip)
        
        # ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ Ñ‡ÐµÑ€ÐµÐ· Ð²Ñ€ÐµÐ¼Ñ
        async def remove_from_blacklist():
            await asyncio.sleep(duration_seconds)
            self.ip_blacklist.discard(ip)
            self.logger.info(f"Removed {ip} from blacklist after {duration_seconds}s")
        
        asyncio.create_task(remove_from_blacklist())
        self.logger.info(f"Added {ip} to blacklist for {duration_seconds}s")
    
    def get_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸"""
        
        total_requests = self.stats['total_requests']
        if total_requests == 0:
            return dict(self.stats)
        
        stats = dict(self.stats)
        stats.update({
            'block_rate_percent': (self.stats['blocked_requests'] / total_requests) * 100,
            'suspicious_rate_percent': (self.stats['suspicious_requests'] / total_requests) * 100,
            'rate_limit_rate_percent': (self.stats['rate_limited_requests'] / total_requests) * 100,
            'whitelist_size': len(self.ip_whitelist),
            'blacklist_size': len(self.ip_blacklist),
            'currently_blocked_ips': len(self.blocked_ips),
            'suspicious_ips': len(self.suspicious_ips)
        })
        
        return stats

# Rate Limiting Middleware Ð´Ð»Ñ aiohttp
def create_rate_limiting_middleware(rate_limiter: AdvancedRateLimiter):
    
    @web.middleware
    async def rate_limiting_middleware(request: web.Request, handler):
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ‡ÐµÑ€ÐµÐ· rate limiter
        is_allowed, status, details = await rate_limiter.check_request(request)
        
        if not is_allowed:
            # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ð± Ð¾ÑˆÐ¸Ð±ÐºÐµ
            error_response = {
                'error': 'Request blocked',
                'status': status,
                'details': details,
                'timestamp': time.time()
            }
            
            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ HTTP status code
            if status == 'rate_limited':
                http_status = 429  # Too Many Requests
                headers = {}
                if 'retry_after' in details:
                    headers['Retry-After'] = str(details['retry_after'])
            elif status == 'blacklisted':
                http_status = 403  # Forbidden  
                headers = {}
            elif status == 'threat_detected':
                http_status = 403  # Forbidden
                headers = {}
            else:
                http_status = 400  # Bad Request
                headers = {}
            
            return web.json_response(
                error_response, 
                status=http_status,
                headers=headers
            )
        
        # Ð—Ð°Ð¿Ñ€Ð¾Ñ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½, Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ
        return await handler(request)
    
    return rate_limiting_middleware

# ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ñ Ð·Ð°Ñ‰Ð¸Ñ‚Ð¾Ð¹ Ð¾Ñ‚ DDoS
async def create_protected_app():
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð·Ð°Ñ‰Ð¸Ñ‰ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð²ÐµÐ±-Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ"""
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ rate limiter
    rate_limiter = AdvancedRateLimiter()
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð´Ð¾Ð²ÐµÑ€ÐµÐ½Ð½Ñ‹Ðµ ÑÐµÑ‚Ð¸ Ð² whitelist
    rate_limiter.add_to_whitelist('127.0.0.0/8')    # localhost
    rate_limiter.add_to_whitelist('10.0.0.0/8')     # private network
    rate_limiter.add_to_whitelist('192.168.0.0/16') # private network
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ
    app = web.Application(middlewares=[
        create_rate_limiting_middleware(rate_limiter)
    ])
    
    # API endpoints
    async def health_check(request):
        return web.json_response({'status': 'healthy', 'timestamp': time.time()})
    
    async def api_data(request):
        # Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        await asyncio.sleep(0.1)  # Ð¸Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð‘Ð”
        
        return web.json_response({
            'data': [{'id': i, 'value': f'item_{i}'} for i in range(10)],
            'timestamp': time.time()
        })
    
    async def api_stats(request):
        """Ð­Ð½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚ Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð·Ð°Ñ‰Ð¸Ñ‚Ñ‹"""
        stats = rate_limiter.get_stats()
        return web.json_response(stats)
    
    async def admin_block_ip(request):
        """ÐÐ´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ ÑÐ½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚ Ð´Ð»Ñ Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ¸ IP"""
        data = await request.json()
        ip = data.get('ip')
        duration = data.get('duration', 3600)
        
        if ip:
            rate_limiter.add_to_blacklist(ip, duration)
            return web.json_response({'message': f'IP {ip} blocked for {duration}s'})
        else:
            return web.json_response({'error': 'IP address required'}, status=400)
    
    # Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ routes
    app.router.add_get('/health', health_check)
    app.router.add_get('/api/data', api_data)
    app.router.add_get('/api/stats', api_stats)
    app.router.add_post('/admin/block-ip', admin_block_ip)
    
    return app, rate_limiter

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ DDoS Ð·Ð°Ñ‰Ð¸Ñ‚Ñ‹
async def demonstrate_ddos_protection():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ DDoS Ð·Ð°Ñ‰Ð¸Ñ‚Ñ‹"""
    
    print("ðŸ›¡ï¸ DDoS Protection System Demonstration")
    print("=" * 60)
    
    app, rate_limiter = await create_protected_app()
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€ Ð² Ñ„Ð¾Ð½Ðµ
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, 'localhost', 8080)
    await site.start()
    
    print("âœ… Protected server started on http://localhost:8080")
    
    try:
        # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ñ€Ð°Ñ„Ð¸Ðº
        print("\nðŸ“Š Test 1: Normal Traffic")
        
        async with aiohttp.ClientSession() as session:
            for i in range(5):
                async with session.get('http://localhost:8080/api/data') as response:
                    print(f"  Request {i+1}: {response.status}")
                await asyncio.sleep(0.5)
        
        # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ burst Ñ‚Ñ€Ð°Ñ„Ð¸Ðº (rate limiting)
        print("\nâš¡ Test 2: Burst Traffic (Rate Limiting)")
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            for i in range(15):  # ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐ°ÐµÐ¼ Ð»Ð¸Ð¼Ð¸Ñ‚ 10 req/sec
                task = session.get('http://localhost:8080/api/data')
                tasks.append(task)
            
            responses = await asyncio.gather(*tasks, return_exceptions=True)
            
            status_codes = {}
            for i, response in enumerate(responses):
                if isinstance(response, Exception):
                    status_codes[f'Error_{i}'] = str(response)
                else:
                    status = response.status
                    response.close()
                    status_codes[status] = status_codes.get(status, 0) + 1
            
            print(f"  Response status codes: {status_codes}")
        
        # Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ñ€Ð°Ñ„Ð¸Ðº
        print("\nðŸš¨ Test 3: Suspicious Traffic")
        
        suspicious_headers = {
            'User-Agent': 'python-requests/2.25.1',  # Bot-like UA
            'Accept': '*/*'  # Minimal headers
        }
        
        async with aiohttp.ClientSession(headers=suspicious_headers) as session:
            # ÐŸÐ¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹
            suspicious_paths = [
                '/admin/users',
                '/api/data?id=1 UNION SELECT * FROM users',
                '/.env',
                '/config/database.yml'
            ]
            
            for path in suspicious_paths:
                try:
                    async with session.get(f'http://localhost:8080{path}') as response:
                        print(f"  Suspicious request to {path}: {response.status}")
                except Exception as e:
                    print(f"  Suspicious request to {path}: ERROR - {e}")
        
        # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
        print("\nðŸ“ˆ Protection Statistics:")
        async with aiohttp.ClientSession() as session:
            async with session.get('http://localhost:8080/api/stats') as response:
                stats = await response.json()
                
                print(f"  Total requests: {stats['total_requests']}")
                print(f"  Blocked requests: {stats['blocked_requests']}")
                print(f"  Rate limited: {stats['rate_limited_requests']}")
                print(f"  Suspicious requests: {stats['suspicious_requests']}")
                print(f"  Block rate: {stats.get('block_rate_percent', 0):.1f}%")
                print(f"  Threats detected: {dict(stats['threats_detected'])}")
    
    finally:
        # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€
        await runner.cleanup()
        print("\nðŸ›‘ Protected server stopped")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
if __name__ == "__main__":
    asyncio.run(demonstrate_ddos_protection())
```

### ðŸ” Network Intrusion Detection

**Real-time Traffic Analysis:**

```python
import asyncio
import time
import statistics
from typing import Dict, List, Set, Optional, Tuple
from dataclasses import dataclass, field
from collections import defaultdict, deque
import ipaddress
import re
import json
import logging

@dataclass
class NetworkPacket:
    timestamp: float
    source_ip: str
    dest_ip: str
    source_port: int
    dest_port: int
    protocol: str
    payload_size: int
    flags: Set[str] = field(default_factory=set)
    payload_preview: str = ""

@dataclass
class ThreatSignature:
    name: str
    pattern: str
    severity: str
    description: str
    category: str

class NetworkIntrusionDetector:
    def __init__(self):
        # Traffic monitoring
        self.connection_tracking: Dict[str, List[NetworkPacket]] = defaultdict(list)
        self.ip_statistics: Dict[str, Dict] = defaultdict(lambda: {
            'packet_count': 0,
            'byte_count': 0,
            'connections': set(),
            'first_seen': time.time(),
            'last_seen': time.time(),
            'suspicious_activity': []
        })
        
        # Threat detection signatures
        self.threat_signatures = [
            ThreatSignature(
                "port_scan",
                r"multiple_ports_single_ip",
                "medium",
                "Port scanning activity detected",
                "reconnaissance" 
            ),
            ThreatSignature(
                "syn_flood", 
                r"excessive_syn_no_ack",
                "high",
                "SYN flood attack detected",
                "dos"
            ),
            ThreatSignature(
                "brute_force",
                r"repeated_failed_auth",
                "high", 
                "Brute force login attempt",
                "authentication"
            ),
            ThreatSignature(
                "data_exfiltration",
                r"large_outbound_transfer",
                "critical",
                "Potential data exfiltration",
                "data_theft"
            ),
            ThreatSignature(
                "malware_callback",
                r"suspicious_dns_query",
                "high",
                "Potential malware callback",
                "malware"
            )
        ]
        
        # Detection thresholds
        self.thresholds = {
            'port_scan_ports': 10,        # ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¹ Ðº Ñ€Ð°Ð·Ð½Ñ‹Ð¼ Ð¿Ð¾Ñ€Ñ‚Ð°Ð¼
            'port_scan_time': 60,         # Ð—Ð° 60 ÑÐµÐºÑƒÐ½Ð´
            'syn_flood_rate': 100,        # SYN Ð¿Ð°ÐºÐµÑ‚Ð¾Ð² Ð² ÑÐµÐºÑƒÐ½Ð´Ñƒ
            'connection_rate': 50,        # Ð¡Ð¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ð² ÑÐµÐºÑƒÐ½Ð´Ñƒ
            'bandwidth_threshold': 1024 * 1024 * 10,  # 10MB/s
            'failed_auth_attempts': 5,    # ÐÐµÑƒÐ´Ð°Ñ‡Ð½Ñ‹Ñ… Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸
            'dns_query_rate': 20          # DNS Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð² ÑÐµÐºÑƒÐ½Ð´Ñƒ
        }
        
        # Alerts and statistics
        self.alerts: List[Dict] = deque(maxlen=1000)
        self.statistics = {
            'total_packets': 0,
            'total_bytes': 0,
            'unique_ips': set(),
            'active_connections': 0,
            'threats_detected': defaultdict(int),
            'blocked_ips': set()
        }
        
        # Logger
        self.logger = logging.getLogger('NetworkIDS')
        
        # Whitelist Ð´Ð»Ñ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð»Ð¾Ð¶Ð½Ñ‹Ñ… ÑÑ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ð¹
        self.whitelist_networks = [
            ipaddress.ip_network('127.0.0.0/8'),    # localhost
            ipaddress.ip_network('10.0.0.0/8'),     # private
            ipaddress.ip_network('192.168.0.0/16'), # private
            ipaddress.ip_network('172.16.0.0/12')   # private
        ]
    
    def _is_whitelisted(self, ip: str) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° IP Ð² whitelist"""
        try:
            ip_obj = ipaddress.ip_address(ip)
            return any(ip_obj in network for network in self.whitelist_networks)
        except:
            return False
    
    def _get_connection_key(self, packet: NetworkPacket) -> str:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÐºÐ»ÑŽÑ‡Ð° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ"""
        return f"{packet.source_ip}:{packet.source_port}->{packet.dest_ip}:{packet.dest_port}"
    
    async def process_packet(self, packet: NetworkPacket):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐµÑ‚ÐµÐ²Ð¾Ð³Ð¾ Ð¿Ð°ÐºÐµÑ‚Ð°"""
        
        self.statistics['total_packets'] += 1
        self.statistics['total_bytes'] += packet.payload_size
        self.statistics['unique_ips'].add(packet.source_ip)
        self.statistics['unique_ips'].add(packet.dest_ip)
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ IP Ð°Ð´Ñ€ÐµÑÐ¾Ð²
        for ip in [packet.source_ip, packet.dest_ip]:
            stats = self.ip_statistics[ip]
            stats['packet_count'] += 1
            stats['byte_count'] += packet.payload_size
            stats['last_seen'] = packet.timestamp
            
            connection_key = self._get_connection_key(packet)
            stats['connections'].add(connection_key)
        
        # ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°ÐµÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
        connection_key = self._get_connection_key(packet)
        self.connection_tracking[connection_key].append(packet)
        
        # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
        if len(self.connection_tracking[connection_key]) > 100:
            self.connection_tracking[connection_key] = self.connection_tracking[connection_key][-50:]
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸ÑŽ ÑƒÐ³Ñ€Ð¾Ð·
        await self._detect_threats(packet)
    
    async def _detect_threats(self, packet: NetworkPacket):
        """Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ ÑƒÐ³Ñ€Ð¾Ð· Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸"""
        
        # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ whitelisted IPs
        if self._is_whitelisted(packet.source_ip):
            return
        
        current_time = packet.timestamp
        
        # 1. Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Port Scanning
        await self._detect_port_scan(packet, current_time)
        
        # 2. Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ SYN Flood
        await self._detect_syn_flood(packet, current_time)
        
        # 3. Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¹ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚Ð¸ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        await self._detect_connection_flood(packet, current_time)
        
        # 4. Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚Ñ€Ð°Ñ„Ð¸ÐºÐ° Ð¿Ð¾ Ð¾Ð±ÑŠÐµÐ¼Ñƒ
        await self._detect_bandwidth_anomaly(packet, current_time)
        
        # 5. Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²
        await self._detect_suspicious_ports(packet)
        
        # 6. Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð°Ð½Ð¾Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ñ DNS
        await self._detect_dns_anomalies(packet, current_time)
    
    async def _detect_port_scan(self, packet: NetworkPacket, current_time: float):
        """Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²"""
        
        source_ip = packet.source_ip
        time_window = self.thresholds['port_scan_time']
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð½ÐµÐ´Ð°Ð²Ð½Ð¸Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð¾Ñ‚ ÑÑ‚Ð¾Ð³Ð¾ IP
        ip_stats = self.ip_statistics[source_ip]
        recent_connections = [
            conn for conn in ip_stats['connections']
            if current_time - self._get_connection_time(conn) <= time_window
        ]
        
        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
        dest_ports = set()
        for conn in recent_connections:
            try:
                dest_port = int(conn.split('->')[1].split(':')[1])
                dest_ports.add(dest_port)
            except:
                continue
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ñ€ÐµÐ²Ñ‹ÑˆÐµÐ½Ð¸Ðµ Ð¿Ð¾Ñ€Ð¾Ð³Ð°
        if len(dest_ports) >= self.thresholds['port_scan_ports']:
            await self._create_alert(
                "port_scan",
                f"Port scan detected from {source_ip}",
                {
                    'source_ip': source_ip,
                    'scanned_ports': list(dest_ports),
                    'scan_duration': time_window,
                    'severity': 'medium'
                },
                current_time
            )
            
            self.statistics['threats_detected']['port_scan'] += 1
    
    async def _detect_syn_flood(self, packet: NetworkPacket, current_time: float):
        """Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ SYN flood Ð°Ñ‚Ð°ÐºÐ¸"""
        
        if 'SYN' not in packet.flags or 'ACK' in packet.flags:
            return
        
        source_ip = packet.source_ip
        time_window = 1.0  # 1 ÑÐµÐºÑƒÐ½Ð´Ð°
        
        # ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ SYN Ð¿Ð°ÐºÐµÑ‚Ñ‹ Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑŽÑŽ ÑÐµÐºÑƒÐ½Ð´Ñƒ
        connection_key = self._get_connection_key(packet)
        recent_packets = [
            p for p in self.connection_tracking[connection_key]
            if current_time - p.timestamp <= time_window and 'SYN' in p.flags
        ]
        
        syn_rate = len(recent_packets) / time_window
        
        if syn_rate >= self.thresholds['syn_flood_rate']:
            await self._create_alert(
                "syn_flood",
                f"SYN flood attack detected from {source_ip}",
                {
                    'source_ip': source_ip,
                    'syn_rate': syn_rate,
                    'threshold': self.thresholds['syn_flood_rate'],
                    'severity': 'high'
                },
                current_time
            )
            
            self.statistics['threats_detected']['syn_flood'] += 1
    
    async def _detect_connection_flood(self, packet: NetworkPacket, current_time: float):
        """Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ñ„Ð»ÑƒÐ´Ð° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹"""
        
        source_ip = packet.source_ip
        time_window = 1.0  # 1 ÑÐµÐºÑƒÐ½Ð´Ð°
        
        # ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑŽÑŽ ÑÐµÐºÑƒÐ½Ð´Ñƒ
        ip_stats = self.ip_statistics[source_ip]
        recent_connections = [
            conn for conn in ip_stats['connections']
            if current_time - self._get_connection_time(conn) <= time_window
        ]
        
        connection_rate = len(recent_connections) / time_window
        
        if connection_rate >= self.thresholds['connection_rate']:
            await self._create_alert(
                "connection_flood",
                f"Connection flood detected from {source_ip}",
                {
                    'source_ip': source_ip,
                    'connection_rate': connection_rate,
                    'threshold': self.thresholds['connection_rate'],
                    'severity': 'medium'
                },
                current_time
            )
            
            self.statistics['threats_detected']['connection_flood'] += 1
    
    async def _detect_bandwidth_anomaly(self, packet: NetworkPacket, current_time: float):
        """Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ½Ð¾Ð¹ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸"""
        
        source_ip = packet.source_ip
        time_window = 1.0  # 1 ÑÐµÐºÑƒÐ½Ð´Ð°
        
        # ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¾Ð±ÑŠÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑŽÑŽ ÑÐµÐºÑƒÐ½Ð´Ñƒ
        ip_stats = self.ip_statistics[source_ip]
        
        # Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸ÑÑ…Ð¾Ð´ÑÑ‰Ð¸Ð¹ Ñ‚Ñ€Ð°Ñ„Ð¸Ðº (Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð°Ñ ÑÐºÑ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…)
        if packet.source_ip == source_ip:
            recent_bytes = 0
            connection_key = self._get_connection_key(packet)
            
            for p in self.connection_tracking[connection_key]:
                if (current_time - p.timestamp <= time_window and 
                    p.source_ip == source_ip):
                    recent_bytes += p.payload_size
            
            bandwidth_usage = recent_bytes / time_window  # bytes per second
            
            if bandwidth_usage >= self.thresholds['bandwidth_threshold']:
                await self._create_alert(
                    "data_exfiltration",
                    f"Potential data exfiltration from {source_ip}",
                    {
                        'source_ip': source_ip,
                        'bandwidth_mbps': bandwidth_usage / (1024 * 1024),
                        'threshold_mbps': self.thresholds['bandwidth_threshold'] / (1024 * 1024),
                        'severity': 'critical'
                    },
                    current_time
                )
                
                self.statistics['threats_detected']['data_exfiltration'] += 1
    
    async def _detect_suspicious_ports(self, packet: NetworkPacket):
        """Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²"""
        
        # Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²
        suspicious_ports = {
            1433: 'SQL Server',
            3389: 'RDP',
            5432: 'PostgreSQL',
            6379: 'Redis',
            27017: 'MongoDB',
            9200: 'Elasticsearch',
            11211: 'Memcached',
            50070: 'Hadoop NameNode'
        }
        
        if packet.dest_port in suspicious_ports:
            service_name = suspicious_ports[packet.dest_port]
            
            await self._create_alert(
                "suspicious_port_access",
                f"Access to suspicious port {packet.dest_port} ({service_name})",
                {
                    'source_ip': packet.source_ip,
                    'dest_ip': packet.dest_ip,
                    'dest_port': packet.dest_port,
                    'service': service_name,
                    'severity': 'medium'
                },
                packet.timestamp
            )
            
            self.statistics['threats_detected']['suspicious_port'] += 1
    
    async def _detect_dns_anomalies(self, packet: NetworkPacket, current_time: float):
        """Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ DNS Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹"""
        
        # Ð”ÐµÑ‚ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ DNS Ñ‚Ñ€Ð°Ñ„Ð¸Ðº (Ð¿Ð¾Ñ€Ñ‚ 53)
        if packet.dest_port != 53:
            return
        
        source_ip = packet.source_ip
        time_window = 1.0  # 1 ÑÐµÐºÑƒÐ½Ð´Ð°
        
        # ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ DNS Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑŽÑŽ ÑÐµÐºÑƒÐ½Ð´Ñƒ
        dns_queries = 0
        for conn_key, packets in self.connection_tracking.items():
            for p in packets:
                if (p.source_ip == source_ip and 
                    p.dest_port == 53 and
                    current_time - p.timestamp <= time_window):
                    dns_queries += 1
        
        dns_rate = dns_queries / time_window
        
        if dns_rate >= self.thresholds['dns_query_rate']:
            await self._create_alert(
                "dns_anomaly",
                f"Excessive DNS queries from {source_ip}",
                {
                    'source_ip': source_ip,
                    'dns_rate': dns_rate,
                    'threshold': self.thresholds['dns_query_rate'],
                    'severity': 'medium'
                },
                current_time
            )
            
            self.statistics['threats_detected']['dns_anomaly'] += 1
        
        # Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… DNS Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²
        if packet.payload_preview:
            suspicious_domains = [
                '.tk', '.ml', '.ga', '.cf',  # Ð‘ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ñ‹Ðµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹ Ð²ÐµÑ€Ñ…Ð½ÐµÐ³Ð¾ ÑƒÑ€Ð¾Ð²Ð½Ñ
                'dyn.', 'ddns.', 'dynamic.',  # Ð”Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ DNS
                'raw.githubusercontent.com',  # Ð§Ð°ÑÑ‚Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ malware
                'pastebin.com', 'paste.ee'   # Ð§Ð°ÑÑ‚Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ C&C
            ]
            
            payload_lower = packet.payload_preview.lower()
            for domain in suspicious_domains:
                if domain in payload_lower:
                    await self._create_alert(
                        "suspicious_dns_query",
                        f"Suspicious DNS query to {domain}",
                        {
                            'source_ip': source_ip,
                            'suspicious_domain': domain,
                            'severity': 'high'
                        },
                        current_time
                    )
                    
                    self.statistics['threats_detected']['suspicious_dns'] += 1
                    break
    
    def _get_connection_time(self, connection_key: str) -> float:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ Ð¿Ð°ÐºÐµÑ‚Ð° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ"""
        if connection_key in self.connection_tracking:
            packets = self.connection_tracking[connection_key]
            if packets:
                return packets[0].timestamp
        
        return time.time()
    
    async def _create_alert(self, alert_type: str, message: str, 
                          details: Dict, timestamp: float):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ alert'Ð°"""
        
        alert = {
            'id': f"{alert_type}_{int(timestamp)}_{hash(message) % 1000}",
            'type': alert_type,
            'message': message,
            'details': details,
            'timestamp': timestamp,
            'source': 'NetworkIDS'
        }
        
        self.alerts.append(alert)
        
        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ñ‹Ðµ alert'Ñ‹
        severity = details.get('severity', 'medium')
        if severity in ['high', 'critical']:
            self.logger.error(f"SECURITY ALERT: {message} - {details}")
        else:
            self.logger.warning(f"Security notice: {message}")
        
        # ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ° Ð´Ð»Ñ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ñ‹Ñ… ÑƒÐ³Ñ€Ð¾Ð·
        if severity == 'critical' and 'source_ip' in details:
            source_ip = details['source_ip']
            if not self._is_whitelisted(source_ip):
                self.statistics['blocked_ips'].add(source_ip)
                self.logger.error(f"Automatically blocked IP {source_ip} due to critical threat")
    
    def get_recent_alerts(self, count: int = 10) -> List[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½ÐµÐ´Ð°Ð²Ð½Ð¸Ñ… alert'Ð¾Ð²"""
        return list(self.alerts)[-count:]
    
    def get_statistics(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ IDS"""
        
        current_time = time.time()
        
        # Top talking IPs
        top_ips_by_traffic = sorted(
            self.ip_statistics.items(),
            key=lambda x: x[1]['byte_count'],
            reverse=True
        )[:10]
        
        # Active connections count
        active_connections = len([
            conn for conn, packets in self.connection_tracking.items()
            if packets and current_time - packets[-1].timestamp <= 300  # 5 Ð¼Ð¸Ð½ÑƒÑ‚
        ])
        
        return {
            'total_packets': self.statistics['total_packets'],
            'total_bytes': self.statistics['total_bytes'],
            'unique_ips_count': len(self.statistics['unique_ips']),
            'active_connections': active_connections,
            'threats_detected': dict(self.statistics['threats_detected']),
            'blocked_ips_count': len(self.statistics['blocked_ips']),
            'total_alerts': len(self.alerts),
            'top_ips_by_traffic': [
                {
                    'ip': ip,
                    'bytes': stats['byte_count'],
                    'packets': stats['packet_count'],
                    'connections': len(stats['connections'])
                }
                for ip, stats in top_ips_by_traffic
            ],
            'threat_breakdown': {
                threat_type: count 
                for threat_type, count in self.statistics['threats_detected'].items()
            }
        }

# Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ‚Ð¾Ñ€ ÑÐµÑ‚ÐµÐ²Ð¾Ð³Ð¾ Ñ‚Ñ€Ð°Ñ„Ð¸ÐºÐ° Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ IDS
class NetworkTrafficSimulator:
    def __init__(self, ids: NetworkIntrusionDetector):
        self.ids = ids
        self.simulation_ips = [
            '192.168.1.100',  # ÐÐ¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ»Ð¸ÐµÐ½Ñ‚
            '10.0.0.50',      # Ð’Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ð¹ ÑÐµÑ€Ð²Ð¸Ñ
            '203.0.113.10',   # Ð’Ð½ÐµÑˆÐ½Ð¸Ð¹ ÐºÐ»Ð¸ÐµÐ½Ñ‚
            '198.51.100.5',   # ÐŸÐ¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ IP
            '203.0.113.99'    # ÐÑ‚Ð°ÐºÑƒÑŽÑ‰Ð¸Ð¹ IP
        ]
    
    async def simulate_normal_traffic(self, duration_seconds: int = 60):
        """Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚Ñ€Ð°Ñ„Ð¸ÐºÐ°"""
        
        print(f"ðŸ”„ Simulating normal traffic for {duration_seconds} seconds...")
        
        start_time = time.time()
        packet_id = 0
        
        while time.time() - start_time < duration_seconds:
            current_time = time.time()
            
            # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°ÐºÐµÑ‚Ñ‹
            for _ in range(5):  # 5 Ð¿Ð°ÐºÐµÑ‚Ð¾Ð² Ð·Ð° Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸ÑŽ
                packet_id += 1
                
                source_ip = self.simulation_ips[packet_id % 3]  # ÐŸÐµÑ€Ð²Ñ‹Ðµ 3 IP - Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ
                dest_ip = '93.184.216.34'  # example.com
                
                packet = NetworkPacket(
                    timestamp=current_time,
                    source_ip=source_ip,
                    dest_ip=dest_ip,
                    source_port=10000 + (packet_id % 50000),
                    dest_port=443,  # HTTPS
                    protocol='TCP',
                    payload_size=1024 + (packet_id % 4096),
                    flags={'ACK'},
                    payload_preview=f"GET /api/data HTTP/1.1\r\nHost: example.com"
                )
                
                await self.ids.process_packet(packet)
            
            await asyncio.sleep(0.1)  # 100ms Ð¼ÐµÐ¶Ð´Ñƒ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸ÑÐ¼Ð¸
    
    async def simulate_port_scan(self):
        """Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²"""
        
        print("ðŸ” Simulating port scan attack...")
        
        attacker_ip = '198.51.100.5'
        target_ip = '10.0.0.100'
        current_time = time.time()
        
        # Ð¡ÐºÐ°Ð½Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð¾Ñ‚ 1 Ð´Ð¾ 100
        for port in range(1, 101):
            packet = NetworkPacket(
                timestamp=current_time + (port * 0.01),  # 10ms Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ð°ÐºÐµÑ‚Ð°Ð¼Ð¸
                source_ip=attacker_ip,
                dest_ip=target_ip,
                source_port=50000 + port,
                dest_port=port,
                protocol='TCP',
                payload_size=40,  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ TCP Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
                flags={'SYN'},
                payload_preview=""
            )
            
            await self.ids.process_packet(packet)
            await asyncio.sleep(0.01)  # 10ms Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°
    
    async def simulate_syn_flood(self):
        """Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ SYN flood Ð°Ñ‚Ð°ÐºÐ¸"""
        
        print("âš¡ Simulating SYN flood attack...")
        
        attacker_ip = '203.0.113.99'
        target_ip = '10.0.0.200'
        current_time = time.time()
        
        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ 200 SYN Ð¿Ð°ÐºÐµÑ‚Ð¾Ð² Ð·Ð° ÑÐµÐºÑƒÐ½Ð´Ñƒ
        for i in range(200):
            packet = NetworkPacket(
                timestamp=current_time + (i * 0.005),  # 5ms Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ð°ÐºÐµÑ‚Ð°Ð¼Ð¸
                source_ip=attacker_ip,
                dest_ip=target_ip,
                source_port=20000 + i,
                dest_port=80,
                protocol='TCP',
                payload_size=40,
                flags={'SYN'},
                payload_preview=""
            )
            
            await self.ids.process_packet(packet)
            await asyncio.sleep(0.005)  # 5ms Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°
    
    async def simulate_data_exfiltration(self):
        """Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ ÐºÑ€Ð°Ð¶Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
        
        print("ðŸ“¤ Simulating data exfiltration...")
        
        insider_ip = '10.0.0.150'  # Ð’Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ð¹ IP
        external_ip = '203.0.113.50'  # Ð’Ð½ÐµÑˆÐ½Ð¸Ð¹ ÑÐµÑ€Ð²ÐµÑ€
        current_time = time.time()
        
        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ðµ Ð¾Ð±ÑŠÐµÐ¼Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        for i in range(20):
            packet = NetworkPacket(
                timestamp=current_time + (i * 0.1),
                source_ip=insider_ip,
                dest_ip=external_ip,
                source_port=45000 + i,
                dest_port=443,
                protocol='TCP',
                payload_size=1024 * 1024,  # 1MB Ð½Ð° Ð¿Ð°ÐºÐµÑ‚
                flags={'ACK', 'PSH'},
                payload_preview="POST /upload HTTP/1.1\r\nContent-Length: 1048576"
            )
            
            await self.ids.process_packet(packet)
            await asyncio.sleep(0.1)
    
    async def simulate_suspicious_dns(self):
        """Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… DNS Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²"""
        
        print("ðŸ” Simulating suspicious DNS queries...")
        
        infected_ip = '192.168.1.200'
        dns_server = '8.8.8.8'
        current_time = time.time()
        
        suspicious_domains = [
            'malware-c2.tk',
            'bot.dynamic-dns.net',
            'evil.pastebin.com',
            'raw.githubusercontent.com/malware/config'
        ]
        
        # Ð’Ñ‹ÑÐ¾ÐºÐ¾Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ñ‹Ðµ DNS Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ðº Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼ Ð´Ð¾Ð¼ÐµÐ½Ð°Ð¼
        for i in range(50):
            domain = suspicious_domains[i % len(suspicious_domains)]
            
            packet = NetworkPacket(
                timestamp=current_time + (i * 0.02),  # 20ms Ð¼ÐµÐ¶Ð´Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸
                source_ip=infected_ip,
                dest_ip=dns_server,
                source_port=53000 + i,
                dest_port=53,
                protocol='UDP',
                payload_size=64,
                flags=set(),
                payload_preview=f"DNS query for {domain}"
            )
            
            await self.ids.process_packet(packet)
            await asyncio.sleep(0.02)

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Network IDS
async def demonstrate_network_ids():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Network IDS"""
    
    print("ðŸ” Network Intrusion Detection System Demonstration")
    print("=" * 70)
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ IDS
    ids = NetworkIntrusionDetector()
    simulator = NetworkTrafficSimulator(ids)
    
    print("âœ… Network IDS initialized")
    
    # Ð¤Ð¾Ð½Ð¾Ð²Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° Ð´Ð»Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚Ñ€Ð°Ñ„Ð¸ÐºÐ°
    normal_traffic_task = asyncio.create_task(
        simulator.simulate_normal_traffic(120)  # 2 Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚Ñ€Ð°Ñ„Ð¸ÐºÐ°
    )
    
    # Ð–Ð´ÐµÐ¼ Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð´Ð»Ñ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð¹ Ð»Ð¸Ð½Ð¸Ð¸
    await asyncio.sleep(5)
    
    print("\nðŸ“Š Baseline Statistics:")
    stats = ids.get_statistics()
    print(f"  Total packets: {stats['total_packets']}")
    print(f"  Unique IPs: {stats['unique_ips_count']}")
    print(f"  Active connections: {stats['active_connections']}")
    
    # Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð°Ñ‚Ð°Ðº
    print("\nðŸš¨ Starting Attack Simulations:")
    
    # 1. Port Scan
    await simulator.simulate_port_scan()
    await asyncio.sleep(2)
    
    # 2. SYN Flood  
    await simulator.simulate_syn_flood()
    await asyncio.sleep(2)
    
    # 3. Data Exfiltration
    await simulator.simulate_data_exfiltration()
    await asyncio.sleep(2)
    
    # 4. Suspicious DNS
    await simulator.simulate_suspicious_dns()
    await asyncio.sleep(3)
    
    # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ñ€Ð°Ñ„Ð¸Ðº
    normal_traffic_task.cancel()
    
    print("\nðŸ” Final IDS Analysis:")
    
    # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
    final_stats = ids.get_statistics()
    print(f"\nðŸ“ˆ Traffic Statistics:")
    print(f"  Total packets processed: {final_stats['total_packets']}")
    print(f"  Total bytes processed: {final_stats['total_bytes']:,}")
    print(f"  Unique IP addresses: {final_stats['unique_ips_count']}")
    print(f"  Active connections: {final_stats['active_connections']}")
    
    print(f"\nðŸš¨ Threat Detection Results:")
    if final_stats['threats_detected']:
        for threat_type, count in final_stats['threats_detected'].items():
            print(f"  {threat_type.replace('_', ' ').title()}: {count} incidents")
    else:
        print("  No threats detected")
    
    print(f"  Blocked IPs: {final_stats['blocked_ips_count']}")
    print(f"  Total alerts generated: {final_stats['total_alerts']}")
    
    # ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ alert'Ñ‹
    print(f"\nâš ï¸ Recent Security Alerts:")
    recent_alerts = ids.get_recent_alerts(10)
    
    for alert in recent_alerts[-10:]:
        severity = alert['details'].get('severity', 'medium')
        timestamp_str = time.strftime('%H:%M:%S', time.localtime(alert['timestamp']))
        
        severity_icon = {
            'low': 'ðŸ’¡',
            'medium': 'âš ï¸',
            'high': 'ðŸš¨',
            'critical': 'ðŸ”¥'
        }.get(severity, 'âš ï¸')
        
        print(f"  {severity_icon} [{timestamp_str}] {alert['message']}")
        
        if severity in ['high', 'critical']:
            details = alert['details']
            if 'source_ip' in details:
                print(f"      Source IP: {details['source_ip']}")
            if 'severity' in details:
                print(f"      Severity: {details['severity'].upper()}")
    
    # Top IPs Ð¿Ð¾ Ñ‚Ñ€Ð°Ñ„Ð¸ÐºÑƒ
    print(f"\nðŸ“Š Top IPs by Traffic:")
    for ip_info in final_stats['top_ips_by_traffic'][:5]:
        print(f"  {ip_info['ip']}: {ip_info['bytes']:,} bytes "
              f"({ip_info['packets']} packets, {ip_info['connections']} connections)")
    
    print(f"\nâœ… Network IDS demonstration completed")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(demonstrate_network_ids())# ÐšÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ð½Ñ‹Ðµ ÑÐµÑ‚Ð¸ Ð´Ð»Ñ Backend Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ°
## ÐžÑ‚ Ð½Ð¾Ð²Ð¸Ñ‡ÐºÐ° Ð´Ð¾ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð° Ð·Ð° 16 Ð½ÐµÐ´ÐµÐ»ÑŒ

> **Ð¦ÐµÐ»ÑŒ ÐºÑƒÑ€ÑÐ°:** ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ðµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¹ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ…, Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€ÑƒÐµÐ¼Ñ‹Ñ… Ð¸ Ð½Ð°Ð´ÐµÐ¶Ð½Ñ‹Ñ… backend-Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹.

---

## ðŸŽ¯ Ð—Ð°Ñ‡ÐµÐ¼ backend-Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÑƒ Ð¸Ð·ÑƒÑ‡Ð°Ñ‚ÑŒ ÑÐµÑ‚Ð¸?

ÐŸÑ€ÐµÐ´ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ: Ð²Ð°Ñˆ API Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚ Ð·Ð° 500Ð¼Ñ Ð²Ð¼ÐµÑÑ‚Ð¾ 50Ð¼Ñ. ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¶Ð°Ð»ÑƒÑŽÑ‚ÑÑ Ð½Ð° Ñ‚Ð¾Ñ€Ð¼Ð¾Ð·Ð°. Ð“Ð´Ðµ Ð¸ÑÐºÐ°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ?

**80% Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ backend-Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹ ÑÐ²ÑÐ·Ð°Ð½Ñ‹ Ñ ÑÐµÑ‚ÑŒÑŽ:**
- ÐÐµÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ HTTP keep-alive
- ÐŸÐ»Ð¾Ñ…Ð°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° TCP Ð±ÑƒÑ„ÐµÑ€Ð¾Ð²
- ÐÐµÐ¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ° Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
- ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ DNS Ñ€ÐµÐ·Ð¾Ð»ÑŽÑ†Ð¸ÐµÐ¹

**Ð­Ñ‚Ð¾Ñ‚ ÐºÑƒÑ€Ñ Ð½Ð°ÑƒÑ‡Ð¸Ñ‚ Ð²Ð°Ñ:**
- Ð”Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐµÑ‚ÐµÐ²Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð·Ð° Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹
- ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð½Ð° 70-90%
- ÐŸÑ€Ð¾ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ñ‚ÐºÐ°Ð·Ð¾ÑƒÑÑ‚Ð¾Ð¹Ñ‡Ð¸Ð²Ñ‹Ðµ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹
- ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°Ñ‚ÑŒ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹

---

## ðŸ“š Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ

### ÐœÐ¾Ð´ÑƒÐ»ÑŒ 1: [ÐžÑÐ½Ð¾Ð²Ñ‹ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¹](#module-1)
### ÐœÐ¾Ð´ÑƒÐ»ÑŒ 2: [Ð¢Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚Ð½Ñ‹Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ](#module-2)
### ÐœÐ¾Ð´ÑƒÐ»ÑŒ 3: [HTTP Ð¸ Ð²ÐµÐ±-Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ñ‹](#module-3)
### ÐœÐ¾Ð´ÑƒÐ»ÑŒ 4: [DNS Ð¸ ÑÐµÑ€Ð²Ð¸Ñ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ](#module-4)
### ÐœÐ¾Ð´ÑƒÐ»ÑŒ 5: [ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ](#module-5)
### ÐœÐ¾Ð´ÑƒÐ»ÑŒ 6: [Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹](#module-6)
### ÐœÐ¾Ð´ÑƒÐ»ÑŒ 7: [Ð‘Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ° Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¸ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ](#module-7)
### ÐœÐ¾Ð´ÑƒÐ»ÑŒ 8: [Ð¡Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ñ‹ Ð¸ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹](#module-8)

---

# ÐœÐ¾Ð´ÑƒÐ»ÑŒ 1: ÐžÑÐ½Ð¾Ð²Ñ‹ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¹ {#module-1}
*ÐÐµÐ´ÐµÐ»Ð¸ 1-2 | Ð’Ñ€ÐµÐ¼Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ: 16-20 Ñ‡Ð°ÑÐ¾Ð²*

## ÐÐµÐ´ÐµÐ»Ñ 1: ÐœÐ¾Ð´ÐµÐ»ÑŒ OSI Ð¸ TCP/IP ÑÑ‚ÐµÐº

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: Ð—Ð°Ñ‡ÐµÐ¼ Ð½ÑƒÐ¶Ð½Ñ‹ ÑƒÑ€Ð¾Ð²Ð½Ð¸ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ð¾Ð²?

ÐŸÑ€ÐµÐ´ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÑƒ Ð¿Ð¸ÑÑŒÐ¼Ð° Ð¿Ð¾ Ð¿Ð¾Ñ‡Ñ‚Ðµ. Ð•ÑÑ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð°Ð¿Ð¾Ð²:
1. **ÐÐ°Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ** (Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ)
2. **Ð£Ð¿Ð°ÐºÐ¾Ð²ÐºÐ° Ð² ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚** (Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²)
3. **Ð£ÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð°Ð´Ñ€ÐµÑÐ°** (Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ)
4. **Ð¤Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ°** (Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð° Ð¿Ð¾ Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð°Ð¼)

Ð¢Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð°Ðº Ð¶Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‚ ÑÐµÑ‚ÐµÐ²Ñ‹Ðµ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ñ‹ - ÐºÐ°Ð¶Ð´Ñ‹Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ñ€ÐµÑˆÐ°ÐµÑ‚ ÑÐ²Ð¾ÑŽ Ð·Ð°Ð´Ð°Ñ‡Ñƒ.

### ðŸ“Š ÐœÐ¾Ð´ÐµÐ»ÑŒ OSI vs TCP/IP

```
OSI (7 ÑƒÑ€Ð¾Ð²Ð½ÐµÐ¹)          TCP/IP (4 ÑƒÑ€Ð¾Ð²Ð½Ñ)         ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application    â”‚ â”€â”€â”€â†’ â”‚  Application    â”‚ â† HTTP, SMTP, FTP
â”‚  Presentation   â”‚      â”‚                 â”‚
â”‚  Session        â”‚      â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Transport      â”‚ â”€â”€â”€â†’ â”‚  Transport      â”‚ â† TCP, UDP
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Network        â”‚ â”€â”€â”€â†’ â”‚  Internet       â”‚ â† IP, ICMP
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Link      â”‚ â”€â”€â”€â†’ â”‚  Network Access â”‚ â† Ethernet, WiFi
â”‚  Physical       â”‚      â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ’¡ ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ ÑÑ‚Ð¾ Ð²Ð°Ð¶Ð½Ð¾ Ð´Ð»Ñ backend?

**ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹:** API Ñ‚Ð¾Ñ€Ð¼Ð¾Ð·Ð¸Ñ‚ Ð¿Ñ€Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ

**Ð”Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ ÑƒÑ€Ð¾Ð²Ð½ÑÐ¼:**
- **Application (L7):** ÐœÐµÐ´Ð»ÐµÐ½Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð² ÐºÐ¾Ð´Ðµ
- **Transport (L4):** Ð˜ÑÑ‡ÐµÑ€Ð¿Ð°Ð½Ð¸Ðµ TCP ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
- **Network (L3):** ÐÐµÐ¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ
- **Data Link (L2):** ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ ÐºÐ¾Ð¼Ð¼ÑƒÑ‚Ð°Ñ‚Ð¾Ñ€Ð¾Ð¼

### ðŸ”§ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Ð˜Ð½ÐºÐ°Ð¿ÑÑƒÐ»ÑÑ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…

ÐšÐ¾Ð³Ð´Ð° Ð²Ð°Ñˆ ÐºÐ¾Ð´ Ð´ÐµÐ»Ð°ÐµÑ‚ HTTP Ð·Ð°Ð¿Ñ€Ð¾Ñ:

```python
import requests
response = requests.get('https://api.example.com/users')
```

ÐŸÑ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ñ‚ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐµ:

```
1. Application Layer (HTTP):
   GET /users HTTP/1.1
   Host: api.example.com
   
2. Transport Layer (TCP):
   [TCP Header: src_port=12345, dst_port=443, seq=100, ack=200]
   
3. Network Layer (IP):
   [IP Header: src=192.168.1.10, dst=93.184.216.34, protocol=TCP]
   
4. Data Link Layer (Ethernet):
   [Ethernet Header: src_mac=AA:BB:CC:DD:EE:FF, dst_mac=11:22:33:44:55:66]
```

### ðŸ› ï¸ Ð˜Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: Wireshark

ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ Ð½Ð° Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ HTTP Ð·Ð°Ð¿Ñ€Ð¾Ñ:

```bash
# Ð—Ð°Ñ…Ð²Ð°Ñ‚ Ñ‚Ñ€Ð°Ñ„Ð¸ÐºÐ° Ð½Ð° Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐµ
tcpdump -i eth0 -A host api.example.com

# Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð²ÑÐµ ÑƒÑ€Ð¾Ð²Ð½Ð¸:
# Ethernet header â†’ IP header â†’ TCP header â†’ HTTP data
```

### âš¡ Ð’Ð»Ð¸ÑÐ½Ð¸Ðµ Ð½Ð° Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ

**MTU (Maximum Transmission Unit) Ð¸ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ:**

```bash
# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° MTU
ip route get 8.8.8.8
# 8.8.8.8 via 192.168.1.1 dev eth0 src 192.168.1.10 mtu 1500

# Ð¢ÐµÑÑ‚ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸
ping -M do -s 1472 google.com  # OK
ping -M do -s 1473 google.com  # Ð¤Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ!
```

**ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ ÑÑ‚Ð¾ Ð²Ð°Ð¶Ð½Ð¾:**
- Ð¤Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð°ÐºÐµÑ‚Ñ‹ = Ð±Ð¾Ð»ÑŒÑˆÐµ overhead
- Ð’ datacenter Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ MTU = 9000 (jumbo frames)
- ÐÐµÐ¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ MTU Ð¼Ð¾Ð¶ÐµÑ‚ ÑÐ½Ð¸Ð·Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð½Ð° 30%

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ

1. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Wireshark Ð¸ Ð·Ð°Ñ…Ð²Ð°Ñ‚Ð¸Ñ‚Ðµ HTTP Ñ‚Ñ€Ð°Ñ„Ð¸Ðº Ð²Ð°ÑˆÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
2. ÐÐ°Ð¹Ð´Ð¸Ñ‚Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÑƒÑ€Ð¾Ð²Ð½Ñ Ð² Ð¾Ð´Ð½Ð¾Ð¼ Ð¿Ð°ÐºÐµÑ‚Ðµ
3. Ð˜Ð·Ð¼ÐµÑ€ÑŒÑ‚Ðµ MTU Ð´Ð¾ Ð²Ð°ÑˆÐµÐ³Ð¾ API ÑÐµÑ€Ð²ÐµÑ€Ð°
4. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð»Ð¸ jumbo frames Ð² Ð²Ð°ÑˆÐµÐ¹ Ð¸Ð½Ñ„Ñ€Ð°ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ðµ

---

## ÐÐµÐ´ÐµÐ»Ñ 2: IP Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð» Ð¸ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: ÐšÐ°Ðº Ð¿Ð°ÐºÐµÑ‚Ñ‹ Ð½Ð°Ñ…Ð¾Ð´ÑÑ‚ Ð¿ÑƒÑ‚ÑŒ Ð² Ð˜Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ðµ?

IP - ÑÑ‚Ð¾ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð´Ñ€ÐµÑÐ°Ñ†Ð¸Ð¸ Ð¸ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸ Ð¿Ð°ÐºÐµÑ‚Ð¾Ð². ÐšÐ°Ðº GPS Ð´Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ….

### ðŸ“Š Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° IP Ð¿Ð°ÐºÐµÑ‚Ð° (IPv4)

```
IPv4 Header (20 Ð±Ð°Ð¹Ñ‚ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Version â”‚  IHL  â”‚    ToS    â”‚         Total Length          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        Identification         â”‚Flagsâ”‚   Fragment Offset     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    TTL    â”‚  Protocol â”‚           Header Checksum          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Source IP Address                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Destination IP Address                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¿Ð¾Ð»Ñ Ð´Ð»Ñ backend:**
- **TTL (Time To Live):** Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ð¾Ð² Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ñ€Ð¾Ð¹Ñ‚Ð¸ Ð¿Ð°ÐºÐµÑ‚
- **Protocol:** TCP (6), UDP (17), ICMP (1)
- **Fragment Offset:** Ð”Ð»Ñ ÑÐ±Ð¾Ñ€ÐºÐ¸ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð°ÐºÐµÑ‚Ð¾Ð²

### ðŸ”§ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€: CIDR Ð¸ Ð¿Ð¾Ð´ÑÐµÑ‚Ð¸

Ð’Ð°Ñˆ ÑÐµÑ€Ð²ÐµÑ€ Ð² Ð¿Ð¾Ð´ÑÐµÑ‚Ð¸ `10.0.1.0/24`:

```bash
# Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ ÑÐµÑ‚Ð¸
ip addr show eth0
# inet 10.0.1.100/24 brd 10.0.1.255 scope global eth0

# Ð­Ñ‚Ð¾ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚:
# - Ð¡ÐµÑ‚ÑŒ: 10.0.1.0
# - ÐœÐ°ÑÐºÐ°: 255.255.255.0 (/24)
# - Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð°Ð´Ñ€ÐµÑÐ°: 10.0.1.1 - 10.0.1.254
# - Broadcast: 10.0.1.255
```

**Ð Ð°ÑÑ‡ÐµÑ‚ Ð¿Ð¾Ð´ÑÐµÑ‚ÐµÐ¹ Ð´Ð»Ñ Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²:**

```python
import ipaddress

# ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ ÑÐµÑ‚ÑŒ Ð´Ð»Ñ Ð²ÑÐµÑ… ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
main_network = ipaddress.IPv4Network('10.0.0.0/16')

# Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð½Ð° Ð¿Ð¾Ð´ÑÐµÑ‚Ð¸ Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
subnets = list(main_network.subnets(new_prefix=24))

print("ÐŸÐ¾Ð´ÑÐµÑ‚Ð¸ Ð´Ð»Ñ Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²:")
for i, subnet in enumerate(subnets[:10]):
    service_name = ['auth', 'users', 'orders', 'payments', 'inventory', 
                   'notifications', 'analytics', 'logs', 'cache', 'db'][i]
    print(f"{service_name}: {subnet}")

# Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚:
# auth: 10.0.0.0/24
# users: 10.0.1.0/24
# orders: 10.0.2.0/24
# ...
```

### ðŸŒ ÐœÐ°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ: ÐšÐ°Ðº Ð¿Ð°ÐºÐµÑ‚Ñ‹ Ð½Ð°Ñ…Ð¾Ð´ÑÑ‚ Ð¿ÑƒÑ‚ÑŒ?

**Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ:**

```bash
# ÐŸÑ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸
ip route show
```

```
default via 10.0.1.1 dev eth0               # Ð¨Ð»ÑŽÐ· Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
10.0.1.0/24 dev eth0 proto kernel scope link # Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð°Ñ ÑÐµÑ‚ÑŒ
127.0.0.0/8 dev lo scope host                # Loopback
```

**Ð¢Ñ€Ð°ÑÑÐ¸Ñ€Ð¾Ð²ÐºÐ° Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð° Ð´Ð¾ API:**

```bash
# ÐŸÑ€Ð¾ÑÐ»ÐµÐ´Ð¸Ð¼ Ð¿ÑƒÑ‚ÑŒ Ð¿Ð°ÐºÐµÑ‚Ð°
traceroute api.example.com

# Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ hop:
1  gateway (10.0.1.1)          1.234 ms
2  isp-router (192.168.100.1)  15.678 ms
3  backbone-1 (203.0.113.1)    25.432 ms
4  cloudflare (104.16.133.229) 45.123 ms
5  api.example.com (93.184.216.34) 50.789 ms
```

### âš¡ BGP Ð¸ Ð²Ð»Ð¸ÑÐ½Ð¸Ðµ Ð½Ð° Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ API

**ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ðµ?**

BGP (Border Gateway Protocol) Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ñ‹ Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð°Ð¼Ð¸:

```bash
# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° AS (Autonomous System) Ð¿ÑƒÑ‚Ð¸
mtr --report --report-cycles 5 api.example.com

# ÐœÐ¾Ð¶ÐµÑ‚ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ:
# Hop 1: AS64512 (Ð’Ð°Ñˆ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€)
# Hop 2: AS174 (Cogent) - Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¸Ñ€Ð¸Ð½Ð³!
# Hop 3: AS13335 (Cloudflare)
```

**ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸:**

```yaml
# docker-compose.yml Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð¾Ð²
version: '3.8'
services:
  api-test:
    image: tutum/curl
    command: |
      sh -c "
        echo 'Testing US East:'
        time curl -s us-east.api.example.com/health
        echo 'Testing EU West:'
        time curl -s eu-west.api.example.com/health
        echo 'Testing Asia:'
        time curl -s asia.api.example.com/health
      "
```

### ðŸ” IPv6 Ð´Ð»Ñ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹

**ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ IPv6 Ð²Ð°Ð¶ÐµÐ½ Ð´Ð»Ñ backend:**

```bash
# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ IPv6
curl -6 ipv6.google.com
# Ð•ÑÐ»Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ - Ñƒ Ð²Ð°Ñ ÐµÑÑ‚ÑŒ IPv6 connectivity

# ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ nginx Ð´Ð»Ñ dual-stack
# /etc/nginx/sites-available/api
server {
    listen 80;
    listen [::]:80;  # IPv6
    listen 443 ssl http2;
    listen [::]:443 ssl http2;  # IPv6 SSL
    
    server_name api.example.com;
}
```

**ÐŸÑ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð° IPv6 Ð´Ð»Ñ backend:**
- Ð‘Ð¾Ð»ÑŒÑˆÐµ Ð°Ð´Ñ€ÐµÑÐ¾Ð² = Ð¿Ñ€ÑÐ¼Ñ‹Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð±ÐµÐ· NAT
- Ð›ÑƒÑ‡ÑˆÐ°Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ (Ð½ÐµÑ‚ Ñ‚Ñ€Ð°Ð½ÑÐ»ÑÑ†Ð¸Ð¸ Ð°Ð´Ñ€ÐµÑÐ¾Ð²)
- ÐžÐ±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° IPSec = Ð»ÑƒÑ‡ÑˆÐ°Ñ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ

### ðŸ› ï¸ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ¸

```bash
# 1. ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐ²ÑÐ·Ð½Ð¾ÑÑ‚Ð¸
ping -c 4 api.example.com

# 2. ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ñ€Ñ‚Ð°
nc -zv api.example.com 443

# 3. ÐÐ½Ð°Ð»Ð¸Ð· Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð° Ñ Ð¿Ð¾Ñ‚ÐµÑ€ÑÐ¼Ð¸
mtr --report api.example.com

# 4. Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ IP
whois 93.184.216.34

# 5. DNS + IP Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ
dig +short api.example.com
nslookup api.example.com
```

### ðŸ“Š ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº

**Python ÑÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°:**

```python
import time
import subprocess
import json
from datetime import datetime

def check_network_health(target_host):
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐµÑ‚ÐµÐ²Ð¾Ð³Ð¾ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ Ð´Ð¾ Ñ†ÐµÐ»ÐµÐ²Ð¾Ð³Ð¾ Ñ…Ð¾ÑÑ‚Ð°"""
    
    # Ping Ñ‚ÐµÑÑ‚
    ping_result = subprocess.run(
        ['ping', '-c', '4', target_host], 
        capture_output=True, text=True
    )
    
    # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° ping
    if ping_result.returncode == 0:
        lines = ping_result.stdout.split('\n')
        stats_line = [l for l in lines if 'min/avg/max' in l][0]
        avg_latency = float(stats_line.split('/')[4])
    else:
        avg_latency = None
    
    # Traceroute Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿ÑƒÑ‚Ð¸
    trace_result = subprocess.run(
        ['traceroute', '-n', '-q', '1', target_host], 
        capture_output=True, text=True
    )
    
    hop_count = len([l for l in trace_result.stdout.split('\n') 
                    if l.strip() and not l.startswith('traceroute')])
    
    return {
        'timestamp': datetime.now().isoformat(),
        'target': target_host,
        'ping_success': ping_result.returncode == 0,
        'avg_latency_ms': avg_latency,
        'hop_count': hop_count
    }

# ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð²Ð°ÑˆÐ¸Ñ… API endpoints
endpoints = ['api.example.com', 'auth.example.com', 'db.example.com']

while True:
    for endpoint in endpoints:
        health = check_network_health(endpoint)
        print(json.dumps(health, indent=2))
        
        # ÐÐ»ÐµÑ€Ñ‚ ÐµÑÐ»Ð¸ Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ > 100ms
        if health['avg_latency_ms'] and health['avg_latency_ms'] > 100:
            print(f"âš ï¸ HIGH LATENCY to {endpoint}: {health['avg_latency_ms']}ms")
    
    time.sleep(60)  # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÐºÐ°Ð¶Ð´ÑƒÑŽ Ð¼Ð¸Ð½ÑƒÑ‚Ñƒ
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ

1. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ ÑÑ…ÐµÐ¼Ñƒ ÑÐµÑ‚Ð¸ Ð´Ð»Ñ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð´ÑÐµÑ‚ÑÐ¼Ð¸
2. ÐŸÑ€Ð¾ÑÐ»ÐµÐ´Ð¸Ñ‚Ðµ Ð¿ÑƒÑ‚ÑŒ Ð¿Ð°ÐºÐµÑ‚Ð° Ð¾Ñ‚ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° Ð´Ð¾ Ð²Ð°ÑˆÐµÐ³Ð¾ API
3. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº
4. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÑƒ IPv6 Ð² Ð²Ð°ÑˆÐµÐ¹ Ð¸Ð½Ñ„Ñ€Ð°ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ðµ
5. ÐÐ°Ð¹Ð´Ð¸Ñ‚Ðµ ÑƒÐ·ÐºÐ¸Ðµ Ð¼ÐµÑÑ‚Ð° Ð² Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð´Ð¾ Ð²Ð°ÑˆÐ¸Ñ… ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð²

### âœ… ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒÐ½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹

- [ ] ÐœÐ¾Ð¶ÐµÑ‚Ðµ Ð¾Ð±ÑŠÑÑÐ½Ð¸Ñ‚ÑŒ, Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ñ‚ Ñ Ð¿Ð°ÐºÐµÑ‚Ð¾Ð¼ Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¼ ÑƒÑ€Ð¾Ð²Ð½Ðµ OSI?
- [ ] Ð£Ð¼ÐµÐµÑ‚Ðµ Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ð´ÑÐµÑ‚Ð¸ Ð´Ð»Ñ Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ½Ð¾Ð¹ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹?
- [ ] Ð—Ð½Ð°ÐµÑ‚Ðµ, ÐºÐ°Ðº Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸?
- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ Ð²Ð»Ð¸ÑÐ½Ð¸Ðµ MTU Ð½Ð° Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ?
- [ ] ÐœÐ¾Ð¶ÐµÑ‚Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ dual-stack (IPv4 + IPv6) ÑÐµÑ€Ð²ÐµÑ€?

---

# ÐœÐ¾Ð´ÑƒÐ»ÑŒ 2: Ð¢Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚Ð½Ñ‹Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ {#module-2}
*ÐÐµÐ´ÐµÐ»Ð¸ 3-4 | Ð’Ñ€ÐµÐ¼Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ: 16-20 Ñ‡Ð°ÑÐ¾Ð²*

## ÐÐµÐ´ÐµÐ»Ñ 3: TCP Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð» Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ TCP Ð½Ð°Ð·Ñ‹Ð²Ð°ÑŽÑ‚ "Ð½Ð°Ð´ÐµÐ¶Ð½Ñ‹Ð¼" Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ð¾Ð¼?

TCP - ÑÑ‚Ð¾ ÐºÐ°Ðº Ð·Ð°ÐºÐ°Ð·Ð½Ð°Ñ Ð¿Ð¾Ñ‡Ñ‚Ð° Ñ ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð¾ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐµ. ÐšÐ°Ð¶Ð´Ñ‹Ð¹ Ð¿Ð°ÐºÐµÑ‚ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´Ð°ÐµÑ‚ÑÑ, Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ÑÑ.

### ðŸ“Š Ð–Ð¸Ð·Ð½ÐµÐ½Ð½Ñ‹Ð¹ Ñ†Ð¸ÐºÐ» TCP ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ

```
ÐšÐ»Ð¸ÐµÐ½Ñ‚                    Ð¡ÐµÑ€Ð²ÐµÑ€
   â”‚                         â”‚
   â”‚      SYN (seq=100)      â”‚
   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚  1. Ð—Ð°Ð¿Ñ€Ð¾Ñ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
   â”‚                         â”‚
   â”‚   SYN-ACK (seq=200,     â”‚
   â”‚    ack=101)             â”‚
   â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  2. ÐŸÐ¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ + ÑÐ²Ð¾Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ
   â”‚                         â”‚
   â”‚      ACK (ack=201)      â”‚
   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚  3. Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ
   â”‚                         â”‚
   â”‚    ESTABLISHED          â”‚
   â”‚â—„â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â–ºâ”‚  4. Ð¡Ð¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾
```

### ðŸ”§ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 3-way handshake Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸

**Ð—Ð°Ñ…Ð²Ð°Ñ‚ TCP handshake:**

```bash
# Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ tcpdump
sudo tcpdump -i eth0 -nn host api.example.com and port 443

# Ð’ Ð´Ñ€ÑƒÐ³Ð¾Ð¼ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð°Ð»Ðµ Ð´ÐµÐ»Ð°ÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ
curl -I https://api.example.com/health

# Ð’Ð¸Ð´Ð¸Ð¼ Ð² tcpdump:
# 12:34:56.789 IP 192.168.1.10.12345 > 93.184.216.34.443: Flags [S], seq 1234567890
# 12:34:56.825 IP 93.184.216.34.443 > 192.168.1.10.12345: Flags [S.], seq 987654321, ack 1234567891
# 12:34:56.826 IP 192.168.1.10.12345 > 93.184.216.34.443: Flags [.], ack 987654322
```

### âš¡ TCP Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ñ‹Ðµ Ð´Ð»Ñ backend

**1. TCP Ð±ÑƒÑ„ÐµÑ€Ñ‹ - Ð²Ð»Ð¸ÑÑŽÑ‚ Ð½Ð° Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ½ÑƒÑŽ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÑŒ:**

```bash
# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ‚ÐµÐºÑƒÑ‰Ð¸Ñ… Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº
sysctl net.core.rmem_max        # ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ receive buffer
sysctl net.core.wmem_max        # ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ send buffer
sysctl net.ipv4.tcp_rmem        # TCP receive buffer: min default max
sysctl net.ipv4.tcp_wmem        # TCP send buffer: min default max

# ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð½Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð²
echo 'net.core.rmem_max = 134217728' >> /etc/sysctl.conf    # 128MB
echo 'net.core.wmem_max = 134217728' >> /etc/sysctl.conf    # 128MB
echo 'net.ipv4.tcp_rmem = 4096 65536 134217728' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_wmem = 4096 65536 134217728' >> /etc/sysctl.conf
```

**2. TCP_NODELAY Ð¸ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ Nagle:**

```python
import socket

# ÐŸÐ»Ð¾Ñ…Ð¾ Ð´Ð»Ñ real-time API:
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Nagle Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½ - Ð¼ÐµÐ»ÐºÐ¸Ðµ Ð¿Ð°ÐºÐµÑ‚Ñ‹ Ð±ÑƒÑ„ÐµÑ€Ð¸Ð·ÑƒÑŽÑ‚ÑÑ

# Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾ Ð´Ð»Ñ real-time API:
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
# ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð½ÐµÐ¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾, Ð±ÐµÐ· Ð±ÑƒÑ„ÐµÑ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸
```

**ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð² Node.js ÑÐµÑ€Ð²ÐµÑ€Ðµ:**

```javascript
const net = require('net');

const server = net.createServer((socket) => {
    // ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ Nagle Ð´Ð»Ñ WebSocket Ð¸Ð»Ð¸ gaming API
    socket.setNoDelay(true);
    
    // ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð±ÑƒÑ„ÐµÑ€Ð¾Ð²
    socket.setKeepAlive(true, 60000);  // Keep-alive ÐºÐ°Ð¶Ð´Ñ‹Ðµ 60 ÑÐµÐº
    
    socket.on('data', (data) => {
        // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð±ÐµÐ· Ð·Ð°Ð´ÐµÑ€Ð¶ÐµÐº
        const response = processRequest(data);
        socket.write(response);  // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ÑÑ Ð½ÐµÐ¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾
    });
});

server.listen(8080);
```

### ðŸ”„ TCP Window Ð¸ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð¼

**Sliding Window Protocol:**

```
ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÐµÐ»ÑŒ                           ÐŸÐ¾Ð»ÑƒÑ‡Ð°Ñ‚ÐµÐ»ÑŒ
     â”‚                                    â”‚
     â”‚ DATA (seq=1000, len=1000)         â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ Window: 64KB
     â”‚                                    â”‚
     â”‚ DATA (seq=2000, len=1000)         â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ Window: 63KB
     â”‚                                    â”‚
     â”‚          ACK (ack=2000, win=32KB) â”‚
     â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ ÐŸÐ¾Ð»ÑƒÑ‡Ð°Ñ‚ÐµÐ»ÑŒ Ð¿ÐµÑ€ÐµÐ³Ñ€ÑƒÐ¶ÐµÐ½!
     â”‚                                    â”‚
     â”‚ Ð¡Ð½Ð¸Ð¶Ð°ÐµÐ¼ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸         â”‚
```

**ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ TCP Ð¾ÐºÐ¾Ð½:**

```bash
# Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° TCP ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
ss -i state established '( dport = :443 or sport = :443 )'

# Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚:
# tcp   ESTAB   0   0   192.168.1.10:12345   93.184.216.34:443
#       cubic rto:201 rtt:50.5/1.2 ato:40 mss:1448 pmtu:1500 rcvmss:1448
#       advmss:1448 cwnd:10 ssthresh:7 bytes_acked:23456 bytes_received:54321
#       segs_out:45 segs_in:67 data_segs_out:23 data_segs_in:34
#       send 2.3Mbps lastsnd:1234 lastrcv:567 lastack:567 pacing_rate 2.8Mbps
#       delivery_rate 1.9Mbps busy:12345ms unacked:0 rcv_space:29200 rcv_ssthresh:29200
```

### ðŸ› ï¸ Connection Pooling - ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸

**ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð±ÐµÐ· Ð¿ÑƒÐ»Ð° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹:**

```python
import requests
import time

# ÐŸÐ›ÐžÐ¥Ðž: ÐÐ¾Ð²Ð¾Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð½Ð° ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ
def bad_api_calls():
    for i in range(100):
        start = time.time()
        response = requests.get('https://api.example.com/data')
        end = time.time()
        print(f"Request {i}: {end - start:.3f}s")  # ~200-300ms Ð½Ð° ÐºÐ°Ð¶Ð´Ñ‹Ð¹

# Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: 100 Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² = 25-30 ÑÐµÐºÑƒÐ½Ð´
```

**Ð ÐµÑˆÐµÐ½Ð¸Ðµ Ñ Ð¿ÑƒÐ»Ð¾Ð¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹:**

```python
import requests
import time
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

# Ð¥ÐžÐ ÐžÐ¨Ðž: ÐŸÐµÑ€ÐµÐ¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
def good_api_calls():
    session = requests.Session()
    
    # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° connection pool
    adapter = HTTPAdapter(
        pool_connections=10,    # ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ…Ð¾ÑÑ‚Ð¾Ð² Ð² Ð¿ÑƒÐ»Ðµ
        pool_maxsize=20,        # ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ð½Ð° Ñ…Ð¾ÑÑ‚
        max_retries=Retry(
            total=3,
            backoff_factor=0.3,
            status_forcelist=[429, 500, 502, 503, 504]
        )
    )
    
    session.mount('https://', adapter)
    session.mount('http://', adapter)
    
    for i in range(100):
        start = time.time()
        response = session.get('https://api.example.com/data')
        end = time.time()
        print(f"Request {i}: {end - start:.3f}s")  # ~50-80ms Ð¿Ð¾ÑÐ»Ðµ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾

# Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: 100 Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² = 6-8 ÑÐµÐºÑƒÐ½Ð´ (Ð² 4 Ñ€Ð°Ð·Ð° Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ!)
```

### ðŸ“Š TCP ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð¸ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼

**ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¹ TCP:**

```bash
# ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¸
ss -s

# Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ
netstat -tan | awk '{print $6}' | sort | uniq -c

# Ð¢Ð¸Ð¿Ð¸Ñ‡Ð½Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð´Ð»Ñ Ð²ÐµÐ±-ÑÐµÑ€Ð²ÐµÑ€Ð°:
#    245 ESTABLISHED    â† ÐÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
#     12 TIME_WAIT      â† Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÑŽÑ‰Ð¸ÐµÑÑ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
#      8 LISTEN         â† Ð¡Ð»ÑƒÑˆÐ°ÑŽÑ‰Ð¸Ðµ Ð¿Ð¾Ñ€Ñ‚Ñ‹
#      3 SYN_RECV       â† Ð’Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ
```

**ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð°: ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð¼Ð½Ð¾Ð³Ð¾ TIME_WAIT:**

```bash
# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° TIME_WAIT ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
ss -tan state time-wait | wc -l

# Ð•ÑÐ»Ð¸ Ð¼Ð½Ð¾Ð³Ð¾ (>1000), Ð½Ð°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼:
echo 'net.ipv4.tcp_tw_reuse = 1' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_fin_timeout = 30' >> /etc/sysctl.conf
sysctl -p
```

### ðŸ”§ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€: ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²ÐµÐ±-ÑÐµÑ€Ð²ÐµÑ€Ð°

**ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Nginx Ð´Ð»Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¹ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸:**

```nginx
# /etc/nginx/nginx.conf
worker_processes auto;
worker_rlimit_nofile 65535;

events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
}

http {
    # TCP Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    
    # Keep-alive Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
    keepalive_timeout 65s;
    keepalive_requests 1000;
    
    # Upstream Ñ connection pooling
    upstream api_backend {
        keepalive 32;  # ÐŸÑƒÐ» ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ðº backend
        
        server backend1.example.com:8080 max_fails=3 fail_timeout=30s;
        server backend2.example.com:8080 max_fails=3 fail_timeout=30s;
        server backend3.example.com:8080 max_fails=3 fail_timeout=30s;
    }
    
    server {
        listen 80;
        
        location /api/ {
            proxy_pass http://api_backend;
            proxy_http_version 1.1;
            proxy_set_header Connection "";  # Ð’Ð°Ð¶Ð½Ð¾ Ð´Ð»Ñ keepalive
            proxy_set_header Host $host;
        }
    }
}
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ

1. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ TCP Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð½Ð° Ð²Ð°ÑˆÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€Ðµ Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
2. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ connection pooling Ð² Ð²Ð°ÑˆÐµÐ¼ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸
3. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ TCP Ñ‚Ñ€Ð°Ñ„Ð¸Ðº Ð¼ÐµÐ¶Ð´Ñƒ Ð²Ð°ÑˆÐ¸Ð¼Ð¸ Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ°Ð¼Ð¸
4. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ TCP ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¹ Ñ Ð°Ð»ÐµÑ€Ñ‚Ð°Ð¼Ð¸

---

## ÐÐµÐ´ÐµÐ»Ñ 4: UDP Ð¸ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ñ‹

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: ÐšÐ¾Ð³Ð´Ð° ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð²Ð°Ð¶Ð½ÐµÐµ Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸

UDP - ÑÑ‚Ð¾ ÐºÐ°Ðº Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚ÐºÐ¸. Ð‘Ñ‹ÑÑ‚Ñ€Ð¾, Ð´ÐµÑˆÐµÐ²Ð¾, Ð½Ð¾ Ð±ÐµÐ· Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ð¹ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸.

### ðŸ“Š UDP vs TCP ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ

```
TCP                          UDP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… ÐÐ°Ð´ÐµÐ¶Ð½Ð°Ñ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ° â”‚     â”‚ âš¡ Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ  â”‚
â”‚ âœ… ÐŸÐ¾Ñ€ÑÐ´Ð¾Ðº Ð¿Ð°ÐºÐµÑ‚Ð¾Ð²   â”‚     â”‚ âš¡ ÐÐ¸Ð·ÐºÐ°Ñ Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚ÑŒâ”‚
â”‚ âœ… ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Ð¿Ð¾Ñ‚Ð¾ÐºÐ°   â”‚     â”‚ âš¡ ÐœÐ¸Ð½Ð¸Ð¼ÑƒÐ¼ overhead  â”‚
â”‚ âŒ Ð‘Ð¾Ð»ÑŒÑˆÐµ overhead   â”‚     â”‚ âŒ ÐÐµÑ‚ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ð¹     â”‚
â”‚ âŒ Ð’Ñ‹ÑˆÐµ Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ  â”‚     â”‚ âŒ ÐœÐ¾Ð¶ÐµÑ‚ Ð¿Ð¾Ñ‚ÐµÑ€ÑÑ‚ÑŒÑÑ â”‚
â”‚ âŒ Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° ÑÐ¾ÐµÐ´Ð¸Ð½. â”‚     â”‚ âŒ ÐÐ°Ñ€ÑƒÑˆÐµÐ½ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:                Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:
â€¢ HTTP/HTTPS                  â€¢ DNS Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹
â€¢ API Ð²Ñ‹Ð·Ð¾Ð²Ñ‹                  â€¢ Video streaming
â€¢ Ð¤Ð°Ð¹Ð»Ð¾Ð²Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð¸           â€¢ Online Ð¸Ð³Ñ€Ñ‹
â€¢ Email                       â€¢ ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸/Ð»Ð¾Ð³Ð¸
```

### ðŸ”§ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€: UDP Ð´Ð»Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº

**ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ñ‡ÐµÑ€ÐµÐ· UDP (StatsD):**

```python
import socket
import time
import json

class UDPMetrics:
    def __init__(self, host='localhost', port=8125):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.host = host
        self.port = port
    
    def counter(self, metric, value=1, tags=None):
        """Ð¡Ñ‡ÐµÑ‚Ñ‡Ð¸Ðº ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹"""
        message = f"{metric}:{value}|c"
        if tags:
            message += f"|#{','.join(tags)}"
        self._send(message)
    
    def gauge(self, metric, value, tags=None):
        """Ð¢ÐµÐºÑƒÑ‰ÐµÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ"""
        message = f"{metric}:{value}|g"
        if tags:
            message += f"|#{','.join(tags)}"
        self._send(message)
    
    def timing(self, metric, value, tags=None):
        """Ð’Ñ€ÐµÐ¼Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ"""
        message = f"{metric}:{value}|ms"
        if tags:
            message += f"|#{','.join(tags)}"
        self._send(message)
    
    def _send(self, message):
        try:
            self.sock.sendto(message.encode(), (self.host, self.port))
        except Exception:
            # ÐžÑˆÐ¸Ð±ÐºÐ¸ UDP Ð¸Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ - Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð»Ð¾Ð¼Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ
            pass

# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² API
metrics = UDPMetrics()

def api_endpoint():
    start_time = time.time()
    
    try:
        # Ð‘Ð¸Ð·Ð½ÐµÑ Ð»Ð¾Ð³Ð¸ÐºÐ°
        result = process_request()
        
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑƒÑÐ¿ÐµÑ…Ð°
        metrics.counter('api.requests.success', tags=['endpoint:users'])
        metrics.timing('api.response_time', 
                      int((time.time() - start_time) * 1000),
                      tags=['endpoint:users'])
        
        return result
        
    except Exception as e:
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¾ÑˆÐ¸Ð±Ð¾Ðº
        metrics.counter('api.requests.error', 
                       tags=['endpoint:users', f'error:{type(e).__name__}'])
        raise
```

**ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ UDP Ð´Ð»Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº?**
- Ð•ÑÐ»Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ° Ð¿Ð¾Ñ‚ÐµÑ€ÑÐµÑ‚ÑÑ - Ð½Ðµ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¾
- Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ (Ñ‚Ñ‹ÑÑÑ‡Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð² ÑÐµÐºÑƒÐ½Ð´Ñƒ)
- ÐÐµ Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÐµÑ‚ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð´ Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ñ… Ñ ÑÐµÑ‚ÑŒÑŽ

### ðŸŒ QUIC - Ñ€ÐµÐ²Ð¾Ð»ÑŽÑ†Ð¸Ñ Ð² Ñ‚Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ð°Ñ…

**ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ TCP, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ€ÐµÑˆÐ°ÐµÑ‚ QUIC:**

```
TCP Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹:                 QUIC Ñ€ÐµÑˆÐµÐ½Ð¸Ñ:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Head-of-line        â”‚  â†’   â”‚ ÐÐµÐ·Ð°Ð²Ð¸ÑÐ¸Ð¼Ñ‹Ðµ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¸ â”‚
â”‚ blocking            â”‚      â”‚ (streams)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3-way handshake     â”‚  â†’   â”‚ 0-RTT ÑƒÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ°     â”‚
â”‚ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°            â”‚      â”‚ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ NAT/     â”‚  â†’   â”‚ Ð’ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ð°Ñ Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ñ â”‚
â”‚ ÑÐ¼ÐµÐ½Ð¾Ð¹ ÑÐµÑ‚Ð¸         â”‚      â”‚ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ÐœÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ð¹ ÑÑ‚Ð°Ñ€Ñ‚     â”‚  â†’   â”‚ Ð‘Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð°Ð´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸Ñ   â”‚
â”‚ Ð¿Ð¾ÑÐ»Ðµ Ð¿Ð¾Ñ‚ÐµÑ€ÑŒ        â”‚      â”‚ Ð¿Ð¾ÑÐ»Ðµ Ð¿Ð¾Ñ‚ÐµÑ€ÑŒ        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ”§ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€: HTTP/3 Ñ QUIC

**Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ QUIC Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸:**

```bash
# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ HTTP/3
curl --http3 -I https://cloudflare.com
# HTTP/3 200
# alt-svc: h3=":443"; ma=86400

# Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
echo "HTTP/1.1:"
curl -w "@curl-format.txt" -s -o /dev/null https://api.example.com/test

echo "HTTP/2:"
curl --http2 -w "@curl-format.txt" -s -o /dev/null https://api.example.com/test

echo "HTTP/3 (QUIC):"
curl --http3 -w "@curl-format.txt" -s -o /dev/null https://api.example.com/test

# curl-format.txt:
#      time_namelookup:  %{time_namelookup}\n
#         time_connect:  %{time_connect}\n
#      time_appconnect:  %{time_appconnect}\n
#       time_pretransfer: %{time_pretransfer}\n
#          time_starttransfer: %{time_starttransfer}\n
#                     ----------\n
#              time_total:  %{time_total}\n
```

### ðŸ› ï¸ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° QUIC Ð² ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… ÑÐµÑ€Ð²ÐµÑ€Ð°Ñ…

**Caddy ÑÐµÑ€Ð²ÐµÑ€ Ñ HTTP/3:**

```caddyfile
# Caddyfile
api.example.com {
    # HTTP/3 Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
    reverse_proxy localhost:8080
    
    # Ð¤Ð¾Ñ€ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ HTTP/3
    header Alt-Svc "h3=\":443\"; ma=86400"
    
    # Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð²ÐµÑ€ÑÐ¸Ð¹ HTTP
    log {
        output file /var/log/caddy/api.log
        format json
        level INFO
    }
}
```

**Nginx Ñ QUIC (ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°):**

```nginx
# ÐšÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ñ Ñ QUIC Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹
# ./configure --with-http_v3_module --with-stream_quic_module

server {
    listen 443 quic;
    listen 443 ssl http2;
    
    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;
    
    # Ð£ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°Ð¼ Ð¾ QUIC Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐµ
    add_header Alt-Svc 'h3=":443"; ma=86400';
    
    location / {
        proxy_pass http://backend;
    }
}
```

### ðŸ“Š WebRTC Ð´Ð»Ñ P2P ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹

**ÐŸÑ€Ð¸Ð¼ÐµÑ€ WebRTC data channel:**

```javascript
// Ð¡ÐµÑ€Ð²ÐµÑ€ Node.js Ð´Ð»Ñ WebRTC signaling
const WebSocket = require('ws');
const wss = new WebSocket.Server({ port: 8080 });

const rooms = new Map();

wss.on('connection', (ws) => {
    ws.on('message', (message) => {
        const data = JSON.parse(message);
        
        switch (data.type) {
            case 'join':
                if (!rooms.has(data.room)) {
                    rooms.set(data.room, new Set());
                }
                rooms.get(data.room).add(ws);
                ws.room = data.room;
                break;
                
            case 'offer':
            case 'answer':
            case 'ice-candidate':
                // ÐŸÐµÑ€ÐµÑÑ‹Ð»Ð°ÐµÐ¼ WebRTC ÑÐ¸Ð³Ð½Ð°Ð»Ñ‹ Ð´Ñ€ÑƒÐ³Ð¸Ð¼ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ°Ð¼
                if (rooms.has(ws.room)) {
                    rooms.get(ws.room).forEach(client => {
                        if (client !== ws && client.readyState === WebSocket.OPEN) {
                            client.send(message);
                        }
                    });
                }
                break;
        }
    });
});
```

**ÐšÐ»Ð¸ÐµÐ½Ñ‚ÑÐºÐ°Ñ Ñ‡Ð°ÑÑ‚ÑŒ:**

```javascript
// Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° P2P ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· UDP
const pc = new RTCPeerConnection({
    iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
});

// Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ data channel Ð´Ð»Ñ Ð±Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
const dataChannel = pc.createDataChannel('metrics', {
    ordered: false,    // UDP-Ð¿Ð¾Ð´Ð¾Ð±Ð½Ð¾Ðµ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ
    maxRetransmits: 0  // ÐÐµ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÐµÐ¼ Ð¿Ð¾Ñ‚ÐµÑ€ÑÐ½Ð½Ñ‹Ðµ Ð¿Ð°ÐºÐµÑ‚Ñ‹
});

dataChannel.onopen = () => {
    // ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ Ð¼ÐµÐ¶Ð´Ñƒ ÑÐµÑ€Ð²Ð¸ÑÐ°Ð¼Ð¸
    setInterval(() => {
        const metrics = {
            timestamp: Date.now(),
            cpu: process.cpuUsage(),
            memory: process.memoryUsage(),
            connections: getConnectionCount()
        };
        
        dataChannel.send(JSON.stringify(metrics));
    }, 1000);
};
```

### âš¡ Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ð¾Ð²

**Ð‘ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ñ‚ÐµÑÑ‚:**

```python
import socket
import time
import threading
import statistics

def tcp_benchmark(host, port, message_count=1000):
    """Ð¢ÐµÑÑ‚ TCP Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
    times = []
    
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.connect((host, port))
    
    for i in range(message_count):
        start = time.time()
        sock.send(f"message_{i}".encode())
        response = sock.recv(1024)
        end = time.time()
        times.append((end - start) * 1000)  # Ð² Ð¼Ð¸Ð»Ð»Ð¸ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…
    
    sock.close()
    
    return {
        'protocol': 'TCP',
        'avg_latency': statistics.mean(times),
        'median_latency': statistics.median(times),
        'p95_latency': statistics.quantiles(times, n=20)[18],  # 95-Ð¹ Ð¿ÐµÑ€Ñ†ÐµÐ½Ñ‚Ð¸Ð»ÑŒ
        'total_time': sum(times)
    }

def udp_benchmark(host, port, message_count=1000):
    """Ð¢ÐµÑÑ‚ UDP Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
    times = []
    
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    
    for i in range(message_count):
        start = time.time()
        sock.sendto(f"message_{i}".encode(), (host, port))
        # UDP - Ð½Ðµ Ð¶Ð´ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚Ð°, Ð¸Ð·Ð¼ÐµÑ€ÑÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸
        end = time.time()
        times.append((end - start) * 1000)
    
    sock.close()
    
    return {
        'protocol': 'UDP',
        'avg_latency': statistics.mean(times),
        'median_latency': statistics.median(times),
        'p95_latency': statistics.quantiles(times, n=20)[18],
        'total_time': sum(times)
    }

# Ð—Ð°Ð¿ÑƒÑÐº Ñ‚ÐµÑÑ‚Ð¾Ð²
tcp_results = tcp_benchmark('localhost', 8080)
udp_results = udp_benchmark('localhost', 8081)

print("Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°:")
print(f"TCP: {tcp_results['avg_latency']:.2f}ms ÑÑ€ÐµÐ´Ð½ÑÑ, {tcp_results['p95_latency']:.2f}ms p95")
print(f"UDP: {udp_results['avg_latency']:.2f}ms ÑÑ€ÐµÐ´Ð½ÑÑ, {udp_results['p95_latency']:.2f}ms p95")
print(f"UDP Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ Ð² {tcp_results['avg_latency'] / udp_results['avg_latency']:.1f} Ñ€Ð°Ð·")
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ

1. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ UDP-ÑÐµÑ€Ð²ÐµÑ€ Ð´Ð»Ñ ÑÐ±Ð¾Ñ€Ð° Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¾Ñ‚ Ð²Ð°ÑˆÐ¸Ñ… Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
2. ÐŸÑ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ HTTP/3 Ð½Ð° Ð¾Ð´Ð½Ð¾Ð¼ Ð¸Ð· Ð²Ð°ÑˆÐ¸Ñ… API endpoints
3. Ð¡Ñ€Ð°Ð²Ð½Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ TCP Ð¸ UDP Ð´Ð»Ñ Ð²Ð°ÑˆÐµÐ³Ð¾ use case
4. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ WebRTC data channel Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¼ÐµÐ¶Ð´Ñƒ ÑÐµÑ€Ð²Ð¸ÑÐ°Ð¼Ð¸

### âœ… ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒÐ½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹

- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ Ñ€Ð°Ð·Ð½Ð¸Ñ†Ñƒ Ð² overhead Ð¼ÐµÐ¶Ð´Ñƒ TCP Ð¸ UDP?
- [ ] ÐœÐ¾Ð¶ÐµÑ‚Ðµ Ð¾Ð±ÑŠÑÑÐ½Ð¸Ñ‚ÑŒ, ÐºÐ¾Ð³Ð´Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ UDP Ð²Ð¼ÐµÑÑ‚Ð¾ TCP?
- [ ] Ð—Ð½Ð°ÐµÑ‚Ðµ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ QUIC Ð¸ ÐµÐ³Ð¾ Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð°?
- [ ] Ð£Ð¼ÐµÐµÑ‚Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ HTTP/3 Ð½Ð° Ð²ÐµÐ±-ÑÐµÑ€Ð²ÐµÑ€Ðµ?
- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ WebRTC Ð´Ð»Ñ backend ÑÐ¸ÑÑ‚ÐµÐ¼?

---

# ÐœÐ¾Ð´ÑƒÐ»ÑŒ 3: HTTP Ð¸ Ð²ÐµÐ±-Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ñ‹ {#module-3}
*ÐÐµÐ´ÐµÐ»Ð¸ 5-7 | Ð’Ñ€ÐµÐ¼Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ: 24-30 Ñ‡Ð°ÑÐ¾Ð²*

## ÐÐµÐ´ÐµÐ»Ñ 5: HTTP/1.1 Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: HTTP ÐºÐ°Ðº ÑÐ·Ñ‹Ðº Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¼ÐµÐ¶Ð´Ñƒ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð¼ Ð¸ ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð¼

HTTP - ÑÑ‚Ð¾ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð» "Ð²Ð¾Ð¿Ñ€Ð¾Ñ-Ð¾Ñ‚Ð²ÐµÑ‚". ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð·Ð°Ð´Ð°ÐµÑ‚ Ð²Ð¾Ð¿Ñ€Ð¾Ñ (request), ÑÐµÑ€Ð²ÐµÑ€ Ð´Ð°ÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚ (response).

### ðŸ“Š ÐÐ½Ð°Ñ‚Ð¾Ð¼Ð¸Ñ HTTP Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð°

```
HTTP Request:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POST /api/users HTTP/1.1                    â† Ð¡Ñ‚Ð°Ñ€Ñ‚Ð¾Ð²Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ° â”‚
â”‚ Host: api.example.com                       â† Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸       â”‚
â”‚ Content-Type: application/json              â”‚
â”‚ Content-Length: 58                          â”‚
â”‚ Authorization: Bearer eyJhbGciOiJIUzI1NiI... â”‚
â”‚ User-Agent: MyApp/1.0                       â”‚
â”‚ Connection: keep-alive                      â”‚
â”‚                                             â† ÐŸÑƒÑÑ‚Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ°   â”‚
â”‚ {"name": "John", "email": "john@example.com"} â† Ð¢ÐµÐ»Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

HTTP Response:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP/1.1 201 Created                        â† Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑÑ‚Ñ€Ð¾ÐºÐ°  â”‚
â”‚ Content-Type: application/json              â† Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸       â”‚
â”‚ Content-Length: 87                          â”‚
â”‚ Location: /api/users/12345                  â”‚
â”‚ Set-Cookie: session=abc123; HttpOnly        â”‚
â”‚ Cache-Control: no-cache                     â”‚
â”‚ X-RateLimit-Remaining: 99                   â”‚
â”‚                                             â† ÐŸÑƒÑÑ‚Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ°   â”‚
â”‚ {"id": 12345, "name": "John", "created_at": "2024-01-15"} â† Ð¢ÐµÐ»Ð¾ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ”§ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€: ÐŸÑ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ HTTP Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð²

**RESTful API Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð¹ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸ÐºÐ¾Ð¹:**

```python
from flask import Flask, request, jsonify, make_response
import time

app = Flask(__name__)

# GET - Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ð¹ Ð¸ Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ñ‹Ð¹
@app.route('/api/users/<int:user_id>', methods=['GET'])
def get_user(user_id):
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ÐºÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
    response = make_response(jsonify({
        'id': user_id,
        'name': 'John Doe',
        'last_modified': '2024-01-15T10:30:00Z'
    }))
    
    # ÐšÐµÑˆ Ð½Ð° 5 Ð¼Ð¸Ð½ÑƒÑ‚
    response.headers['Cache-Control'] = 'public, max-age=300'
    response.headers['ETag'] = f'"user-{user_id}-v1"'
    response.headers['Last-Modified'] = 'Mon, 15 Jan 2024 10:30:00 GMT'
    
    return response

# POST - ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ€ÐµÑÑƒÑ€ÑÐ° (Ð½Ðµ Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ñ‹Ð¹)
@app.route('/api/users', methods=['POST'])
def create_user():
    data = request.json
    
    # Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
    if not data or 'name' not in data:
        return jsonify({'error': 'Name is required'}), 400
    
    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
    new_user = {
        'id': 12345,  # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ÑÑ ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð¼
        'name': data['name'],
        'created_at': time.strftime('%Y-%m-%dT%H:%M:%SZ')
    }
    
    response = make_response(jsonify(new_user), 201)
    response.headers['Location'] = f'/api/users/{new_user["id"]}'
    
    return response

# PUT - Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ (Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ñ‹Ð¹)
@app.route('/api/users/<int:user_id>', methods=['PUT'])
def update_user(user_id):
    data = request.json
    
    # PUT Ð·Ð°Ð¼ÐµÐ½ÑÐµÑ‚ Ð²ÐµÑÑŒ Ñ€ÐµÑÑƒÑ€Ñ
    updated_user = {
        'id': user_id,
        'name': data.get('name', ''),
        'email': data.get('email', ''),
        'updated_at': time.strftime('%Y-%m-%dT%H:%M:%SZ')
    }
    
    return jsonify(updated_user)

# PATCH - Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ð¾Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ (Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ñ‹Ð¹)
@app.route('/api/users/<int:user_id>', methods=['PATCH'])
def patch_user(user_id):
    data = request.json
    
    # PATCH Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾Ð»Ñ
    current_user = get_current_user(user_id)  # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    
    # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾Ð»Ñ
    for field in ['name', 'email', 'phone']:
        if field in data:
            current_user[field] = data[field]
    
    current_user['updated_at'] = time.strftime('%Y-%m-%dT%H:%M:%SZ')
    
    return jsonify(current_user)

# DELETE - ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ (Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ñ‹Ð¹)
@app.route('/api/users/<int:user_id>', methods=['DELETE'])
def delete_user(user_id):
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ
    if not user_exists(user_id):
        return '', 404
    
    # Ð£Ð´Ð°Ð»ÑÐµÐ¼
    delete_user_from_db(user_id)
    
    # 204 = ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¾, Ð½ÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
    return '', 204

# HEAD - Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ (Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ñ)
@app.route('/api/users/<int:user_id>', methods=['HEAD'])
def head_user(user_id):
    if not user_exists(user_id):
        return '', 404
    
    response = make_response('', 200)
    response.headers['Content-Type'] = 'application/json'
    response.headers['Content-Length'] = '156'  # Ð Ð°Ð·Ð¼ÐµÑ€ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
    response.headers['ETag'] = f'"user-{user_id}-v1"'
    
    return response
```

### ðŸ“ˆ HTTP Status Codes - Ð³Ð¾Ð²Ð¾Ñ€ÑÑ‰Ð¸Ðµ ÐºÐ¾Ð´Ñ‹ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²

**ÐŸÑ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑ ÐºÐ¾Ð´Ð¾Ð²:**

```python
class APIResponse:
    """ÐšÐ»Ð°ÑÑ Ð´Ð»Ñ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸ API Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²"""
    
    @staticmethod
    def success(data=None, message="Success"):
        """200 - Ð£ÑÐ¿ÐµÑˆÐ½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ"""
        return jsonify({
            'success': True,
            'message': message,
            'data': data
        }), 200
    
    @staticmethod
    def created(data=None, location=None):
        """201 - Ð ÐµÑÑƒÑ€Ñ ÑÐ¾Ð·Ð´Ð°Ð½"""
        response = make_response(jsonify({
            'success': True,
            'message': 'Resource created',
            'data': data
        }), 201)
        
        if location:
            response.headers['Location'] = location
        
        return response
    
    @staticmethod
    def no_content():
        """204 - Ð£ÑÐ¿ÐµÑˆÐ½Ð¾, Ð½Ð¾ Ð½ÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°"""
        return '', 204
    
    @staticmethod
    def not_modified():
        """304 - Ð ÐµÑÑƒÑ€Ñ Ð½Ðµ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»ÑÑ"""
        return '', 304
    
    @staticmethod
    def bad_request(message="Bad request", errors=None):
        """400 - ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ"""
        return jsonify({
            'success': False,
            'message': message,
            'errors': errors or []
        }), 400
    
    @staticmethod
    def unauthorized(message="Unauthorized"):
        """401 - Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ"""
        response = make_response(jsonify({
            'success': False,
            'message': message
        }), 401)
        response.headers['WWW-Authenticate'] = 'Bearer'
        return response
    
    @staticmethod
    def forbidden(message="Forbidden"):
        """403 - Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð·Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½"""
        return jsonify({
            'success': False,
            'message': message
        }), 403
    
    @staticmethod
    def not_found(message="Resource not found"):
        """404 - Ð ÐµÑÑƒÑ€Ñ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½"""
        return jsonify({
            'success': False,
            'message': message
        }), 404
    
    @staticmethod
    def conflict(message="Conflict"):
        """409 - ÐšÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, email ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚)"""
        return jsonify({
            'success': False,
            'message': message
        }), 409
    
    @staticmethod
    def rate_limited(retry_after=3600):
        """429 - ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²"""
        response = make_response(jsonify({
            'success': False,
            'message': 'Rate limit exceeded'
        }), 429)
        response.headers['Retry-After'] = str(retry_after)
        return response
    
    @staticmethod
    def server_error(message="Internal server error"):
        """500 - Ð’Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½ÑÑ Ð¾ÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        return jsonify({
            'success': False,
            'message': message
        }), 500
    
    @staticmethod
    def service_unavailable(retry_after=60):
        """503 - Ð¡ÐµÑ€Ð²Ð¸Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½"""
        response = make_response(jsonify({
            'success': False,
            'message': 'Service temporarily unavailable'
        }), 503)
        response.headers['Retry-After'] = str(retry_after)
        return response

# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² API
@app.route('/api/users', methods=['POST'])
def create_user():
    try:
        data = request.json
        
        # Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
        if not data or 'email' not in data:
            return APIResponse.bad_request(
                message="Email is required",
                errors=[{'field': 'email', 'message': 'This field is required'}]
            )
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ñ
        if user_exists(data['email']):
            return APIResponse.conflict("User with this email already exists")
        
        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ
        user = create_user_in_db(data)
        return APIResponse.created(
            data=user,
            location=f'/api/users/{user["id"]}'
        )
        
    except ValidationError as e:
        return APIResponse.bad_request(str(e))
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        return APIResponse.server_error()
```

### ðŸ”„ Connection Management Ð¸ Keep-Alive

**ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð±ÐµÐ· Keep-Alive:**

```
ÐšÐ»Ð¸ÐµÐ½Ñ‚                           Ð¡ÐµÑ€Ð²ÐµÑ€
   â”‚                                â”‚
   â”‚ â”€â”€â”€â”€â”€ TCP Connect â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ (100ms)
   â”‚ â†â”€â”€â”€â”€ TCP Connected â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
   â”‚                                â”‚
   â”‚ â”€â”€â”€â”€â”€ HTTP Request â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ (50ms)
   â”‚ â†â”€â”€â”€â”€ HTTP Response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
   â”‚                                â”‚
   â”‚ â”€â”€â”€â”€â”€ TCP Close â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ (20ms)
   â”‚ â†â”€â”€â”€â”€ TCP Closed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
   
   Total: 170ms Ð½Ð° Ð¾Ð´Ð¸Ð½ Ð·Ð°Ð¿Ñ€Ð¾Ñ
```

**Ð ÐµÑˆÐµÐ½Ð¸Ðµ Ñ Keep-Alive:**

```
ÐšÐ»Ð¸ÐµÐ½Ñ‚                           Ð¡ÐµÑ€Ð²ÐµÑ€
   â”‚                                â”‚
   â”‚ â”€â”€â”€â”€â”€ TCP Connect â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ (100ms) - Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð·
   â”‚ â†â”€â”€â”€â”€ TCP Connected â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
   â”‚                                â”‚
   â”‚ â”€â”€â”€â”€â”€ HTTP Request #1 â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ (50ms)
   â”‚ â†â”€â”€â”€â”€ HTTP Response #1 â”€â”€â”€â”€â”€â”€â”€ â”‚
   â”‚                                â”‚
   â”‚ â”€â”€â”€â”€â”€ HTTP Request #2 â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ (50ms) - Ð±ÐµÐ· ÑƒÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
   â”‚ â†â”€â”€â”€â”€ HTTP Response #2 â”€â”€â”€â”€â”€â”€â”€ â”‚
   â”‚                                â”‚
   â”‚ â”€â”€â”€â”€â”€ HTTP Request #3 â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ (50ms)
   â”‚ â†â”€â”€â”€â”€ HTTP Response #3 â”€â”€â”€â”€â”€â”€â”€ â”‚
   
   Total: 250ms Ð½Ð° Ñ‚Ñ€Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° (Ð±Ñ‹Ð»Ð¾ Ð±Ñ‹ 510ms Ð±ÐµÐ· keep-alive)
```

**ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Keep-Alive Ð² Ñ€Ð°Ð·Ð½Ñ‹Ñ… ÑÐµÑ€Ð²ÐµÑ€Ð°Ñ…:**

```nginx
# Nginx
http {
    keepalive_timeout 65s;           # Ð’Ñ€ÐµÐ¼Ñ Ð¶Ð¸Ð·Ð½Ð¸ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
    keepalive_requests 1000;         # ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð½Ð° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ
    
    upstream backend {
        server backend1:8080;
        keepalive 32;                # ÐŸÑƒÐ» ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ðº backend
    }
    
    server {
        location / {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Connection "";  # Ð’Ð°Ð¶Ð½Ð¾!
        }
    }
}
```

```javascript
// Node.js Express
const express = require('express');
const app = express();

// ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° HTTP keep-alive
const server = app.listen(3000, () => {
    // ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ keep-alive Ð´Ð»Ñ ÑÐµÑ€Ð²ÐµÑ€Ð°
    server.keepAliveTimeout = 65000;  // 65 ÑÐµÐºÑƒÐ½Ð´
    server.headersTimeout = 66000;    // Ð‘Ð¾Ð»ÑŒÑˆÐµ Ñ‡ÐµÐ¼ keepAliveTimeout
});

// ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° keep-alive Ð´Ð»Ñ Ð¸ÑÑ…Ð¾Ð´ÑÑ‰Ð¸Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
const http = require('http');
const https = require('https');

const httpAgent = new http.Agent({
    keepAlive: true,
    keepAliveMsecs: 1000,
    maxSockets: 50,
    maxFreeSockets: 10,
    timeout: 60000
});

const httpsAgent = new https.Agent({
    keepAlive: true,
    keepAliveMsecs: 1000,
    maxSockets: 50,
    maxFreeSockets: 10,
    timeout: 60000
});

// Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ñ…
const axios = require('axios');
const client = axios.create({
    httpAgent: httpAgent,
    httpsAgent: httpsAgent
});
```

### ðŸŽ¯ Content Negotiation Ð¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸

**ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ð°Ñ content negotiation:**

```python
from flask import Flask, request, jsonify
import json
import xml.etree.ElementTree as ET

app = Flask(__name__)

@app.route('/api/users/<int:user_id>')
def get_user(user_id):
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
    user_data = {
        'id': user_id,
        'name': 'John Doe',
        'email': 'john@example.com'
    }
    
    # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Accept Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
    accept_header = request.headers.get('Accept', 'application/json')
    
    if 'application/json' in accept_header:
        response = make_response(jsonify(user_data))
        response.headers['Content-Type'] = 'application/json'
        
    elif 'application/xml' in accept_header:
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ XML
        root = ET.Element('user')
        for key, value in user_data.items():
            elem = ET.SubElement(root, key)
            elem.text = str(value)
        
        xml_string = ET.tostring(root, encoding='unicode')
        response = make_response(xml_string)
        response.headers['Content-Type'] = 'application/xml'
        
    elif 'text/csv' in accept_header:
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ CSV
        csv_data = ','.join(user_data.keys()) + '\n'
        csv_data += ','.join(str(v) for v in user_data.values())
        
        response = make_response(csv_data)
        response.headers['Content-Type'] = 'text/csv'
        response.headers['Content-Disposition'] = f'attachment; filename=user_{user_id}.csv'
        
    else:
        # ÐÐµÐ¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚
        return jsonify({
            'error': 'Not Acceptable',
            'supported_formats': ['application/json', 'application/xml', 'text/csv']
        }), 406
    
    # ÐžÐ±Ñ‰Ð¸Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸
    response.headers['Vary'] = 'Accept'  # Ð’Ð°Ð¶Ð½Ð¾ Ð´Ð»Ñ ÐºÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
    response.headers['Cache-Control'] = 'public, max-age=300'
    
    return response

# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¶Ð°Ñ‚Ð¸Ñ
@app.after_request
def after_request(response):
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÑƒ ÑÐ¶Ð°Ñ‚Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð¼
    accept_encoding = request.headers.get('Accept-Encoding', '')
    
    # Ð¡Ð¶Ð¸Ð¼Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹ Ð±Ð¾Ð»ÑŒÑˆÐµ 1KB
    if (response.content_length and response.content_length > 1024 and
        response.content_type.startswith(('application/json', 'text/', 'application/xml'))):
        
        if 'gzip' in accept_encoding:
            response.headers['Content-Encoding'] = 'gzip'
            # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ middleware Ð´Ð»Ñ ÑÐ¶Ð°Ñ‚Ð¸Ñ
        elif 'deflate' in accept_encoding:
            response.headers['Content-Encoding'] = 'deflate'
    
    return response
```

### ðŸ“Š ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ HTTP Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸

**Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ HTTP Ð¼ÐµÑ‚Ñ€Ð¸Ðº:**

```python
import time
import functools
from collections import defaultdict
from flask import Flask, request, g

app = Flask(__name__)

# Ð¥Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
http_metrics = {
    'requests_total': defaultdict(int),
    'request_duration': defaultdict(list),
    'response_sizes': defaultdict(list),
    'status_codes': defaultdict(int)
}

def monitor_http_request(f):
    """Ð”ÐµÐºÐ¾Ñ€Ð°Ñ‚Ð¾Ñ€ Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° HTTP Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²"""
    @functools.wraps(f)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        method = request.method
        endpoint = request.endpoint or 'unknown'
        user_agent = request.headers.get('User-Agent', 'unknown')
        
        try:
            # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº
            response = f(*args, **kwargs)
            
            # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
            if hasattr(response, 'status_code'):
                status_code = response.status_code
                content_length = len(response.get_data()) if hasattr(response, 'get_data') else 0
            else:
                status_code = 200
                content_length = len(str(response))
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
            duration = (time.time() - start_time) * 1000  # Ð² Ð¼Ð¸Ð»Ð»Ð¸ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…
            
            metrics_key = f"{method}_{endpoint}"
            http_metrics['requests_total'][metrics_key] += 1
            http_metrics['request_duration'][metrics_key].append(duration)
            http_metrics['response_sizes'][metrics_key].append(content_length)
            http_metrics['status_codes'][f"{metrics_key}_{status_code}"] += 1
            
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
            if hasattr(response, 'headers'):
                response.headers['X-Response-Time'] = f"{duration:.2f}ms"
                response.headers['X-Content-Length'] = str(content_length)
            
            return response
            
        except Exception as e:
            # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¾ÑˆÐ¸Ð±Ð¾Ðº
            duration = (time.time() - start_time) * 1000
            metrics_key = f"{method}_{endpoint}"
            http_metrics['requests_total'][f"{metrics_key}_error"] += 1
            http_metrics['request_duration'][metrics_key].append(duration)
            http_metrics['status_codes'][f"{metrics_key}_500"] += 1
            
            raise
    
    return wrapper

# ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÐºÐ¾ Ð²ÑÐµÐ¼ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð°Ð¼
@app.before_request
def before_request():
    g.start_time = time.time()

@app.after_request
def after_request(response):
    if hasattr(g, 'start_time'):
        duration = (time.time() - g.start_time) * 1000
        response.headers['X-Response-Time'] = f"{duration:.2f}ms"
    return response

# Endpoint Ð´Ð»Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº (Prometheus Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚)
@app.route('/metrics')
def metrics():
    """Endpoint Ð´Ð»Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð² Prometheus Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ"""
    import statistics
    
    metrics_output = []
    
    # ÐžÐ±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
    metrics_output.append("# HELP http_requests_total Total HTTP requests")
    metrics_output.append("# TYPE http_requests_total counter")
    
    for key, value in http_metrics['requests_total'].items():
        method, endpoint = key.split('_', 1)
        metrics_output.append(f'http_requests_total{{method="{method}",endpoint="{endpoint}"}} {value}')
    
    # Ð’Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
    metrics_output.append("\n# HELP http_request_duration_ms HTTP request duration in milliseconds")
    metrics_output.append("# TYPE http_request_duration_ms histogram")
    
    for key, durations in http_metrics['request_duration'].items():
        if durations:
            method, endpoint = key.split('_', 1)
            avg_duration = statistics.mean(durations)
            p95_duration = statistics.quantiles(durations, n=20)[18] if len(durations) > 1 else durations[0]
            
            metrics_output.append(f'http_request_duration_ms_avg{{method="{method}",endpoint="{endpoint}"}} {avg_duration:.2f}')
            metrics_output.append(f'http_request_duration_ms_p95{{method="{method}",endpoint="{endpoint}"}} {p95_duration:.2f}')
    
    # Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÐºÐ¾Ð´Ñ‹
    metrics_output.append("\n# HELP http_responses_total Total HTTP responses by status code")
    metrics_output.append("# TYPE http_responses_total counter")
    
    for key, value in http_metrics['status_codes'].items():
        parts = key.rsplit('_', 1)
        if len(parts) == 2:
            method_endpoint, status_code = parts
            method, endpoint = method_endpoint.split('_', 1)
            metrics_output.append(f'http_responses_total{{method="{method}",endpoint="{endpoint}",status_code="{status_code}"}} {value}')
    
    return '\n'.join(metrics_output), 200, {'Content-Type': 'text/plain'}

# ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ
@app.route('/api/users/<int:user_id>')
@monitor_http_request
def get_user(user_id):
    # Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹
    time.sleep(0.05)  # 50ms
    return jsonify({'id': user_id, 'name': 'John Doe'})
```

### ðŸ”§ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€: HTTP Pipelining

**ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ HTTP/1.1 pipelining:**

```python
import asyncio
import aiohttp
import time

async def sequential_requests():
    """ÐŸÐ¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ - Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾"""
    start_time = time.time()
    
    async with aiohttp.ClientSession() as session:
        urls = [f'https://api.example.com/users/{i}' for i in range(1, 11)]
        
        responses = []
        for url in urls:
            async with session.get(url) as response:
                data = await response.json()
                responses.append(data)
    
    end_time = time.time()
    print(f"Sequential: {end_time - start_time:.2f}s for 10 requests")
    return responses

async def pipelined_requests():
    """ÐšÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð½Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ - Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ"""
    start_time = time.time()
    
    async with aiohttp.ClientSession() as session:
        urls = [f'https://api.example.com/users/{i}' for i in range(1, 11)]
        
        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð²ÑÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ ÑÑ€Ð°Ð·Ñƒ
        tasks = [session.get(url) for url in urls]
        responses = await asyncio.gather(*tasks)
        
        # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð²ÑÐµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹
        data = []
        for response in responses:
            json_data = await response.json()
            data.append(json_data)
            response.close()
    
    end_time = time.time()
    print(f"Pipelined: {end_time - start_time:.2f}s for 10 requests")
    return data

# Ð—Ð°Ð¿ÑƒÑÐº Ñ‚ÐµÑÑ‚Ð¾Ð²
async def main():
    print("Testing HTTP request patterns:")
    await sequential_requests()  # ~5-10 ÑÐµÐºÑƒÐ½Ð´
    await pipelined_requests()   # ~0.5-1 ÑÐµÐºÑƒÐ½Ð´Ð°
    
    # Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð¾ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
    # Ð´Ð°Ð¶Ðµ Ð² HTTP/1.1

if __name__ == "__main__":
    asyncio.run(main())
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ ÐÐµÐ´ÐµÐ»Ñ 5

1. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ RESTful API Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ HTTP Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð² Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ ÐºÐ¾Ð´Ð¾Ð²
2. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ HTTP keep-alive Ð´Ð»Ñ ÑÐ²Ð¾ÐµÐ³Ð¾ Ð²ÐµÐ±-ÑÐµÑ€Ð²ÐµÑ€Ð°
3. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ content negotiation Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¾Ð² (JSON, XML, CSV)
4. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ HTTP Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð² Prometheus Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ
5. ÐŸÑ€Ð¾Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð³Ñ€ÑƒÐ·Ð¾Ñ‡Ð½Ð¾Ðµ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ/Ð±ÐµÐ· keep-alive

---

## ÐÐµÐ´ÐµÐ»Ñ 6: HTTP/2 Ð¸ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: Ð ÐµÑˆÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ HTTP/1.1

HTTP/2 Ð±Ñ‹Ð» ÑÐ¾Ð·Ð´Ð°Ð½ Ð´Ð»Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ fundamental Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ HTTP/1.1:
- **Head-of-line blocking** - Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ° Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸
- **ÐœÐ½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ** - Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ñ‹ Ð¾Ñ‚ÐºÑ€Ñ‹Ð²Ð°ÑŽÑ‚ 6-8 ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
- **ÐÐµÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸** - Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÐµÐ½Ð¸Ðµ Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ñ‹Ñ… Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²

### ðŸ“Š HTTP/1.1 vs HTTP/2 Architecture

```
HTTP/1.1 (Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ð¡Ð¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ 1: [Req1] â”€â”€â†’ [Resp1] â”€â”€â†’ [Req2] â”€â”€â†’ [Resp2]   â”‚
â”‚ Ð¡Ð¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ 2: [Req3] â”€â”€â†’ [Resp3] â”€â”€â†’ [Req4] â”€â”€â†’ [Resp4]   â”‚
â”‚ Ð¡Ð¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ 3: [Req5] â”€â”€â†’ [Resp5] â”€â”€â†’ [Req6] â”€â”€â†’ [Resp6]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âŒ Head-of-line blocking: Req2 Ð¶Ð´ÐµÑ‚ Resp1                   â”‚
â”‚ âŒ ÐœÐ½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹: overhead TCP handshake            â”‚
â”‚ âŒ ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸ÐµÑÑ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸: User-Agent Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

HTTP/2 (Ñ€ÐµÑˆÐµÐ½Ð¸Ñ):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ÐžÐ´Ð½Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ:                                            â”‚
â”‚ Stream 1: [Req1] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• [Resp1]       â”‚
â”‚ Stream 3: [Req3] â•â•â•â•â• [Resp3]                             â”‚
â”‚ Stream 5: [Req5] â•â•â•â•â•â•â•â•â•â•â• [Resp5]                       â”‚
â”‚ Stream 7: [Req7] â• [Resp7]                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… Multiplexing: Ð²ÑÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾                    â”‚
â”‚ âœ… ÐžÐ´Ð½Ð¾ TCP ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ: Ð¼ÐµÐ½ÑŒÑˆÐµ overhead                     â”‚
â”‚ âœ… HPACK ÑÐ¶Ð°Ñ‚Ð¸Ðµ: Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ÑÐ¶Ð¸Ð¼Ð°ÑŽÑ‚ÑÑ                       â”‚
â”‚ âœ… Server Push: ÑÐµÑ€Ð²ÐµÑ€ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ Ñ€ÐµÑÑƒÑ€ÑÑ‹ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ”§ HTTP/2 Binary Framing Layer

**ÐšÐ°Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ binary framing:**

```
HTTP/1.1 (Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹):
GET /api/users HTTP/1.1\r\n
Host: api.example.com\r\n
User-Agent: MyApp/1.0\r\n
\r\n

HTTP/2 (Ð±Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ð¹):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frame Type: HEADERS (0x1)                   â”‚
â”‚ Stream ID: 1                                â”‚
â”‚ Flags: END_HEADERS (0x4)                    â”‚
â”‚ Length: 42                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Compressed Headers (HPACK):                 â”‚
â”‚ :method: GET                                â”‚
â”‚ :path: /api/users                          â”‚
â”‚ :authority: api.example.com                â”‚
â”‚ user-agent: MyApp/1.0                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### âš¡ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€: HTTP/2 Multiplexing

**Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸:**

```javascript
// Node.js HTTP/2 ÑÐµÑ€Ð²ÐµÑ€
const http2 = require('http2');
const fs = require('fs');

// Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ HTTP/2 ÑÐµÑ€Ð²ÐµÑ€
const server = http2.createSecureServer({
    key: fs.readFileSync('private-key.pem'),
    cert: fs.readFileSync('certificate.pem')
});

server.on('stream', (stream, headers) => {
    const path = headers[':path'];
    const method = headers[':method'];
    
    console.log(`HTTP/2 ${method} ${path} - Stream ID: ${stream.id}`);
    
    // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð¿ÑƒÑ‚ÐµÐ¹
    if (path === '/api/users') {
        // Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        setTimeout(() => {
            stream.respond({
                'content-type': 'application/json',
                ':status': 200
            });
            stream.end(JSON.stringify({
                users: Array.from({length: 100}, (_, i) => ({
                    id: i + 1,
                    name: `User ${i + 1}`
                }))
            }));
        }, 2000); // 2 ÑÐµÐºÑƒÐ½Ð´Ñ‹ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°
        
    } else if (path === '/api/quick') {
        // Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ
        stream.respond({
            'content-type': 'application/json',
            ':status': 200
        });
        stream.end(JSON.stringify({ message: 'Quick response' }));
        
    } else {
        stream.respond({ ':status': 404 });
        stream.end('Not found');
    }
});

server.listen(3000, () => {
    console.log('HTTP/2 server running on https://localhost:3000');
});
```

**Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ multiplexing:**

```bash
# Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° nghttp2-client Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
# Ubuntu: sudo apt-get install nghttp2-client
# macOS: brew install nghttp2

# HTTP/2 Ñ‚ÐµÑÑ‚ Ñ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ð¼Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸
nghttp -v https://localhost:3000/api/users https://localhost:3000/api/quick https://localhost:3000/api/users

# Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚:
# Stream 1: /api/users   (2000ms) - Ð½Ð¾ Ð½Ðµ Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÐµÑ‚ Ð´Ñ€ÑƒÐ³Ð¸Ðµ
# Stream 3: /api/quick   (50ms)   - Ð·Ð°Ð²ÐµÑ€ÑˆÐ°ÐµÑ‚ÑÑ Ð±Ñ‹ÑÑ‚Ñ€Ð¾
# Stream 5: /api/users   (2000ms) - Ð¸Ð´ÐµÑ‚ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾
# 
# ÐžÐ±Ñ‰ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ: ~2050ms Ð²Ð¼ÐµÑÑ‚Ð¾ 4050ms Ð² HTTP/1.1
```

### ðŸ—œï¸ HPACK Header Compression

**ÐšÐ°Ðº HPACK ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸Ñ‚ bandwidth:**

```python
# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸Ð¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²
import json

# Ð¢Ð¸Ð¿Ð¸Ñ‡Ð½Ñ‹Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ API Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
http1_headers = {
    'GET /api/users/1 HTTP/1.1': '',
    'Host': 'api.example.com',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'application/json',
    'Accept-Encoding': 'gzip, deflate, br',
    'Accept-Language': 'en-US,en;q=0.9',
    'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...',
    'Cache-Control': 'no-cache',
    'Connection': 'keep-alive',
    'Pragma': 'no-cache'
}

# ÐŸÐ¾Ð´ÑÑ‡ÐµÑ‚ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ð² HTTP/1.1
http1_size = sum(len(f"{k}: {v}\r\n") for k, v in http1_headers.items())
http1_size += len("GET /api/users/1 HTTP/1.1\r\n\r\n")

print(f"HTTP/1.1 headers size: {http1_size} bytes")

# Ð’ HTTP/2 Ñ HPACK (ÑÐ¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ)
# ÐŸÐµÑ€Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ - Ð¿Ð¾Ð»Ð½Ñ‹Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ (Ð½Ð¾ ÑÐ¶Ð°Ñ‚Ñ‹Ðµ)
first_request_size = http1_size * 0.7  # HPACK ÑÐ¶Ð¸Ð¼Ð°ÐµÑ‚ ~30%

# ÐŸÐ¾ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ - Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ
subsequent_requests = [
    {'path': '/api/users/2'},  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ path Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»ÑÑ
    {'path': '/api/users/3'},  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ path Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»ÑÑ
    {'path': '/api/orders/1'}, # Ð¢Ð¾Ð»ÑŒÐºÐ¾ path Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»ÑÑ
]

subsequent_size = 20  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ñ‹Ð¹ path + ÑÐ»ÑƒÐ¶ÐµÐ±Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ

total_http1 = http1_size * 4  # 4 Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
total_http2 = first_request_size + (subsequent_size * 3)

print(f"HTTP/1.1 total: {total_http1} bytes")
print(f"HTTP/2 total: {total_http2:.0f} bytes")
print(f"Savings: {((total_http1 - total_http2) / total_http1 * 100):.1f}%")

# Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚:
# HTTP/1.1 headers size: 456 bytes
# HTTP/1.1 total: 1824 bytes  
# HTTP/2 total: 379 bytes
# Savings: 79.2%
```

### ðŸš€ Server Push - Ð¿Ñ€Ð¾Ð°ÐºÑ‚Ð¸Ð²Ð½Ð°Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²

**ÐšÐ¾Ð³Ð´Ð° Server Push Ð¿Ð¾Ð»ÐµÐ·ÐµÐ½:**

```javascript
// HTTP/2 Server Push Ð¿Ñ€Ð¸Ð¼ÐµÑ€
const http2 = require('http2');
const fs = require('fs');
const path = require('path');

const server = http2.createSecureServer({
    key: fs.readFileSync('private-key.pem'),
    cert: fs.readFileSync('certificate.pem')
});

server.on('stream', (stream, headers) => {
    const reqPath = headers[':path'];
    
    if (reqPath === '/api/user/profile') {
        // ÐŸÑ€Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ñ, push ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ€ÐµÑÑƒÑ€ÑÑ‹
        
        // Push user preferences (Ð¿Ð¾Ð½Ð°Ð´Ð¾Ð±Ð¸Ñ‚ÑÑ Ð½Ð° Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´Ðµ)
        const pushStream1 = stream.pushStream({
            ':method': 'GET',
            ':path': '/api/user/preferences',
            ':scheme': 'https',
            ':authority': headers[':authority']
        });
        
        pushStream1.respond({ ':status': 200, 'content-type': 'application/json' });
        pushStream1.end(JSON.stringify({
            theme: 'dark',
            language: 'en',
            notifications: true
        }));
        
        // Push user notifications (Ð¿Ð¾Ð½Ð°Ð´Ð¾Ð±Ð¸Ñ‚ÑÑ Ñ‚Ð¾Ð¶Ðµ)
        const pushStream2 = stream.pushStream({
            ':method': 'GET',
            ':path': '/api/user/notifications',
            ':scheme': 'https',
            ':authority': headers[':authority']
        });
        
        pushStream2.respond({ ':status': 200, 'content-type': 'application/json' });
        pushStream2.end(JSON.stringify({
            unread_count: 3,
            latest: ['Message 1', 'Message 2', 'Message 3']
        }));
        
        // ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚
        stream.respond({
            ':status': 200,
            'content-type': 'application/json',
            'link': '</api/user/preferences>; rel=preload, </api/user/notifications>; rel=preload'
        });
        
        stream.end(JSON.stringify({
            id: 123,
            name: 'John Doe',
            email: 'john@example.com'
        }));
    }
});

server.listen(3000);
```

**ÐžÑÑ‚Ð¾Ñ€Ð¾Ð¶Ð½Ð¾ Ñ Server Push:**

```javascript
// ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Server Push
const pushMetrics = {
    pushed: 0,
    used: 0,
    wasted: 0
};

server.on('stream', (stream, headers) => {
    // ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°ÐµÐ¼ pushed Ñ€ÐµÑÑƒÑ€ÑÑ‹
    stream.on('push', (pushStream) => {
        pushMetrics.pushed++;
        
        pushStream.on('close', () => {
            if (pushStream.rstCode === http2.constants.NGHTTP2_NO_ERROR) {
                pushMetrics.used++;
            } else if (pushStream.rstCode === http2.constants.NGHTTP2_CANCEL) {
                pushMetrics.wasted++;
                console.log('Client cancelled push - resource not needed');
            }
        });
    });
});

// Endpoint Ð´Ð»Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
server.on('stream', (stream, headers) => {
    if (headers[':path'] === '/metrics/push') {
        const efficiency = (pushMetrics.used / pushMetrics.pushed * 100).toFixed(1);
        const waste = (pushMetrics.wasted / pushMetrics.pushed * 100).toFixed(1);
        
        stream.respond({ ':status': 200, 'content-type': 'application/json' });
        stream.end(JSON.stringify({
            pushed_total: pushMetrics.pushed,
            used_total: pushMetrics.used,
            wasted_total: pushMetrics.wasted,
            efficiency_percent: efficiency,
            waste_percent: waste
        }));
    }
});
```

### ðŸ”§ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° HTTP/2 Ð² production

**Nginx Ñ HTTP/2:**

```nginx
# /etc/nginx/sites-available/api
server {
    listen 443 ssl http2;  # HTTP/2 Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½
    listen [::]:443 ssl http2;
    
    server_name api.example.com;
    
    # SSL Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð´Ð»Ñ HTTP/2
    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:!aNULL:!SHA1:!WEAK;
    ssl_prefer_server_ciphers off;
    
    # HTTP/2 Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    http2_max_field_size 8k;        # Ð Ð°Ð·Ð¼ÐµÑ€ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²
    http2_max_header_size 32k;      # ÐžÐ±Ñ‰Ð¸Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²
    http2_body_preread_size 64k;    # Preread body Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    
    # Server Push Ð´Ð»Ñ ÑÑ‚Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²
    location = /app.js {
        add_header Link "</style.css>; rel=preload; as=style" always;
        add_header Link "</config.json>; rel=preload; as=fetch" always;
    }
    
    # API endpoints
    location /api/ {
        proxy_pass http://backend;
        proxy_http_version 1.1;  # Backend Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ HTTP/1.1
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection '';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Ð‘ÑƒÑ„ÐµÑ€Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ HTTP/2
        proxy_buffering on;
        proxy_buffer_size 128k;
        proxy_buffers 4 256k;
        proxy_busy_buffers_size 256k;
    }
}

# Ð ÐµÐ´Ð¸Ñ€ÐµÐºÑ‚ HTTP -> HTTPS
server {
    listen 80;
    listen [::]:80;
    server_name api.example.com;
    return 301 https://$server_name$request_uri;
}
```

**ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ HTTP/2 Ð¼ÐµÑ‚Ñ€Ð¸Ðº:**

```bash
# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° HTTP/2 ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ð² nginx
tail -f /var/log/nginx/access.log | grep "HTTP/2"

# Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ HTTP/2 Ð² nginx (Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¼Ð¾Ð´ÑƒÐ»ÑŒ)
curl -s localhost/nginx_status | grep http2

# ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
# /etc/nginx/nginx.conf
http {
    log_format http2_log '$remote_addr - $remote_user [$time_local] '
                         '"$request" $status $body_bytes_sent '
                         '"$http_referer" "$http_user_agent" '
                         'rt=$request_time '
                         'ua="$upstream_addr" us="$upstream_status" '
                         'ut="$upstream_response_time" ul="$upstream_response_length" '
                         'h2="$http2"';  # HTTP/2 flag
                         
    access_log /var/log/nginx/http2.log http2_log;
}
```

### ðŸ“Š ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ HTTP/2 Ð½Ð° Ð¿Ñ€Ð°ÐºÑ‚Ð¸ÐºÐµ

**Benchmark HTTP/1.1 vs HTTP/2:**

```python
import asyncio
import aiohttp
import time
from statistics import mean, median

async def benchmark_http_version(urls, http_version='1.1'):
    """Ð‘ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº HTTP/1.1 vs HTTP/2"""
    
    # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÐºÐ¾Ð½Ð½ÐµÐºÑ‚Ð¾Ñ€Ð°
    if http_version == '2.0':
        # ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ: aiohttp Ð¿Ð¾ÐºÐ° Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ HTTP/2 ÐºÐ»Ð¸ÐµÐ½Ñ‚
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ curl Ð´Ð»Ñ HTTP/2 Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        return await benchmark_with_curl(urls, '--http2')
    else:
        return await benchmark_with_aiohttp(urls)

async def benchmark_with_aiohttp(urls):
    """Ð¢ÐµÑÑ‚ Ñ aiohttp (HTTP/1.1)"""
    start_time = time.time()
    times = []
    
    connector = aiohttp.TCPConnector(
        limit=10,  # ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        limit_per_host=6  # ÐšÐ°Ðº Ð² Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ðµ Ð´Ð»Ñ HTTP/1.1
    )
    
    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = []
        for url in urls:
            task = fetch_with_timing(session, url)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        times = [r['time'] for r in results if r['success']]
    
    total_time = time.time() - start_time
    
    return {
        'version': 'HTTP/1.1',
        'total_time': total_time,
        'avg_time': mean(times) if times else 0,
        'median_time': median(times) if times else 0,
        'success_count': len(times),
        'total_requests': len(urls)
    }

async def fetch_with_timing(session, url):
    """Fetch Ñ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸ÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸"""
    start = time.time()
    try:
        async with session.get(url) as response:
            await response.text()
            return {
                'success': True,
                'time': (time.time() - start) * 1000,  # Ð² Ð¼Ñ
                'status': response.status
            }
    except Exception as e:
        return {
            'success': False,
            'time': (time.time() - start) * 1000,
            'error': str(e)
        }

async def benchmark_with_curl(urls, http_flag):
    """Ð¢ÐµÑÑ‚ Ñ curl (Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ HTTP/2)"""
    import subprocess
    import json
    
    start_time = time.time()
    times = []
    
    # ÐŸÐ°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ðµ curl Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹
    processes = []
    for url in urls:
        cmd = [
            'curl', http_flag, '-s', '-o', '/dev/null',
            '-w', '%{time_total},%{http_code}',
            url
        ]
        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        processes.append((proc, url))
    
    # Ð–Ð´ÐµÐ¼ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ð²ÑÐµÑ…
    for proc, url in processes:
        stdout, stderr = proc.communicate()
        if proc.returncode == 0:
            try:
                time_total, status_code = stdout.decode().strip().split(',')
                times.append(float(time_total) * 1000)  # Ð² Ð¼Ñ
            except ValueError:
                pass
    
    total_time = time.time() - start_time
    
    return {
        'version': 'HTTP/2' if '--http2' in http_flag else 'HTTP/1.1',
        'total_time': total_time,
        'avg_time': mean(times) if times else 0,
        'median_time': median(times) if times else 0,
        'success_count': len(times),
        'total_requests': len(urls)
    }

# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
async def main():
    # Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ URL (Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚Ðµ Ð½Ð° Ð²Ð°ÑˆÐ¸)
    test_urls = [
        'https://api.example.com/users',
        'https://api.example.com/orders',
        'https://api.example.com/products',
        'https://api.example.com/analytics',
        'https://api.example.com/reports'
    ] * 10  # 50 Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð²ÑÐµÐ³Ð¾
    
    print("Benchmarking HTTP versions...")
    
    # HTTP/1.1 Ñ‚ÐµÑÑ‚
    http1_result = await benchmark_with_aiohttp(test_urls)
    print(f"HTTP/1.1: {http1_result}")
    
    # HTTP/2 Ñ‚ÐµÑÑ‚
    http2_result = await benchmark_with_curl(test_urls, '--http2')
    print(f"HTTP/2: {http2_result}")
    
    # Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ
    if http1_result['avg_time'] > 0 and http2_result['avg_time'] > 0:
        improvement = (http1_result['avg_time'] - http2_result['avg_time']) / http1_result['avg_time'] * 100
        print(f"HTTP/2 faster by: {improvement:.1f}%")

if __name__ == "__main__":
    asyncio.run(main())
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ ÐÐµÐ´ÐµÐ»Ñ 6

1. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ HTTP/2 Ð½Ð° Ð²Ð°ÑˆÐµÐ¼ Ð²ÐµÐ±-ÑÐµÑ€Ð²ÐµÑ€Ðµ
2. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ HTTP/2 server push Ð´Ð»Ñ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð² API
3. ÐŸÑ€Ð¾Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð³Ñ€ÑƒÐ·Ð¾Ñ‡Ð½Ð¾Ðµ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ HTTP/1.1 vs HTTP/2
4. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Server Push
5. ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ HPACK ÑÐ¶Ð°Ñ‚Ð¸Ñ

---

## ÐÐµÐ´ÐµÐ»Ñ 7: HTTP/3 Ð¸ HTTPS

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: Ð ÐµÐ²Ð¾Ð»ÑŽÑ†Ð¸Ñ HTTP/3 Ñ QUIC

HTTP/3 - ÑÑ‚Ð¾ Ð½Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ HTTP/2. Ð­Ñ‚Ð¾ Ð¿Ð¾Ð»Ð½Ð°Ñ Ð·Ð°Ð¼ÐµÐ½Ð° Ñ‚Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚Ð½Ð¾Ð³Ð¾ ÑƒÑ€Ð¾Ð²Ð½Ñ Ñ TCP Ð½Ð° QUIC (UDP-based).

### ðŸ“Š Ð­Ð²Ð¾Ð»ÑŽÑ†Ð¸Ñ HTTP Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ð¾Ð²

```
HTTP/1.1 (1997):        HTTP/2 (2015):         HTTP/3 (2022):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application     â”‚    â”‚ Application     â”‚    â”‚ Application     â”‚
â”‚ HTTP/1.1        â”‚    â”‚ HTTP/2          â”‚    â”‚ HTTP/3          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TLS (optional)  â”‚    â”‚ TLS 1.2+        â”‚    â”‚ TLS 1.3         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚ (integrated)    â”‚
â”‚ TCP             â”‚    â”‚ TCP             â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚ QUIC            â”‚
â”‚ IP              â”‚    â”‚ IP              â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ UDP             â”‚
                                              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹:              Ð ÐµÑˆÐµÐ½Ð¸Ñ HTTP/2:        â”‚ IP              â”‚
â€¢ Head-of-line         â€¢ Multiplexing         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  blocking             â€¢ Binary framing       
â€¢ ÐœÐ½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾            â€¢ Header compression   Ð ÐµÑˆÐµÐ½Ð¸Ñ HTTP/3:
  ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹           â€¢ Server push          â€¢ ÐÐµÑ‚ TCP blocking
â€¢ ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ñ‹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²   â€¢ ÐžÐ´Ð½Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ     â€¢ 0-RTT handshake
                                              â€¢ Connection migration
                                              â€¢ Better congestion control
```

### ðŸš€ QUIC Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð° Ð½Ð°Ð´ TCP

**1. Ð£ÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Head-of-Line Blocking:**

```
TCP (Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°):
Stream 1: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] â† Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÐµÑ‚ Ð²ÑÐµ Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ
Stream 2: [    Ð¶Ð´ÐµÑ‚...     ]
Stream 3: [    Ð¶Ð´ÐµÑ‚...     ]

QUIC (Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ):
Stream 1: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
Stream 2: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      ] â† Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð½ÐµÐ·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾
Stream 3: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] â† Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð»ÑÑ Ð¿ÐµÑ€Ð²Ñ‹Ð¼
```

**2. 0-RTT Connection Establishment:**

```bash
# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ 0-RTT Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ
curl --http3 -w "@curl-timing.txt" https://cloudflare.com

# curl-timing.txt:
#     time_namelookup:  %{time_namelookup}
#        time_connect:  %{time_connect}     â† Ð´Ð»Ñ QUIC Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ 0!
#     time_appconnect:  %{time_appconnect}
#    time_pretransfer:  %{time_pretransfer}
#   time_starttransfer: %{time_starttransfer}
#            time_total: %{time_total}

# Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð´Ð»Ñ QUIC 0-RTT:
# time_connect: 0.000
# time_appconnect: 0.000  â† Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð³Ð½Ð¾Ð²ÐµÐ½Ð½Ð¾Ðµ!
```

### ðŸ”§ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° HTTP/3

**Caddy ÑÐµÑ€Ð²ÐµÑ€ (Ð½Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° HTTP/3):**

```caddyfile
# Caddyfile
{
    # Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ HTTP/3
    experimental_http3
    log {
        level DEBUG
    }
}

api.example.com {
    # HTTP/3 Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸
    reverse_proxy localhost:8080 {
        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð´Ð»Ñ backend
        header_up Host {http.request.host}
        header_up X-Real-IP {http.request.remote}
        header_up X-Forwarded-For {http.request.remote}
        header_up X-Forwarded-Proto {http.request.scheme}
        
        # Health check
        health_uri /health
        health_interval 30s
        health_timeout 5s
    }
    
    # ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ HTTP/3 Ð´Ð»Ñ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²
    @supports_h3 {
        header Alt-Svc h3=":443"
    }
    
    # Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ Ð²ÐµÑ€ÑÐ¸ÐµÐ¹ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ð°
    log {
        output file /var/log/caddy/api.log {
            roll_size 100mb
            roll_keep 10
        }
        format json {
            time_format "2006-01-02T15:04:05.000Z07:00"
            level_format "upper"
        }
        level INFO
    }
    
    # CORS Ð´Ð»Ñ HTTP/3
    header {
        Access-Control-Allow-Origin *
        Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS"
        Access-Control-Allow-Headers "Content-Type, Authorization"
        # Ð’Ð°Ð¶Ð½Ð¾ Ð´Ð»Ñ HTTP/3 preflight
        Access-Control-Max-Age 86400
    }
}
```

**Node.js HTTP/3 ÑÐµÑ€Ð²ÐµÑ€ (ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°):**

```javascript
// Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ Node.js 15+ Ñ Ñ„Ð»Ð°Ð³Ð¾Ð¼ --experimental-quic
const { createQuicSocket } = require('quic');
const fs = require('fs');

// Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ QUIC ÑÐ¾ÐºÐµÑ‚Ð°
const socket = createQuicSocket({
    endpoint: { port: 1234 },
    server: {
        key: fs.readFileSync('server-key.pem'),
        cert: fs.readFileSync('server-cert.pem'),
        ca: fs.readFileSync('ca-cert.pem'),  // Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾
        requestCert: false,
        rejectUnauthorized: false,
        alpn: 'h3'  // HTTP/3 ALPN identifier
    }
});

socket.on('session', (session) => {
    console.log('New QUIC session established');
    
    // ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ ÑÐµÑÑÐ¸Ð¸
    session.on('secure', () => {
        console.log('Session is secure');
        console.log('Cipher:', session.cipher);
        console.log('ALPN:', session.alpnProtocol);
    });
    
    session.on('stream', (stream) => {
        console.log('New stream created:', stream.id);
        
        let requestData = '';
        
        stream.on('data', (chunk) => {
            requestData += chunk.toString();
        });
        
        stream.on('end', () => {
            // ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ HTTP/3 Ð¾Ñ‚Ð²ÐµÑ‚
            const response = JSON.stringify({
                message: 'Hello from HTTP/3!',
                timestamp: new Date().toISOString(),
                stream_id: stream.id,
                protocol: 'HTTP/3'
            });
            
            // HTTP/3 headers
            const headers = [
                [':status', '200'],
                ['content-type', 'application/json'],
                ['content-length', response.length.toString()],
                ['server', 'Node.js QUIC'],
                ['date', new Date().toUTCString()]
            ];
            
            // ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° headers
            stream.sendHeaders(headers);
            
            // ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° body
            stream.end(response);
        });
        
        stream.on('error', (err) => {
            console.error('Stream error:', err);
        });
    });
    
    session.on('close', () => {
        console.log('Session closed');
    });
});

socket.on('error', (err) => {
    console.error('Socket error:', err);
});

socket.listen()
    .then(() => console.log('QUIC server listening on port 1234'))
    .catch(console.error);

// Graceful shutdown
process.on('SIGINT', () => {
    console.log('Shutting down...');
    socket.close(() => {
        process.exit(0);
    });
});
```

### ðŸ” TLS 1.3 Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ð² QUIC

**ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ TLS Ð² QUIC:**

```python
# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ TLS 1.3 handshake Ð² QUIC
import ssl
import socket
import time

def analyze_tls_handshake(hostname, port=443):
    """ÐÐ½Ð°Ð»Ð¸Ð· TLS handshake Ð´Ð»Ñ HTTP/3"""
    
    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð»Ñ TLS 1.3
    context = ssl.create_default_context()
    context.minimum_version = ssl.TLSVersion.TLSv1_3
    context.maximum_version = ssl.TLSVersion.TLSv1_3
    
    # ALPN Ð´Ð»Ñ HTTP/3
    context.set_alpn_protocols(['h3', 'h3-29', 'h3-28'])
    
    start_time = time.time()
    
    try:
        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
        sock = socket.create_connection((hostname, port), timeout=10)
        
        # TLS wrap
        tls_sock = context.wrap_socket(sock, server_hostname=hostname)
        
        end_time = time.time()
        
        # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¸
        info = {
            'hostname': hostname,
            'handshake_time': (end_time - start_time) * 1000,  # Ð¼Ñ
            'tls_version': tls_sock.version(),
            'cipher': tls_sock.cipher(),
            'alpn_protocol': tls_sock.selected_alpn_protocol(),
            'compression': tls_sock.compression(),
            'certificate': {
                'subject': dict(x[0] for x in tls_sock.getpeercert()['subject']),
                'issuer': dict(x[0] for x in tls_sock.getpeercert()['issuer']),
                'version': tls_sock.getpeercert()['version'],
                'serial_number': tls_sock.getpeercert()['serialNumber']
            }
        }
        
        tls_sock.close()
        
        return info
        
    except Exception as e:
        return {'error': str(e), 'handshake_time': (time.time() - start_time) * 1000}

# Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ€Ð°Ð·Ð½Ñ‹Ñ… ÑÐ°Ð¹Ñ‚Ð¾Ð²
sites = [
    'cloudflare.com',  # ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ HTTP/3
    'google.com',      # ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ HTTP/3
    'facebook.com',    # ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ HTTP/3
    'github.com'       # HTTP/2 only
]

print("TLS 1.3 / HTTP/3 Support Analysis:")
print("=" * 50)

for site in sites:
    result = analyze_tls_handshake(site)
    
    if 'error' not in result:
        print(f"\n{site}:")
        print(f"  TLS Version: {result['tls_version']}")
        print(f"  Handshake Time: {result['handshake_time']:.1f}ms")
        print(f"  Cipher: {result['cipher'][0]} (strength: {result['cipher'][2]})")
        print(f"  ALPN: {result['alpn_protocol']}")
        print(f"  HTTP/3 Support: {'Yes' if result['alpn_protocol'] and 'h3' in result['alpn_protocol'] else 'No'}")
    else:
        print(f"\n{site}: ERROR - {result['error']}")
```

### ðŸ“Š Connection Migration Ð² QUIC

**ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ ÑÑ‚Ð¾ Ñ€ÐµÐ²Ð¾Ð»ÑŽÑ†Ð¸Ð¾Ð½Ð½Ð¾ Ð´Ð»Ñ Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ñ… API:**

```javascript
// Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ connection migration
const quicMetrics = {
    connections: new Map(),
    migrations: 0,
    migrationTime: []
};

// ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ QUIC connection events
socket.on('session', (session) => {
    const connectionId = session.id;
    
    quicMetrics.connections.set(connectionId, {
        created: Date.now(),
        ip_changes: 0,
        last_ip: session.remoteAddress,
        active: true
    });
    
    // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¼ÐµÐ½Ñ‹ IP (connection migration)
    session.on('pathValidation', (pathData) => {
        const conn = quicMetrics.connections.get(connectionId);
        
        if (conn && pathData.remoteAddress !== conn.last_ip) {
            const migrationStart = Date.now();
            
            console.log(`Connection migration detected:`);
            console.log(`  From: ${conn.last_ip}`);
            console.log(`  To: ${pathData.remoteAddress}`);
            
            // ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
            conn.ip_changes++;
            conn.last_ip = pathData.remoteAddress;
            quicMetrics.migrations++;
            
            // Ð’Ñ€ÐµÐ¼Ñ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
            const migrationTime = Date.now() - migrationStart;
            quicMetrics.migrationTime.push(migrationTime);
            
            console.log(`  Migration completed in: ${migrationTime}ms`);
            
            // Ð’ TCP ÑÑ‚Ð¾ Ð±Ñ‹Ð»Ð¾ Ð±Ñ‹ Ñ€Ð°Ð·Ñ€Ñ‹Ð² ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ!
            // Ð’ QUIC - Ð±ÐµÑÑˆÐ¾Ð²Ð½Ð¾Ðµ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ
        }
    });
    
    session.on('close', () => {
        const conn = quicMetrics.connections.get(connectionId);
        if (conn) {
            conn.active = false;
            conn.duration = Date.now() - conn.created;
        }
    });
});

// API Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° connection migration
app.get('/api/quic/metrics', (req, res) => {
    const activeConnections = Array.from(quicMetrics.connections.values())
        .filter(conn => conn.active).length;
    
    const avgMigrationTime = quicMetrics.migrationTime.length > 0 
        ? quicMetrics.migrationTime.reduce((a, b) => a + b, 0) / quicMetrics.migrationTime.length
        : 0;
    
    res.json({
        active_connections: activeConnections,
        total_migrations: quicMetrics.migrations,
        avg_migration_time_ms: avgMigrationTime.toFixed(2),
        migration_success_rate: 100,  // QUIC migrations Ð¿Ð¾Ñ‡Ñ‚Ð¸ Ð²ÑÐµÐ³Ð´Ð° ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹
        tcp_equivalent_failures: quicMetrics.migrations  // Ð’ TCP ÑÑ‚Ð¾ Ð±Ñ‹Ð»Ð¸ Ð±Ñ‹ Ñ€Ð°Ð·Ñ€Ñ‹Ð²Ñ‹
    });
});
```

### ðŸ›¡ï¸ Security Headers Ð´Ð»Ñ HTTP/3

**Ð£ÑÐ¸Ð»ÐµÐ½Ð½Ñ‹Ðµ security headers:**

```python
from flask import Flask, make_response, request
import secrets

app = Flask(__name__)

@app.after_request
def add_security_headers(response):
    """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ security headers Ð´Ð»Ñ HTTP/3"""
    
    # Strict Transport Security Ñ preload
    response.headers['Strict-Transport-Security'] = (
        'max-age=63072000; includeSubDomains; preload'
    )
    
    # Content Security Policy
    nonce = secrets.token_urlsafe(16)
    response.headers['Content-Security-Policy'] = (
        f"default-src 'self'; "
        f"script-src 'self' 'nonce-{nonce}' 'strict-dynamic'; "
        f"style-src 'self' 'unsafe-inline'; "
        f"img-src 'self' data: https:; "
        f"font-src 'self' data:; "
        f"connect-src 'self' wss: https:; "
        f"frame-ancestors 'none'; "
        f"base-uri 'self'; "
        f"form-action 'self'"
    )
    
    # ÐŸÑ€ÐµÐ´Ð¾Ñ‚Ð²Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ðµ MIME sniffing
    response.headers['X-Content-Type-Options'] = 'nosniff'
    
    # Ð—Ð°Ñ‰Ð¸Ñ‚Ð° Ð¾Ñ‚ clickjacking
    response.headers['X-Frame-Options'] = 'DENY'
    
    # XSS Protection
    response.headers['X-XSS-Protection'] = '1; mode=block'
    
    # Referrer Policy
    response.headers['Referrer-Policy'] = 'strict-origin-when-cross-origin'
    
    # Feature Policy / Permissions Policy
    response.headers['Permissions-Policy'] = (
        'geolocation=(), microphone=(), camera=(), '
        'payment=(), usb=(), magnetometer=(), gyroscope=()'
    )
    
    # Cross-Origin Embedder Policy (Ð²Ð°Ð¶Ð½Ð¾ Ð´Ð»Ñ HTTP/3)
    response.headers['Cross-Origin-Embedder-Policy'] = 'require-corp'
    
    # Cross-Origin Opener Policy
    response.headers['Cross-Origin-Opener-Policy'] = 'same-origin'
    
    # Cross-Origin Resource Policy
    response.headers['Cross-Origin-Resource-Policy'] = 'same-origin'
    
    # Cache control Ð´Ð»Ñ API
    if request.path.startswith('/api/'):
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
    
    # Alt-Svc header Ð´Ð»Ñ HTTP/3 upgrade
    response.headers['Alt-Svc'] = 'h3=":443"; ma=86400, h3-29=":443"; ma=86400'
    
    return response

# Endpoint Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ security headers
@app.route('/api/security/check')
def security_check():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° security headers"""
    headers_to_check = [
        'Strict-Transport-Security',
        'Content-Security-Policy',
        'X-Content-Type-Options',
        'X-Frame-Options',
        'X-XSS-Protection',
        'Referrer-Policy',
        'Permissions-Policy',
        'Alt-Svc'
    ]
    
    present_headers = {}
    for header in headers_to_check:
        if header in request.headers:
            present_headers[header] = request.headers[header]
    
    return {
        'security_headers_present': len(present_headers),
        'security_headers_total': len(headers_to_check),
        'security_score': len(present_headers) / len(headers_to_check) * 100,
        'headers': present_headers,
        'recommendations': [
            'Enable HSTS with preload',
            'Implement strict CSP',
            'Use HTTP/3 Alt-Svc header',
            'Set proper CORS policies',
            'Enable security monitoring'
        ]
    }
```

### ðŸ“ˆ Performance Monitoring HTTP/3

**Comprehensive HTTP/3 metrics:**

```javascript
// HTTP/3 Performance Monitor
class HTTP3Monitor {
    constructor() {
        this.metrics = {
            connections: new Map(),
            streams: new Map(),
            performance: {
                handshake_times: [],
                first_byte_times: [],
                transfer_rates: [],
                error_rates: new Map()
            }
        };
        
        this.startTime = Date.now();
    }
    
    recordConnection(sessionId, details) {
        this.metrics.connections.set(sessionId, {
            id: sessionId,
            started: Date.now(),
            handshake_time: details.handshakeTime,
            cipher: details.cipher,
            alpn: details.alpn,
            streams: 0,
            bytes_transferred: 0,
            errors: 0
        });
        
        this.metrics.performance.handshake_times.push(details.handshakeTime);
    }
    
    recordStream(sessionId, streamId, details) {
        const connection = this.metrics.connections.get(sessionId);
        if (connection) {
            connection.streams++;
            connection.bytes_transferred += details.bytes || 0;
        }
        
        this.metrics.streams.set(streamId, {
            session_id: sessionId,
            started: details.startTime,
            ended: details.endTime,
            bytes: details.bytes,
            status: details.status,
            first_byte_time: details.firstByteTime
        });
        
        if (details.firstByteTime) {
            this.metrics.performance.first_byte_times.push(details.firstByteTime);
        }
        
        if (details.bytes && details.duration) {
            const rate = details.bytes / details.duration * 8; // bits per second
            this.metrics.performance.transfer_rates.push(rate);
        }
    }
    
    recordError(sessionId, errorType, errorDetails) {
        const connection = this.metrics.connections.get(sessionId);
        if (connection) {
            connection.errors++;
        }
        
        if (!this.metrics.performance.error_rates.has(errorType)) {
            this.metrics.performance.error_rates.set(errorType, 0);
        }
        this.metrics.performance.error_rates.set(
            errorType, 
            this.metrics.performance.error_rates.get(errorType) + 1
        );
    }
    
    getStatistics() {
        const now = Date.now();
        const uptime = now - this.startTime;
        
        const activeConnections = Array.from(this.metrics.connections.values())
            .filter(conn => !conn.ended).length;
        
        const totalStreams = this.metrics.streams.size;
        const totalErrors = Array.from(this.metrics.performance.error_rates.values())
            .reduce((sum, count) => sum + count, 0);
        
        // Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        const avgHandshakeTime = this.average(this.metrics.performance.handshake_times);
        const avgFirstByteTime = this.average(this.metrics.performance.first_byte_times);
        const avgTransferRate = this.average(this.metrics.performance.transfer_rates);
        
        return {
            uptime_ms: uptime,
            connections: {
                active: activeConnections,
                total: this.metrics.connections.size
            },
            streams: {
                total: totalStreams,
                errors: totalErrors,
                success_rate: ((totalStreams - totalErrors) / totalStreams * 100).toFixed(2)
            },
            performance: {
                avg_handshake_time_ms: avgHandshakeTime.toFixed(2),
                avg_first_byte_time_ms: avgFirstByteTime.toFixed(2),
                avg_transfer_rate_mbps: (avgTransferRate / 1024 / 1024).toFixed(2),
                error_breakdown: Object.fromEntries(this.metrics.performance.error_rates)
            },
            http3_advantages: {
                zero_rtt_connections: this.metrics.performance.handshake_times.filter(t => t < 1).length,
                connection_migrations: this.getConnectionMigrations(),
                multiplexing_efficiency: this.getMultiplexingEfficiency()
            }
        };
    }
    
    average(array) {
        return array.length > 0 ? array.reduce((a, b) => a + b, 0) / array.length : 0;
    }
    
    getConnectionMigrations() {
        // ÐŸÐ¾Ð´ÑÑ‡ÐµÑ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… connection migration ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹
        return Array.from(this.metrics.connections.values())
            .reduce((sum, conn) => sum + (conn.migrations || 0), 0);
    }
    
    getMultiplexingEfficiency() {
        // Ð¡Ñ€ÐµÐ´Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ streams Ð½Ð° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ
        const connections = Array.from(this.metrics.connections.values());
        const totalStreams = connections.reduce((sum, conn) => sum + conn.streams, 0);
        return connections.length > 0 ? (totalStreams / connections.length).toFixed(2) : 0;
    }
}

// Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² QUIC ÑÐµÑ€Ð²ÐµÑ€Ðµ
const monitor = new HTTP3Monitor();

socket.on('session', (session) => {
    const startTime = Date.now();
    
    session.on('secure', () => {
        const handshakeTime = Date.now() - startTime;
        
        monitor.recordConnection(session.id, {
            handshakeTime: handshakeTime,
            cipher: session.cipher,
            alpn: session.alpnProtocol
        });
    });
    
    session.on('stream', (stream) => {
        const streamStart = Date.now();
        let firstByteTime = null;
        let bytesReceived = 0;
        
        stream.on('data', (chunk) => {
            if (firstByteTime === null) {
                firstByteTime = Date.now() - streamStart;
            }
            bytesReceived += chunk.length;
        });
        
        stream.on('end', () => {
            const streamEnd = Date.now();
            
            monitor.recordStream(session.id, stream.id, {
                startTime: streamStart,
                endTime: streamEnd,
                duration: streamEnd - streamStart,
                bytes: bytesReceived,
                firstByteTime: firstByteTime,
                status: 'completed'
            });
        });
        
        stream.on('error', (err) => {
            monitor.recordError(session.id, err.code || 'UNKNOWN', err.message);
        });
    });
});

// API endpoint Ð´Ð»Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
app.get('/api/http3/metrics', (req, res) => {
    res.json(monitor.getStatistics());
});
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ ÐÐµÐ´ÐµÐ»Ñ 7

1. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ HTTP/3 ÑÐµÑ€Ð²ÐµÑ€ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Caddy Ð¸Ð»Ð¸ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Node.js
2. ÐŸÑ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ 0-RTT Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð¸ connection migration
3. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ comprehensive security headers Ð´Ð»Ñ HTTP/3
4. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ HTTP/3 Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
5. Ð¡Ñ€Ð°Ð²Ð½Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ HTTP/1.1, HTTP/2 Ð¸ HTTP/3 Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ…

### âœ… ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒÐ½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹

- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð¸Ñ QUIC Ð¾Ñ‚ TCP?
- [ ] ÐœÐ¾Ð¶ÐµÑ‚Ðµ Ð¾Ð±ÑŠÑÑÐ½Ð¸Ñ‚ÑŒ Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð° 0-RTT handshake?
- [ ] Ð—Ð½Ð°ÐµÑ‚Ðµ, ÐºÐ°Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ connection migration Ð² QUIC?
- [ ] Ð£Ð¼ÐµÐµÑ‚Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ HTTP/3 ÑÐµÑ€Ð²ÐµÑ€ Ð² production?
- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ security implications HTTP/3?

---

# ÐœÐ¾Ð´ÑƒÐ»ÑŒ 4: DNS Ð¸ ÑÐµÑ€Ð²Ð¸Ñ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ {#module-4}
*ÐÐµÐ´ÐµÐ»Ñ 8 | Ð’Ñ€ÐµÐ¼Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ: 8-10 Ñ‡Ð°ÑÐ¾Ð²*

## DNS Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ðµ Ð¿Ð¾Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: DNS ÐºÐ°Ðº ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¸Ð½Ñ„Ñ€Ð°ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°

DNS - ÑÑ‚Ð¾ Ð½Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ "Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ð½Ð°Ñ ÐºÐ½Ð¸Ð³Ð° Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ð°". Ð”Ð»Ñ backend-ÑÐ¸ÑÑ‚ÐµÐ¼ ÑÑ‚Ð¾:
- Service discovery Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼
- Load balancing Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚
- Failover ÑÐ¸ÑÑ‚ÐµÐ¼Ð°
- Security boundary

**ÐšÐ°Ð¶Ð´Ñ‹Ð¹ DNS Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ðº Ð²Ð°ÑˆÐµÐ¼Ñƒ API!**

### ðŸ“Š DNS Resolution Process

```
ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ DNS Resolution Chain:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Browser Cache (0ms)                                     â”‚
â”‚    â”œâ”€ Hit: api.example.com â†’ 93.184.216.34               â”‚
â”‚    â””â”€ Miss: Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð¿Ð¾Ð¸ÑÐº                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. OS Cache (1-2ms)                                       â”‚
â”‚    â”œâ”€ /etc/hosts check                                    â”‚
â”‚    â”œâ”€ System DNS cache                                    â”‚
â”‚    â””â”€ Miss: Ð¸Ð´ÐµÐ¼ Ðº DNS resolver                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. DNS Resolver (10-50ms)                                 â”‚
â”‚    â”œâ”€ ISP DNS Ð¸Ð»Ð¸ 8.8.8.8                                â”‚
â”‚    â”œâ”€ ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐµÑˆ resolver'Ð°                            â”‚
â”‚    â””â”€ Miss: Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ñ€ÐµÐºÑƒÑ€ÑÐ¸Ð²Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. Root Nameserver (50-100ms)                             â”‚
â”‚    Query: api.example.com                                  â”‚
â”‚    Response: ÑÐ¼. .com nameservers                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. TLD Nameserver (50-100ms)                              â”‚
â”‚    Query: api.example.com                                  â”‚
â”‚    Response: ÑÐ¼. example.com nameservers                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6. Authoritative Nameserver (20-80ms)                     â”‚
â”‚    Query: api.example.com                                  â”‚
â”‚    Response: A 93.184.216.34 TTL 300                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total: Ð¾Ñ‚ 0ms (cache hit) Ð´Ð¾ 300ms (cold resolution)
```

### ðŸ”§ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€: DNS Performance Monitoring

```python
import socket
import time
import dns.resolver
import dns.query
import dns.message
from concurrent.futures import ThreadPoolExecutor
import statistics

class DNSMonitor:
    def __init__(self):
        self.resolver = dns.resolver.Resolver()
        self.resolver.timeout = 5
        self.resolver.lifetime = 10
        
    def measure_dns_resolution(self, hostname, record_type='A'):
        """Ð˜Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ DNS Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ñ"""
        start_time = time.time()
        
        try:
            # DNS query
            answer = self.resolver.resolve(hostname, record_type)
            end_time = time.time()
            
            resolution_time = (end_time - start_time) * 1000  # Ð² Ð¼Ñ
            
            return {
                'hostname': hostname,
                'record_type': record_type,
                'resolution_time_ms': resolution_time,
                'success': True,
                'answers': [str(rdata) for rdata in answer],
                'ttl': answer.ttl
            }
            
        except Exception as e:
            end_time = time.time()
            return {
                'hostname': hostname,
                'record_type': record_type,
                'resolution_time_ms': (end_time - start_time) * 1000,
                'success': False,
                'error': str(e)
            }
    
    def test_dns_servers(self, hostname, dns_servers):
        """Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€Ð°Ð·Ð½Ñ‹Ñ… DNS ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð²"""
        results = []
        
        for dns_server in dns_servers:
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ resolver Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ DNS ÑÐµÑ€Ð²ÐµÑ€Ð°
            resolver = dns.resolver.Resolver()
            resolver.nameservers = [dns_server]
            resolver.timeout = 3
            
            start_time = time.time()
            
            try:
                answer = resolver.resolve(hostname, 'A')
                end_time = time.time()
                
                results.append({
                    'dns_server': dns_server,
                    'hostname': hostname,
                    'resolution_time_ms': (end_time - start_time) * 1000,
                    'success': True,
                    'answer': str(answer[0]),
                    'ttl': answer.ttl
                })
                
            except Exception as e:
                end_time = time.time()
                results.append({
                    'dns_server': dns_server,
                    'hostname': hostname,
                    'resolution_time_ms': (end_time - start_time) * 1000,
                    'success': False,
                    'error': str(e)
                })
        
        return results
    
    def trace_dns_resolution(self, hostname):
        """Ð¢Ñ€Ð°ÑÑÐ¸Ñ€Ð¾Ð²ÐºÐ° DNS Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¿Ð¾ Ð²ÑÐµÐ¹ Ñ†ÐµÐ¿Ð¾Ñ‡ÐºÐµ"""
        trace_results = []
        
        # 1. ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ root nameservers
        start_time = time.time()
        try:
            root_ns = self.resolver.resolve('.', 'NS')
            trace_results.append({
                'step': 'root_nameservers',
                'time_ms': (time.time() - start_time) * 1000,
                'servers': [str(ns) for ns in root_ns]
            })
        except Exception as e:
            trace_results.append({
                'step': 'root_nameservers',
                'error': str(e)
            })
        
        # 2. ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ TLD nameservers Ð´Ð»Ñ Ð´Ð¾Ð¼ÐµÐ½Ð°
        domain_parts = hostname.split('.')
        tld = '.'.join(domain_parts[-2:])  # example.com
        
        start_time = time.time()
        try:
            tld_ns = self.resolver.resolve(tld, 'NS')
            trace_results.append({
                'step': f'tld_nameservers_{tld}',
                'time_ms': (time.time() - start_time) * 1000,
                'servers': [str(ns) for ns in tld_ns]
            })
        except Exception as e:
            trace_results.append({
                'step': f'tld_nameservers_{tld}',
                'error': str(e)
            })
        
        # 3. Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ
        start_time = time.time()
        try:
            final_answer = self.resolver.resolve(hostname, 'A')
            trace_results.append({
                'step': 'final_resolution',
                'time_ms': (time.time() - start_time) * 1000,
                'answer': str(final_answer[0]),
                'ttl': final_answer.ttl
            })
        except Exception as e:
            trace_results.append({
                'step': 'final_resolution',
                'error': str(e)
            })
        
        return trace_results

# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ DNS Monitor
monitor = DNSMonitor()

# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
critical_services = [
    'api.example.com',
    'auth.example.com', 
    'db.example.com',
    'cache.example.com'
]

# ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ‹Ðµ DNS ÑÐµÑ€Ð²ÐµÑ€Ñ‹ Ð´Ð»Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ
dns_servers = [
    '8.8.8.8',        # Google
    '1.1.1.1',        # Cloudflare
    '208.67.222.222', # OpenDNS
    '9.9.9.9'         # Quad9
]

print("DNS Performance Analysis")
print("=" * 50)

for service in critical_services:
    print(f"\nTesting {service}:")
    
    # Ð¢ÐµÑÑ‚ Ñ€Ð°Ð·Ð½Ñ‹Ñ… DNS ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð²
    results = monitor.test_dns_servers(service, dns_servers)
    
    for result in results:
        if result['success']:
            print(f"  {result['dns_server']}: {result['resolution_time_ms']:.1f}ms (TTL: {result['ttl']}s)")
        else:
            print(f"  {result['dns_server']}: FAILED - {result['error']}")
    
    # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ ÑÐ°Ð¼Ñ‹Ð¹ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ DNS ÑÐµÑ€Ð²ÐµÑ€
    successful_results = [r for r in results if r['success']]
    if successful_results:
        fastest = min(successful_results, key=lambda x: x['resolution_time_ms'])
        print(f"  â†’ Fastest: {fastest['dns_server']} ({fastest['resolution_time_ms']:.1f}ms)")
```

### âš¡ DNS Caching Strategies

**ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ DNS ÐºÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ:**

```python
import redis
import json
import time
from functools import wraps

class DNSCache:
    def __init__(self, redis_client, default_ttl=300):
        self.redis = redis_client
        self.default_ttl = default_ttl
        self.cache_hits = 0
        self.cache_misses = 0
    
    def get_cached_dns(self, hostname, record_type='A'):
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ DNS Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð¸Ð· ÐºÐµÑˆÐ°"""
        cache_key = f"dns:{hostname}:{record_type}"
        
        try:
            cached_data = self.redis.get(cache_key)
            if cached_data:
                self.cache_hits += 1
                data = json.loads(cached_data)
                
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ðµ Ð¸ÑÑ‚ÐµÐº Ð»Ð¸ TTL
                if time.time() - data['cached_at'] < data['ttl']:
                    return data['answer']
                else:
                    # TTL Ð¸ÑÑ‚ÐµÐº, ÑƒÐ´Ð°Ð»ÑÐµÐ¼ Ð¸Ð· ÐºÐµÑˆÐ°
                    self.redis.delete(cache_key)
            
            self.cache_misses += 1
            return None
            
        except Exception as e:
            print(f"Cache error: {e}")
            self.cache_misses += 1
            return None
    
    def cache_dns(self, hostname, record_type, answer, ttl=None):
        """ÐšÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ DNS Ð·Ð°Ð¿Ð¸ÑÐ¸"""
        cache_key = f"dns:{hostname}:{record_type}"
        
        cache_data = {
            'answer': answer,
            'ttl': ttl or self.default_ttl,
            'cached_at': time.time(),
            'hostname': hostname,
            'record_type': record_type
        }
        
        try:
            # ÐšÐµÑˆÐ¸Ñ€ÑƒÐµÐ¼ Ð½Ð° Ð²Ñ€ÐµÐ¼Ñ TTL + 10% Ð±ÑƒÑ„ÐµÑ€
            cache_ttl = int((ttl or self.default_ttl) * 1.1)
            self.redis.setex(
                cache_key, 
                cache_ttl, 
                json.dumps(cache_data)
            )
        except Exception as e:
            print(f"Cache write error: {e}")
    
    def get_cache_stats(self):
        """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÐºÐµÑˆÐ°"""
        total_requests = self.cache_hits + self.cache_misses
        hit_rate = (self.cache_hits / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'cache_hits': self.cache_hits,
            'cache_misses': self.cache_misses,
            'hit_rate_percent': round(hit_rate, 2),
            'total_requests': total_requests
        }

def dns_cached(cache, ttl=300):
    """Ð”ÐµÐºÐ¾Ñ€Ð°Ñ‚Ð¾Ñ€ Ð´Ð»Ñ ÐºÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ DNS Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²"""
    def decorator(func):
        @wraps(func)
        def wrapper(hostname, record_type='A', *args, **kwargs):
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐµÑˆ
            cached_result = cache.get_cached_dns(hostname, record_type)
            if cached_result:
                return {
                    'hostname': hostname,
                    'record_type': record_type,
                    'answer': cached_result,
                    'cached': True,
                    'resolution_time_ms': 0  # Ð˜Ð· ÐºÐµÑˆÐ° Ð¼Ð³Ð½Ð¾Ð²ÐµÐ½Ð½Ð¾
                }
            
            # ÐšÐµÑˆÐ° Ð½ÐµÑ‚, Ð´ÐµÐ»Ð°ÐµÐ¼ DNS Ð·Ð°Ð¿Ñ€Ð¾Ñ
            result = func(hostname, record_type, *args, **kwargs)
            
            # ÐšÐµÑˆÐ¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
            if result.get('success') and result.get('answers'):
                cache.cache_dns(
                    hostname, 
                    record_type, 
                    result['answers'],
                    result.get('ttl', ttl)
                )
                result['cached'] = False
            
            return result
            
        return wrapper
    return decorator

# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ ÐºÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼
redis_client = redis.Redis(host='localhost', port=6379, db=0)
dns_cache = DNSCache(redis_client)

@dns_cached(dns_cache, ttl=600)
def resolve_hostname(hostname, record_type='A'):
    """DNS resolution Ñ ÐºÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼"""
    monitor = DNSMonitor()
    return monitor.measure_dns_resolution(hostname, record_type)

# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ ÐºÐµÑˆÐ°
print("Testing DNS Cache Efficiency:")
test_hostnames = ['api.example.com', 'google.com', 'github.com'] * 5

start_time = time.time()
for hostname in test_hostnames:
    result = resolve_hostname(hostname)
    cache_status = "HIT" if result.get('cached') else "MISS"
    print(f"{hostname}: {result.get('resolution_time_ms', 0):.1f}ms [{cache_status}]")

total_time = time.time() - start_time
cache_stats = dns_cache.get_cache_stats()

print(f"\nCache Statistics:")
print(f"Total time: {total_time:.2f}s")
print(f"Cache hit rate: {cache_stats['hit_rate_percent']}%")
print(f"Cache hits: {cache_stats['cache_hits']}")
print(f"Cache misses: {cache_stats['cache_misses']}")
```

### ðŸ”„ DNS Load Balancing

**DNS Round Robin Ð¸ Weighted Records:**

```python
import random
import time
from collections import defaultdict

class DNSLoadBalancer:
    def __init__(self):
        self.backends = {}
        self.health_checks = {}
        self.request_counts = defaultdict(int)
        self.response_times = defaultdict(list)
    
    def add_backend(self, hostname, backends_config):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ backend ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð² Ð´Ð»Ñ hostname"""
        self.backends[hostname] = backends_config
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ health checks
        for backend in backends_config:
            backend_ip = backend['ip']
            self.health_checks[backend_ip] = {
                'healthy': True,
                'last_check': time.time(),
                'failures': 0,
                'response_time': 0
            }
    
    def health_check(self, backend_ip, port=80):
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ backend ÑÐµÑ€Ð²ÐµÑ€Ð°"""
        import socket
        
        start_time = time.time()
        try:
            sock = socket.create_connection((backend_ip, port), timeout=5)
            sock.close()
            
            response_time = (time.time() - start_time) * 1000
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ
            self.health_checks[backend_ip].update({
                'healthy': True,
                'last_check': time.time(),
                'failures': 0,
                'response_time': response_time
            })
            
            return True
            
        except Exception as e:
            response_time = (time.time() - start_time) * 1000
            
            # Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÑÑ‡ÐµÑ‚Ñ‡Ð¸Ðº Ð½ÐµÑƒÐ´Ð°Ñ‡
            self.health_checks[backend_ip]['failures'] += 1
            self.health_checks[backend_ip]['last_check'] = time.time()
            self.health_checks[backend_ip]['response_time'] = response_time
            
            # ÐŸÐ¾Ð¼ÐµÑ‡Ð°ÐµÐ¼ ÐºÐ°Ðº Ð½ÐµÐ·Ð´Ð¾Ñ€Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾ÑÐ»Ðµ 3 Ð½ÐµÑƒÐ´Ð°Ñ‡
            if self.health_checks[backend_ip]['failures'] >= 3:
                self.health_checks[backend_ip]['healthy'] = False
            
            return False
    
    def get_backend_round_robin(self, hostname):
        """Round Robin Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ°"""
        if hostname not in self.backends:
            return None
        
        backends = self.backends[hostname]
        healthy_backends = [
            b for b in backends 
            if self.health_checks.get(b['ip'], {}).get('healthy', True)
        ]
        
        if not healthy_backends:
            # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ð·Ð´Ð¾Ñ€Ð¾Ð²Ñ‹Ñ… ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð², Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð»ÑŽÐ±Ð¾Ð¹
            healthy_backends = backends
        
        # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ round robin Ð¿Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
        selected = min(healthy_backends, key=lambda b: self.request_counts[b['ip']])
        self.request_counts[selected['ip']] += 1
        
        return selected['ip']
    
    def get_backend_weighted(self, hostname):
        """Weighted Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ°"""
        if hostname not in self.backends:
            return None
        
        backends = self.backends[hostname]
        healthy_backends = [
            b for b in backends 
            if self.health_checks.get(b['ip'], {}).get('healthy', True)
        ]
        
        if not healthy_backends:
            healthy_backends = backends
        
        # Weighted random selection
        total_weight = sum(b.get('weight', 1) for b in healthy_backends)
        random_weight = random.uniform(0, total_weight)
        
        current_weight = 0
        for backend in healthy_backends:
            current_weight += backend.get('weight', 1)
            if random_weight <= current_weight:
                self.request_counts[backend['ip']] += 1
                return backend['ip']
        
        # Fallback
        return healthy_backends[0]['ip']
    
    def get_backend_least_connections(self, hostname):
        """Least connections Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ°"""
        if hostname not in self.backends:
            return None
        
        backends = self.backends[hostname]
        healthy_backends = [
            b for b in backends 
            if self.health_checks.get(b['ip'], {}).get('healthy', True)
        ]
        
        if not healthy_backends:
            healthy_backends = backends
        
        # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ backend Ñ Ð½Ð°Ð¸Ð¼ÐµÐ½ÑŒÑˆÐ¸Ð¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        selected = min(healthy_backends, key=lambda b: self.request_counts[b['ip']])
        self.request_counts[selected['ip']] += 1
        
        return selected['ip']
    
    def get_backend_fastest_response(self, hostname):
        """Fastest response Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ°"""
        if hostname not in self.backends:
            return None
        
        backends = self.backends[hostname]
        healthy_backends = [
            b for b in backends 
            if self.health_checks.get(b['ip'], {}).get('healthy', True)
        ]
        
        if not healthy_backends:
            healthy_backends = backends
        
        # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ backend Ñ Ð»ÑƒÑ‡ÑˆÐ¸Ð¼ response time
        selected = min(
            healthy_backends, 
            key=lambda b: self.health_checks.get(b['ip'], {}).get('response_time', float('inf'))
        )
        self.request_counts[selected['ip']] += 1
        
        return selected['ip']
    
    def get_stats(self):
        """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°"""
        return {
            'backends': dict(self.backends),
            'health_checks': dict(self.health_checks),
            'request_counts': dict(self.request_counts),
            'total_requests': sum(self.request_counts.values())
        }

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° DNS Load Balancer
lb = DNSLoadBalancer()

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ backend ÑÐµÑ€Ð²ÐµÑ€Ñ‹ Ð´Ð»Ñ API
lb.add_backend('api.example.com', [
    {'ip': '10.0.1.10', 'weight': 3},  # Ð‘Ð¾Ð»ÐµÐµ Ð¼Ð¾Ñ‰Ð½Ñ‹Ð¹ ÑÐµÑ€Ð²ÐµÑ€
    {'ip': '10.0.1.11', 'weight': 2},  # Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ ÑÐµÑ€Ð²ÐµÑ€
    {'ip': '10.0.1.12', 'weight': 1},  # Ð¡Ð»Ð°Ð±Ñ‹Ð¹ ÑÐµÑ€Ð²ÐµÑ€
])

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ backend ÑÐµÑ€Ð²ÐµÑ€Ñ‹ Ð´Ð»Ñ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
lb.add_backend('db.example.com', [
    {'ip': '10.0.2.10', 'weight': 1},  # Primary DB
    {'ip': '10.0.2.11', 'weight': 1},  # Secondary DB
])

# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð²
print("Health checking backends...")
for hostname, backends in lb.backends.items():
    for backend in backends:
        is_healthy = lb.health_check(backend['ip'], 80)
        status = "HEALTHY" if is_healthy else "UNHEALTHY"
        print(f"{hostname} -> {backend['ip']}: {status}")

# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¾Ð² Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ¸
print("\nTesting load balancing algorithms:")

algorithms = {
    'round_robin': lb.get_backend_round_robin,
    'weighted': lb.get_backend_weighted,
    'least_connections': lb.get_backend_least_connections,
    'fastest_response': lb.get_backend_fastest_response
}

for alg_name, alg_func in algorithms.items():
    print(f"\n{alg_name.upper()}:")
    
    # Ð¡Ð±Ñ€Ð¾Ñ ÑÑ‡ÐµÑ‚Ñ‡Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ Ñ‡ÐµÑÑ‚Ð½Ð¾Ð³Ð¾ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ
    lb.request_counts.clear()
    
    # Ð”ÐµÐ»Ð°ÐµÐ¼ 20 Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
    for i in range(20):
        backend_ip = alg_func('api.example.com')
        print(f"  Request {i+1}: {backend_ip}")
    
    # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ
    print(f"  Distribution: {dict(lb.request_counts)}")
```

### ðŸŒ Service Discovery Ñ DNS

**Microservices Service Discovery:**

```python
import consul
import dns.resolver
import json
from typing import List, Dict, Optional

class ServiceDiscovery:
    def __init__(self, consul_host='localhost', consul_port=8500):
        self.consul = consul.Consul(host=consul_host, port=consul_port)
        self.dns_resolver = dns.resolver.Resolver()
        self.service_cache = {}
        
    def register_service(self, service_name: str, service_id: str, 
                        address: str, port: int, tags: List[str] = None,
                        health_check: Dict = None):
        """Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÐµÑ€Ð²Ð¸ÑÐ° Ð² Consul"""
        
        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° health check Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
        if health_check is None:
            health_check = {
                'http': f'http://{address}:{port}/health',
                'interval': '30s',
                'timeout': '10s',
                'deregister_critical_service_after': '60s'
            }
        
        # Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð² Consul
        self.consul.agent.service.register(
            name=service_name,
            service_id=service_id,
            address=address,
            port=port,
            tags=tags or [],
            check=health_check
        )
        
        print(f"Service registered: {service_name} ({service_id}) at {address}:{port}")
    
    def discover_service(self, service_name: str, tag: str = None) -> List[Dict]:
        """ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð² Ñ‡ÐµÑ€ÐµÐ· Consul"""
        try:
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð·Ð´Ð¾Ñ€Ð¾Ð²Ñ‹Ðµ ÑÐµÑ€Ð²Ð¸ÑÑ‹
            _, services = self.consul.health.service(
                service_name, 
                passing=True,  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð·Ð´Ð¾Ñ€Ð¾Ð²Ñ‹Ðµ
                tag=tag
            )
            
            discovered_services = []
            for service in services:
                service_info = service['Service']
                discovered_services.append({
                    'id': service_info['ID'],
                    'name': service_info['Service'],
                    'address': service_info['Address'],
                    'port': service_info['Port'],
                    'tags': service_info['Tags'],
                    'datacenter': service['Node']['Datacenter']
                })
            
            # ÐšÐµÑˆÐ¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
            cache_key = f"{service_name}:{tag or 'all'}"
            self.service_cache[cache_key] = {
                'services': discovered_services,
                'cached_at': time.time(),
                'ttl': 30  # 30 ÑÐµÐºÑƒÐ½Ð´ TTL
            }
            
            return discovered_services
            
        except Exception as e:
            print(f"Service discovery error: {e}")
            
            # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÐµÑˆ Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ
            cache_key = f"{service_name}:{tag or 'all'}"
            if cache_key in self.service_cache:
                cached = self.service_cache[cache_key]
                if time.time() - cached['cached_at'] < cached['ttl'] * 2:  # Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ð¹ TTL
                    print(f"Using cached services for {service_name}")
                    return cached['services']
            
            return []
    
    def discover_service_dns(self, service_name: str, domain: str = 'service.consul') -> List[str]:
        """ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð² Ñ‡ÐµÑ€ÐµÐ· DNS Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ðº Consul"""
        dns_name = f"{service_name}.{domain}"
        
        try:
            # SRV Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²
            srv_records = self.dns_resolver.resolve(dns_name, 'SRV')
            
            services = []
            for srv in srv_records:
                # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ A Ð·Ð°Ð¿Ð¸ÑÑŒ Ð´Ð»Ñ Ñ…Ð¾ÑÑ‚Ð°
                try:
                    a_records = self.dns_resolver.resolve(str(srv.target), 'A')
                    for a_record in a_records:
                        services.append({
                            'address': str(a_record),
                            'port': srv.port,
                            'priority': srv.priority,
                            'weight': srv.weight,
                            'target': str(srv.target)
                        })
                except:
                    continue
            
            return services
            
        except Exception as e:
            print(f"DNS service discovery error: {e}")
            return []
    
    def get_service_endpoint(self, service_name: str, load_balance: str = 'round_robin') -> Optional[str]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ endpoint ÑÐµÑ€Ð²Ð¸ÑÐ° Ñ Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ¾Ð¹ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸"""
        services = self.discover_service(service_name)
        
        if not services:
            return None
        
        if load_balance == 'round_robin':
            # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ round robin Ð¿Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
            cache_key = f"requests:{service_name}"
            if cache_key not in self.service_cache:
                self.service_cache[cache_key] = 0
            
            index = self.service_cache[cache_key] % len(services)
            self.service_cache[cache_key] += 1
            
            selected = services[index]
            
        elif load_balance == 'random':
            import random
            selected = random.choice(services)
            
        else:
            # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð¿ÐµÑ€Ð²Ñ‹Ð¹
            selected = services[0]
        
        return f"http://{selected['address']}:{selected['port']}"
    
    def health_check_service(self, service_name: str) -> Dict:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ Ð²ÑÐµÑ… Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð² ÑÐµÑ€Ð²Ð¸ÑÐ°"""
        services = self.discover_service(service_name)
        
        health_status = {
            'service_name': service_name,
            'total_instances': len(services),
            'healthy_instances': 0,
            'unhealthy_instances': 0,
            'instances': []
        }
        
        for service in services:
            try:
                # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾Ñ€Ñ‚Ð°
                import socket
                sock = socket.create_connection(
                    (service['address'], service['port']), 
                    timeout=5
                )
                sock.close()
                
                health_status['healthy_instances'] += 1
                health_status['instances'].append({
                    'id': service['id'],
                    'address': f"{service['address']}:{service['port']}",
                    'status': 'healthy'
                })
                
            except Exception as e:
                health_status['unhealthy_instances'] += 1
                health_status['instances'].append({
                    'id': service['id'],
                    'address': f"{service['address']}:{service['port']}",
                    'status': 'unhealthy',
                    'error': str(e)
                })
        
        return health_status

# ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Service Discovery
sd = ServiceDiscovery()

# Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÑ‹
services_to_register = [
    {
        'name': 'user-service',
        'id': 'user-service-1',
        'address': '10.0.1.10',
        'port': 8001,
        'tags': ['api', 'users', 'v1']
    },
    {
        'name': 'user-service',
        'id': 'user-service-2', 
        'address': '10.0.1.11',
        'port': 8001,
        'tags': ['api', 'users', 'v1']
    },
    {
        'name': 'order-service',
        'id': 'order-service-1',
        'address': '10.0.1.20',
        'port': 8002,
        'tags': ['api', 'orders', 'v1']
    },
    {
        'name': 'payment-service',
        'id': 'payment-service-1',
        'address': '10.0.1.30',
        'port': 8003,
        'tags': ['api', 'payments', 'v1', 'critical']
    }
]

print("Registering microservices...")
for service in services_to_register:
    sd.register_service(**service)

# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ service discovery
print("\nDiscovering services...")

for service_name in ['user-service', 'order-service', 'payment-service']:
    print(f"\n{service_name}:")
    
    # Ð§ÐµÑ€ÐµÐ· Consul API
    services = sd.discover_service(service_name)
    print(f"  Found {len(services)} instances via Consul API")
    
    for service in services:
        print(f"    {service['id']}: {service['address']}:{service['port']} {service['tags']}")
    
    # Ð§ÐµÑ€ÐµÐ· DNS
    dns_services = sd.discover_service_dns(service_name)
    print(f"  Found {len(dns_services)} instances via DNS")
    
    # ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ endpoint Ñ Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ¾Ð¹
    endpoint = sd.get_service_endpoint(service_name, 'round_robin')
    print(f"  Load balanced endpoint: {endpoint}")
    
    # Health check
    health = sd.health_check_service(service_name)
    print(f"  Health: {health['healthy_instances']}/{health['total_instances']} healthy")
```

### ðŸ“Š DNS Security Ð¸ Monitoring

**DNS over HTTPS (DoH) Ð¸ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³:**

```python
import requests
import base64
import json
import time
from urllib.parse import urlencode

class SecureDNSResolver:
    def __init__(self):
        self.doh_servers = {
            'cloudflare': 'https://cloudflare-dns.com/dns-query',
            'google': 'https://dns.google/dns-query',
            'quad9': 'https://dns.quad9.net/dns-query'
        }
        
        self.metrics = {
            'queries_total': 0,
            'queries_by_server': {},
            'response_times': {},
            'cache_hits': 0,
            'cache_misses': 0,
            'security_blocks': 0
        }
        
        # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ ÐºÐµÑˆ Ð´Ð»Ñ DoH Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
        self.cache = {}
    
    def query_doh(self, hostname: str, record_type: str = 'A', 
                  server: str = 'cloudflare') -> Dict:
        """DNS over HTTPS Ð·Ð°Ð¿Ñ€Ð¾Ñ"""
        
        if server not in self.doh_servers:
            raise ValueError(f"Unknown DoH server: {server}")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐµÑˆ
        cache_key = f"{hostname}:{record_type}:{server}"
        if cache_key in self.cache:
            cached_data = self.cache[cache_key]
            if time.time() - cached_data['cached_at'] < cached_data.get('ttl', 300):
                self.metrics['cache_hits'] += 1
                return {
                    'hostname': hostname,
                    'record_type': record_type,
                    'answers': cached_data['answers'],
                    'cached': True,
                    'server': server,
                    'response_time_ms': 0
                }
        
        self.metrics['cache_misses'] += 1
        
        doh_url = self.doh_servers[server]
        
        # ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð´Ð»Ñ DoH Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        params = {
            'name': hostname,
            'type': record_type,
            'do': 'false',  # DNSSEC Ð½Ðµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð°
            'cd': 'false'   # Checking disabled
        }
        
        headers = {
            'Accept': 'application/dns-json',
            'User-Agent': 'SecureDNSResolver/1.0'
        }
        
        start_time = time.time()
        
        try:
            response = requests.get(
                doh_url,
                params=params,
                headers=headers,
                timeout=10
            )
            
            response_time = (time.time() - start_time) * 1000
            
            if response.status_code == 200:
                dns_response = response.json()
                
                # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                self.metrics['queries_total'] += 1
                if server not in self.metrics['queries_by_server']:
                    self.metrics['queries_by_server'][server] = 0
                self.metrics['queries_by_server'][server] += 1
                
                if server not in self.metrics['response_times']:
                    self.metrics['response_times'][server] = []
                self.metrics['response_times'][server].append(response_time)
                
                # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹
                answers = []
                if 'Answer' in dns_response:
                    for answer in dns_response['Answer']:
                        answers.append({
                            'type': answer['type'],
                            'data': answer['data'],
                            'ttl': answer['TTL']
                        })
                
                # ÐšÐµÑˆÐ¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
                if answers:
                    min_ttl = min(answer['ttl'] for answer in answers)
                    self.cache[cache_key] = {
                        'answers': answers,
                        'ttl': min_ttl,
                        'cached_at': time.time()
                    }
                
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð° security Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ¸
                if dns_response.get('Status') == 3:  # NXDOMAIN Ð¾Ñ‚ security Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°
                    self.metrics['security_blocks'] += 1
                
                return {
                    'hostname': hostname,
                    'record_type': record_type,
                    'answers': answers,
                    'status': dns_response.get('Status', 0),
                    'cached': False,
                    'server': server,
                    'response_time_ms': response_time,
                    'truncated': dns_response.get('TC', False),
                    'authentic_data': dns_response.get('AD', False)
                }
            
            else:
                return {
                    'hostname': hostname,
                    'record_type': record_type,
                    'error': f"HTTP {response.status_code}: {response.text}",
                    'server': server,
                    'response_time_ms': response_time
                }
                
        except Exception as e:
            response_time = (time.time() - start_time) * 1000
            return {
                'hostname': hostname,
                'record_type': record_type,
                'error': str(e),
                'server': server,
                'response_time_ms': response_time
            }
    
    def security_scan(self, hostnames: List[str]) -> Dict:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð² Ð½Ð° malware/phishing Ñ‡ÐµÑ€ÐµÐ· secure DNS"""
        
        results = {
            'total_checked': len(hostnames),
            'clean': 0,
            'blocked': 0,
            'errors': 0,
            'details': []
        }
        
        for hostname in hostnames:
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Quad9 (Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÐµÑ‚ Ð²Ñ€ÐµÐ´Ð¾Ð½Ð¾ÑÐ½Ñ‹Ðµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹)
            result = self.query_doh(hostname, 'A', 'quad9')
            
            detail = {
                'hostname': hostname,
                'status': 'unknown'
            }
            
            if 'error' in result:
                results['errors'] += 1
                detail['status'] = 'error'
                detail['error'] = result['error']
            
            elif result.get('status') == 3:  # NXDOMAIN (Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ°)
                results['blocked'] += 1
                detail['status'] = 'blocked'
                detail['reason'] = 'Blocked by security filter'
            
            elif result.get('answers'):
                results['clean'] += 1
                detail['status'] = 'clean'
                detail['ip_addresses'] = [a['data'] for a in result['answers'] if a['type'] == 1]
            
            else:
                results['errors'] += 1
                detail['status'] = 'no_answer'
            
            results['details'].append(detail)
        
        return results
    
    def get_metrics(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº DNS resolver'Ð°"""
        
        # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ response times
        avg_response_times = {}
        for server, times in self.metrics['response_times'].items():
            if times:
                avg_response_times[server] = {
                    'avg_ms': sum(times) / len(times),
                    'min_ms': min(times),
                    'max_ms': max(times),
                    'queries': len(times)
                }
        
        cache_total = self.metrics['cache_hits'] + self.metrics['cache_misses']
        cache_hit_rate = (self.metrics['cache_hits'] / cache_total * 100) if cache_total > 0 else 0
        
        return {
            'total_queries': self.metrics['queries_total'],
            'queries_by_server': self.metrics['queries_by_server'],
            'avg_response_times': avg_response_times,
            'cache_hit_rate_percent': round(cache_hit_rate, 2),
            'cache_hits': self.metrics['cache_hits'],
            'cache_misses': self.metrics['cache_misses'],
            'security_blocks': self.metrics['security_blocks'],
            'cached_entries': len(self.cache)
        }

# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Secure DNS Resolver
resolver = SecureDNSResolver()

# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€Ð°Ð·Ð½Ñ‹Ñ… DoH ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð²
test_domains = [
    'api.example.com',
    'google.com',
    'github.com',
    'stackoverflow.com'
]

print("Testing DNS over HTTPS...")
print("=" * 40)

for domain in test_domains:
    print(f"\nResolving {domain}:")
    
    for server in ['cloudflare', 'google', 'quad9']:
        result = resolver.query_doh(domain, 'A', server)
        
        if 'error' not in result:
            ips = [a['data'] for a in result['answers'] if a['type'] == 1]
            cache_status = " [CACHED]" if result['cached'] else ""
            print(f"  {server}: {', '.join(ips)} ({result['response_time_ms']:.1f}ms){cache_status}")
        else:
            print(f"  {server}: ERROR - {result['error']}")

# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ security Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¹
print("\n\nTesting security scanning...")
suspicious_domains = [
    'google.com',           # Ð§Ð¸ÑÑ‚Ñ‹Ð¹ Ð´Ð¾Ð¼ÐµÐ½
    'malware.testing.google.test',  # Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ malware Ð´Ð¾Ð¼ÐµÐ½
    'phishing.testing.google.test'  # Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ phishing Ð´Ð¾Ð¼ÐµÐ½
]

security_results = resolver.security_scan(suspicious_domains)
print(f"Security scan results:")
print(f"  Total: {security_results['total_checked']}")
print(f"  Clean: {security_results['clean']}")
print(f"  Blocked: {security_results['blocked']}")
print(f"  Errors: {security_results['errors']}")

for detail in security_results['details']:
    print(f"  {detail['hostname']}: {detail['status']}")

# ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
print("\n\nDNS Resolver Metrics:")
metrics = resolver.get_metrics()
print(json.dumps(metrics, indent=2))
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ

1. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ DNS ÐºÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ñ Redis
2. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ DNS load balancing Ð´Ð»Ñ Ð²Ð°ÑˆÐ¸Ñ… API endpoints
3. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Service Discovery Ñ Consul Ð´Ð»Ñ Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
4. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ DNS Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
5. ÐŸÑ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ DNS over HTTPS Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ñ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸

### âœ… ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒÐ½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹

- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ Ð²Ð»Ð¸ÑÐ½Ð¸Ðµ DNS Ð½Ð° Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ API?
- [ ] ÐœÐ¾Ð¶ÐµÑ‚Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ðµ DNS ÐºÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ?
- [ ] Ð—Ð½Ð°ÐµÑ‚Ðµ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹ DNS load balancing?
- [ ] Ð£Ð¼ÐµÐµÑ‚Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ DNS Ð´Ð»Ñ service discovery?
- [ ] ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚Ðµ Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ DNS security Ð¸ DoH?

---

# ÐœÐ¾Ð´ÑƒÐ»ÑŒ 5: ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ {#module-5}
*ÐÐµÐ´ÐµÐ»Ð¸ 9-10 | Ð’Ñ€ÐµÐ¼Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ: 16-20 Ñ‡Ð°ÑÐ¾Ð²*

## ÐÐµÐ´ÐµÐ»Ñ 9: Ð¡ÐµÑ‚ÐµÐ²Ð°Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: Latency vs Throughput - ÐºÐ»ÑŽÑ‡ÐµÐ²Ð¾Ðµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ

**Latency** (Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°) - Ð²Ñ€ÐµÐ¼Ñ Ð¾Ñ‚ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð´Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
**Throughput** (Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ½Ð°Ñ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÑŒ) - ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² ÐµÐ´Ð¸Ð½Ð¸Ñ†Ñƒ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸

```
ÐÐ½Ð°Ð»Ð¾Ð³Ð¸Ñ Ñ Ñ‚Ñ€ÑƒÐ±Ð¾Ð¹:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Latency = Ð²Ñ€ÐµÐ¼Ñ Ð¿Ñ€Ð¾Ñ…Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ ÐºÐ°Ð¿Ð»Ð¸ Ð¾Ñ‚ Ð½Ð°Ñ‡Ð°Ð»Ð° Ð´Ð¾ ÐºÐ¾Ð½Ñ†Ð° Ñ‚Ñ€ÑƒÐ±Ñ‹ â”‚
â”‚ Throughput = Ð¾Ð±ÑŠÐµÐ¼ Ð²Ð¾Ð´Ñ‹, Ð¿Ñ€Ð¾Ñ…Ð¾Ð´ÑÑ‰Ð¸Ð¹ Ñ‡ÐµÑ€ÐµÐ· Ñ‚Ñ€ÑƒÐ±Ñƒ Ð² ÑÐµÐºÑƒÐ½Ð´Ñƒ  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ÐœÐ¾Ð¶Ð½Ð¾ Ð¸Ð¼ÐµÑ‚ÑŒ:                                                â”‚
â”‚ â€¢ Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹ throughput, Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¹ latency (Ñ‚Ð¾Ð»ÑÑ‚Ð°Ñ Ð´Ð»Ð¸Ð½Ð½Ð°Ñ)    â”‚
â”‚ â€¢ ÐÐ¸Ð·ÐºÐ¸Ð¹ throughput, Ð½Ð¸Ð·ÐºÐ¸Ð¹ latency (Ñ‚Ð¾Ð½ÐºÐ°Ñ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ°Ñ)      â”‚
â”‚ â€¢ Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹ throughput, Ð½Ð¸Ð·ÐºÐ¸Ð¹ latency (Ñ‚Ð¾Ð»ÑÑ‚Ð°Ñ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ°Ñ)    â”‚
â”‚ â€¢ ÐÐ¸Ð·ÐºÐ¸Ð¹ throughput, Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¹ latency (Ñ‚Ð¾Ð½ÐºÐ°Ñ Ð´Ð»Ð¸Ð½Ð½Ð°Ñ)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ“Š Ð˜Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº

**Comprehensive Network Performance Monitor:**

```python
import time
import socket
import subprocess
import threading
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed
import psutil
import requests
from dataclasses import dataclass
from typing import List, Dict, Optional
import json

@dataclass
class NetworkMetrics:
    timestamp: float
    latency_ms: float
    throughput_mbps: float
    packet_loss_percent: float
    jitter_ms: float
    bandwidth_utilization_percent: float

class NetworkPerformanceMonitor:
    def __init__(self):
        self.metrics_history = []
        self.baseline_metrics = None
        
    def measure_latency(self, host: str, port: int = 80, samples: int = 10) -> Dict:
        """Ð˜Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ latency Ñ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¾Ð±Ð°Ð¼Ð¸"""
        latencies = []
        successful_connections = 0
        
        for i in range(samples):
            start_time = time.time()
            try:
                sock = socket.create_connection((host, port), timeout=10)
                sock.close()
                
                latency = (time.time() - start_time) * 1000  # Ð² Ð¼Ñ
                latencies.append(latency)
                successful_connections += 1
                
            except Exception as e:
                # Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð½ÐµÑƒÐ´Ð°Ñ‡Ð½Ñ‹Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ ÐºÐ°Ðº Ð¾Ñ‡ÐµÐ½ÑŒ Ð±Ð¾Ð»ÑŒÑˆÑƒÑŽ latency
                latencies.append(10000)  # 10 ÑÐµÐºÑƒÐ½Ð´ timeout
            
            # ÐÐµÐ±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð¿Ð°ÑƒÐ·Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ñ€Ð¾Ð±Ð°Ð¼Ð¸
            time.sleep(0.1)
        
        if latencies:
            return {
                'min_ms': min(latencies),
                'max_ms': max(latencies),
                'avg_ms': statistics.mean(latencies),
                'median_ms': statistics.median(latencies),
                'p95_ms': statistics.quantiles(latencies, n=20)[18] if len(latencies) > 1 else latencies[0],
                'jitter_ms': statistics.stdev(latencies) if len(latencies) > 1 else 0,
                'success_rate': (successful_connections / samples) * 100,
                'samples': samples
            }
        else:
            return None
    
    def measure_throughput(self, url: str, duration_seconds: int = 30) -> Dict:
        """Ð˜Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ throughput Ñ‡ÐµÑ€ÐµÐ· HTTP download"""
        
        start_time = time.time()
        total_bytes = 0
        chunk_times = []
        
        try:
            response = requests.get(url, stream=True, timeout=duration_seconds + 10)
            response.raise_for_status()
            
            chunk_start = time.time()
            
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    chunk_end = time.time()
                    chunk_time = chunk_end - chunk_start
                    
                    total_bytes += len(chunk)
                    chunk_times.append(chunk_time)
                    
                    chunk_start = chunk_end
                    
                    # ÐŸÑ€ÐµÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ð¾ÑÐ»Ðµ Ð·Ð°Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
                    if time.time() - start_time >= duration_seconds:
                        break
            
            total_time = time.time() - start_time
            
            if total_time > 0:
                throughput_bps = total_bytes / total_time
                throughput_mbps = throughput_bps / (1024 * 1024)
                
                return {
                    'throughput_mbps': throughput_mbps,
                    'throughput_bps': throughput_bps,
                    'total_bytes': total_bytes,
                    'duration_seconds': total_time,
                    'avg_chunk_time_ms': statistics.mean(chunk_times) * 1000 if chunk_times else 0,
                    'chunks_received': len(chunk_times)
                }
            
        except Exception as e:
            return {
                'error': str(e),
                'throughput_mbps': 0
            }
        
        return {'throughput_mbps': 0}
    
    def measure_packet_loss(self, host: str, count: int = 100) -> float:
        """Ð˜Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ packet loss Ñ‡ÐµÑ€ÐµÐ· ping"""
        try:
            result = subprocess.run(
                ['ping', '-c', str(count), host],
                capture_output=True,
                text=True,
                timeout=count + 30
            )
            
            output = result.stdout
            
            # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð²Ñ‹Ð²Ð¾Ð´ ping Ð´Ð»Ñ packet loss
            for line in output.split('\n'):
                if 'packet loss' in line:
                    # Ð˜Ñ‰ÐµÐ¼ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚ Ð¿Ð¾Ñ‚ÐµÑ€ÑŒ
                    parts = line.split()
                    for i, part in enumerate(parts):
                        if '%' in part and 'loss' in parts[i+1:i+2]:
                            return float(part.replace('%', ''))
            
            return 0.0
            
        except Exception as e:
            print(f"Packet loss measurement error: {e}")
            return 100.0  # ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ñ‚ÐµÑ€Ð¸ Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ
    
    def measure_bandwidth_utilization(self) -> Dict:
        """Ð˜Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ bandwidth ÑÐµÑ‚ÐµÐ²Ð¾Ð³Ð¾ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°"""
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð´Ð¾ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ñ
        net_stats_before = psutil.net_io_counters()
        time_before = time.time()
        
        # Ð–Ð´ÐµÐ¼ ÑÐµÐºÑƒÐ½Ð´Ñƒ Ð´Ð»Ñ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ñ
        time.sleep(1)
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾ÑÐ»Ðµ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ñ
        net_stats_after = psutil.net_io_counters()
        time_after = time.time()
        
        time_delta = time_after - time_before
        
        # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚Ð¸
        bytes_sent_per_sec = (net_stats_after.bytes_sent - net_stats_before.bytes_sent) / time_delta
        bytes_recv_per_sec = (net_stats_after.bytes_recv - net_stats_before.bytes_recv) / time_delta
        
        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² Mbps
        upload_mbps = (bytes_sent_per_sec * 8) / (1024 * 1024)
        download_mbps = (bytes_recv_per_sec * 8) / (1024 * 1024)
        
        return {
            'upload_mbps': upload_mbps,
            'download_mbps': download_mbps,
            'total_mbps': upload_mbps + download_mbps,
            'bytes_sent_per_sec': bytes_sent_per_sec,
            'bytes_recv_per_sec': bytes_recv_per_sec,
            'packets_sent': net_stats_after.packets_sent - net_stats_before.packets_sent,
            'packets_recv': net_stats_after.packets_recv - net_stats_before.packets_recv
        }
    
    def comprehensive_network_test(self, target_host: str, test_url: str = None) -> Dict:
        """ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ð¾Ðµ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÐµÑ‚ÐµÐ²Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
        
        print(f"Starting comprehensive network test for {target_host}...")
        
        results = {
            'target_host': target_host,
            'timestamp': time.time(),
            'tests': {}
        }
        
        # 1. Latency Ñ‚ÐµÑÑ‚
        print("  Testing latency...")
        latency_results = self.measure_latency(target_host)
        if latency_results:
            results['tests']['latency'] = latency_results
            print(f"    Avg latency: {latency_results['avg_ms']:.1f}ms")
            print(f"    P95 latency: {latency_results['p95_ms']:.1f}ms")
            print(f"    Jitter: {latency_results['jitter_ms']:.1f}ms")
        
        # 2. Packet loss Ñ‚ÐµÑÑ‚
        print("  Testing packet loss...")
        packet_loss = self.measure_packet_loss(target_host)
        results['tests']['packet_loss'] = {
            'loss_percent': packet_loss
        }
        print(f"    Packet loss: {packet_loss}%")
        
        # 3. Throughput Ñ‚ÐµÑÑ‚ (ÐµÑÐ»Ð¸ URL Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½)
        if test_url:
            print("  Testing throughput...")
            throughput_results = self.measure_throughput(test_url, 10)
            results['tests']['throughput'] = throughput_results
            if 'throughput_mbps' in throughput_results:
                print(f"    Throughput: {throughput_results['throughput_mbps']:.2f} Mbps")
        
        # 4. Bandwidth utilization
        print("  Measuring bandwidth utilization...")
        bandwidth_results = self.measure_bandwidth_utilization()
        results['tests']['bandwidth'] = bandwidth_results
        print(f"    Current usage: {bandwidth_results['total_mbps']:.2f} Mbps")
        
        # 5. ÐÐ½Ð°Ð»Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        analysis = self.analyze_performance(results)
        results['analysis'] = analysis
        
        return results
    
    def analyze_performance(self, test_results: Dict) -> Dict:
        """ÐÐ½Ð°Ð»Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
        
        analysis = {
            'performance_score': 100,  # ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ ÑÐ¾ 100%
            'issues': [],
            'recommendations': []
        }
        
        tests = test_results.get('tests', {})
        
        # ÐÐ½Ð°Ð»Ð¸Ð· latency
        if 'latency' in tests:
            latency = tests['latency']
            avg_latency = latency.get('avg_ms', 0)
            jitter = latency.get('jitter_ms', 0)
            
            if avg_latency > 200:
                analysis['performance_score'] -= 30
                analysis['issues'].append(f"High latency: {avg_latency:.1f}ms (>200ms)")
                analysis['recommendations'].append("Consider using CDN or closer servers")
            
            elif avg_latency > 100:
                analysis['performance_score'] -= 15
                analysis['issues'].append(f"Moderate latency: {avg_latency:.1f}ms (>100ms)")
                analysis['recommendations'].append("Optimize server response time")
            
            if jitter > 50:
                analysis['performance_score'] -= 20
                analysis['issues'].append(f"High jitter: {jitter:.1f}ms (>50ms)")
                analysis['recommendations'].append("Check network stability")
        
        # ÐÐ½Ð°Ð»Ð¸Ð· packet loss
        if 'packet_loss' in tests:
            packet_loss = tests['packet_loss'].get('loss_percent', 0)
            
            if packet_loss > 5:
                analysis['performance_score'] -= 40
                analysis['issues'].append(f"High packet loss: {packet_loss}% (>5%)")
                analysis['recommendations'].append("Check network infrastructure")
            
            elif packet_loss > 1:
                analysis['performance_score'] -= 20
                analysis['issues'].append(f"Moderate packet loss: {packet_loss}% (>1%)")
                analysis['recommendations'].append("Monitor network quality")
        
        # ÐÐ½Ð°Ð»Ð¸Ð· throughput
        if 'throughput' in tests:
            throughput = tests['throughput'].get('throughput_mbps', 0)
            
            if throughput < 1:
                analysis['performance_score'] -= 25
                analysis['issues'].append(f"Low throughput: {throughput:.2f} Mbps (<1 Mbps)")
                analysis['recommendations'].append("Check bandwidth limitations")
            
            elif throughput < 10:
                analysis['performance_score'] -= 10
                analysis['issues'].append(f"Moderate throughput: {throughput:.2f} Mbps (<10 Mbps)")
                analysis['recommendations'].append("Consider bandwidth upgrade")
        
        # ÐžÐ±Ñ‰Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ°
        if analysis['performance_score'] >= 90:
            analysis['overall_rating'] = 'Excellent'
        elif analysis['performance_score'] >= 70:
            analysis['overall_rating'] = 'Good'
        elif analysis['performance_score'] >= 50:
            analysis['overall_rating'] = 'Fair'
        else:
            analysis['overall_rating'] = 'Poor'
        
        return analysis
    
    def continuous_monitoring(self, targets: List[str], interval_seconds: int = 60):
        """ÐÐµÐ¿Ñ€ÐµÑ€Ñ‹Ð²Ð½Ñ‹Ð¹ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÐµÑ‚ÐµÐ²Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
        
        print(f"Starting continuous monitoring of {len(targets)} targets...")
        print(f"Monitoring interval: {interval_seconds} seconds")
        
        while True:
            timestamp = time.time()
            print(f"\n--- Monitoring cycle at {time.strftime('%Y-%m-%d %H:%M:%S')} ---")
            
            for target in targets:
                try:
                    # Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ñ‚ÐµÑÑ‚ latency
                    latency_result = self.measure_latency(target, samples=5)
                    
                    if latency_result:
                        avg_latency = latency_result['avg_ms']
                        jitter = latency_result['jitter_ms']
                        success_rate = latency_result['success_rate']
                        
                        status = "OK"
                        if avg_latency > 200 or jitter > 50 or success_rate < 90:
                            status = "DEGRADED"
                        if avg_latency > 500 or success_rate < 50:
                            status = "CRITICAL"
                        
                        print(f"{target}: {avg_latency:.1f}ms (Â±{jitter:.1f}ms) [{status}]")
                        
                        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                        metric = NetworkMetrics(
                            timestamp=timestamp,
                            latency_ms=avg_latency,
                            throughput_mbps=0,  # ÐÐµ Ð¸Ð·Ð¼ÐµÑ€ÑÐµÐ¼ throughput Ð² continuous Ñ€ÐµÐ¶Ð¸Ð¼Ðµ
                            packet_loss_percent=0,
                            jitter_ms=jitter,
                            bandwidth_utilization_percent=0
                        )
                        self.metrics_history.append(metric)
                    
                except Exception as e:
                    print(f"{target}: ERROR - {e}")
            
            # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¼Ð¸ 1000 Ð·Ð°Ð¿Ð¸ÑÑÐ¼Ð¸
            if len(self.metrics_history) > 1000:
                self.metrics_history = self.metrics_history[-1000:]
            
            time.sleep(interval_seconds)

# ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ
monitor = NetworkPerformanceMonitor()

# Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
critical_services = [
    {
        'name': 'API Server',
        'host': 'api.example.com',
        'test_url': 'https://api.example.com/health'
    },
    {
        'name': 'Database',
        'host': 'db.example.com',
        'test_url': None
    },
    {
        'name': 'CDN',
        'host': 'cdn.example.com',
        'test_url': 'https://cdn.example.com/test.jpg'
    }
]

print("Network Performance Testing Suite")
print("=" * 50)

for service in critical_services:
    print(f"\nðŸ” Testing {service['name']} ({service['host']}):")
    
    results = monitor.comprehensive_network_test(
        service['host'], 
        service['test_url']
    )
    
    # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·
    analysis = results['analysis']
    print(f"\nðŸ“Š Performance Analysis:")
    print(f"  Overall Rating: {analysis['overall_rating']}")
    print(f"  Performance Score: {analysis['performance_score']}/100")
    
    if analysis['issues']:
        print(f"  Issues Found:")
        for issue in analysis['issues']:
            print(f"    âš ï¸ {issue}")
    
    if analysis['recommendations']:
        print(f"  Recommendations:")
        for rec in analysis['recommendations']:
            print(f"    ðŸ’¡ {rec}")
    
    print("-" * 50)

# Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð´Ð»Ñ Ð´Ð°Ð»ÑŒÐ½ÐµÐ¹ÑˆÐµÐ³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
results_file = f"network_performance_{int(time.time())}.json"
with open(results_file, 'w') as f:
    json.dump({
        'timestamp': time.time(),
        'services_tested': len(critical_services),
        'test_results': [
            monitor.comprehensive_network_test(service['host'], service['test_url']) 
            for service in critical_services
        ]
    }, f, indent=2)

print(f"\nðŸ“ Results saved to: {results_file}")
```

### âš¡ TCP Tuning Ð´Ð»Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸

**ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ TCP Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð½Ð° production ÑÐµÑ€Ð²ÐµÑ€Ð°Ñ…:**

```bash
#!/bin/bash
# tcp_optimization.sh - Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ TCP Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²

echo "ðŸ”§ Optimizing TCP parameters for high-performance backend servers"

# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ backup Ñ‚ÐµÐºÑƒÑ‰Ð¸Ñ… Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº
echo "ðŸ“‹ Creating backup of current settings..."
sysctl -a | grep -E "(tcp|net\.core)" > /tmp/tcp_settings_backup_$(date +%s).txt

# TCP Buffer Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
echo "ðŸš€ Optimizing TCP buffers..."

# Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€Ñ‹ Ð±ÑƒÑ„ÐµÑ€Ð¾Ð² (128MB)
sysctl -w net.core.rmem_max=134217728
sysctl -w net.core.wmem_max=134217728

# TCP socket Ð±ÑƒÑ„ÐµÑ€Ñ‹: min default max (Ð² Ð±Ð°Ð¹Ñ‚Ð°Ñ…)
# min: 64KB, default: 1MB, max: 128MB
sysctl -w net.ipv4.tcp_rmem="65536 1048576 134217728"
sysctl -w net.ipv4.tcp_wmem="65536 1048576 134217728"

# Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð±ÑƒÑ„ÐµÑ€Ñ‹ Ð´Ð»Ñ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²
sysctl -w net.core.netdev_max_backlog=30000
sysctl -w net.core.netdev_budget=600

echo "âš¡ Optimizing TCP congestion control..."

# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ BBR congestion control (ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½)
if sysctl net.ipv4.tcp_available_congestion_control | grep -q bbr; then
    sysctl -w net.ipv4.tcp_congestion_control=bbr
    echo "âœ… BBR congestion control enabled"
else
    # Fallback Ðº cubic
    sysctl -w net.ipv4.tcp_congestion_control=cubic
    echo "âš ï¸ BBR not available, using cubic"
fi

echo "ðŸ”„ Optimizing connection handling..."

# Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ð² Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸
sysctl -w net.core.somaxconn=65535

# ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ TIME_WAIT ÑÐ¾ÐºÐµÑ‚Ð¾Ð²
sysctl -w net.ipv4.tcp_tw_reuse=1
sysctl -w net.ipv4.tcp_fin_timeout=15

# Ð‘Ñ‹ÑÑ‚Ñ€Ð¾Ðµ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ€Ñ‚Ð²Ñ‹Ñ… ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
sysctl -w net.ipv4.tcp_keepalive_time=600
sysctl -w net.ipv4.tcp_keepalive_intvl=60
sysctl -w net.ipv4.tcp_keepalive_probes=3

echo "ðŸ›¡ï¸ Optimizing security and stability..."

# Ð—Ð°Ñ‰Ð¸Ñ‚Ð° Ð¾Ñ‚ SYN flood Ð°Ñ‚Ð°Ðº
sysctl -w net.ipv4.tcp_max_syn_backlog=65535
sysctl -w net.ipv4.tcp_syncookies=1

# ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð½Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð²
sysctl -w net.ipv4.ip_local_port_range="1024 65535"
sysctl -w net.ipv4.tcp_max_tw_buckets=1440000

echo "ðŸ“Š Optimizing for high throughput..."

# Disable slow start after idle
sysctl -w net.ipv4.tcp_slow_start_after_idle=0

# Enable window scaling
sysctl -w net.ipv4.tcp_window_scaling=1

# Enable timestamps
sysctl -w net.ipv4.tcp_timestamps=1

# Enable SACK
sysctl -w net.ipv4.tcp_sack=1

echo "ðŸ’¾ Making settings persistent..."

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² /etc/sysctl.conf Ð´Ð»Ñ Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ
cat >> /etc/sysctl.conf << 'EOF'

# High-performance TCP settings for backend servers
# Generated by tcp_optimization.sh

# TCP Buffer optimization
net.core.rmem_max = 134217728
net.core.wmem_max = 134217728
net.ipv4.tcp_rmem = 65536 1048576 134217728
net.ipv4.tcp_wmem = 65536 1048576 134217728

# Network device buffers
net.core.netdev_max_backlog = 30000
net.core.netdev_budget = 600

# Connection handling
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 65535

# TIME_WAIT optimization
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 15

# Keep-alive optimization
net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_keepalive_intvl = 60
net.ipv4.tcp_keepalive_probes = 3

# Security
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_tw_buckets = 1440000

# Performance
net.ipv4.ip_local_port_range = 1024 65535
net.ipv4.tcp_slow_start_after_idle = 0
net.ipv4.tcp_window_scaling = 1
net.ipv4.tcp_timestamps = 1
net.ipv4.tcp_sack = 1

EOF

echo "âœ… TCP optimization completed!"
echo "ðŸ“Š Current TCP settings summary:"

# ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
echo "Buffer sizes:"
echo "  Max receive buffer: $(sysctl -n net.core.rmem_max) bytes"
echo "  Max send buffer: $(sysctl -n net.core.wmem_max) bytes"
echo "  TCP receive buffers: $(sysctl -n net.ipv4.tcp_rmem)"
echo "  TCP send buffers: $(sysctl -n net.ipv4.tcp_wmem)"

echo "Connection limits:"
echo "  Max connections queue: $(sysctl -n net.core.somaxconn)"
echo "  Max SYN backlog: $(sysctl -n net.ipv4.tcp_max_syn_backlog)"

echo "Congestion control:"
echo "  Algorithm: $(sysctl -n net.ipv4.tcp_congestion_control)"

echo ""
echo "ðŸ”„ Reboot required for some changes to take full effect"
echo "ðŸ“ Backup of previous settings saved to /tmp/tcp_settings_backup_*.txt"
```

**ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ TCP Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸:**

```python
import subprocess
import re
import time
import json
from typing import Dict, List

class TCPPerformanceMonitor:
    def __init__(self):
        self.metrics_history = []
    
    def get_tcp_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ð¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ TCP"""
        
        stats = {}
        
        try:
            # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° TCP ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
            ss_output = subprocess.check_output(['ss', '-s'], text=True)
            
            # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð²Ñ‹Ð²Ð¾Ð´ ss -s
            for line in ss_output.split('\n'):
                if 'TCP:' in line:
                    # TCP: 1234 (estab 856, closed 234, orphaned 12, synrecv 0, timewait 132/0)
                    numbers = re.findall(r'\d+', line)
                    if len(numbers) >= 6:
                        stats['tcp_total'] = int(numbers[0])
                        stats['tcp_established'] = int(numbers[1])
                        stats['tcp_closed'] = int(numbers[2])
                        stats['tcp_orphaned'] = int(numbers[3])
                        stats['tcp_synrecv'] = int(numbers[4])
                        stats['tcp_timewait'] = int(numbers[5])
        
        except Exception as e:
            print(f"Error getting TCP stats: {e}")
        
        try:
            # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° netstat
            netstat_output = subprocess.check_output(['netstat', '-s'], text=True)
            
            tcp_section = False
            for line in netstat_output.split('\n'):
                line = line.strip()
                
                if line.startswith('Tcp:'):
                    tcp_section = True
                    continue
                elif line.startswith(('Udp:', 'Icmp:', 'Ip:')):
                    tcp_section = False
                    continue
                
                if tcp_section and line:
                    # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ TCP Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                    if 'segments received' in line:
                        stats['tcp_segments_received'] = int(re.search(r'(\d+)', line).group(1))
                    elif 'segments sent out' in line:
                        stats['tcp_segments_sent'] = int(re.search(r'(\d+)', line).group(1))
                    elif 'bad segments received' in line:
                        stats['tcp_bad_segments'] = int(re.search(r'(\d+)', line).group(1))
                    elif 'segments retransmitted' in line:
                        stats['tcp_retransmissions'] = int(re.search(r'(\d+)', line).group(1))
                    elif 'connections established' in line:
                        stats['tcp_connections_established'] = int(re.search(r'(\d+)', line).group(1))
                    elif 'failed connection attempts' in line:
                        stats['tcp_failed_connections'] = int(re.search(r'(\d+)', line).group(1))
        
        except Exception as e:
            print(f"Error getting netstat data: {e}")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        try:
            # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð±ÑƒÑ„ÐµÑ€Ð°Ñ…
            with open('/proc/sys/net/core/rmem_max', 'r') as f:
                stats['rmem_max'] = int(f.read().strip())
            
            with open('/proc/sys/net/core/wmem_max', 'r') as f:
                stats['wmem_max'] = int(f.read().strip())
            
            # TCP congestion control
            with open('/proc/sys/net/ipv4/tcp_congestion_control', 'r') as f:
                stats['congestion_control'] = f.read().strip()
        
        except Exception as e:
            print(f"Error reading system TCP settings: {e}")
        
        stats['timestamp'] = time.time()
        return stats
    
    def calculate_tcp_efficiency(self, stats: Dict) -> Dict:
        """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ TCP"""
        
        efficiency = {}
        
        # ÐšÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ Ñ€ÐµÑ‚Ñ€Ð°Ð½ÑÐ¼Ð¸ÑÑÐ¸Ð¸
        if 'tcp_segments_sent' in stats and 'tcp_retransmissions' in stats:
            if stats['tcp_segments_sent'] > 0:
                retrans_rate = (stats['tcp_retransmissions'] / stats['tcp_segments_sent']) * 100
                efficiency['retransmission_rate_percent'] = retrans_rate
                
                # ÐžÑ†ÐµÐ½ÐºÐ° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° ÑÐµÑ‚Ð¸
                if retrans_rate < 0.1:
                    efficiency['network_quality'] = 'Excellent'
                elif retrans_rate < 0.5:
                    efficiency['network_quality'] = 'Good'
                elif retrans_rate < 1.0:
                    efficiency['network_quality'] = 'Fair'
                else:
                    efficiency['network_quality'] = 'Poor'
        
        # ÐšÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        if 'tcp_connections_established' in stats and 'tcp_failed_connections' in stats:
            total_attempts = stats['tcp_connections_established'] + stats['tcp_failed_connections']
            if total_attempts > 0:
                success_rate = (stats['tcp_connections_established'] / total_attempts) * 100
                efficiency['connection_success_rate_percent'] = success_rate
        
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²
        if 'tcp_established' in stats:
            # ÐŸÑ€ÐµÐ´Ð¿Ð¾Ð»Ð°Ð³Ð°ÐµÐ¼ Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 65535 Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²
            port_utilization = (stats['tcp_established'] / 65535) * 100
            efficiency['port_utilization_percent'] = port_utilization
            
            if port_utilization > 80:
                efficiency['port_warning'] = 'High port utilization - consider port reuse optimization'
        
        # TIME_WAIT Ð°Ð½Ð°Ð»Ð¸Ð·
        if 'tcp_timewait' in stats and 'tcp_established' in stats:
            if stats['tcp_established'] > 0:
                timewait_ratio = stats['tcp_timewait'] / stats['tcp_established']
                efficiency['timewait_ratio'] = timewait_ratio
                
                if timewait_ratio > 0.5:
                    efficiency['timewait_warning'] = 'High TIME_WAIT ratio - consider tcp_tw_reuse'
        
        return efficiency
    
    def monitor_tcp_performance(self, duration_minutes: int = 5):
        """ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ TCP Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð² Ñ‚ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸"""
        
        print(f"Starting TCP performance monitoring for {duration_minutes} minutes...")
        
        start_time = time.time()
        end_time = start_time + (duration_minutes * 60)
        
        baseline_stats = self.get_tcp_stats()
        print("Baseline TCP stats collected")
        
        while time.time() < end_time:
            current_stats = self.get_tcp_stats()
            efficiency = self.calculate_tcp_efficiency(current_stats)
            
            # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð´ÐµÐ»ÑŒÑ‚Ñƒ Ñ baseline
            delta_stats = {}
            for key in current_stats:
                if key in baseline_stats and isinstance(current_stats[key], (int, float)):
                    delta_stats[f'delta_{key}'] = current_stats[key] - baseline_stats[key]
            
            monitoring_record = {
                'timestamp': current_stats['timestamp'],
                'current_stats': current_stats,
                'efficiency': efficiency,
                'delta_from_baseline': delta_stats
            }
            
            self.metrics_history.append(monitoring_record)
            
            # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
            print(f"\n--- {time.strftime('%H:%M:%S')} ---")
            print(f"Established connections: {current_stats.get('tcp_established', 'N/A')}")
            print(f"TIME_WAIT connections: {current_stats.get('tcp_timewait', 'N/A')}")
            
            if 'retransmission_rate_percent' in efficiency:
                print(f"Retransmission rate: {efficiency['retransmission_rate_percent']:.3f}%")
            
            if 'connection_success_rate_percent' in efficiency:
                print(f"Connection success rate: {efficiency['connection_success_rate_percent']:.1f}%")
            
            # ÐŸÑ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ
            for key, value in efficiency.items():
                if 'warning' in key:
                    print(f"âš ï¸ {value}")
            
            time.sleep(30)  # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ðµ 30 ÑÐµÐºÑƒÐ½Ð´
        
        return self.metrics_history
    
    def generate_tcp_report(self) -> Dict:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¿Ð¾ TCP Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
        
        if not self.metrics_history:
            return {'error': 'No metrics data available'}
        
        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ñ€ÐµÐ½Ð´Ñ‹
        report = {
            'monitoring_period': {
                'start': min(record['timestamp'] for record in self.metrics_history),
                'end': max(record['timestamp'] for record in self.metrics_history),
                'duration_minutes': len(self.metrics_history) * 0.5  # 30 ÑÐµÐº Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñ‹
            },
            'performance_summary': {},
            'trends': {},
            'recommendations': []
        }
        
        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        established_counts = [r['current_stats'].get('tcp_established', 0) for r in self.metrics_history]
        timewait_counts = [r['current_stats'].get('tcp_timewait', 0) for r in self.metrics_history]
        retrans_rates = [r['efficiency'].get('retransmission_rate_percent', 0) for r in self.metrics_history if 'retransmission_rate_percent' in r['efficiency']]
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸ÑÐ¼
        if established_counts:
            report['performance_summary']['connections'] = {
                'avg_established': statistics.mean(established_counts),
                'max_established': max(established_counts),
                'min_established': min(established_counts)
            }
        
        if timewait_counts:
            report['performance_summary']['timewait'] = {
                'avg_timewait': statistics.mean(timewait_counts),
                'max_timewait': max(timewait_counts)
            }
        
        if retrans_rates:
            avg_retrans = statistics.mean(retrans_rates)
            report['performance_summary']['retransmission_rate_percent'] = avg_retrans
            
            # Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ñ€ÐµÑ‚Ñ€Ð°Ð½ÑÐ¼Ð¸ÑÑÐ¸ÑÐ¼
            if avg_retrans > 1.0:
                report['recommendations'].append("High retransmission rate detected. Check network quality and congestion control settings.")
            elif avg_retrans > 0.5:
                report['recommendations'].append("Moderate retransmission rate. Monitor network conditions.")
        
        # Ð¢Ñ€ÐµÐ½Ð´Ñ‹
        if len(established_counts) > 1:
            # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ñ‚Ñ€ÐµÐ½Ð´ Ð°Ð½Ð°Ð»Ð¸Ð·
            first_half = established_counts[:len(established_counts)//2]
            second_half = established_counts[len(established_counts)//2:]
            
            avg_first = statistics.mean(first_half)
            avg_second = statistics.mean(second_half)
            
            if avg_second > avg_first * 1.2:
                report['trends']['connections'] = 'Increasing significantly'
                report['recommendations'].append("Connection count is growing. Monitor resource usage.")
            elif avg_second > avg_first * 1.05:
                report['trends']['connections'] = 'Slightly increasing'
            else:
                report['trends']['connections'] = 'Stable'
        
        # ÐžÐ±Ñ‰Ð¸Ðµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
        last_stats = self.metrics_history[-1]['current_stats']
        
        if last_stats.get('tcp_timewait', 0) > 1000:
            report['recommendations'].append("High TIME_WAIT count. Consider enabling tcp_tw_reuse.")
        
        if last_stats.get('tcp_established', 0) > 10000:
            report['recommendations'].append("High connection count. Ensure proper connection pooling.")
        
        return report

# ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ TCP Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
tcp_monitor = TCPPerformanceMonitor()

print("ðŸ” TCP Performance Analysis Suite")
print("=" * 50)

# ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
current_stats = tcp_monitor.get_tcp_stats()
efficiency = tcp_monitor.calculate_tcp_efficiency(current_stats)

print("ðŸ“Š Current TCP Statistics:")
print(f"  Established connections: {current_stats.get('tcp_established', 'N/A')}")
print(f"  TIME_WAIT connections: {current_stats.get('tcp_timewait', 'N/A')}")
print(f"  Orphaned connections: {current_stats.get('tcp_orphaned', 'N/A')}")
print(f"  Total segments sent: {current_stats.get('tcp_segments_sent', 'N/A')}")
print(f"  Retransmissions: {current_stats.get('tcp_retransmissions', 'N/A')}")

print("\nâš¡ TCP Efficiency Metrics:")
for key, value in efficiency.items():
    if 'warning' not in key:
        print(f"  {key}: {value}")

print("\nâš ï¸ Warnings:")
for key, value in efficiency.items():
    if 'warning' in key:
        print(f"  {value}")

print("\nðŸ”§ Current TCP Configuration:")
print(f"  Max receive buffer: {current_stats.get('rmem_max', 'N/A')} bytes")
print(f"  Max send buffer: {current_stats.get('wmem_max', 'N/A')} bytes")
print(f"  Congestion control: {current_stats.get('congestion_control', 'N/A')}")

# Ð—Ð°Ð¿ÑƒÑÐº Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ð½Ð° 2 Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
print("\nðŸ• Starting 2-minute TCP monitoring...")
metrics_data = tcp_monitor.monitor_tcp_performance(2)

# Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°
print("\nðŸ“‹ Generating TCP Performance Report...")
report = tcp_monitor.generate_tcp_report()

print("\nðŸ“Š TCP Performance Report:")
print(json.dumps(report, indent=2, default=str))

# Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
report_file = f"tcp_performance_report_{int(time.time())}.json"
with open(report_file, 'w') as f:
    json.dump({
        'report': report,
        'raw_metrics': metrics_data
    }, f, indent=2, default=str)

print(f"\nðŸ’¾ Detailed report saved to: {report_file}")
```

### ðŸ”§ Application-Level Performance Optimization

**HTTP Client Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ connection pooling:**

```python
import aiohttp
import asyncio
import time
import ssl
from aiohttp import TCPConnector
from typing import List, Dict, Optional
import statistics

class OptimizedHTTPClient:
    def __init__(self, max_connections: int = 100, max_connections_per_host: int = 30):
        """
        ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ HTTP ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        
        Args:
            max_connections: ÐžÐ±Ñ‰Ð¸Ð¹ Ð»Ð¸Ð¼Ð¸Ñ‚ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
            max_connections_per_host: Ð›Ð¸Ð¼Ð¸Ñ‚ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ð½Ð° Ñ…Ð¾ÑÑ‚
        """
        
        # SSL ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ HTTPS ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        ssl_context = ssl.create_default_context()
        ssl_context.set_ciphers('ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:!aNULL:!SHA1:!WEAK')
        
        # TCP ÐºÐ¾Ð½Ð½ÐµÐºÑ‚Ð¾Ñ€ Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸ÑÐ¼Ð¸
        self.connector = TCPConnector(
            limit=max_connections,              # ÐžÐ±Ñ‰Ð¸Ð¹ Ð»Ð¸Ð¼Ð¸Ñ‚ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
            limit_per_host=max_connections_per_host,  # Ð›Ð¸Ð¼Ð¸Ñ‚ Ð½Ð° Ñ…Ð¾ÑÑ‚
            ttl_dns_cache=300,                  # DNS ÐºÐµÑˆ Ð½Ð° 5 Ð¼Ð¸Ð½ÑƒÑ‚
            use_dns_cache=True,                 # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ DNS ÐºÐµÑˆ
            ssl=ssl_context,                    # SSL ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚
            keepalive_timeout=30,               # Keep-alive Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚
            enable_cleanup_closed=True,         # ÐÐ²Ñ‚Ð¾Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ñ‹Ñ… ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
            force_close=False,                  # ÐÐµ Ñ„Ð¾Ñ€ÑÐ¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ
            resolver=aiohttp.AsyncResolver()    # ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ DNS resolver
        )
        
        # Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ñ‹ Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹
        self.timeout = aiohttp.ClientTimeout(
            total=30,           # ÐžÐ±Ñ‰Ð¸Ð¹ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
            connect=10,         # Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
            sock_read=10,       # Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ñ‡Ñ‚ÐµÐ½Ð¸Ñ Ð¸Ð· ÑÐ¾ÐºÐµÑ‚Ð°
            sock_connect=10     # Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ ÑÐ¾ÐºÐµÑ‚Ð°
        )
        
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        self.metrics = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'response_times': [],
            'connection_reuse_count': 0,
            'dns_lookup_times': [],
            'connection_times': [],
            'ssl_handshake_times': []
        }
        
        self.session = None
    
    async def __aenter__(self):
        """Async context manager entry"""
        self.session = aiohttp.ClientSession(
            connector=self.connector,
            timeout=self.timeout,
            headers={
                'User-Agent': 'OptimizedHTTPClient/1.0',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive'
            }
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit"""
        if self.session:
            await self.session.close()
    
    async def get(self, url: str, headers: Dict = None, **kwargs) -> Dict:
        """ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ GET Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸"""
        return await self._request('GET', url, headers=headers, **kwargs)
    
    async def post(self, url: str, json_data: Dict = None, headers: Dict = None, **kwargs) -> Dict:
        """ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ POST Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸"""
        return await self._request('POST', url, json=json_data, headers=headers, **kwargs)
    
    async def _request(self, method: str, url: str, **kwargs) -> Dict:
        """Ð’Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸"""
        
        start_time = time.time()
        
        # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²
        headers = kwargs.get('headers', {})
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        default_headers = {
            'Accept': 'application/json',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
        
        for key, value in default_headers.items():
            if key not in headers:
                headers[key] = value
        
        kwargs['headers'] = headers
        
        try:
            # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ
            async with self.session.request(method, url, **kwargs) as response:
                
                # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ñ‚ÐµÐ»Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
                if response.content_type == 'application/json':
                    response_data = await response.json()
                else:
                    response_data = await response.text()
                
                end_time = time.time()
                response_time = (end_time - start_time) * 1000  # Ð² Ð¼Ñ
                
                # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                self.metrics['total_requests'] += 1
                self.metrics['response_times'].append(response_time)
                
                if 200 <= response.status < 300:
                    self.metrics['successful_requests'] += 1
                else:
                    self.metrics['failed_requests'] += 1
                
                return {
                    'status': response.status,
                    'headers': dict(response.headers),
                    'data': response_data,
                    'response_time_ms': response_time,
                    'url': str(response.url),
                    'method': method,
                    'success': 200 <= response.status < 300
                }
        
        except asyncio.TimeoutError:
            end_time = time.time()
            response_time = (end_time - start_time) * 1000
            
            self.metrics['total_requests'] += 1
            self.metrics['failed_requests'] += 1
            
            return {
                'status': 0,
                'error': 'Request timeout',
                'response_time_ms': response_time,
                'url': url,
                'method': method,
                'success': False
            }
        
        except Exception as e:
            end_time = time.time()
            response_time = (end_time - start_time) * 1000
            
            self.metrics['total_requests'] += 1
            self.metrics['failed_requests'] += 1
            
            return {
                'status': 0,
                'error': str(e),
                'response_time_ms': response_time,
                'url': url,
                'method': method,
                'success': False
            }
    
    async def batch_requests(self, requests: List[Dict], max_concurrent: int = 50) -> List[Dict]:
        """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð¿Ð°ÐºÐµÑ‚Ð° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸ÐµÐ¼ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚Ð¸"""
        
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def bounded_request(request_config):
            async with semaphore:
                method = request_config.get('method', 'GET')
                url = request_config['url']
                kwargs = {k: v for k, v in request_config.items() if k not in ['method', 'url']}
                
                return await self._request(method, url, **kwargs)
        
        # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð²ÑÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾
        tasks = [bounded_request(req) for req in requests]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                processed_results.append({
                    'status': 0,
                    'error': str(result),
                    'success': False
                })
            else:
                processed_results.append(result)
        
        return processed_results
    
    def get_performance_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
        
        if not self.metrics['response_times']:
            return {'error': 'No requests made yet'}
        
        response_times = self.metrics['response_times']
        
        stats = {
            'total_requests': self.metrics['total_requests'],
            'successful_requests': self.metrics['successful_requests'],
            'failed_requests': self.metrics['failed_requests'],
            'success_rate_percent': (self.metrics['successful_requests'] / self.metrics['total_requests'] * 100) if self.metrics['total_requests'] > 0 else 0,
            'response_time_stats': {
                'min_ms': min(response_times),
                'max_ms': max(response_times),
                'avg_ms': statistics.mean(response_times),
                'median_ms': statistics.median(response_times),
                'p95_ms': statistics.quantiles(response_times, n=20)[18] if len(response_times) > 1 else response_times[0],
                'p99_ms': statistics.quantiles(response_times, n=100)[98] if len(response_times) > 1 else response_times[0]
            },
            'connection_pool_stats': {
                'total_connections': self.connector._limit,
                'connections_per_host': self.connector._limit_per_host,
                'dns_cache_enabled': self.connector._use_dns_cache,
                'keepalive_timeout': self.connector._keepalive_timeout
            }
        }
        
        return stats

# ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ
async def performance_benchmark():
    """Ð‘ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ HTTP ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°"""
    
    # URLs Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
    test_urls = [
        'https://httpbin.org/get',
        'https://httpbin.org/delay/1',
        'https://httpbin.org/status/200',
        'https://httpbin.org/json',
        'https://httpbin.org/gzip'
    ] * 20  # 100 Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð²ÑÐµÐ³Ð¾
    
    print("ðŸš€ Starting HTTP Client Performance Benchmark")
    print("=" * 60)
    
    # Ð¢ÐµÑÑ‚ Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð¼
    print("Testing optimized HTTP client...")
    
    async with OptimizedHTTPClient(max_connections=50, max_connections_per_host=10) as client:
        
        start_time = time.time()
        
        # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹
        requests = [{'method': 'GET', 'url': url} for url in test_urls]
        
        # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð¿Ð°ÐºÐµÑ‚ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
        results = await client.batch_requests(requests, max_concurrent=25)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
        successful_results = [r for r in results if r.get('success', False)]
        failed_results = [r for r in results if not r.get('success', False)]
        
        print(f"\nðŸ“Š Benchmark Results:")
        print(f"  Total time: {total_time:.2f} seconds")
        print(f"  Total requests: {len(results)}")
        print(f"  Successful: {len(successful_results)}")
        print(f"  Failed: {len(failed_results)}")
        print(f"  Requests per second: {len(results) / total_time:.1f}")
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
        stats = client.get_performance_stats()
        print(f"\nâš¡ Performance Statistics:")
        print(f"  Success rate: {stats['success_rate_percent']:.1f}%")
        print(f"  Average response time: {stats['response_time_stats']['avg_ms']:.1f}ms")
        print(f"  P95 response time: {stats['response_time_stats']['p95_ms']:.1f}ms")
        print(f"  P99 response time: {stats['response_time_stats']['p99_ms']:.1f}ms")
        
        # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
        if failed_results:
            print(f"\nâŒ Failed Requests:")
            error_types = {}
            for result in failed_results:
                error = result.get('error', 'Unknown error')
                error_types[error] = error_types.get(error, 0) + 1
            
            for error, count in error_types.items():
                print(f"  {error}: {count} times")
    
    print("\nâœ… Benchmark completed!")

# Ð—Ð°Ð¿ÑƒÑÐº Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°
if __name__ == "__main__":
    asyncio.run(performance_benchmark())
```

### ðŸ“ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ ÐÐµÐ´ÐµÐ»Ñ 9

1. ÐŸÑ€Ð¾Ð²ÐµÐ´Ð¸Ñ‚Ðµ comprehensive Ð°Ð½Ð°Ð»Ð¸Ð· ÑÐµÑ‚ÐµÐ²Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð²Ð°ÑˆÐ¸Ñ… ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
2. ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ TCP Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð½Ð° production ÑÐµÑ€Ð²ÐµÑ€Ð°Ñ…
3. Ð ÐµÐ°Ð»Ð¸Ð·ÑƒÐ¹Ñ‚Ðµ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ TCP ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Ñ Ð°Ð»ÐµÑ€Ñ‚Ð°Ð¼Ð¸
4. ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ HTTP ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñ‹ Ñ connection pooling
5. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ñ‚ÐµÑÑ‚Ñ‹ Ð´Ð»Ñ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ñ improvement

---

## ÐÐµÐ´ÐµÐ»Ñ 10: ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹

### ðŸ§  ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ: Connection Lifecycle Management

Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¶Ð¸Ð·Ð½ÐµÐ½Ð½Ñ‹Ð¼ Ñ†Ð¸ÐºÐ»Ð¾Ð¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ - ÐºÐ»ÑŽÑ‡ Ðº Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€ÑƒÐµÐ¼Ð¾ÑÑ‚Ð¸:

```
Connection Lifecycle:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Creation (Expensive)                                     â”‚
â”‚    â”œâ”€ DNS Resolution (50-200ms)                            â”‚
â”‚    â”œâ”€ TCP Handshake (RTT)                                  â”‚
â”‚    â”œâ”€ TLS Handshake (2-3 RTT)                             â”‚
â”‚    â””â”€ Application Protocol Setup                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Usage (Cheap)                                           â”‚
â”‚    â”œâ”€ Request/Response cycles                              â”‚
â”‚    â”œâ”€ Keep-alive maintenance                               â”‚
â”‚    â””â”€ Connection validation                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Management (Critical)                                   â”‚
â”‚    â”œâ”€ Pool size optimization                               â”‚
â”‚    â”œâ”€ Health checking                                      â”‚
â”‚    â”œâ”€ Load balancing                                       â”‚
â”‚    â””â”€ Timeout handling                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. Destruction (Controlled)                                â”‚
â”‚    â”œâ”€ Graceful shutdown                                    â”‚
â”‚    â”œâ”€ Resource cleanup                                     â”‚
â”‚    â””â”€ Connection draining                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸŠâ€â™‚ï¸ Advanced Connection Pooling

**Enterprise-grade Connection Pool Implementation:**

```python
import asyncio
import time
import logging
import weakref
from typing import Dict, List, Optional, Set, Callable, Any
from dataclasses import dataclass, field
from enum import Enum
import aiohttp
import statistics
from contextlib import asynccontextmanager

class ConnectionState(Enum):
    CREATING = "creating"
    IDLE = "idle"
    BUSY = "busy"
    STALE = "stale"
    UNHEALTHY = "unhealthy"
    CLOSING = "closing"

@dataclass
class ConnectionMetrics:
    created_at: float
    last_used_at: float
    total_requests: int = 0
    failed_requests: int = 0
    avg_response_time: float = 0.0
    state: ConnectionState = ConnectionState.IDLE
    health_score: float = 1.0  # 1.0 = Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð·Ð´Ð¾Ñ€Ð¾Ð², 0.0 = Ð½ÐµÐ·Ð´Ð¾Ñ€Ð¾Ð²

@dataclass
class PoolConfig:
    min_size: int = 5
    max_size: int = 50
    max_idle_time: float = 300.0  # 5 Ð¼Ð¸Ð½ÑƒÑ‚
    max_lifetime: float = 3600.0  # 1 Ñ‡Ð°Ñ
    health_check_interval: float = 60.0  # 1 Ð¼Ð¸Ð½ÑƒÑ‚Ð°
    max_requests_per_connection: int = 1000
    connection_timeout: float = 10.0
    request_timeout: float = 30.0
    retry_attempts: int = 3
    backoff_factor: float = 0.3

class AdvancedConnectionPool:
    def __init__(self, 
                 target_host: str, 
                 target_port: int = 443,
                 config: PoolConfig = None,
                 health_check_callback: Callable = None):
        
        self.target_host = target_host
        self.target_port = target_port
        self.config = config or PoolConfig()
        self.health_check_callback = health_check_callback
        
        # Connection storage
        self._connections: Dict[str, aiohttp.ClientSession] = {}
        self._connection_metrics: Dict[str, ConnectionMetrics] = {}
        self._connection_semaphore = asyncio.Semaphore(self.config.max_size)
        
        # State management
        self._creating_connections: Set[str] = set()
        self._busy_connections: Set[str] = set()
        self._idle_connections: Set[str] = set()
        
        # Background tasks
        self._maintenance_task: Optional[asyncio.Task] = None
        self._health_check_task: Optional[asyncio.Task] = None
        self._closed = False
        
        # Metrics
        self.pool_metrics = {
            'total_connections_created': 0,
            'total_connections_destroyed': 0,
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'pool_exhaustions': 0,
            'health_check_failures': 0
        }
        
        # Logger
        self.logger = logging.getLogger(f'ConnectionPool.{target_host}')
        
    async def start(self):
        """Ð—Ð°Ð¿ÑƒÑÐº Ð¿ÑƒÐ»Ð° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹"""
        if self._maintenance_task is not None:
            return
        
        self.logger.info(f"Starting connection pool for {self.target_host}:{self.target_port}")
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
        await self._ensure_min_connections()
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ñ„Ð¾Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
        self._maintenance_task = asyncio.create_task(self._maintenance_loop())
        self._health_check_task = asyncio.create_task(self._health_check_loop())
        
        self.logger.info(f"Connection pool started with {len(self._connections)} connections")
    
    async def stop(self):
        """ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð¿ÑƒÐ»Ð° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹"""
        if self._closed:
            return
        
        self._closed = True
        self.logger.info("Shutting down connection pool...")
        
        # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ñ„Ð¾Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
        if self._maintenance_task:
            self._maintenance_task.cancel()
            try:
                await self._maintenance_task
            except asyncio.CancelledError:
                pass
        
        if self._health_check_task:
            self._health_check_task.cancel()
            try:
                await self._health_check_task
            except asyncio.CancelledError:
                pass
        
        # Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð²ÑÐµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
        for conn_id in list(self._connections.keys()):
            await self._destroy_connection(conn_id)
        
        self.logger.info("Connection pool shut down complete")
    
    @asynccontextmanager
    async def get_connection(self):
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð¸Ð· Ð¿ÑƒÐ»Ð° Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚Ð¾Ð¼"""
        if self._closed:
            raise RuntimeError("Connection pool is closed")
        
        connection = await self._acquire_connection()
        try:
            yield connection
        finally:
            await self._release_connection(connection)
    
    async def _acquire_connection(self) -> aiohttp.ClientSession:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð¸Ð· Ð¿ÑƒÐ»Ð°"""
        
        # Ð–Ð´ÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ð¸ ÑÐ»Ð¾Ñ‚Ð° Ð² Ð¿ÑƒÐ»Ðµ
        await self._connection_semaphore.acquire()
        
        try:
            # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐµ idle ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ
            if self._idle_connections:
                conn_id = self._idle_connections.pop()
                connection = self._connections[conn_id]
                
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
                if await self._is_connection_healthy(conn_id):
                    self._busy_connections.add(conn_id)
                    self._connection_metrics[conn_id].last_used_at = time.time()
                    self.logger.debug(f"Reusing existing connection {conn_id}")
                    return connection
                else:
                    # Ð¡Ð¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð½ÐµÐ·Ð´Ð¾Ñ€Ð¾Ð²Ð¾, ÑƒÐ½Ð¸Ñ‡Ñ‚Ð¾Ð¶Ð°ÐµÐ¼ ÐµÐ³Ð¾
                    await self._destroy_connection(conn_id)
            
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²Ð¾Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ ÐµÑÐ»Ð¸ Ð½ÐµÑ‚ Ð·Ð´Ð¾Ñ€Ð¾Ð²Ñ‹Ñ… idle
            if len(self._connections) < self.config.max_size:
                conn_id = await self._create_connection()
                self._busy_connections.add(conn_id)
                return self._connections[conn_id]
            
            # ÐŸÑƒÐ» Ð¸ÑÑ‡ÐµÑ€Ð¿Ð°Ð½, Ð¶Ð´ÐµÐ¼ Ð¾ÑÐ²Ð¾Ð±Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
            self.pool_metrics['pool_exhaustions'] += 1
            self.logger.warning("Connection pool exhausted, waiting for available connection")
            
            # ÐœÐ¾Ð¶Ð½Ð¾ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ð¸Ð»Ð¸ Ð²Ñ‹Ð±Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ
            raise RuntimeError("Connection pool exhausted")
            
        except Exception:
            self._connection_semaphore.release()
            raise
    
    async def _release_connection(self, connection: aiohttp.ClientSession):
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð² Ð¿ÑƒÐ»"""
        
        # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ connection ID
        conn_id = None
        for cid, conn in self._connections.items():
            if conn is connection:
                conn_id = cid
                break
        
        if conn_id is None:
            self.logger.error("Attempted to release unknown connection")
            self._connection_semaphore.release()
            return
        
        # ÐŸÐµÑ€ÐµÐ¼ÐµÑ‰Ð°ÐµÐ¼ Ð¸Ð· busy Ð² idle
        if conn_id in self._busy_connections:
            self._busy_connections.remove(conn_id)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ðµ Ð¿Ñ€ÐµÐ²Ñ‹ÑÐ¸Ð» Ð»Ð¸ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
            metrics = self._connection_metrics[conn_id]
            if metrics.total_requests >= self.config.max_requests_per_connection:
                self.logger.info(f"Connection {conn_id} reached request limit, destroying")
                await self._destroy_connection(conn_id)
            else:
                self._idle_connections.add(conn_id)
                metrics.state = ConnectionState.IDLE
        
        self._connection_semaphore.release()
    
    async def _create_connection(self) -> str:
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ð³Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ"""
        
        conn_id = f"{self.target_host}:{self.target_port}:{time.time()}"
        self._creating_connections.add(conn_id)
        
        try:
            self.logger.debug(f"Creating new connection {conn_id}")
            
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ SSL ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚
            import ssl
            ssl_context = ssl.create_default_context()
            
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ TCP ÐºÐ¾Ð½Ð½ÐµÐºÑ‚Ð¾Ñ€
            connector = aiohttp.TCPConnector(
                limit=1,  # ÐžÐ´Ð½Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð½Ð° ÐºÐ¾Ð½Ð½ÐµÐºÑ‚Ð¾Ñ€
                ssl=ssl_context,
                keepalive_timeout=self.config.max_idle_time,
                enable_cleanup_closed=True
            )
            
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐµÑÑÐ¸ÑŽ
            timeout = aiohttp.ClientTimeout(
                total=self.config.request_timeout,
                connect=self.config.connection_timeout
            )
            
            session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                headers={
                    'User-Agent': 'AdvancedConnectionPool/1.0',
                    'Connection': 'keep-alive'
                }
            )
            
            # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ
            test_url = f"https://{self.target_host}:{self.target_port}/health"
            try:
                async with session.get(test_url) as response:
                    if response.status < 500:  # Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ð¼ Ð»ÑŽÐ±Ð¾Ð¹ Ð½Ðµ-server error
                        pass
            except Exception as e:
                self.logger.debug(f"Health check during creation failed (normal): {e}")
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ
            self._connections[conn_id] = session
            self._connection_metrics[conn_id] = ConnectionMetrics(
                created_at=time.time(),
                last_used_at=time.time(),
                state=ConnectionState.IDLE
            )
            
            self.pool_metrics['total_connections_created'] += 1
            self.logger.info(f"Created new connection {conn_id}")
            
            return conn_id
            
        except Exception as e:
            self.logger.error(f"Failed to create connection {conn_id}: {e}")
            raise
        finally:
            self._creating_connections.discard(conn_id)
    
    async def _destroy_connection(self, conn_id: str):
        """Ð£Ð½Ð¸Ñ‡Ñ‚Ð¾Ð¶ÐµÐ½Ð¸Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ"""
        
        if conn_id not in self._connections:
            return
        
        self.logger.debug(f"Destroying connection {conn_id}")
        
        # Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ ÑÐµÑÑÐ¸ÑŽ
        session = self._connections[conn_id]
        if not session.closed:
            await session.close()
        
        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¸Ð· Ð²ÑÐµÑ… ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¹
        self._connections.pop(conn_id, None)
        self._connection_metrics.pop(conn_id, None)
        self._busy_connections.discard(conn_id)
        self._idle_connections.discard(conn_id)
        self._creating_connections.discard(conn_id)
        
        self.pool_metrics['total_connections_destroyed'] += 1
        self.logger.debug(f"Destroyed connection {conn_id}")
    
    async def _is_connection_healthy(self, conn_id: str) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ"""
        
        if conn_id not in self._connections:
            return False
        
        metrics = self._connection_metrics[conn_id]
        session = self._connections[conn_id]
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ
        if session.closed:
            return False
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
        if time.time() - metrics.created_at > self.config.max_lifetime:
            self.logger.debug(f"Connection {conn_id} exceeded max lifetime")
            return False
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð±ÐµÐ·Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ
        if time.time() - metrics.last_used_at > self.config.max_idle_time:
            self.logger.debug(f"Connection {conn_id} exceeded max idle time")
            return False
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ health score
        if metrics.health_score < 0.5:
            self.logger.debug(f"Connection {conn_id} has low health score: {metrics.health_score}")
            return False
        
        # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· callback
        if self.health_check_callback:
            try:
                is_healthy = await self.health_check_callback(session)
                if not is_healthy:
                    metrics.health_score *= 0.8  # Ð¡Ð½Ð¸Ð¶Ð°ÐµÐ¼ health score
                    return False
            except Exception as e:
                self.logger.debug(f"Health check callback failed for {conn_id}: {e}")
                metrics.health_score *= 0.7
                return False
        
        return True
    
    async def _ensure_min_connections(self):
        """ÐžÐ±ÐµÑÐ¿ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹"""
        
        current_count = len(self._connections)
        if current_count < self.config.min_size:
            needed = self.config.min_size - current_count
            
            self.logger.info(f"Creating {needed} connections to reach minimum pool size")
            
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾
            tasks = []
            for _ in range(needed):
                if len(self._connections) + len(tasks) < self.config.max_size:
                    task = asyncio.create_task(self._create_connection())
                    tasks.append(task)
            
            if tasks:
                created_conn_ids = await asyncio.gather(*tasks, return_exceptions=True)
                
                # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð² idle Ð¿ÑƒÐ»
                for conn_id in created_conn_ids:
                    if isinstance(conn_id, str) and conn_id in self._connections:
                        self._idle_connections.add(conn_id)
    
    async def _maintenance_loop(self):
        """Ð¤Ð¾Ð½Ð¾Ð²Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¿ÑƒÐ»Ð°"""
        
        self.logger.info("Started maintenance loop")
        
        while not self._closed:
            try:
                await asyncio.sleep(30)  # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ðµ 30 ÑÐµÐºÑƒÐ½Ð´
                
                if self._closed:
                    break
                
                # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑƒÑÑ‚Ð°Ñ€ÐµÐ²ÑˆÐ¸Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
                stale_connections = []
                current_time = time.time()
                
                for conn_id, metrics in self._connection_metrics.items():
                    if (current_time - metrics.last_used_at > self.config.max_idle_time or
                        current_time - metrics.created_at > self.config.max_lifetime or
                        metrics.health_score < 0.3):
                        stale_connections.append(conn_id)
                
                # Ð£Ð´Ð°Ð»ÑÐµÐ¼ stale ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ (Ð½Ð¾ Ð½Ðµ Ð½Ð¸Ð¶Ðµ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ð°)
                for conn_id in stale_connections:
                    if len(self._connections) > self.config.min_size:
                        await self._destroy_connection(conn_id)
                
                # ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
                await self._ensure_min_connections()
                
                self.logger.debug(f"Maintenance: {len(self._connections)} total, "
                                f"{len(self._idle_connections)} idle, "
                                f"{len(self._busy_connections)} busy")
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"Error in maintenance loop: {e}")
        
        self.logger.info("Maintenance loop stopped")
    
    async def _health_check_loop(self):
        """Ð¤Ð¾Ð½Ð¾Ð²Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹"""
        
        self.logger.info("Started health check loop")
        
        while not self._closed:
            try:
                await asyncio.sleep(self.config.health_check_interval)
                
                if self._closed:
                    break
                
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ idle ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹
                unhealthy_connections = []
                
                for conn_id in list(self._idle_connections):
                    if not await self._is_connection_healthy(conn_id):
                        unhealthy_connections.append(conn_id)
                        self.pool_metrics['health_check_failures'] += 1
                
                # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð½ÐµÐ·Ð´Ð¾Ñ€Ð¾Ð²Ñ‹Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
                for conn_id in unhealthy_connections:
                    await self._destroy_connection(conn_id)
                
                if unhealthy_connections:
                    self.logger.info(f"Health check removed {len(unhealthy_connections)} unhealthy connections")
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"Error in health check loop: {e}")
        
        self.logger.info("Health check loop stopped")
    
    def get_pool_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¿ÑƒÐ»Ð°"""
        
        return {
            'pool_config': {
                'min_size': self.config.min_size,
                'max_size': self.config.max_size,
                'max_idle_time': self.config.max_idle_time,
                'max_lifetime': self.config.max_lifetime
            },
            'current_state': {
                'total_connections': len(self._connections),
                'idle_connections': len(self._idle_connections),
                'busy_connections': len(self._busy_connections),
                'creating_connections': len(self._creating_connections)
            },
            'lifetime_metrics': dict(self.pool_metrics),
            'connection_details': {
                conn_id: {
                    'created_at': metrics.created_at,
                    'last_used_at': metrics.last_used_at,
                    'total_requests': metrics.total_requests,
                    'failed_requests': metrics.failed_requests,
                    'health_score': metrics.health_score,
                    'state': metrics.state.value,
                    'age_seconds': time.time() - metrics.created_at,
                    'idle_seconds': time.time() - metrics.last_used_at
                }
                for conn_id, metrics in self._connection_metrics.items()
            }
        }

# ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Advanced Connection Pool
async def demonstrate_advanced_pool():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ð¾Ð³Ð¾ Ð¿ÑƒÐ»Ð° ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹"""
    
    print("ðŸŠâ€â™‚ï¸ Advanced Connection Pool Demonstration")
    print("=" * 60)
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¿ÑƒÐ»Ð°
    config = PoolConfig(
        min_size=3,
        max_size=10,
        max_idle_time=60.0,  # 1 Ð¼Ð¸Ð½ÑƒÑ‚Ð° Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
        max_lifetime=300.0,  # 5 Ð¼Ð¸Ð½ÑƒÑ‚ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
        health_check_interval=30.0,
        max_requests_per_connection=50
    )
    
    # Health check callback
    async def health_check(session: aiohttp.ClientSession) -> bool:
        try:
            async with session.get('https://httpbin.org/status/200', timeout=aiohttp.ClientTimeout(total=5)) as response:
                return response.status == 200
        except:
            return False
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿ÑƒÐ»
    pool = AdvancedConnectionPool(
        target_host='httpbin.org',
        target_port=443,
        config=config,
        health_check_callback=health_check
    )
    
    try:
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿ÑƒÐ»
        await pool.start()
        print("âœ… Connection pool started")
        
        # Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿ÑƒÐ»Ð°
        print("\nðŸ”„ Making requests through connection pool...")
        
        successful_requests = 0
        failed_requests = 0
        
        # Ð”ÐµÐ»Ð°ÐµÐ¼ ÑÐµÑ€Ð¸ÑŽ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
        for i in range(20):
            try:
                async with pool.get_connection() as session:
                    async with session.get('https://httpbin.org/delay/0.5') as response:
                        if response.status == 200:
                            successful_requests += 1
                        else:
                            failed_requests += 1
                        
                        print(f"Request {i+1}: {response.status} ({response.content_length} bytes)")
                
            except Exception as e:
                failed_requests += 1
                print(f"Request {i+1}: ERROR - {e}")
            
            # ÐÐµÐ±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¼ÐµÐ¶Ð´Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸
            if i % 5 == 4:
                await asyncio.sleep(1)
        
        print(f"\nðŸ“Š Request Results:")
        print(f"  Successful: {successful_requests}")
        print(f"  Failed: {failed_requests}")
        print(f"  Success rate: {successful_requests / (successful_requests + failed_requests) * 100:.1f}%")
        
        # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿ÑƒÐ»Ð°
        stats = pool.get_pool_stats()
        print(f"\nðŸŠâ€â™‚ï¸ Pool Statistics:")
        print(f"  Total connections: {stats['current_state']['total_connections']}")
        print(f"  Idle connections: {stats['current_state']['idle_connections']}")
        print(f"  Busy connections: {stats['current_state']['busy_connections']}")
        print(f"  Connections created: {stats['lifetime_metrics']['total_connections_created']}")
        print(f"  Connections destroyed: {stats['lifetime_metrics']['total_connections_destroyed']}")
        print(f"  Pool exhaustions: {stats['lifetime_metrics']['pool_exhaustions']}")
        
        print(f"\nðŸ” Connection Details:")
        for conn_id, details in stats['connection_details'].items():
            print(f"  {conn_id[-20:]}: {details['state']} (age: {details['age_seconds']:.1f}s, "
                  f"requests: {details['total_requests']}, health: {details['health_score']:.2f})")
        
        # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¹ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ
        print(f"\nâš¡ High Load Test (50 concurrent requests)...")
        
        async def make_request(request_id):
            try:
                async with pool.get_connection() as session:
                    async with session.get('https://httpbin.org/delay/1') as response:
                        return {'id': request_id, 'status': response.status, 'success': True}
            except Exception as e:
                return {'id': request_id, 'error': str(e), 'success': False}
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ 50 Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
        start_time = time.time()
        tasks = [make_request(i) for i in range(50)]
        results = await asyncio.gather(*tasks)
        end_time = time.time()
        
        successful_concurrent = len([r for r in results if r.get('success')])
        failed_concurrent = len([r for r in results if not r.get('success')])
        
        print(f"  Total time: {end_time - start_time:.2f} seconds")
        print(f"  Successful: {successful_concurrent}")
        print(f"  Failed: {failed_concurrent}")
        print(f"  Requests per second: {len(results) / (end_time - start_time):.1f}")
        
        # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿ÑƒÐ»Ð°
        final_stats = pool.get_pool_stats()
        print(f"\nðŸ“ˆ Final Pool Metrics:")
        print(f"  Pool exhaustions: {final_stats['lifetime_metrics']['pool_exhaustions']}")
        print(f"  Health check failures: {final_stats['lifetime_metrics']['health_check_failures']}")
        print(f"  Total connections ever created: {final_stats['lifetime_metrics']['total_connections_created']}")
        
    finally:
        # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿ÑƒÐ»
        await pool.stop()
        print("\nðŸ›‘ Connection pool stopped")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
if __name__ == "__main__":
    asyncio.run(demonstrate_advanced_pool())
```

### ðŸ”„ Circuit Breaker Pattern Ð´Ð»Ñ Network Resilience

**Ð ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Circuit Breaker Ð´Ð»Ñ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð²:**

```python
import asyncio
import time
import logging
from enum import Enum
from typing import Callable, Any, Dict, Optional
from dataclasses import dataclass
import statistics

class CircuitState(Enum):
    CLOSED = "closed"        # ÐÐ¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°
    OPEN = "open"           # Ð‘Ð»Ð¾ÐºÐ¸Ñ€ÑƒÐµÑ‚ Ð²Ñ‹Ð·Ð¾Ð²Ñ‹
    HALF_OPEN = "half_open" # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ

@dataclass
class CircuitBreakerConfig:
    failure_threshold: int = 5          # ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð´Ð»Ñ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ñ
    recovery_timeout: float = 60.0      # Ð’Ñ€ÐµÐ¼Ñ Ð´Ð¾ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ¸ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ
    success_threshold: int = 3          # Ð£ÑÐ¿ÐµÑ…Ð¾Ð² Ð´Ð»Ñ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð² half-open
    timeout: float = 30.0               # Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð²Ñ‹Ð·Ð¾Ð²Ð°
    expected_exception: type = Exception # Ð¢Ð¸Ð¿ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ ÑƒÑ‡ÐµÑ‚Ð°

class CircuitBreakerOpenException(Exception):
    """Ð˜ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð³Ð´Ð° Circuit Breaker Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚"""
    pass

class NetworkCircuitBreaker:
    def __init__(self, name: str, config: CircuitBreakerConfig = None):
        self.name = name
        self.config = config or CircuitBreakerConfig()
        
        # State management
        self._state = CircuitState.CLOSED
        self._failure_count = 0
        self._success_count = 0
        self._last_failure_time = 0
        self._last_success_time = 0
        
        # Metrics
        self._metrics = {
            'total_calls': 0,
            'successful_calls': 0,
            'failed_calls': 0,
            'circuit_opened_count': 0,
            'circuit_closed_count': 0,
            'calls_rejected': 0,
            'response_times': []
        }
        
        # Logger
        self.logger = logging.getLogger(f'CircuitBreaker.{name}')
    
    async def __call__(self, func: Callable, *args, **kwargs) -> Any:
        """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ñ‡ÐµÑ€ÐµÐ· Circuit Breaker"""
        
        self._metrics['total_calls'] += 1
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Circuit Breaker
        if self._state == CircuitState.OPEN:
            if self._should_attempt_reset():
                self._state = CircuitState.HALF_OPEN
                self.logger.info(f"Circuit breaker {self.name} entering HALF_OPEN state")
            else:
                self._metrics['calls_rejected'] += 1
                raise CircuitBreakerOpenException(
                    f"Circuit breaker {self.name} is OPEN. "
                    f"Last failure: {time.time() - self._last_failure_time:.1f}s ago"
                )
        
        # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ñ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸ÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
        start_time = time.time()
        
        try:
            # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ñ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð¾Ð¼
            result = await asyncio.wait_for(
                func(*args, **kwargs),
                timeout=self.config.timeout
            )
            
            # Ð£ÑÐ¿ÐµÑˆÐ½Ñ‹Ð¹ Ð²Ñ‹Ð·Ð¾Ð²
            end_time = time.time()
            response_time = (end_time - start_time) * 1000  # Ð² Ð¼Ñ
            
            self._on_success(response_time)
            return result
            
        except asyncio.TimeoutError as e:
            end_time = time.time()
            response_time = (end_time - start_time) * 1000
            self._on_failure(e, response_time)
            raise
            
        except self.config.expected_exception as e:
            end_time = time.time()
            response_time = (end_time - start_time) * 1000
            self._on_failure(e, response_time)
            raise
    
    def _should_attempt_reset(self) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ°, ÑÑ‚Ð¾Ð¸Ñ‚ Ð»Ð¸ Ð¿Ñ‹Ñ‚Ð°Ñ‚ÑŒÑÑ ÑÐ±Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Circuit Breaker"""
        return (time.time() - self._last_failure_time) >= self.config.recovery_timeout
    
    def _on_success(self, response_time: float):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ð³Ð¾ Ð²Ñ‹Ð·Ð¾Ð²Ð°"""
        
        self._metrics['successful_calls'] += 1
        self._metrics['response_times'].append(response_time)
        self._last_success_time = time.time()
        
        if self._state == CircuitState.HALF_OPEN:
            self._success_count += 1
            
            if self._success_count >= self.config.success_threshold:
                self._reset()
        
        elif self._state == CircuitState.CLOSED:
            # Ð¡Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ ÑÑ‡ÐµÑ‚Ñ‡Ð¸Ðº Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð¿Ñ€Ð¸ ÑƒÑÐ¿ÐµÑ…Ðµ
            self._failure_count = 0
    
    def _on_failure(self, exception: Exception, response_time: float):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½ÐµÑƒÐ´Ð°Ñ‡Ð½Ð¾Ð³Ð¾ Ð²Ñ‹Ð·Ð¾Ð²Ð°"""
        
        self._metrics['failed_calls'] += 1
        self._metrics['response_times'].append(response_time)
        self._last_failure_time = time.time()
        
        self.logger.warning(f"Call failed in {self.name}: {exception}")
        
        if self._state == CircuitState.HALF_OPEN:
            # Ð’ half-open ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¸ Ð»ÑŽÐ±Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‚ÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ circuit
            self._trip()
        
        elif self._state == CircuitState.CLOSED:
            self._failure_count += 1
            
            if self._failure_count >= self.config.failure_threshold:
                self._trip()
    
    def _trip(self):
        """ÐžÑ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ Circuit Breaker"""
        self._state = CircuitState.OPEN
        self._success_count = 0
        self._metrics['circuit_opened_count'] += 1
        
        self.logger.error(f"Circuit breaker {self.name} OPENED after {self._failure_count} failures")
    
    def _reset(self):
        """Ð—Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ Circuit Breaker"""
        self._state = CircuitState.CLOSED
        self._failure_count = 0
        self._success_count = 0
        self._metrics['circuit_closed_count'] += 1
        
        self.logger.info(f"Circuit breaker {self.name} CLOSED after successful recovery")
    
    def force_open(self):
        """ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ Circuit Breaker"""
        self._trip()
        self.logger.warning(f"Circuit breaker {self.name} force opened")
    
    def force_close(self):
        """ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ Circuit Breaker"""
        self._reset()
        self.logger.info(f"Circuit breaker {self.name} force closed")
    
    @property
    def state(self) -> CircuitState:
        """Ð¢ÐµÐºÑƒÑ‰ÐµÐµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Circuit Breaker"""
        return self._state
    
    @property
    def failure_rate(self) -> float:
        """ÐšÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ Ð¾ÑˆÐ¸Ð±Ð¾Ðº"""
        total = self._metrics['total_calls']
        if total == 0:
            return 0.0
        return (self._metrics['failed_calls'] / total) * 100
    
    def get_metrics(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Circuit Breaker"""
        
        response_times = self._metrics['response_times']
        
        metrics = {
            'name': self.name,
            'state': self._state.value,
            'config': {
                'failure_threshold': self.config.failure_threshold,
                'recovery_timeout': self.config.recovery_timeout,
                'success_threshold': self.config.success_threshold,
                'timeout': self.config.timeout
            },
            'current_counts': {
                'failure_count': self._failure_count,
                'success_count': self._success_count
            },
            'lifetime_metrics': dict(self._metrics),
            'failure_rate_percent': self.failure_rate,
            'last_failure_ago_seconds': time.time() - self._last_failure_time if self._last_failure_time > 0 else None,
            'last_success_ago_seconds': time.time() - self._last_success_time if self._last_success_time > 0 else None
        }
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
        if response_times:
            metrics['response_time_stats'] = {
                'avg_ms': statistics.mean(response_times),
                'min_ms': min(response_times),
                'max_ms': max(response_times),
                'p95_ms': statistics.quantiles(response_times, n=20)[18] if len(response_times) > 1 else response_times[0]
            }
        
        return metrics

# ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Circuit Breaker Ñ ÑÐµÑ‚ÐµÐ²Ñ‹Ð¼Ð¸ Ð²Ñ‹Ð·Ð¾Ð²Ð°Ð¼Ð¸
class ResilientAPIClient:
    def __init__(self):
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Circuit Breakers Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
        self.circuit_breakers = {
            'user_service': NetworkCircuitBreaker(
                'user_service',
                CircuitBreakerConfig(
                    failure_threshold=3,
                    recovery_timeout=30.0,
                    timeout=10.0
                )
            ),
            'order_service': NetworkCircuitBreaker(
                'order_service', 
                CircuitBreakerConfig(
                    failure_threshold=5,
                    recovery_timeout=60.0,
                    timeout=15.0
                )
            ),
            'payment_service': NetworkCircuitBreaker(
                'payment_service',
                CircuitBreakerConfig(
                    failure_threshold=2,  # Ð‘Ð¾Ð»ÐµÐµ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð´Ð»Ñ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ ÑÐµÑ€Ð²Ð¸ÑÐ°
                    recovery_timeout=120.0,
                    timeout=20.0
                )
            )
        }
        
        # HTTP ÐºÐ»Ð¸ÐµÐ½Ñ‚
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_user(self, user_id: int) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ñ‡ÐµÑ€ÐµÐ· Circuit Breaker"""
        
        async def api_call():
            url = f'https://jsonplaceholder.typicode.com/users/{user_id}'
            async with self.session.get(url) as response:
                if response.status >= 500:
                    raise aiohttp.ClientError(f"Server error: {response.status}")
                return await response.json()
        
        cb = self.circuit_breakers['user_service']
        return await cb(api_call)
    
    async def create_order(self, order_data: Dict) -> Dict:
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð·Ð°ÐºÐ°Ð·Ð° Ñ‡ÐµÑ€ÐµÐ· Circuit Breaker"""
        
        async def api_call():
            url = 'https://jsonplaceholder.typicode.com/posts'
            async with self.session.post(url, json=order_data) as response:
                if
            